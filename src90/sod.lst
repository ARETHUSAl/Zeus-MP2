IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- sod.f90 07/08/15 15:48:47
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** sod   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-534 (I) Loop (loop index 1) at sod.f90 <line 79> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 2) at sod.f90 <line 80> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns2.[1ll + ($$CIVC * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns2.[2ll + ($$CIVC * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns3.[1ll + ($$CIVC * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns1.[2ll + ($$CIVC * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns1.[1ll + ($$CIVC * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns3.[2ll + ($$CIVC * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-536 (I) Loop (loop index 3) at sod.f90 <line 83> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 83> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at sod.f90 <line 83> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at sod.f90 <line 83> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at sod.f90 <line 83> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 83> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at sod.f90 <line 83> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at sod.f90 <line 83> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at sod.f90 <line 84> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 84> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at sod.f90 <line 84> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at sod.f90 <line 84> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at sod.f90 <line 82> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 82> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at sod.f90 <line 82> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at sod.f90 <line 82> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at sod.f90 <line 82> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 82> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at sod.f90 <line 82> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at sod.f90 <line 82> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(1ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at sod.f90 <line 84> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at sod.f90 <line 84> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at sod.f90 <line 84> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at sod.f90 <line 84> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(2ll + ($$CIVC * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
1586-538 (I) Loop (loop index 4) at sod.f90 <line 158> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 4) at sod.f90 <line 158> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 5) at sod.f90 <line 157> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 6) at sod.f90 <line 156> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 9) at sod.f90 <line 156> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 9) at sod.f90 <line 156> was not SIMD vectorized because it contains unsupported loop structure.
1586-534 (I) Loop (loop index 10) at sod.f90 <line 126> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 11) at sod.f90 <line 127> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 12) at sod.f90 <line 128> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 12) at sod.f90 <line 128> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 13) at sod.f90 <line 141> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 14) at sod.f90 <line 142> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 15) at sod.f90 <line 143> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 15) at sod.f90 <line 143> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 16) at sod.f90 <line 156> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 17) at sod.f90 <line 157> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 18) at sod.f90 <line 158> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 18) at sod.f90 <line 158> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 19) at sod.f90 <line 157> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 20) at sod.f90 <line 158> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 20) at sod.f90 <line 158> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 21) at sod.f90 <line 141> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 21) at sod.f90 <line 141> was not SIMD vectorized because it contains unsupported loop structure.
1586-534 (I) Loop (loop index 24) at sod.f90 <line 141> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 25) at sod.f90 <line 142> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 26) at sod.f90 <line 143> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 26) at sod.f90 <line 143> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 27) at sod.f90 <line 142> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 28) at sod.f90 <line 143> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 28) at sod.f90 <line 143> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 29) at sod.f90 <line 126> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 29) at sod.f90 <line 126> was not SIMD vectorized because it contains unsupported loop structure.
1586-534 (I) Loop (loop index 32) at sod.f90 <line 126> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 33) at sod.f90 <line 127> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 34) at sod.f90 <line 128> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 34) at sod.f90 <line 128> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 35) at sod.f90 <line 127> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 36) at sod.f90 <line 128> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 36) at sod.f90 <line 128> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 40) at sod.f90 <line 79> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 41) at sod.f90 <line 80> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 42) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns3.[$$CIV2 + 1ll][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 42) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns1.[$$CIV2 + 1ll][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 42) at sod.f90 <line 81> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns2.[$$CIV2 + 1ll][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-536 (I) Loop (loop index 42) at sod.f90 <line 84> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 42) at sod.f90 <line 84> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 42) at sod.f90 <line 84> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 42) at sod.f90 <line 84> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 42) at sod.f90 <line 82> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 42) at sod.f90 <line 82> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 42) at sod.f90 <line 82> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 42) at sod.f90 <line 82> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 42) at sod.f90 <line 83> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 42) at sod.f90 <line 83> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 42) at sod.f90 <line 83> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 42) at sod.f90 <line 83> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"11">. Total number of the innermost loops SIMD vectorized <"0">.


    11|         SUBROUTINE sod ()
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 8))
    42|           x10 =  5.0000000000000000E-001
    43|           x20 =  5.0000000000000000E-001
    44|           x30 =  5.0000000000000000E-001
    45|           d0 =  1.0000000000000000E+000
    46|           p0 =  1.0000000000000000E+000
    47|           d1 =  1.2500000000000000E-001
    48|           p1 =  1.0000000000000000E-001
    50|           IF ((myid == 0)) THEN
    11|             |pgen%nlitems%type.off32 = 4
                    |pgen%nlitems%kind.off40 = 
                    |pgen%nlitems%size.off48 = 
                    |pgen%nlitems%name_addr.off56 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 4
                    |pgen%nlitems%name_len.off64 = 3
                    |pgen%nlitems%item_addr.off72 = loc(x10)
                    |pgen%nlitems%type.off80 = 4
                    |pgen%nlitems%kind.off88 = 
                    |pgen%nlitems%size.off96 = 
                    |pgen%nlitems%name_addr.off104 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 8
                    |pgen%nlitems%name_len.off112 = 3
                    |pgen%nlitems%item_addr.off120 = loc(x20)
                    |pgen%nlitems%type.off128 = 4
                    |pgen%nlitems%kind.off136 = 
                    |pgen%nlitems%size.off144 = 
                    |pgen%nlitems%name_addr.off152 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 12
                    |pgen%nlitems%name_len.off160 = 2
                    |pgen%nlitems%item_addr.off168 = loc(p0)
                    |pgen%nlitems%type.off176 = 4
                    |pgen%nlitems%kind.off184 = 
                    |pgen%nlitems%size.off192 = 
                    |pgen%nlitems%name_addr.off200 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 14
                    |pgen%nlitems%name_len.off208 = 2
                    |pgen%nlitems%item_addr.off216 = loc(d0)
                    |pgen%nlitems%type.off224 = 4
                    |pgen%nlitems%kind.off232 = 
                    |pgen%nlitems%size.off240 = 
                    |pgen%nlitems%name_addr.off248 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 16
                    |pgen%nlitems%name_len.off256 = 2
                    |pgen%nlitems%item_addr.off264 = loc(p1)
                    |pgen%nlitems%type.off272 = 4
                    |pgen%nlitems%kind.off280 = 
                    |pgen%nlitems%size.off288 = 
                    |pgen%nlitems%name_addr.off296 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 18
                    |pgen%nlitems%name_len.off304 = 2
                    |pgen%nlitems%item_addr.off312 = loc(d1)
                    |pgen%nlitems%type.off320 = 0
                    |pgen%nlitems%kind.off328 = 
                    |pgen%nlitems%size.off336 = 
                    |pgen%nlitems%name_addr.off344 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 20
                    |pgen%nlitems%name_len.off352 = 7
                    |pgen%nlitems%item_addr.off360 = loc(idirect)
                    |pgen%version = 129
                    |pgen%name_addr = "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90"
                    |pgen%name_len = 4
                    |pgen%num_of_items = 8
                    |pgen%nlitems%type.off368 = 4
                    |pgen%nlitems%kind.off376 = 
                    |pgen%nlitems%size.off384 = 
                    |pgen%nlitems%name_addr.off392 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 28
                    |pgen%nlitems%name_len.off400 = 3
                    |pgen%nlitems%item_addr.off408 = loc(x30)
    51|             |pgen%name_flags = 0
                    #9 = _xlfBeginIO(1,2,#8,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#9))
    52|             |pgen%name_flags = 0
                    #11 = _xlfBeginIO(2,258,#10,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#11))
    53|             buf_in[].off1744 = x10
    54|             buf_in[].off1752 = x20
    55|             buf_in[].off1760 = d0
    56|             buf_in[].off1768 = p0
    57|             buf_in[].off1776 = d1
    58|             buf_in[].off1784 = p1
    59|             ibuf_in[].off144 = idirect
    60|           ENDIF
    61|           T_2 = 6
                  T_3 = 1275070495
                  T_4 = 0
                  CALL mpi_bcast(buf_in,T_2,T_3,T_4,comm3d,ierr)
    63|           T_5 = 1
                  T_6 = 1275069467
                  T_7 = 0
                  CALL mpi_bcast(ibuf_in,T_5,T_6,T_7,comm3d,ierr)
    65|           IF ((myid <> 0)) THEN
    66|             x10 = buf_in[].off1744
    67|             x20 = buf_in[].off1752
    68|             d0 = buf_in[].off1760
    69|             p0 = buf_in[].off1768
    70|             d1 = buf_in[].off1776
    71|             p1 = buf_in[].off1784
    72|             idirect = ibuf_in[].off144
    73|           ENDIF
    77|           e0 = p0 / gamm1
    78|           e1 = p1 / gamm1
    79|           IF ((MOD(int(kn), 2) > 0  .AND.  int(kn) > 0)) THEN
                    $$CIV2 = 0
       Id=40        DO $$CIV2 = $$CIV2, MOD(int(kn), int(2))-1
    80|               IF ((int(jn) > 0)) THEN
                        $$CIV1 = 0
       Id=41            DO $$CIV1 = $$CIV1, int(int(jn))-1
    81|                   IF ((int(in) > 0)) THEN
                            $$CIV0 = 0
       Id=42                DO $$CIV0 = $$CIV0, int(int(in))-1
    82|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
    83|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
    84|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
    85|                     ENDDO
                          ENDIF
    86|                 ENDDO
                      ENDIF
    87|             ENDDO
                  ENDIF
    79|           IF ((int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 2))) THEN
                    $$CIVC = int(0)
       Id=1         DO $$CIVC = $$CIVC, int((((int(kn) - MOD(int(kn), 2)) - 1)&
                &        / 2 + 1))-1
    80|               IF ((int(jn) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int(int(jn))-1
    81|                   IF ((int(in) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int(int(in))-1
    82|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    83|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    84|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    82|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    83|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    84|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    85|                     ENDDO
                          ENDIF
    86|                 ENDDO
                      ENDIF
    87|             ENDDO
                  ENDIF
   125|           IF ((idirect == 1)) THEN
   126|             IF ((MOD(int(kn), 4) > 0  .AND.  int(kn) > 0)) THEN
                      $$CIV5 = 0
       Id=32          DO $$CIV5 = $$CIV5, MOD(int(kn), int(4))-1
   127|                 IF ((int(jn) > 0)) THEN
                          $$CIV4 = 0
       Id=33              DO $$CIV4 = $$CIV4, int(int(jn))-1
   128|                     IF ((int(in) > 0)) THEN
                              $$CIV3 = 0
       Id=34                  DO $$CIV3 = $$CIV3, int(int(in))-1
   129|                         IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                           d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = e0
   131|                           d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = d0
   132|                         ELSE
   133|                           d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = e1
   134|                           d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = d1
   135|                         ENDIF
   136|                       ENDDO
                            ENDIF
   137|                   ENDDO
                        ENDIF
   138|               ENDDO
                    ENDIF
   126|             IF ((int(kn) > MOD(int(kn), 4)  .AND.  int(kn) > 0)) THEN
                      $$CIV5 = MOD(int(kn), int(4))
       Id=29          DO $$CIV5 = $$CIV5, int(int(kn))
   127|                 IF ((MOD(int(jn), 2) > 0  .AND.  int(jn) > 0)) THEN
                          $$CIV4 = 0
       Id=35              DO $$CIV4 = $$CIV4, MOD(int(jn), int(2))-1
   128|                     IF ((int(in) > 0)) THEN
                              $$CIV3 = 0
       Id=36                  DO $$CIV3 = $$CIV3, int(int(in))-1
   129|                         IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                           d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = e0
   131|                           d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = d0
   132|                         ELSE
   133|                           d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = e1
   134|                           d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = d1
   135|                         ENDIF
   136|                       ENDDO
                            ENDIF
   137|                   ENDDO
                        ENDIF
   138|               ENDDO
                    ENDIF
   126|             IF (.NOT.(int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 4))) &
                &     GOTO lab_105
                    $$CIVE = int(0)
       Id=10        DO $$CIVE = $$CIVE, int((((int(kn) - MOD(int(kn), 4)) - 1)&
                &        / 4 + 1))-1
   127|               IF ((int(jn) > 0  .AND.  int(jn) > MOD(int(jn), 2))) THEN
                        $$CIVD = int(0)
       Id=11            DO $$CIVD = $$CIVD, int((((int(jn) - MOD(int(jn), 2)) &
                &           - 1) / 2 + 1))-1
   128|                   IF ((int(in) > 0)) THEN
                            $$CIV3 = 0
       Id=12                DO $$CIV3 = $$CIV3, int(int(in))-1
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   136|                     ENDDO
                          ENDIF
   137|                 ENDDO
                      ENDIF
   138|             ENDDO
                    lab_105
   139|             lab_42
   140|             IF ((idirect == 2)) THEN
   141|               IF ((MOD(int(kn), 4) > 0  .AND.  int(kn) > 0)) THEN
                        $$CIV8 = 0
       Id=24            DO $$CIV8 = $$CIV8, MOD(int(kn), int(4))-1
   142|                   IF ((int(jn) > 0)) THEN
                            $$CIV7 = 0
       Id=25                DO $$CIV7 = $$CIV7, int(int(jn))-1
   143|                       IF ((int(in) > 0)) THEN
                                $$CIV6 = 0
       Id=26                    DO $$CIV6 = $$CIV6, int(int(in))-1
   144|                           IF ((d-x2a%addr%x2a($$CIV7 + 1) <= x20)) THEN
   145|                             d-e%addr%e($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = e0
   146|                             d-d%addr%d($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = d0
   147|                           ELSE
   148|                             d-e%addr%e($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = e1
   149|                             d-d%addr%d($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = d1
   150|                           ENDIF
   151|                         ENDDO
                              ENDIF
   152|                     ENDDO
                          ENDIF
   153|                 ENDDO
                      ENDIF
   141|               IF ((int(kn) > MOD(int(kn), 4)  .AND.  int(kn) > 0)) THEN
                        $$CIV8 = MOD(int(kn), int(4))
       Id=21            DO $$CIV8 = $$CIV8, int(int(kn))
   142|                   IF ((MOD(int(jn), 2) > 0  .AND.  int(jn) > 0)) THEN
                            $$CIV7 = 0
       Id=27                DO $$CIV7 = $$CIV7, MOD(int(jn), int(2))-1
   143|                       IF ((int(in) > 0)) THEN
                                $$CIV6 = 0
       Id=28                    DO $$CIV6 = $$CIV6, int(int(in))-1
   144|                           IF ((d-x2a%addr%x2a($$CIV7 + 1) <= x20)) THEN
   145|                             d-e%addr%e($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = e0
   146|                             d-d%addr%d($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = d0
   147|                           ELSE
   148|                             d-e%addr%e($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = e1
   149|                             d-d%addr%d($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = d1
   150|                           ENDIF
   151|                         ENDDO
                              ENDIF
   152|                     ENDDO
                          ENDIF
   153|                 ENDDO
                      ENDIF
   141|               IF (.NOT.(int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 4))) &
                &       GOTO lab_111
                      $$CIV10 = int(0)
       Id=13          DO $$CIV10 = $$CIV10, int((((int(kn) - MOD(int(kn), 4)) &
                &         - 1) / 4 + 1))-1
   142|                 IF ((int(jn) > 0  .AND.  int(jn) > MOD(int(jn), 2))) &
                &         THEN
                          $$CIVF = int(0)
       Id=14              DO $$CIVF = $$CIVF, int((((int(jn) - MOD(int(jn), 2)&
                &             ) - 1) / 2 + 1))-1
   143|                     IF ((int(in) > 0)) THEN
                              $$CIV6 = 0
       Id=15                  DO $$CIV6 = $$CIV6, int(int(in))-1
   144|                         IF ((d-x2a%addr%x2a(1 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(2 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(1 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(2 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(1 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(2 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(1 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(2 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   151|                       ENDDO
                            ENDIF
   152|                   ENDDO
                        ENDIF
   153|               ENDDO
                      lab_111
   154|               lab_57
   155|               IF ((idirect == 3)) THEN
   156|                 IF ((MOD(int(kn), 4) > 0  .AND.  int(kn) > 0)) THEN
                          $$CIVB = 0
       Id=6               DO $$CIVB = $$CIVB, MOD(int(kn), int(4))-1
   157|                     IF ((int(jn) > 0)) THEN
                              $$CIVA = 0
       Id=5                   DO $$CIVA = $$CIVA, int(int(jn))-1
   158|                         IF ((int(in) > 0)) THEN
                                  $$CIV9 = 0
       Id=4                       DO $$CIV9 = $$CIV9, int(int(in))-1
   159|                             IF ((d-x3a%addr%x3a($$CIVB + 1) <= x30)) &
                &                     THEN
   160|                               d-e%addr%e($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = e0
   161|                               d-d%addr%d($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = d0
   162|                             ELSE
   163|                               d-e%addr%e($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = e1
   164|                               d-d%addr%d($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = d1
   165|                             ENDIF
   166|                           ENDDO
                                ENDIF
   167|                       ENDDO
                            ENDIF
   168|                   ENDDO
                        ENDIF
   156|                 IF ((int(kn) > MOD(int(kn), 4)  .AND.  int(kn) > 0)) &
                &         THEN
                          $$CIVB = MOD(int(kn), int(4))
       Id=9               DO $$CIVB = $$CIVB, int(int(kn))
   157|                     IF ((MOD(int(jn), 2) > 0  .AND.  int(jn) > 0)) THEN
                              $$CIVA = 0
       Id=19                  DO $$CIVA = $$CIVA, MOD(int(jn), int(2))-1
   158|                         IF ((int(in) > 0)) THEN
                                  $$CIV9 = 0
       Id=20                      DO $$CIV9 = $$CIV9, int(int(in))-1
   159|                             IF ((d-x3a%addr%x3a($$CIVB + 1) <= x30)) &
                &                     THEN
   160|                               d-e%addr%e($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = e0
   161|                               d-d%addr%d($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = d0
   162|                             ELSE
   163|                               d-e%addr%e($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = e1
   164|                               d-d%addr%d($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = d1
   165|                             ENDIF
   166|                           ENDDO
                                ENDIF
   167|                       ENDDO
                            ENDIF
   168|                   ENDDO
                        ENDIF
   156|                 IF (.NOT.(int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 4))&
                &         ) GOTO lab_117
                        $$CIV12 = int(0)
       Id=16            DO $$CIV12 = $$CIV12, int((((int(kn) - MOD(int(kn), 4)&
                &           ) - 1) / 4 + 1))-1
   157|                   IF ((int(jn) > 0  .AND.  int(jn) > MOD(int(jn), 2))) &
                &           THEN
                            $$CIV11 = int(0)
       Id=17                DO $$CIV11 = $$CIV11, int((((int(jn) - MOD(int(jn)&
                &               , 2)) - 1) / 2 + 1))-1
   158|                       IF ((int(in) > 0)) THEN
                                $$CIV9 = 0
       Id=18                    DO $$CIV9 = $$CIV9, int(int(in))-1
   159|                           IF ((d-x3a%addr%x3a(1 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(1 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(2 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(2 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(3 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(3 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(4 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(4 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   166|                         ENDDO
                              ENDIF
   167|                     ENDDO
                          ENDIF
   168|                 ENDDO
                        lab_117
   169|                 lab_72
   172|                 RETURN
                      END SUBROUTINE sod


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0            79            40    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            80            41    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            82                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            82                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            82                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            82                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v1%addr  
                                          + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV2 + 
                                          1ll) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
         0            83                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            83                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v2%addr  
                                          + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV2 + 
                                          1ll) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
         0            84                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            84                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v3%addr  
                                          + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV2 + 
                                          1ll) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
         0            79             1    Outer loop has been unrolled 2 time(s).
         0            79             1    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            80             2    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            82                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(1ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            82                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(1ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            82                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            82                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v1%addr  
                                          + d-v1%rvo + (d-v1%bounds%mult[].off464)*(1ll + 
                                          ($$CIVC * 2ll + (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
         0            83                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(1ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(1ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            83                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v2%addr  
                                          + d-v2%rvo + (d-v2%bounds%mult[].off568)*(1ll + 
                                          ($$CIVC * 2ll + (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
         0            84                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(1ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(1ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            84                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v3%addr  
                                          + d-v3%rvo + (d-v3%bounds%mult[].off672)*(1ll + 
                                          ($$CIVC * 2ll + (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
         0            82                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(2ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            82                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(2ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            82                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            82                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v1%addr  
                                          + d-v1%rvo + (d-v1%bounds%mult[].off464)*(2ll + 
                                          ($$CIVC * 2ll + (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
         0            83                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(2ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(2ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            83                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v2%addr  
                                          + d-v2%rvo + (d-v2%bounds%mult[].off568)*(2ll + 
                                          ($$CIVC * 2ll + (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
         0            84                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(2ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(2ll + ($$CIVC * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0            84                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v3%addr  
                                          + d-v3%rvo + (d-v3%bounds%mult[].off672)*(2ll + 
                                          ($$CIVC * 2ll + (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
         0           126            32    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           127            33    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           128            34    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           128            34    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           126            29    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           126            29    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           127            35    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           128            36    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           128            36    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           126            10    Outer loop has been unrolled 4 time(s).
         0           126            10    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           127            11    Outer loop has been unrolled 2 time(s).
         0           127            11    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           128            12    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           128            12    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           141            24    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           142            25    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           143            26    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           143            26    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           141            21    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           141            21    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           142            27    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           143            28    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           143            28    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           141            13    Outer loop has been unrolled 4 time(s).
         0           141            13    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           142            14    Outer loop has been unrolled 2 time(s).
         0           142            14    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           143            15    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           143            15    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           156             6    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           157             5    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           158             4    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           158             4    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           156             9    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           156             9    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           157            19    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           158            20    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           158            20    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           156            16    Outer loop has been unrolled 4 time(s).
         0           156            16    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           157            17    Outer loop has been unrolled 2 time(s).
         0           157            17    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           158            18    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           158            18    Loop was not SIMD vectorized because it contains 
                                          control flow.


    11|         SUBROUTINE sod ()
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 8)
    42|           x10 =  5.0000000000000000E-001
    43|           x20 =  5.0000000000000000E-001
    44|           x30 =  5.0000000000000000E-001
    45|           d0 =  1.0000000000000000E+000
    46|           p0 =  1.0000000000000000E+000
    47|           d1 =  1.2500000000000000E-001
    48|           p1 =  1.0000000000000000E-001
    50|           IF ((myid == 0)) THEN
    11|             |pgen%nlitems%type.off32 = 4
                    |pgen%nlitems%kind.off40 = 
                    |pgen%nlitems%size.off48 = 
                    |pgen%nlitems%name_addr.off56 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 4
                    |pgen%nlitems%name_len.off64 = 3
                    |pgen%nlitems%item_addr.off72 = loc(x10)
                    |pgen%nlitems%type.off80 = 4
                    |pgen%nlitems%kind.off88 = 
                    |pgen%nlitems%size.off96 = 
                    |pgen%nlitems%name_addr.off104 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 8
                    |pgen%nlitems%name_len.off112 = 3
                    |pgen%nlitems%item_addr.off120 = loc(x20)
                    |pgen%nlitems%type.off128 = 4
                    |pgen%nlitems%kind.off136 = 
                    |pgen%nlitems%size.off144 = 
                    |pgen%nlitems%name_addr.off152 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 12
                    |pgen%nlitems%name_len.off160 = 2
                    |pgen%nlitems%item_addr.off168 = loc(p0)
                    |pgen%nlitems%type.off176 = 4
                    |pgen%nlitems%kind.off184 = 
                    |pgen%nlitems%size.off192 = 
                    |pgen%nlitems%name_addr.off200 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 14
                    |pgen%nlitems%name_len.off208 = 2
                    |pgen%nlitems%item_addr.off216 = loc(d0)
                    |pgen%nlitems%type.off224 = 4
                    |pgen%nlitems%kind.off232 = 
                    |pgen%nlitems%size.off240 = 
                    |pgen%nlitems%name_addr.off248 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 16
                    |pgen%nlitems%name_len.off256 = 2
                    |pgen%nlitems%item_addr.off264 = loc(p1)
                    |pgen%nlitems%type.off272 = 4
                    |pgen%nlitems%kind.off280 = 
                    |pgen%nlitems%size.off288 = 
                    |pgen%nlitems%name_addr.off296 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 18
                    |pgen%nlitems%name_len.off304 = 2
                    |pgen%nlitems%item_addr.off312 = loc(d1)
                    |pgen%nlitems%type.off320 = 0
                    |pgen%nlitems%kind.off328 = 
                    |pgen%nlitems%size.off336 = 
                    |pgen%nlitems%name_addr.off344 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 20
                    |pgen%nlitems%name_len.off352 = 7
                    |pgen%nlitems%item_addr.off360 = loc(idirect)
                    |pgen%version = 129
                    |pgen%name_addr = "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90"
                    |pgen%name_len = 4
                    |pgen%num_of_items = 8
                    |pgen%nlitems%type.off368 = 4
                    |pgen%nlitems%kind.off376 = 
                    |pgen%nlitems%size.off384 = 
                    |pgen%nlitems%name_addr.off392 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Isod.f90" + 28
                    |pgen%nlitems%name_len.off400 = 3
                    |pgen%nlitems%item_addr.off408 = loc(x30)
    51|             |pgen%name_flags = 0
                    #9 = _xlfBeginIO(1,2,#8,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#9))
    52|             |pgen%name_flags = 0
                    #11 = _xlfBeginIO(2,258,#10,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#11))
    53|             buf_in[].off1744 = x10
    54|             buf_in[].off1752 = x20
    55|             buf_in[].off1760 = d0
    56|             buf_in[].off1768 = p0
    57|             buf_in[].off1776 = d1
    58|             buf_in[].off1784 = p1
    59|             ibuf_in[].off144 = idirect
    60|           ENDIF
    61|           T_2 = 6
                  T_3 = 1275070495
                  T_4 = 0
                  CALL mpi_bcast(buf_in,T_2,T_3,T_4,comm3d,ierr)
    63|           T_5 = 1
                  T_6 = 1275069467
                  T_7 = 0
                  CALL mpi_bcast(ibuf_in,T_5,T_6,T_7,comm3d,ierr)
    65|           IF ((myid <> 0)) THEN
    66|             x10 = buf_in[].off1744
    67|             x20 = buf_in[].off1752
    68|             d0 = buf_in[].off1760
    69|             p0 = buf_in[].off1768
    70|             d1 = buf_in[].off1776
    71|             p1 = buf_in[].off1784
    72|             idirect = ibuf_in[].off144
    73|           ENDIF
    77|           e0 = p0 / gamm1
    78|           e1 = p1 / gamm1
    79|           IF ((MOD(int(kn), 2) > 0  .AND.  int(kn) > 0)) THEN
                    $$CIV2 = 0
       Id=40        DO $$CIV2 = $$CIV2, MOD(int(kn), int(2))-1
    80|               IF ((int(jn) > 0)) THEN
                        $$CIV1 = 0
       Id=41            DO $$CIV1 = $$CIV1, int(int(jn))-1
    81|                   IF ((int(in) > 0)) THEN
                            $$CIV0 = 0
       Id=42                DO $$CIV0 = $$CIV0, int(int(in))-1
    82|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
    83|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
    84|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
    85|                     ENDDO
                          ENDIF
    86|                 ENDDO
                      ENDIF
    87|             ENDDO
                  ENDIF
    79|           IF ((int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 2))) THEN
                    $$CIVC = int(0)
       Id=1         DO $$CIVC = $$CIVC, int((((int(kn) - MOD(int(kn), 2)) - 1)&
                &        / 2 + 1))-1
    80|               IF ((int(jn) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int(int(jn))-1
    81|                   IF ((int(in) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int(int(in))-1
    82|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    83|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    84|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    82|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    83|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    84|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIVC * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
    85|                     ENDDO
                          ENDIF
    86|                 ENDDO
                      ENDIF
    87|             ENDDO
                  ENDIF
   125|           IF ((idirect == 1)) THEN
   126|             IF ((MOD(int(kn), 4) > 0  .AND.  int(kn) > 0)) THEN
                      $$CIV5 = 0
       Id=32          DO $$CIV5 = $$CIV5, MOD(int(kn), int(4))-1
   127|                 IF ((int(jn) > 0)) THEN
                          $$CIV4 = 0
       Id=33              DO $$CIV4 = $$CIV4, int(int(jn))-1
   128|                     IF ((int(in) > 0)) THEN
                              $$CIV3 = 0
       Id=34                  DO $$CIV3 = $$CIV3, int(int(in))-1
   129|                         IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                           d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = e0
   131|                           d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = d0
   132|                         ELSE
   133|                           d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = e1
   134|                           d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = d1
   135|                         ENDIF
   136|                       ENDDO
                            ENDIF
   137|                   ENDDO
                        ENDIF
   138|               ENDDO
                    ENDIF
   126|             $$csx0 = int(kn) > MOD(int(kn), 4)  .AND.  int(kn) > 0
                    IF ($$csx0) THEN
                      $$CIV5 = MOD(int(kn), int(4))
       Id=29          DO $$CIV5 = $$CIV5, int(int(kn))
   127|                 IF ((MOD(int(jn), 2) > 0  .AND.  int(jn) > 0)) THEN
                          $$CIV4 = 0
       Id=35              DO $$CIV4 = $$CIV4, MOD(int(jn), int(2))-1
   128|                     IF ((int(in) > 0)) THEN
                              $$CIV3 = 0
       Id=36                  DO $$CIV3 = $$CIV3, int(int(in))-1
   129|                         IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                           d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = e0
   131|                           d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = d0
   132|                         ELSE
   133|                           d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = e1
   134|                           d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) &
                &                   = d1
   135|                         ENDIF
   136|                       ENDDO
                            ENDIF
   137|                   ENDDO
                        ENDIF
   138|               ENDDO
                    ENDIF
   126|             IF (.NOT.$$csx0) GOTO lab_105
                    $$CIVE = int(0)
       Id=10        DO $$CIVE = $$CIVE, int((((int(kn) - MOD(int(kn), 4)) - 1)&
                &        / 4 + 1))-1
   127|               IF ((int(jn) > 0  .AND.  int(jn) > MOD(int(jn), 2))) THEN
                        $$CIVD = int(0)
       Id=11            DO $$CIVD = $$CIVD, int((((int(jn) - MOD(int(jn), 2)) &
                &           - 1) / 2 + 1))-1
   128|                   IF ((int(in) > 0)) THEN
                            $$CIV3 = 0
       Id=12                DO $$CIV3 = $$CIV3, int(int(in))-1
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),1 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),2 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),3 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,1 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   129|                       IF ((d-x1a%addr%x1a($$CIV3 + 1) <= x10)) THEN
   130|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e0
   131|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d0
   132|                       ELSE
   133|                         d-e%addr%e($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 e1
   134|                         d-d%addr%d($$CIV3 + 1,2 + ($$CIVD * 2 + MOD(int(&
                &                 jn), 2)),4 + ($$CIVE * 4 + MOD(int(kn), 4))) = &
                &                 d1
   135|                       ENDIF
   136|                     ENDDO
                          ENDIF
   137|                 ENDDO
                      ENDIF
   138|             ENDDO
                    lab_105
   139|             lab_42
   140|             IF ((idirect == 2)) THEN
   141|               IF ((MOD(int(kn), 4) > 0  .AND.  int(kn) > 0)) THEN
                        $$CIV8 = 0
       Id=24            DO $$CIV8 = $$CIV8, MOD(int(kn), int(4))-1
   142|                   IF ((int(jn) > 0)) THEN
                            $$CIV7 = 0
       Id=25                DO $$CIV7 = $$CIV7, int(int(jn))-1
   143|                       IF ((int(in) > 0)) THEN
                                $$CIV6 = 0
       Id=26                    DO $$CIV6 = $$CIV6, int(int(in))-1
   144|                           IF ((d-x2a%addr%x2a($$CIV7 + 1) <= x20)) THEN
   145|                             d-e%addr%e($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = e0
   146|                             d-d%addr%d($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = d0
   147|                           ELSE
   148|                             d-e%addr%e($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = e1
   149|                             d-d%addr%d($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = d1
   150|                           ENDIF
   151|                         ENDDO
                              ENDIF
   152|                     ENDDO
                          ENDIF
   153|                 ENDDO
                      ENDIF
   141|               $$csx1 = int(kn) > MOD(int(kn), 4)  .AND.  int(kn) > 0
                      IF ($$csx1) THEN
                        $$CIV8 = MOD(int(kn), int(4))
       Id=21            DO $$CIV8 = $$CIV8, int(int(kn))
   142|                   IF ((MOD(int(jn), 2) > 0  .AND.  int(jn) > 0)) THEN
                            $$CIV7 = 0
       Id=27                DO $$CIV7 = $$CIV7, MOD(int(jn), int(2))-1
   143|                       IF ((int(in) > 0)) THEN
                                $$CIV6 = 0
       Id=28                    DO $$CIV6 = $$CIV6, int(int(in))-1
   144|                           IF ((d-x2a%addr%x2a($$CIV7 + 1) <= x20)) THEN
   145|                             d-e%addr%e($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = e0
   146|                             d-d%addr%d($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = d0
   147|                           ELSE
   148|                             d-e%addr%e($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = e1
   149|                             d-d%addr%d($$CIV6 + 1,$$CIV7 + 1,$$CIV8 + 1)&
                &                      = d1
   150|                           ENDIF
   151|                         ENDDO
                              ENDIF
   152|                     ENDDO
                          ENDIF
   153|                 ENDDO
                      ENDIF
   141|               IF (.NOT.$$csx1) GOTO lab_111
                      $$CIV10 = int(0)
       Id=13          DO $$CIV10 = $$CIV10, int((((int(kn) - MOD(int(kn), 4)) &
                &         - 1) / 4 + 1))-1
   142|                 IF ((int(jn) > 0  .AND.  int(jn) > MOD(int(jn), 2))) &
                &         THEN
                          $$CIVF = int(0)
       Id=14              DO $$CIVF = $$CIVF, int((((int(jn) - MOD(int(jn), 2)&
                &             ) - 1) / 2 + 1))-1
   143|                     IF ((int(in) > 0)) THEN
                              $$CIV6 = 0
       Id=15                  DO $$CIV6 = $$CIV6, int(int(in))-1
   144|                         IF ((d-x2a%addr%x2a(1 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(2 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),1 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(1 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(2 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),2 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(1 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(2 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),3 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(1 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,1 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   144|                         IF ((d-x2a%addr%x2a(2 + ($$CIVF * 2 + MOD(int(&
                &                 jn), 2))) <= x20)) THEN
   145|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e0
   146|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d0
   147|                         ELSE
   148|                           d-e%addr%e($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = e1
   149|                           d-d%addr%d($$CIV6 + 1,2 + ($$CIVF * 2 + MOD(&
                &                   int(jn), 2)),4 + ($$CIV10 * 4 + MOD(int(kn), &
                &                   4))) = d1
   150|                         ENDIF
   151|                       ENDDO
                            ENDIF
   152|                   ENDDO
                        ENDIF
   153|               ENDDO
                      lab_111
   154|               lab_57
   155|               IF ((idirect == 3)) THEN
   156|                 IF ((MOD(int(kn), 4) > 0  .AND.  int(kn) > 0)) THEN
                          $$CIVB = 0
       Id=6               DO $$CIVB = $$CIVB, MOD(int(kn), int(4))-1
   157|                     IF ((int(jn) > 0)) THEN
                              $$CIVA = 0
       Id=5                   DO $$CIVA = $$CIVA, int(int(jn))-1
   158|                         IF ((int(in) > 0)) THEN
                                  $$CIV9 = 0
       Id=4                       DO $$CIV9 = $$CIV9, int(int(in))-1
   159|                             IF ((d-x3a%addr%x3a($$CIVB + 1) <= x30)) &
                &                     THEN
   160|                               d-e%addr%e($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = e0
   161|                               d-d%addr%d($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = d0
   162|                             ELSE
   163|                               d-e%addr%e($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = e1
   164|                               d-d%addr%d($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = d1
   165|                             ENDIF
   166|                           ENDDO
                                ENDIF
   167|                       ENDDO
                            ENDIF
   168|                   ENDDO
                        ENDIF
   156|                 $$csx2 = int(kn) > MOD(int(kn), 4)  .AND.  int(kn) > 0
                        IF ($$csx2) THEN
                          $$CIVB = MOD(int(kn), int(4))
       Id=9               DO $$CIVB = $$CIVB, int(int(kn))
   157|                     IF ((MOD(int(jn), 2) > 0  .AND.  int(jn) > 0)) THEN
                              $$CIVA = 0
       Id=19                  DO $$CIVA = $$CIVA, MOD(int(jn), int(2))-1
   158|                         IF ((int(in) > 0)) THEN
                                  $$CIV9 = 0
       Id=20                      DO $$CIV9 = $$CIV9, int(int(in))-1
   159|                             IF ((d-x3a%addr%x3a($$CIVB + 1) <= x30)) &
                &                     THEN
   160|                               d-e%addr%e($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = e0
   161|                               d-d%addr%d($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = d0
   162|                             ELSE
   163|                               d-e%addr%e($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = e1
   164|                               d-d%addr%d($$CIV9 + 1,$$CIVA + 1,$$CIVB + &
                &                       1) = d1
   165|                             ENDIF
   166|                           ENDDO
                                ENDIF
   167|                       ENDDO
                            ENDIF
   168|                   ENDDO
                        ENDIF
   156|                 IF (.NOT.$$csx2) GOTO lab_117
                        $$CIV12 = int(0)
       Id=16            DO $$CIV12 = $$CIV12, int((((int(kn) - MOD(int(kn), 4)&
                &           ) - 1) / 4 + 1))-1
   157|                   IF ((int(jn) > 0  .AND.  int(jn) > MOD(int(jn), 2))) &
                &           THEN
                            $$CIV11 = int(0)
       Id=17                DO $$CIV11 = $$CIV11, int((((int(jn) - MOD(int(jn)&
                &               , 2)) - 1) / 2 + 1))-1
   158|                       IF ((int(in) > 0)) THEN
                                $$CIV9 = 0
       Id=18                    DO $$CIV9 = $$CIV9, int(int(in))-1
   159|                           IF ((d-x3a%addr%x3a(1 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(1 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),1 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(2 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(2 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),2 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(3 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(3 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),3 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(4 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,1 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   159|                           IF ((d-x3a%addr%x3a(4 + ($$CIV12 * 4 + MOD(&
                &                   int(kn), 4))) <= x30)) THEN
   160|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e0
   161|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d0
   162|                           ELSE
   163|                             d-e%addr%e($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = e1
   164|                             d-d%addr%d($$CIV9 + 1,2 + ($$CIV11 * 2 + &
                &                     MOD(int(jn), 2)),4 + ($$CIV12 * 4 + MOD(int(&
                &                     kn), 4))) = d1
   165|                           ENDIF
   166|                         ENDDO
                              ENDIF
   167|                     ENDDO
                          ENDIF
   168|                 ENDDO
                        lab_117
   169|                 lab_72
   172|                 RETURN
                      END SUBROUTINE sod

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   suus ssss ssss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ss--  ---- ---- --ss ssss
 CCR's set/used:   ss-- ssss
     | 000000                           PDEF     sod
   11|                                  PROC      
    0| 000000 stfd     DBE1FFF8   1     STFL      #stack(gr1,-8)=fp31
    0| 000004 stfd     DBC1FFF0   1     STFL      #stack(gr1,-16)=fp30
    0| 000008 stfd     DBA1FFE8   1     STFL      #stack(gr1,-24)=fp29
    0| 00000C stfd     DB81FFE0   1     STFL      #stack(gr1,-32)=fp28
    0| 000010 stfd     DB61FFD8   1     STFL      #stack(gr1,-40)=fp27
    0| 000014 stfd     DB41FFD0   1     STFL      #stack(gr1,-48)=fp26
    0| 000018 std      FBE1FFC8   1     ST8       #stack(gr1,-56)=gr31
    0| 00001C std      FBC1FFC0   1     ST8       #stack(gr1,-64)=gr30
    0| 000020 std      FBA1FFB8   1     ST8       #stack(gr1,-72)=gr29
    0| 000024 std      FB81FFB0   1     ST8       #stack(gr1,-80)=gr28
    0| 000028 std      FB61FFA8   1     ST8       #stack(gr1,-88)=gr27
    0| 00002C std      FB41FFA0   1     ST8       #stack(gr1,-96)=gr26
    0| 000030 std      FB21FF98   1     ST8       #stack(gr1,-104)=gr25
    0| 000034 std      FB01FF90   1     ST8       #stack(gr1,-112)=gr24
    0| 000038 std      FAE1FF88   1     ST8       #stack(gr1,-120)=gr23
    0| 00003C std      FAC1FF80   1     ST8       #stack(gr1,-128)=gr22
    0| 000040 std      FAA1FF78   1     ST8       #stack(gr1,-136)=gr21
    0| 000044 std      FA81FF70   1     ST8       #stack(gr1,-144)=gr20
    0| 000048 std      FA61FF68   1     ST8       #stack(gr1,-152)=gr19
    0| 00004C std      FA41FF60   1     ST8       #stack(gr1,-160)=gr18
    0| 000050 std      FA21FF58   1     ST8       #stack(gr1,-168)=gr17
    0| 000054 std      FA01FF50   1     ST8       #stack(gr1,-176)=gr16
    0| 000058 std      F9E1FF48   1     ST8       #stack(gr1,-184)=gr15
    0| 00005C std      F9C1FF40   1     ST8       #stack(gr1,-192)=gr14
    0| 000060 mfspr    7C0802A6   1     LFLR      gr0=lr
    0| 000064 mfcr     7D800026   1     LFCR      gr12=cr4,4
    0| 000068 stw      91810008   1     ST4A      #stack(gr1,8)=gr12
    0| 00006C std      F8010010   1     ST8       #stack(gr1,16)=gr0
    0| 000070 stdu     F821FB41   1     ST8U      gr1,#stack(gr1,-1216)=gr1
    0| 000074 or       7C3F0B78   1     LR        gr31=gr1
   50| 000078 ld       EB620000   1     L8        gr27=.&&N&&mpipar(gr2,0)
   42| 00007C ld       EBC20000   1     L8        gr30=.+CONSTANT_AREA(gr2,0)
   42| 000080 addi     386001FF   1     LI        gr3=511
   45| 000084 addi     380003FF   1     LI        gr0=1023
   47| 000088 addi     38A000FF   1     LI        gr5=255
   42| 00008C rldicr   7863AA86   1     SLL8      gr3=gr3,53
   50| 000090 lwz      809B0004   1     L4Z       gr4=<s251:d4:l4>(gr27,4)
   42| 000094 std      F87F00A0   1     ST8       x10(gr31,160)=gr3
   43| 000098 std      F87F00A8   1     ST8       x20(gr31,168)=gr3
   44| 00009C std      F87F00B0   1     ST8       x30(gr31,176)=gr3
   48| 0000A0 lfd      CBFE0040   1     LFL       fp31=+CONSTANT_AREA(gr30,64)
   42| 0000A4 lfs      C3DE0030   1     LFS       fp30=+CONSTANT_AREA(gr30,48)
   45| 0000A8 lfs      C39E0034   1     LFS       fp28=+CONSTANT_AREA(gr30,52)
   45| 0000AC rldicr   7800A2C6   1     SLL8      gr0=gr0,52
   47| 0000B0 rldicr   78A3B246   1     SLL8      gr3=gr5,54
   45| 0000B4 std      F81F00B8   1     ST8       d0(gr31,184)=gr0
   46| 0000B8 std      F81F00C0   1     ST8       p0(gr31,192)=gr0
   47| 0000BC std      F87F00C8   1     ST8       d1(gr31,200)=gr3
   43| 0000C0 fmr      FFA0F090   1     LRFL      fp29=fp30
   48| 0000C4 stfd     DBFF00D0   1     STFL      p1(gr31,208)=fp31
   46| 0000C8 fmr      FF60E090   1     LRFL      fp27=fp28
   50| 0000CC cmpdi    2C240000   1     C8        cr0=gr4,0
   47| 0000D0 lfs      C35E0038   1     LFS       fp26=+CONSTANT_AREA(gr30,56)
   50| 0000D4 bc       408201D4   1     BF        CL.1,cr0,0x4/eq,taken=60%(60,40)
    0| 0000D8 addi     38600008   1     LI        gr3=8
    0| 0000DC addi     38000004   1     LI        gr0=4
    0| 0000E0 std      F87F0108   1     ST8       <a1:d264:l8>(gr31,264)=gr3
    0| 0000E4 std      F87F0110   1     ST8       <a1:d272:l8>(gr31,272)=gr3
    0| 0000E8 std      F87F0138   1     ST8       <a1:d312:l8>(gr31,312)=gr3
    0| 0000EC std      F87F0140   1     ST8       <a1:d320:l8>(gr31,320)=gr3
    0| 0000F0 std      F87F0168   1     ST8       <a1:d360:l8>(gr31,360)=gr3
    0| 0000F4 std      F87F0170   1     ST8       <a1:d368:l8>(gr31,368)=gr3
    0| 0000F8 std      F87F0198   1     ST8       <a1:d408:l8>(gr31,408)=gr3
    0| 0000FC std      F87F01A0   1     ST8       <a1:d416:l8>(gr31,416)=gr3
    0| 000100 std      F87F01C8   1     ST8       <a1:d456:l8>(gr31,456)=gr3
    0| 000104 std      F87F01D0   1     ST8       <a1:d464:l8>(gr31,464)=gr3
    0| 000108 std      F87F01F8   1     ST8       <a1:d504:l8>(gr31,504)=gr3
    0| 00010C std      F87F0200   1     ST8       <a1:d512:l8>(gr31,512)=gr3
    0| 000110 std      F87F00F8   1     ST8       <a1:d248:l8>(gr31,248)=gr3
    0| 000114 std      F87F0258   1     ST8       <a1:d600:l8>(gr31,600)=gr3
    0| 000118 std      F87F0260   1     ST8       <a1:d608:l8>(gr31,608)=gr3
    0| 00011C std      F81F0100   1     ST8       <a1:d256:l8>(gr31,256)=gr0
    0| 000120 std      F81F0130   1     ST8       <a1:d304:l8>(gr31,304)=gr0
    0| 000124 std      F81F0160   1     ST8       <a1:d352:l8>(gr31,352)=gr0
    0| 000128 std      F81F0190   1     ST8       <a1:d400:l8>(gr31,400)=gr0
    0| 00012C std      F81F01C0   1     ST8       <a1:d448:l8>(gr31,448)=gr0
    0| 000130 std      F81F01F0   1     ST8       <a1:d496:l8>(gr31,496)=gr0
    0| 000134 std      F81F0228   1     ST8       <a1:d552:l8>(gr31,552)=gr0
    0| 000138 std      F81F0230   1     ST8       <a1:d560:l8>(gr31,560)=gr0
    0| 00013C std      F81F00F0   1     ST8       <a1:d240:l8>(gr31,240)=gr0
    0| 000140 std      F81F0250   1     ST8       <a1:d592:l8>(gr31,592)=gr0
    0| 000144 addi     38600003   1     LI        gr3=3
    0| 000148 addi     381E000C   1     AI        gr0=gr30,12
    0| 00014C std      F87F0120   1     ST8       <a1:d288:l8>(gr31,288)=gr3
    0| 000150 std      F87F0150   1     ST8       <a1:d336:l8>(gr31,336)=gr3
    0| 000154 std      F87F0270   1     ST8       <a1:d624:l8>(gr31,624)=gr3
    0| 000158 std      F81F0118   1     ST8       <a1:d280:l8>(gr31,280)=gr0
    0| 00015C addi     387E0010   1     AI        gr3=gr30,16
    0| 000160 addi     381F00A0   1     AI        gr0=gr31,160
    0| 000164 std      F87F0148   1     ST8       <a1:d328:l8>(gr31,328)=gr3
    0| 000168 std      F81F0128   1     ST8       <a1:d296:l8>(gr31,296)=gr0
    0| 00016C addi     387E0014   1     AI        gr3=gr30,20
    0| 000170 addi     381F00A8   1     AI        gr0=gr31,168
    0| 000174 std      F87F0178   1     ST8       <a1:d376:l8>(gr31,376)=gr3
    0| 000178 std      F81F0158   1     ST8       <a1:d344:l8>(gr31,344)=gr0
    0| 00017C addi     38600002   1     LI        gr3=2
    0| 000180 addi     381F00C0   1     AI        gr0=gr31,192
    0| 000184 std      F87F0180   1     ST8       <a1:d384:l8>(gr31,384)=gr3
    0| 000188 std      F81F0188   1     ST8       <a1:d392:l8>(gr31,392)=gr0
    0| 00018C std      F87F01B0   1     ST8       <a1:d432:l8>(gr31,432)=gr3
    0| 000190 std      F87F01E0   1     ST8       <a1:d480:l8>(gr31,480)=gr3
    0| 000194 std      F87F0210   1     ST8       <a1:d528:l8>(gr31,528)=gr3
    0| 000198 addi     387E0016   1     AI        gr3=gr30,22
    0| 00019C addi     381F00C8   1     AI        gr0=gr31,200
    0| 0001A0 std      F87F01A8   1     ST8       <a1:d424:l8>(gr31,424)=gr3
    0| 0001A4 addi     387E0018   1     AI        gr3=gr30,24
    0| 0001A8 std      F81F0218   1     ST8       <a1:d536:l8>(gr31,536)=gr0
    0| 0001AC std      F87F01D8   1     ST8       <a1:d472:l8>(gr31,472)=gr3
    0| 0001B0 addi     387E001A   1     AI        gr3=gr30,26
    0| 0001B4 addi     381F00B8   1     AI        gr0=gr31,184
    0| 0001B8 std      F87F0208   1     ST8       <a1:d520:l8>(gr31,520)=gr3
    0| 0001BC addi     387E001C   1     AI        gr3=gr30,28
    0| 0001C0 addi     38800007   1     LI        gr4=7
    0| 0001C4 std      F87F0238   1     ST8       <a1:d568:l8>(gr31,568)=gr3
    0| 0001C8 std      F89F0240   1     ST8       <a1:d576:l8>(gr31,576)=gr4
    0| 0001CC addi     387F0080   1     AI        gr3=gr31,128
    0| 0001D0 std      F81F01B8   1     ST8       <a1:d440:l8>(gr31,440)=gr0
    0| 0001D4 std      F87F0248   1     ST8       <a1:d584:l8>(gr31,584)=gr3
    0| 0001D8 addi     381F00D0   1     AI        gr0=gr31,208
    0| 0001DC addi     38600081   1     LI        gr3=129
    0| 0001E0 addi     389E0008   1     AI        gr4=gr30,8
    0| 0001E4 std      F81F01E8   1     ST8       <a1:d488:l8>(gr31,488)=gr0
    0| 0001E8 stw      907F00E0   1     ST4Z      <a1:d224:l4>(gr31,224)=gr3
    0| 0001EC std      F89F00E8   1     ST8       <a1:d232:l8>(gr31,232)=gr4
    0| 0001F0 addi     38000000   1     LI        gr0=0
    0| 0001F4 addi     387E0024   1     AI        gr3=gr30,36
    0| 0001F8 addi     389F00B0   1     AI        gr4=gr31,176
    0| 0001FC std      F81F0220   1     ST8       <a1:d544:l8>(gr31,544)=gr0
    0| 000200 std      F87F0268   1     ST8       <a1:d616:l8>(gr31,616)=gr3
    0| 000204 std      F89F0278   1     ST8       <a1:d632:l8>(gr31,632)=gr4
   51| 000208 ld       EBA20000   1     L8        gr29=.$STATIC(gr2,0)
   51| 00020C stw      901F00E4   1     ST4Z      <a1:d228:l4>(gr31,228)=gr0
   51| 000210 ori      601C8000   1     OIL       gr28=gr0,0x8000
   51| 000214 addi     38600001   1     LI        gr3=1
   51| 000218 addi     38800002   1     LI        gr4=2
   51| 00021C or       7F86E378   1     LR        gr6=gr28
   51| 000220 or       7FA5EB78   1     LR        gr5=gr29
   51| 000224 addi     38E00000   1     LI        gr7=0
   51| 000228 addi     39000000   1     LI        gr8=0
   51| 00022C addi     393F00E0   1     AI        gr9=gr31,224
   51| 000230 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#8",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,|pgen,gr9,#def_xlfBeginIO11",_xlfBeginIO",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   51| 000234 ori      60000000   1
   51| 000238 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   51| 00023C ori      60000000   1
   52| 000240 addi     38BD0040   1     AI        gr5=gr29,64
   52| 000244 addi     38600002   1     LI        gr3=2
   52| 000248 addi     38800102   1     LI        gr4=258
   52| 00024C or       7F86E378   1     LR        gr6=gr28
   52| 000250 addi     38E00000   1     LI        gr7=0
   52| 000254 addi     39000000   1     LI        gr8=0
   52| 000258 addi     393F00E0   1     AI        gr9=gr31,224
   52| 00025C bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#10",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,|pgen,gr9,#use_xlfBeginIO21,_xlfBeginIO",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   52| 000260 ori      60000000   1
   52| 000264 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   52| 000268 ori      60000000   1
   53| 00026C lfd      CBDF00A0   1     LFL       fp30=x10(gr31,160)
   54| 000270 lfd      CBBF00A8   1     LFL       fp29=x20(gr31,168)
   55| 000274 lfd      CB9F00B8   1     LFL       fp28=d0(gr31,184)
   56| 000278 lfd      CB7F00C0   1     LFL       fp27=p0(gr31,192)
   57| 00027C lfd      CB5F00C8   1     LFL       fp26=d1(gr31,200)
   58| 000280 lfd      CBFF00D0   1     LFL       fp31=p1(gr31,208)
   59| 000284 lwz      835F0080   1     L4Z       gr26=idirect(gr31,128)
   53| 000288 stfd     DBDB06D0   1     STFL      <s251:d1744:l8>(gr27,1744)=fp30
   54| 00028C stfd     DBBB06D8   1     STFL      <s251:d1752:l8>(gr27,1752)=fp29
   55| 000290 stfd     DB9B06E0   1     STFL      <s251:d1760:l8>(gr27,1760)=fp28
   56| 000294 stfd     DB7B06E8   1     STFL      <s251:d1768:l8>(gr27,1768)=fp27
   59| 000298 std      FB5F02C8   1     ST8       #SPILL0(gr31,712)=gr26
   57| 00029C stfd     DB5B06F0   1     STFL      <s251:d1776:l8>(gr27,1776)=fp26
   58| 0002A0 stfd     DBFB06F8   1     STFL      <s251:d1784:l8>(gr27,1784)=fp31
   59| 0002A4 stw      935B0090   1     ST4Z      <s251:d144:l4>(gr27,144)=gr26
   60|                              CL.1:
   61| 0002A8 addis    3FA04C00   1     LIU       gr29=19456
   61| 0002AC addi     38000006   1     LI        gr0=6
   61| 0002B0 addi     387D081F   1     AI        gr3=gr29,2079
   61| 0002B4 stw      901F0084   1     ST4Z      T_2(gr31,132)=gr0
   61| 0002B8 addi     3B800000   1     LI        gr28=0
   61| 0002BC stw      907F0088   1     ST4Z      T_3(gr31,136)=gr3
   61| 0002C0 addi     387B06D0   1     AI        gr3=gr27,1744
   61| 0002C4 stw      939F008C   1     ST4Z      T_4(gr31,140)=gr28
   61| 0002C8 addi     38DF008C   1     AI        gr6=gr31,140
   61| 0002CC addi     38BF0088   1     AI        gr5=gr31,136
   61| 0002D0 addi     389F0084   1     AI        gr4=gr31,132
   61| 0002D4 addi     38FB0020   1     AI        gr7=gr27,32
   61| 0002D8 addi     391B0014   1     AI        gr8=gr27,20
   61| 0002DC bl       48000001   1     CALL      mpi_bcast,6,buf_in[]",gr3,T_2",gr4,T_3",gr5,T_4",gr6,comm3d",gr7,ierr",gr8,#ProcAlias",mpi_bcast",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   61| 0002E0 ori      60000000   1
   63| 0002E4 addi     38000001   1     LI        gr0=1
   63| 0002E8 stw      939F0098   1     ST4Z      T_7(gr31,152)=gr28
   63| 0002EC addi     387D041B   1     AI        gr3=gr29,1051
   63| 0002F0 stw      901F0090   1     ST4Z      T_5(gr31,144)=gr0
   63| 0002F4 stw      907F0094   1     ST4Z      T_6(gr31,148)=gr3
   63| 0002F8 addi     38DF0098   1     AI        gr6=gr31,152
   63| 0002FC addi     38BF0094   1     AI        gr5=gr31,148
   63| 000300 addi     389F0090   1     AI        gr4=gr31,144
   63| 000304 addi     387B0090   1     AI        gr3=gr27,144
   63| 000308 addi     38FB0020   1     AI        gr7=gr27,32
   63| 00030C addi     391B0014   1     AI        gr8=gr27,20
   63| 000310 bl       48000001   1     CALL      mpi_bcast,6,ibuf_in[]",gr3,T_5",gr4,T_6",gr5,T_7",gr6,comm3d",gr7,ierr",gr8,#ProcAlias",mpi_bcast",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   63| 000314 ori      60000000   1
   65| 000318 lwz      801B0004   1     L4Z       gr0=<s251:d4:l4>(gr27,4)
   65| 00031C cmpdi    2C200000   1     C8        cr0=gr0,0
   65| 000320 bc       41820024   1     BT        CL.2,cr0,0x4/eq,taken=50%(0,0)
   72| 000324 lwz      801B0090   1     L4Z       gr0=<s251:d144:l4>(gr27,144)
   66| 000328 lfd      CBDB06D0   1     LFL       fp30=<s251:d1744:l8>(gr27,1744)
   67| 00032C lfd      CBBB06D8   1     LFL       fp29=<s251:d1752:l8>(gr27,1752)
   68| 000330 lfd      CB9B06E0   1     LFL       fp28=<s251:d1760:l8>(gr27,1760)
   69| 000334 lfd      CB7B06E8   1     LFL       fp27=<s251:d1768:l8>(gr27,1768)
   70| 000338 lfd      CB5B06F0   1     LFL       fp26=<s251:d1776:l8>(gr27,1776)
   72| 00033C std      F81F02C8   1     ST8       #SPILL0(gr31,712)=gr0
   71| 000340 lfd      CBFB06F8   1     LFL       fp31=<s251:d1784:l8>(gr27,1784)
   73|                              CL.2:
   77| 000344 ld       E8620000   1     L8        gr3=.&&N&&root(gr2,0)
   77| 000348 lfs      C07E0034   1     LFS       fp3=+CONSTANT_AREA(gr30,52)
   79| 00034C ld       E8A20000   1     L8        gr5=.&&N&&param(gr2,0)
   77| 000350 lfd      C80300E8   1     LFL       fp0=<s278:d232:l8>(gr3,232)
   79| 000354 lwa      E8C5000A   1     L4A       gr6=<s11:d8:l4>(gr5,8)
   77| 000358 qvfre    10200030   1     QVFRE     fp1=fp0
   79| 00035C sradi    7CC00E74   1     SRA8CA    gr0,ca=gr6,1
   79| 000360 cmpwi    2E060000   1     C4        cr4=gr6,0
   79| 000364 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
   79| 000368 std      F8DF02D0   1     ST8       #SPILL1(gr31,720)=gr6
   79| 00036C rldicr   78030FA4   1     SLL8      gr3=gr0,1
   77| 000370 fmsub    FC401878   1     FMS       fp2=fp3,fp0,fp1,fcr
   79| 000374 subf     7C833051   1     S_R       gr4,cr0=gr6,gr3
   79| 000378 crand    4C310A02   1     CR_N      cr0=cr[40],0x2/gt,0x2/gt,0x2/gt,cr0
   77| 00037C fnmsub   FC2108BC   1     FNMS      fp1=fp1,fp1,fp2,fcr
   77| 000380 fmsub    FC401878   2     FMS       fp2=fp3,fp0,fp1,fcr
   77| 000384 fnmsub   FC2108BC   2     FNMS      fp1=fp1,fp1,fp2,fcr
   77| 000388 fmul     FC5B0072   2     MFL       fp2=fp27,fp1,fcr
   78| 00038C fmul     FC7F0072   2     MFL       fp3=fp31,fp1,fcr
   77| 000390 fmsub    FC80D8B8   2     FMS       fp4=fp27,fp0,fp2,fcr
   78| 000394 fmsub    FC00F8F8   2     FMS       fp0=fp31,fp0,fp3,fcr
   77| 000398 fnmsub   FC41113C   2     FNMS      fp2=fp2,fp1,fp4,fcr
   78| 00039C fnmsub   FC01183C   2     FNMS      fp0=fp3,fp1,fp0,fcr
   79| 0003A0 bc       408100EC   1     BF        CL.244,cr0,0x2/gt,taken=50%(0,0)
   82| 0003A4 ld       E9020000   1     L8        gr8=.&&N&field(gr2,0)
   80| 0003A8 lwa      E8050006   1     L4A       gr0=<s11:d4:l4>(gr5,4)
   81| 0003AC lwa      EBA50002   1     L4A       gr29=<s11:d0:l4>(gr5,0)
   79| 0003B0 addi     38A00000   1     LI        gr5=0
   82| 0003B4 ld       E92801A0   1     L8        gr9=<s86:d416:l8>(gr8,416)
   83| 0003B8 ld       E9480208   1     L8        gr10=<s86:d520:l8>(gr8,520)
   84| 0003BC ld       E9680270   1     L8        gr11=<s86:d624:l8>(gr8,624)
   82| 0003C0 ld       E98801B8   1     L8        gr12=<s86:d440:l8>(gr8,440)
   83| 0003C4 ld       EAC80220   1     L8        gr22=<s86:d544:l8>(gr8,544)
   84| 0003C8 ld       EAE80288   1     L8        gr23=<s86:d648:l8>(gr8,648)
   82| 0003CC ld       EB8801E8   1     L8        gr28=<s86:d488:l8>(gr8,488)
   83| 0003D0 ld       EB680250   1     L8        gr27=<s86:d592:l8>(gr8,592)
   84| 0003D4 ld       EB4802B8   1     L8        gr26=<s86:d696:l8>(gr8,696)
    0| 0003D8 cmpwi    2C800000   1     C4        cr1=gr0,0
   82| 0003DC ld       EB2801D0   1     L8        gr25=<s86:d464:l8>(gr8,464)
   83| 0003E0 ld       EB080238   1     L8        gr24=<s86:d568:l8>(gr8,568)
   84| 0003E4 ld       EA2802A0   1     L8        gr17=<s86:d672:l8>(gr8,672)
   82| 0003E8 ld       E8C80200   1     L8        gr6=<s86:d512:l8>(gr8,512)
   83| 0003EC ld       E8E80268   1     L8        gr7=<s86:d616:l8>(gr8,616)
   84| 0003F0 ld       E90802D0   1     L8        gr8=<s86:d720:l8>(gr8,720)
    0| 0003F4 bc       40851828   1     BF        CL.767,cr1,0x2/gt,taken=40%(40,60)
    0| 0003F8 add      7D6BBA14   1     A         gr11=gr11,gr23
    0| 0003FC add      7D4AB214   1     A         gr10=gr10,gr22
    0| 000400 add      7D296214   1     A         gr9=gr9,gr12
    0| 000404 add      7D6BD214   1     A         gr11=gr11,gr26
    0| 000408 add      7D4ADA14   1     A         gr10=gr10,gr27
    0| 00040C add      7D29E214   1     A         gr9=gr9,gr28
    0| 000410 add      7EEB8A14   1     A         gr23=gr11,gr17
    0| 000414 add      7ECAC214   1     A         gr22=gr10,gr24
    0| 000418 add      7EA9CA14   1     A         gr21=gr9,gr25
    0| 00041C cmpdi    2C3D0000   1     C8        cr0=gr29,0
    0| 000420 lfs      C03E0048   1     LFS       fp1=+CONSTANT_AREA(gr30,72)
   79|                              CL.239:
   80| 000424 addi     39200000   1     LI        gr9=0
    0| 000428 bc       4081004C   1     BF        CL.243,cr0,0x2/gt,taken=50%(0,0)
    0| 00042C or       7EB4AB78   1     LR        gr20=gr21
    0| 000430 or       7ED3B378   1     LR        gr19=gr22
    0| 000434 or       7EF2BB78   1     LR        gr18=gr23
   80|                              CL.240:
    0| 000438 addi     39290001   1     AI        gr9=gr9,1
   84| 00043C or       7E4A9378   1     LR        gr10=gr18
   83| 000440 or       7E6B9B78   1     LR        gr11=gr19
   82| 000444 or       7E8CA378   1     LR        gr12=gr20
    0| 000448 mtspr    7FA903A6   1     LCTR      ctr=gr29
    0| 00044C ori      60210000   1     XNOP      
    0|                              CL.1148:
   82| 000450 stfdux   7C2C35EE   1     STFDU     gr12,v1(gr12,gr6,0)=fp1
   83| 000454 stfdux   7C2B3DEE   1     STFDU     gr11,v2(gr11,gr7,0)=fp1
   84| 000458 stfdux   7C2A45EE   1     STFDU     gr10,v3(gr10,gr8,0)=fp1
    0| 00045C bc       4200FFF4   1     BCT       ctr=CL.1148,taken=100%(100,0)
   86| 000460 cmpld    7CA90040   1     CL8       cr1=gr9,gr0
    0| 000464 add      7E94E214   1     A         gr20=gr20,gr28
    0| 000468 add      7E73DA14   1     A         gr19=gr19,gr27
    0| 00046C add      7E52D214   1     A         gr18=gr18,gr26
   86| 000470 bc       4184FFC8   1     BT        CL.240,cr1,0x8/llt,taken=80%(80,20)
   86|                              CL.243:
   87| 000474 addi     38A50001   1     AI        gr5=gr5,1
    0| 000478 add      7EB5CA14   1     A         gr21=gr21,gr25
   87| 00047C cmpd     7CA42800   1     C8        cr1=gr4,gr5
    0| 000480 add      7ED6C214   1     A         gr22=gr22,gr24
    0| 000484 add      7EF1BA14   1     A         gr23=gr17,gr23
   87| 000488 bc       4185FF9C   1     BT        CL.239,cr1,0x2/gt,taken=80%(80,20)
   87|                              CL.244:
   79| 00048C ld       E81F02D0   1     L8        gr0=#SPILL1(gr31,720)
   79| 000490 cmpd     7CA02000   1     C8        cr1=gr0,gr4
   79| 000494 crand    4C312A02   1     CR_N      cr0=cr[41],0x2/gt,0x2/gt,0x2/gt,cr0
   79| 000498 bc       4081019C   1     BF        CL.87,cr0,0x2/gt,taken=50%(0,0)
   82| 00049C ld       E8C20000   1     L8        gr6=.&&N&field(gr2,0)
   80| 0004A0 ld       EAC20000   1     L8        gr22=.&&N&&param(gr2,0)
   87| 0004A4 addi     3863FFFF   1     AI        gr3=gr3,-1
   87| 0004A8 sradi    7C670E74   1     SRA8CA    gr7,ca=gr3,1
   79| 0004AC addi     38600000   1     LI        gr3=0
   82| 0004B0 ld       E8A601D0   1     L8        gr5=<s86:d464:l8>(gr6,464)
   83| 0004B4 ld       E9260238   1     L8        gr9=<s86:d568:l8>(gr6,568)
   84| 0004B8 ld       E98602A0   1     L8        gr12=<s86:d672:l8>(gr6,672)
   82| 0004BC ld       EB2601A0   1     L8        gr25=<s86:d416:l8>(gr6,416)
   83| 0004C0 ld       E9660208   1     L8        gr11=<s86:d520:l8>(gr6,520)
   84| 0004C4 ld       E9060270   1     L8        gr8=<s86:d624:l8>(gr6,624)
   82| 0004C8 ld       EAE601B8   1     L8        gr23=<s86:d440:l8>(gr6,440)
   83| 0004CC ld       EB060220   1     L8        gr24=<s86:d544:l8>(gr6,544)
   84| 0004D0 ld       E9460288   1     L8        gr10=<s86:d648:l8>(gr6,648)
   82| 0004D4 ld       EB8601E8   1     L8        gr28=<s86:d488:l8>(gr6,488)
   83| 0004D8 ld       EB660250   1     L8        gr27=<s86:d592:l8>(gr6,592)
   84| 0004DC ld       EB4602B8   1     L8        gr26=<s86:d696:l8>(gr6,696)
   80| 0004E0 lwa      E8160006   1     L4A       gr0=<s11:d4:l4>(gr22,4)
    0| 0004E4 add      7F39BA14   1     A         gr25=gr25,gr23
    0| 0004E8 add      7D6BC214   1     A         gr11=gr11,gr24
    0| 0004EC add      7EE85214   1     A         gr23=gr8,gr10
    0| 0004F0 mulld    7D0429D2   1     M         gr8=gr4,gr5
    0| 0004F4 mulld    7F0461D2   1     M         gr24=gr4,gr12
    0| 0004F8 mulld    7D4449D2   1     M         gr10=gr4,gr9
    0| 0004FC rldicr   79950FA4   1     SLL8      gr21=gr12,1
    0| 000500 add      7EF7D214   1     A         gr23=gr23,gr26
    0| 000504 std      FABF02D8   1     ST8       #SPILL2(gr31,728)=gr21
    0| 000508 rldicr   79340FA4   1     SLL8      gr20=gr9,1
    0| 00050C add      7D6BDA14   1     A         gr11=gr11,gr27
    0| 000510 std      FA9F02E0   1     ST8       #SPILL3(gr31,736)=gr20
    0| 000514 rldicr   78B30FA4   1     SLL8      gr19=gr5,1
    0| 000518 add      7C99E214   1     A         gr4=gr25,gr28
   87| 00051C addze    7CE70194   1     ADDE      gr7,ca=gr7,0,ca
    0| 000520 cmpwi    2C000000   1     C4        cr0=gr0,0
    0| 000524 add      7F35BA14   1     A         gr25=gr21,gr23
    0| 000528 std      FA7F02E8   1     ST8       #SPILL4(gr31,744)=gr19
   81| 00052C lwa      EBB60002   1     L4A       gr29=<s11:d0:l4>(gr22,0)
    0| 000530 add      7ECCBA14   1     A         gr22=gr12,gr23
    0| 000534 add      7EEBA214   1     A         gr23=gr11,gr20
    0| 000538 add      7D895A14   1     A         gr12=gr9,gr11
    0| 00053C add      7D649A14   1     A         gr11=gr4,gr19
    0| 000540 add      7D242A14   1     A         gr9=gr4,gr5
   82| 000544 ld       E8860200   1     L8        gr4=<s86:d512:l8>(gr6,512)
   83| 000548 ld       E8A60268   1     L8        gr5=<s86:d616:l8>(gr6,616)
   84| 00054C ld       E8C602D0   1     L8        gr6=<s86:d720:l8>(gr6,720)
    0| 000550 bc       408100E4   1     BF        CL.87,cr0,0x2/gt,taken=20%(20,80)
    0| 000554 add      7EA85A14   1     A         gr21=gr8,gr11
    0| 000558 add      7E884A14   1     A         gr20=gr8,gr9
    0| 00055C addi     39070001   1     AI        gr8=gr7,1
    0| 000560 add      7F38CA14   1     A         gr25=gr24,gr25
    0| 000564 std      F91F02F0   1     ST8       #SPILL5(gr31,752)=gr8
    0| 000568 add      7F18B214   1     A         gr24=gr24,gr22
    0| 00056C add      7EEABA14   1     A         gr23=gr10,gr23
    0| 000570 add      7ECA6214   1     A         gr22=gr10,gr12
    0| 000574 cmpdi    2C3D0000   1     C8        cr0=gr29,0
    0| 000578 lfs      C03E0048   1     LFS       fp1=+CONSTANT_AREA(gr30,72)
   79|                              CL.88:
   80| 00057C addi     38E00000   1     LI        gr7=0
    0| 000580 bc       40810080   1     BF        CL.89,cr0,0x2/gt,taken=20%(20,80)
    0| 000584 or       7E93A378   1     LR        gr19=gr20
    0| 000588 or       7EB2AB78   1     LR        gr18=gr21
    0| 00058C or       7ED1B378   1     LR        gr17=gr22
    0| 000590 or       7EF0BB78   1     LR        gr16=gr23
    0| 000594 or       7F0FC378   1     LR        gr15=gr24
    0| 000598 or       7F2ECB78   1     LR        gr14=gr25
   80|                              CL.90:
    0| 00059C addi     38E70001   1     AI        gr7=gr7,1
   84| 0005A0 or       7DC87378   1     LR        gr8=gr14
   84| 0005A4 or       7DE97B78   1     LR        gr9=gr15
   83| 0005A8 or       7E0A8378   1     LR        gr10=gr16
   83| 0005AC or       7E2B8B78   1     LR        gr11=gr17
   82| 0005B0 or       7E4C9378   1     LR        gr12=gr18
   82| 0005B4 or       7E7E9B78   1     LR        gr30=gr19
    0| 0005B8 mtspr    7FA903A6   1     LCTR      ctr=gr29
    0| 0005BC ori      60210000   1     XNOP      
    0| 0005C0 ori      60210000   1     XNOP      
    0|                              CL.1149:
   82| 0005C4 stfdux   7C3E25EE   1     STFDU     gr30,v1(gr30,gr4,0)=fp1
   82| 0005C8 stfdux   7C2C25EE   1     STFDU     gr12,v1(gr12,gr4,0)=fp1
   83| 0005CC stfdux   7C2B2DEE   1     STFDU     gr11,v2(gr11,gr5,0)=fp1
   83| 0005D0 stfdux   7C2A2DEE   1     STFDU     gr10,v2(gr10,gr5,0)=fp1
   84| 0005D4 stfdux   7C2935EE   1     STFDU     gr9,v3(gr9,gr6,0)=fp1
   84| 0005D8 stfdux   7C2835EE   1     STFDU     gr8,v3(gr8,gr6,0)=fp1
    0| 0005DC bc       4200FFE8   1     BCT       ctr=CL.1149,taken=100%(100,0)
   86| 0005E0 cmpld    7F270040   1     CL8       cr6=gr7,gr0
    0| 0005E4 add      7E73E214   1     A         gr19=gr19,gr28
    0| 0005E8 add      7E52E214   1     A         gr18=gr18,gr28
    0| 0005EC add      7E31DA14   1     A         gr17=gr17,gr27
    0| 0005F0 add      7E10DA14   1     A         gr16=gr16,gr27
    0| 0005F4 add      7DEFD214   1     A         gr15=gr15,gr26
    0| 0005F8 add      7DCED214   1     A         gr14=gr14,gr26
   86| 0005FC bc       4198FFA0   1     BT        CL.90,cr6,0x8/llt,taken=80%(80,20)
   86|                              CL.89:
   87| 000600 ld       E91F02F0   1     L8        gr8=#SPILL5(gr31,752)
    0| 000604 ld       E8FF02D8   1     L8        gr7=#SPILL2(gr31,728)
    0| 000608 ld       E93F02E0   1     L8        gr9=#SPILL3(gr31,736)
    0| 00060C ld       E95F02E8   1     L8        gr10=#SPILL4(gr31,744)
   87| 000610 addi     38630001   1     AI        gr3=gr3,1
   87| 000614 cmpld    7F234040   1     CL8       cr6=gr3,gr8
    0| 000618 add      7F27CA14   1     A         gr25=gr7,gr25
    0| 00061C add      7F07C214   1     A         gr24=gr7,gr24
    0| 000620 add      7EE9BA14   1     A         gr23=gr9,gr23
    0| 000624 add      7EC9B214   1     A         gr22=gr9,gr22
    0| 000628 add      7EAAAA14   1     A         gr21=gr10,gr21
    0| 00062C add      7E8AA214   1     A         gr20=gr10,gr20
   87| 000630 bc       4198FF4C   1     BT        CL.88,cr6,0x8/llt,taken=80%(80,20)
   87|                              CL.87:
  125| 000634 ld       E81F02C8   1     L8        gr0=#SPILL0(gr31,712)
  125| 000638 cmpwi    2C000001   1     C4        cr0=gr0,1
  125| 00063C bc       408206E4   1     BF        CL.42,cr0,0x4/eq,taken=50%(0,0)
   78| 000640 ld       E87F02D0   1     L8        gr3=#SPILL1(gr31,720)
   78| 000644 sradi    7C601674   1     SRA8CA    gr0,ca=gr3,2
   78| 000648 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
  126| 00064C rldicr   78081764   1     SLL8      gr8=gr0,2
  126| 000650 subf     7F881851   1     S_R       gr28,cr0=gr3,gr8
  126| 000654 crand    4C310A02   1     CR_N      cr0=cr[40],0x2/gt,0x2/gt,0x2/gt,cr0
  126| 000658 bc       4081011C   1     BF        CL.212,cr0,0x2/gt,taken=50%(0,0)
  127| 00065C ld       EAE20000   1     L8        gr23=.&&N&&param(gr2,0)
  131| 000660 ld       EB620000   1     L8        gr27=.&&N&field(gr2,0)
  129| 000664 ld       E8820000   1     L8        gr4=.&&N&grid(gr2,0)
  126| 000668 addi     38600000   1     LI        gr3=0
  127| 00066C lwa      E8170006   1     L4A       gr0=<s11:d4:l4>(gr23,4)
  131| 000670 ld       E8BB0000   1     L8        gr5=<s86:d0:l8>(gr27,0)
  130| 000674 ld       E8DB0068   1     L8        gr6=<s86:d104:l8>(gr27,104)
  130| 000678 ld       E8FB0080   1     L8        gr7=<s86:d128:l8>(gr27,128)
  131| 00067C ld       EB1B0018   1     L8        gr24=<s86:d24:l8>(gr27,24)
  131| 000680 ld       E95B0030   1     L8        gr10=<s86:d48:l8>(gr27,48)
  131| 000684 ld       E97B0048   1     L8        gr11=<s86:d72:l8>(gr27,72)
  131| 000688 ld       E99B0060   1     L8        gr12=<s86:d96:l8>(gr27,96)
  130| 00068C ld       EBDB0098   1     L8        gr30=<s86:d152:l8>(gr27,152)
  130| 000690 ld       EBBB00B0   1     L8        gr29=<s86:d176:l8>(gr27,176)
  130| 000694 ld       EB7B00C8   1     L8        gr27=<s86:d200:l8>(gr27,200)
    0| 000698 cmpwi    2F000000   1     C4        cr6=gr0,0
  128| 00069C lwa      E9370002   1     L4A       gr9=<s11:d0:l4>(gr23,0)
  129| 0006A0 ld       EB240000   1     L8        gr25=<s216:d0:l8>(gr4,0)
  129| 0006A4 ld       EB440018   1     L8        gr26=<s216:d24:l8>(gr4,24)
    0| 0006A8 bc       40991560   1     BF        CL.777,cr6,0x2/gt,taken=40%(40,60)
    0| 0006AC add      7C85C214   1     A         gr4=gr5,gr24
    0| 0006B0 add      7CA63A14   1     A         gr5=gr6,gr7
    0| 0006B4 add      7CC46214   1     A         gr6=gr4,gr12
    0| 0006B8 add      7CEA5A14   1     A         gr7=gr10,gr11
    0| 0006BC add      7C85DA14   1     A         gr4=gr5,gr27
    0| 0006C0 add      7CBDF214   1     A         gr5=gr29,gr30
  129| 0006C4 add      7F59D214   1     A         gr26=gr25,gr26
    0| 0006C8 add      7EC63A14   1     A         gr22=gr6,gr7
    0| 0006CC add      7F242A14   1     A         gr25=gr4,gr5
    0| 0006D0 cmpdi    2C290000   1     C8        cr0=gr9,0
  126|                              CL.205:
  127| 0006D4 addi     38800000   1     LI        gr4=0
    0| 0006D8 bc       40810088   1     BF        CL.211,cr0,0x2/gt,taken=50%(0,0)
    0| 0006DC or       7F38CB78   1     LR        gr24=gr25
    0| 0006E0 or       7ED7B378   1     LR        gr23=gr22
  127|                              CL.206:
  129| 0006E4 or       7F45D378   1     LR        gr5=gr26
    0| 0006E8 or       7EE6BB78   1     LR        gr6=gr23
  129| 0006EC lfdu     CC250008   1     LFDU      fp1,gr5=x1a(gr5,8)
    0| 0006F0 or       7F07C378   1     LR        gr7=gr24
    0| 0006F4 mtspr    7D2903A6   1     LCTR      ctr=gr9
    0| 0006F8 addi     38840001   1     AI        gr4=gr4,1
  129| 0006FC fcmpu    FF01F000   1     CFL       cr6=fp1,fp30
  129| 000700 bc       41990010   1     BT        CL.1150,cr6,0x40/fgt,taken=50%(0,0)
  130| 000704 stfd     D8580000   1     STFL      e(gr24,0)=fp2
  131| 000708 stfd     DB970000   1     STFL      d(gr23,0)=fp28
    0| 00070C b        4800000C   1     B         CL.1151,-1
  132|                              CL.1150:
  133| 000710 stfd     D8070000   1     STFL      e(gr7,0)=fp0
  134| 000714 stfd     DB460000   1     STFL      d(gr6,0)=fp26
  135|                              CL.1151:
    0| 000718 bc       42400038   1     BCF       ctr=CL.1152,taken=0%(0,100)
    0| 00071C ori      60210000   1     XNOP      
    0| 000720 ori      60210000   1     XNOP      
    0|                              CL.1153:
  129| 000724 lfdu     CC250008   1     LFDU      fp1,gr5=x1a(gr5,8)
  129| 000728 fcmpu    FF01F000   1     CFL       cr6=fp1,fp30
    0| 00072C add      7CC66214   1     A         gr6=gr6,gr12
    0| 000730 add      7CE7DA14   1     A         gr7=gr7,gr27
  129| 000734 bc       41990010   1     BT        CL.1154,cr6,0x40/fgt,taken=50%(0,0)
  130| 000738 stfd     D8470000   1     STFL      e(gr7,0)=fp2
  131| 00073C stfd     DB860000   1     STFL      d(gr6,0)=fp28
    0| 000740 b        4800000C   1     B         CL.1155,-1
  132|                              CL.1154:
  133| 000744 stfd     D8070000   1     STFL      e(gr7,0)=fp0
  134| 000748 stfd     DB460000   1     STFL      d(gr6,0)=fp26
  135|                              CL.1155:
    0| 00074C bc       4200FFD8   1     BCT       ctr=CL.1153,taken=100%(100,0)
    0|                              CL.1152:
  137| 000750 cmpld    7F240040   1     CL8       cr6=gr4,gr0
    0| 000754 add      7F18EA14   1     A         gr24=gr24,gr29
    0| 000758 add      7EEBBA14   1     A         gr23=gr11,gr23
  137| 00075C bc       4198FF88   1     BT        CL.206,cr6,0x8/llt,taken=80%(80,20)
  137|                              CL.211:
  138| 000760 addi     38630001   1     AI        gr3=gr3,1
    0| 000764 add      7F39F214   1     A         gr25=gr25,gr30
  138| 000768 cmpd     7F3C1800   1     C8        cr6=gr28,gr3
    0| 00076C add      7ECAB214   1     A         gr22=gr10,gr22
  138| 000770 bc       4199FF64   1     BT        CL.205,cr6,0x2/gt,taken=80%(80,20)
  138|                              CL.212:
  126| 000774 ld       E81F02D0   1     L8        gr0=#SPILL1(gr31,720)
  126| 000778 cmpd     7F20E000   1     C8        cr6=gr0,gr28
  126| 00077C crand    4C31CA02   1     CR_N      cr0=cr[46],0x2/gt,0x2/gt,0x2/gt,cr0
  126| 000780 bc       408105A0   1     BF        CL.42,cr0,0x2/gt,taken=50%(0,0)
  127| 000784 ld       EA420000   1     L8        gr18=.&&N&&param(gr2,0)
  131| 000788 ld       E9620000   1     L8        gr11=.&&N&field(gr2,0)
  129| 00078C ld       E8C20000   1     L8        gr6=.&&N&grid(gr2,0)
  126| 000790 or       7F89E378   1     LR        gr9=gr28
  127| 000794 lwa      EB720006   1     L4A       gr27=<s11:d4:l4>(gr18,4)
  131| 000798 ld       E88B0030   1     L8        gr4=<s86:d48:l8>(gr11,48)
  130| 00079C ld       E8AB0098   1     L8        gr5=<s86:d152:l8>(gr11,152)
  128| 0007A0 lwa      EA320002   1     L4A       gr17=<s11:d0:l4>(gr18,0)
  131| 0007A4 ld       EB4B0000   1     L8        gr26=<s86:d0:l8>(gr11,0)
  130| 0007A8 ld       EB2B0068   1     L8        gr25=<s86:d104:l8>(gr11,104)
  130| 0007AC sradi    7F600E74   1     SRA8CA    gr0,ca=gr27,1
  130| 0007B0 ld       EB0B0080   1     L8        gr24=<s86:d128:l8>(gr11,128)
  131| 0007B4 ld       EACB0018   1     L8        gr22=<s86:d24:l8>(gr11,24)
  130| 0007B8 addze    7D400194   1     ADDE      gr10,ca=gr0,0,ca
  131| 0007BC ld       E8EB0048   1     L8        gr7=<s86:d72:l8>(gr11,72)
  131| 0007C0 ld       E80B0060   1     L8        gr0=<s86:d96:l8>(gr11,96)
  130| 0007C4 ld       E86B00B0   1     L8        gr3=<s86:d176:l8>(gr11,176)
  130| 0007C8 ld       EAEB00C8   1     L8        gr23=<s86:d200:l8>(gr11,200)
  128| 0007CC std      FA3F02D8   1     ST8       #SPILL2(gr31,728)=gr17
    0| 0007D0 add      7FB6D214   1     A         gr29=gr22,gr26
    0| 0007D4 add      7D98CA14   1     A         gr12=gr24,gr25
  127| 0007D8 rldicr   794A0FA4   1     SLL8      gr10=gr10,1
  129| 0007DC ld       E9E60000   1     L8        gr15=<s216:d0:l8>(gr6,0)
  129| 0007E0 ld       E8C60018   1     L8        gr6=<s216:d24:l8>(gr6,24)
    0| 0007E4 mulld    7FC4E1D2   1     M         gr30=gr4,gr28
    0| 0007E8 mulld    7D65E1D2   1     M         gr11=gr5,gr28
    0| 0007EC add      7FA0EA14   1     A         gr29=gr0,gr29
    0| 0007F0 add      7E643A14   1     A         gr19=gr4,gr7
    0| 0007F4 add      7D8CBA14   1     A         gr12=gr12,gr23
    0| 0007F8 add      7E832A14   1     A         gr20=gr3,gr5
  127| 0007FC subf     7EAAD851   1     S_R       gr21,cr0=gr27,gr10
  127| 000800 cmpwi    2F9B0000   1     C4        cr7=gr27,0
    0| 000804 add      7FB3EA14   1     A         gr29=gr19,gr29
    0| 000808 add      7D8CA214   1     A         gr12=gr12,gr20
  127| 00080C crand    4C3D0A02   1     CR_N      cr0=cr[70],0x2/gt,0x2/gt,0x2/gt,cr0
    0| 000810 bc       408100B8   1     BF        CL.696,cr0,0x2/gt,taken=20%(20,80)
  129| 000814 add      7E867A14   1     A         gr20=gr6,gr15
    0| 000818 add      7E7DF214   1     A         gr19=gr29,gr30
    0| 00081C add      7E4B6214   1     A         gr18=gr11,gr12
    0| 000820 cmpdi    2C310000   1     C8        cr0=gr17,0
    0| 000824 ld       E9DF02D8   1     L8        gr14=#SPILL2(gr31,728)
  126|                              CL.197:
  127| 000828 addi     39600000   1     LI        gr11=0
    0| 00082C bc       40810084   1     BF        CL.218,cr0,0x2/gt,taken=50%(0,0)
    0| 000830 or       7E519378   1     LR        gr17=gr18
    0| 000834 or       7E709B78   1     LR        gr16=gr19
  127|                              CL.213:
  129| 000838 or       7E8CA378   1     LR        gr12=gr20
    0| 00083C or       7E1E8378   1     LR        gr30=gr16
  129| 000840 lfdu     CC2C0008   1     LFDU      fp1,gr12=x1a(gr12,8)
    0| 000844 or       7E3D8B78   1     LR        gr29=gr17
    0| 000848 mtspr    7DC903A6   1     LCTR      ctr=gr14
    0| 00084C addi     396B0001   1     AI        gr11=gr11,1
  129| 000850 fcmpu    FF01F000   1     CFL       cr6=fp1,fp30
  129| 000854 bc       41990010   1     BT        CL.1156,cr6,0x40/fgt,taken=50%(0,0)
  130| 000858 stfd     D8510000   1     STFL      e(gr17,0)=fp2
  131| 00085C stfd     DB900000   1     STFL      d(gr16,0)=fp28
    0| 000860 b        4800000C   1     B         CL.1157,-1
  132|                              CL.1156:
  133| 000864 stfd     D81D0000   1     STFL      e(gr29,0)=fp0
  134| 000868 stfd     DB5E0000   1     STFL      d(gr30,0)=fp26
  135|                              CL.1157:
    0| 00086C bc       42400034   1     BCF       ctr=CL.1158,taken=0%(0,100)
    0| 000870 ori      60210000   1     XNOP      
    0|                              CL.1159:
  129| 000874 lfdu     CC2C0008   1     LFDU      fp1,gr12=x1a(gr12,8)
  129| 000878 fcmpu    FF01F000   1     CFL       cr6=fp1,fp30
    0| 00087C add      7FC0F214   1     A         gr30=gr0,gr30
    0| 000880 add      7FB7EA14   1     A         gr29=gr23,gr29
  129| 000884 bc       41990010   1     BT        CL.1160,cr6,0x40/fgt,taken=50%(0,0)
  130| 000888 stfd     D85D0000   1     STFL      e(gr29,0)=fp2
  131| 00088C stfd     DB9E0000   1     STFL      d(gr30,0)=fp28
    0| 000890 b        4800000C   1     B         CL.1161,-1
  132|                              CL.1160:
  133| 000894 stfd     D81D0000   1     STFL      e(gr29,0)=fp0
  134| 000898 stfd     DB5E0000   1     STFL      d(gr30,0)=fp26
  135|                              CL.1161:
    0| 00089C bc       4200FFD8   1     BCT       ctr=CL.1159,taken=100%(100,0)
    0|                              CL.1158:
  137| 0008A0 cmpd     7F2BA800   1     C8        cr6=gr11,gr21
    0| 0008A4 add      7E238A14   1     A         gr17=gr3,gr17
    0| 0008A8 add      7E078214   1     A         gr16=gr7,gr16
  137| 0008AC bc       4198FF8C   1     BT        CL.213,cr6,0x1/lt,taken=80%(80,20)
  137|                              CL.218:
  138| 0008B0 ld       E97F02D0   1     L8        gr11=#SPILL1(gr31,720)
  138| 0008B4 addi     39290001   1     AI        gr9=gr9,1
    0| 0008B8 add      7E732214   1     A         gr19=gr19,gr4
    0| 0008BC add      7E459214   1     A         gr18=gr5,gr18
  138| 0008C0 cmpld    7F295840   1     CL8       cr6=gr9,gr11
  138| 0008C4 bc       4198FF64   1     BT        CL.197,cr6,0x8/llt,taken=80%(80,20)
    0|                              CL.696:
    0| 0008C8 mulld    7D25E1D2   1     M         gr9=gr5,gr28
    0| 0008CC mulld    7D64E1D2   1     M         gr11=gr4,gr28
    0| 0008D0 add      7FD8CA14   1     A         gr30=gr24,gr25
    0| 0008D4 add      7FB6D214   1     A         gr29=gr22,gr26
  138| 0008D8 addi     3B88FFFF   1     AI        gr28=gr8,-1
    0| 0008DC mulld    7D83A9D2   1     M         gr12=gr3,gr21
    0| 0008E0 mulld    7D07A9D2   1     M         gr8=gr7,gr21
    0| 0008E4 add      7F57F214   1     A         gr26=gr23,gr30
    0| 0008E8 add      7FA0EA14   1     A         gr29=gr0,gr29
    0| 0008EC add      7D29D214   1     A         gr9=gr9,gr26
    0| 0008F0 add      7D6BEA14   1     A         gr11=gr11,gr29
  138| 0008F4 sradi    7F9E1674   1     SRA8CA    gr30,ca=gr28,2
    0| 0008F8 addi     394AFFFF   1     AI        gr10=gr10,-1
  127| 0008FC cmpd     7C3BA800   1     C8        cr0=gr27,gr21
    0| 000900 rldicr   78BB1764   1     SLL8      gr27=gr5,2
    0| 000904 rldicr   78760FA4   1     SLL8      gr22=gr3,1
    0| 000908 std      FB7F02E0   1     ST8       #SPILL3(gr31,736)=gr27
    0| 00090C add      7D296214   1     A         gr9=gr9,gr12
    0| 000910 rldicr   78991764   1     SLL8      gr25=gr4,2
    0| 000914 add      7D085A14   1     A         gr8=gr8,gr11
    0| 000918 std      FB3F02E8   1     ST8       #SPILL4(gr31,744)=gr25
    0| 00091C rldicr   78F50FA4   1     SLL8      gr21=gr7,1
  138| 000920 addze    7F9E0194   1     ADDE      gr28,ca=gr30,0,ca
    0| 000924 sradi    7D5D0E74   1     SRA8CA    gr29,ca=gr10,1
    0| 000928 rldicr   78BE0FA4   1     SLL8      gr30=gr5,1
    0| 00092C add      7D89B214   1     A         gr12=gr9,gr22
    0| 000930 add      7C634A14   1     A         gr3=gr3,gr9
    0| 000934 subf     7D65D850   1     S         gr11=gr27,gr5
    0| 000938 add      7CE74214   1     A         gr7=gr7,gr8
    0| 00093C rldicr   788A0FA4   1     SLL8      gr10=gr4,1
    0| 000940 add      7D08AA14   1     A         gr8=gr8,gr21
    0| 000944 subf     7D24C850   1     S         gr9=gr25,gr4
  129| 000948 add      7E867A14   1     A         gr20=gr6,gr15
    0| 00094C add      7CCCF214   1     A         gr6=gr12,gr30
  129| 000950 std      FA9F02F8   1     ST8       #SPILL6(gr31,760)=gr20
    0| 000954 std      F8DF0300   1     ST8       #SPILL7(gr31,768)=gr6
    0| 000958 add      7E432A14   1     A         gr18=gr3,gr5
    0| 00095C add      7E2B6214   1     A         gr17=gr11,gr12
    0| 000960 std      FA5F0310   1     ST8       #SPILL9(gr31,784)=gr18
    0| 000964 std      FA3F0318   1     ST8       #SPILL10(gr31,792)=gr17
    0| 000968 add      7E0CDA14   1     A         gr16=gr12,gr27
    0| 00096C add      7DE56214   1     A         gr15=gr5,gr12
    0| 000970 std      FA1F0320   1     ST8       #SPILL11(gr31,800)=gr16
    0| 000974 std      F9FF0328   1     ST8       #SPILL12(gr31,808)=gr15
    0| 000978 add      7CA43A14   1     A         gr5=gr4,gr7
    0| 00097C add      7DC85214   1     A         gr14=gr8,gr10
    0| 000980 std      F8BF0330   1     ST8       #SPILL13(gr31,816)=gr5
    0| 000984 std      F9DF0338   1     ST8       #SPILL14(gr31,824)=gr14
    0| 000988 add      7F474A14   1     A         gr26=gr7,gr9
    0| 00098C add      7D88CA14   1     A         gr12=gr8,gr25
    0| 000990 std      FB5F0340   1     ST8       #SPILL15(gr31,832)=gr26
    0| 000994 std      F99F0348   1     ST8       #SPILL16(gr31,840)=gr12
    0| 000998 add      7C844214   1     A         gr4=gr4,gr8
    0| 00099C add      7D084A14   1     A         gr8=gr8,gr9
    0| 0009A0 std      F89F0350   1     ST8       #SPILL17(gr31,848)=gr4
    0| 0009A4 std      F91F0358   1     ST8       #SPILL18(gr31,856)=gr8
    0| 0009A8 add      7D275214   1     A         gr9=gr7,gr10
    0| 0009AC add      7D47CA14   1     A         gr10=gr7,gr25
    0| 0009B0 std      F93F0360   1     ST8       #SPILL19(gr31,864)=gr9
    0| 0009B4 std      F95F0368   1     ST8       #SPILL20(gr31,872)=gr10
    0| 0009B8 add      7CE35A14   1     A         gr7=gr3,gr11
    0| 0009BC add      7D63F214   1     A         gr11=gr3,gr30
    0| 0009C0 std      F8FF0370   1     ST8       #SPILL21(gr31,880)=gr7
    0| 0009C4 std      F97F0378   1     ST8       #SPILL22(gr31,888)=gr11
    0| 0009C8 addi     3BDC0001   1     AI        gr30=gr28,1
    0| 0009CC ld       EB9F02D8   1     L8        gr28=#SPILL2(gr31,728)
    0| 0009D0 std      FBDF0380   1     ST8       #SPILL23(gr31,896)=gr30
    0| 0009D4 addze    7FBD0194   1     ADDE      gr29,ca=gr29,0,ca
  126| 0009D8 addi     3B000000   1     LI        gr24=0
    0| 0009DC add      7E63DA14   1     A         gr19=gr3,gr27
  126| 0009E0 std      FB1F02F0   1     ST8       #SPILL5(gr31,752)=gr24
    0| 0009E4 addi     387D0001   1     AI        gr3=gr29,1
    0| 0009E8 std      FA7F0308   1     ST8       #SPILL8(gr31,776)=gr19
    0| 0009EC std      F87F0388   1     ST8       #SPILL24(gr31,904)=gr3
  127| 0009F0 crand    4CBD0A02   1     CR_N      cr1=cr[70],0x2/gt,0x2/gt,0x2/gt,cr1
    0| 0009F4 crnor    4CA52842   1     CR_NOR    cr1=cr[11],0x2/gt,0x2/gt,0x2/gt,cr1
    0| 0009F8 cmpdi    2C3C0000   1     C8        cr0=gr28,0
  126|                              CL.106:
  127| 0009FC bc       41850244   1     BT        CL.107,cr1,0x2/gt,taken=20%(20,80)
    0| 000A00 ld       E89F0300   1     L8        gr4=#SPILL7(gr31,768)
    0| 000A04 ld       E8BF0308   1     L8        gr5=#SPILL8(gr31,776)
    0| 000A08 ld       E8DF0370   1     L8        gr6=#SPILL21(gr31,880)
    0| 000A0C ld       E8FF0378   1     L8        gr7=#SPILL22(gr31,888)
    0| 000A10 ld       E91F0310   1     L8        gr8=#SPILL9(gr31,784)
    0| 000A14 ld       E93F0318   1     L8        gr9=#SPILL10(gr31,792)
    0| 000A18 std      F89F0398   1     ST8       #SPILL26(gr31,920)=gr4
    0| 000A1C std      F8BF03A0   1     ST8       #SPILL27(gr31,928)=gr5
    0| 000A20 std      F8DF03A8   1     ST8       #SPILL28(gr31,936)=gr6
    0| 000A24 std      F8FF03B0   1     ST8       #SPILL29(gr31,944)=gr7
    0| 000A28 ld       E95F0328   1     L8        gr10=#SPILL12(gr31,808)
    0| 000A2C ld       E97F0330   1     L8        gr11=#SPILL13(gr31,816)
    0| 000A30 std      F91F03B8   1     ST8       #SPILL30(gr31,952)=gr8
    0| 000A34 ld       E99F0368   1     L8        gr12=#SPILL20(gr31,872)
    0| 000A38 std      F93F03C0   1     ST8       #SPILL31(gr31,960)=gr9
  127| 000A3C addi     38600000   1     LI        gr3=0
    0| 000A40 std      F95F03C8   1     ST8       #SPILL32(gr31,968)=gr10
  127| 000A44 std      F87F0390   1     ST8       #SPILL25(gr31,912)=gr3
    0| 000A48 std      F97F03D0   1     ST8       #SPILL33(gr31,976)=gr11
    0| 000A4C std      F99F03D8   1     ST8       #SPILL34(gr31,984)=gr12
    0| 000A50 ld       EA9F0340   1     L8        gr20=#SPILL15(gr31,832)
    0| 000A54 ld       EA7F0360   1     L8        gr19=#SPILL19(gr31,864)
    0| 000A58 ld       EA5F0338   1     L8        gr18=#SPILL14(gr31,824)
    0| 000A5C ld       EA3F0348   1     L8        gr17=#SPILL16(gr31,840)
    0| 000A60 ld       EA1F0358   1     L8        gr16=#SPILL18(gr31,856)
    0| 000A64 ld       E9FF0350   1     L8        gr15=#SPILL17(gr31,848)
    0| 000A68 ld       E9DF0320   1     L8        gr14=#SPILL11(gr31,800)
  127|                              CL.108:
  128| 000A6C bc       40810134   1     BF        CL.109,cr0,0x2/gt,taken=20%(20,80)
    0| 000A70 std      F81F03E0   1     ST8       #SPILL35(gr31,992)=gr0
    0| 000A74 ld       E81F02D8   1     L8        gr0=#SPILL2(gr31,728)
    0| 000A78 or       7DE37B78   1     LR        gr3=gr15
    0| 000A7C ld       E89F03D8   1     L8        gr4=#SPILL34(gr31,984)
    0| 000A80 or       7E459378   1     LR        gr5=gr18
    0| 000A84 or       7E268B78   1     LR        gr6=gr17
    0| 000A88 or       7E078378   1     LR        gr7=gr16
    0| 000A8C or       7E88A378   1     LR        gr8=gr20
    0| 000A90 ld       E93F03C8   1     L8        gr9=#SPILL32(gr31,968)
    0| 000A94 ld       E95F03A0   1     L8        gr10=#SPILL27(gr31,928)
    0| 000A98 ld       E97F0398   1     L8        gr11=#SPILL26(gr31,920)
    0| 000A9C ld       E99F03C0   1     L8        gr12=#SPILL31(gr31,960)
    0| 000AA0 or       7DDE7378   1     LR        gr30=gr14
    0| 000AA4 ld       EBBF03A8   1     L8        gr29=#SPILL28(gr31,936)
    0| 000AA8 ld       EB9F03D0   1     L8        gr28=#SPILL33(gr31,976)
    0| 000AAC or       7E7B9B78   1     LR        gr27=gr19
    0| 000AB0 ld       EB5F03B8   1     L8        gr26=#SPILL30(gr31,952)
    0| 000AB4 ld       EB3F03B0   1     L8        gr25=#SPILL29(gr31,944)
  129| 000AB8 ld       EB1F02F8   1     L8        gr24=#SPILL6(gr31,760)
    0| 000ABC mtspr    7C0903A6   1     LCTR      ctr=gr0
    0| 000AC0 ld       E81F03E0   1     L8        gr0=#SPILL35(gr31,992)
    0| 000AC4 ori      60210000   1     XNOP      
    0| 000AC8 ori      60210000   1     XNOP      
  128|                              CL.110:
  129| 000ACC lfdu     CC380008   1     LFDU      fp1,gr24=x1a(gr24,8)
  129| 000AD0 fcmpu    FF01F000   1     CFL       cr6=fp1,fp30
  129| 000AD4 bc       41990048   1     BT        CL.422,cr6,0x40/fgt,taken=50%(0,0)
  130| 000AD8 stfd     D85A0000   1     STFL      e(gr26,0)=fp2
  131| 000ADC stfd     DB9C0000   1     STFL      d(gr28,0)=fp28
  130| 000AE0 stfd     D8490000   1     STFL      e(gr9,0)=fp2
  131| 000AE4 stfd     DB830000   1     STFL      d(gr3,0)=fp28
  130| 000AE8 stfd     D8590000   1     STFL      e(gr25,0)=fp2
  131| 000AEC stfd     DB9B0000   1     STFL      d(gr27,0)=fp28
  130| 000AF0 stfd     D84B0000   1     STFL      e(gr11,0)=fp2
  131| 000AF4 stfd     DB850000   1     STFL      d(gr5,0)=fp28
  130| 000AF8 stfd     D85D0000   1     STFL      e(gr29,0)=fp2
  131| 000AFC stfd     DB880000   1     STFL      d(gr8,0)=fp28
  130| 000B00 stfd     D84C0000   1     STFL      e(gr12,0)=fp2
  131| 000B04 stfd     DB870000   1     STFL      d(gr7,0)=fp28
  130| 000B08 stfd     D84A0000   1     STFL      e(gr10,0)=fp2
  131| 000B0C stfd     DB840000   1     STFL      d(gr4,0)=fp28
  130| 000B10 stfd     D85E0000   1     STFL      e(gr30,0)=fp2
  131| 000B14 stfd     DB860000   1     STFL      d(gr6,0)=fp28
  134| 000B18 b        48000044   1     B         CL.232,-1
  132|                              CL.422:
  133| 000B1C stfd     D81A0000   1     STFL      e(gr26,0)=fp0
  134| 000B20 stfd     DB5C0000   1     STFL      d(gr28,0)=fp26
  133| 000B24 stfd     D8090000   1     STFL      e(gr9,0)=fp0
  134| 000B28 stfd     DB430000   1     STFL      d(gr3,0)=fp26
  133| 000B2C stfd     D8190000   1     STFL      e(gr25,0)=fp0
  134| 000B30 stfd     DB5B0000   1     STFL      d(gr27,0)=fp26
  133| 000B34 stfd     D80B0000   1     STFL      e(gr11,0)=fp0
  134| 000B38 stfd     DB450000   1     STFL      d(gr5,0)=fp26
  133| 000B3C stfd     D81D0000   1     STFL      e(gr29,0)=fp0
  134| 000B40 stfd     DB480000   1     STFL      d(gr8,0)=fp26
  133| 000B44 stfd     D80C0000   1     STFL      e(gr12,0)=fp0
  134| 000B48 stfd     DB470000   1     STFL      d(gr7,0)=fp26
  133| 000B4C stfd     D80A0000   1     STFL      e(gr10,0)=fp0
  134| 000B50 stfd     DB440000   1     STFL      d(gr4,0)=fp26
  133| 000B54 stfd     D81E0000   1     STFL      e(gr30,0)=fp0
  134| 000B58 stfd     DB460000   1     STFL      d(gr6,0)=fp26
  135|                              CL.232:
    0| 000B5C add      7C601A14   1     A         gr3=gr0,gr3
    0| 000B60 add      7C802214   1     A         gr4=gr0,gr4
    0| 000B64 add      7CA02A14   1     A         gr5=gr0,gr5
    0| 000B68 add      7CC03214   1     A         gr6=gr0,gr6
    0| 000B6C add      7CE03A14   1     A         gr7=gr0,gr7
    0| 000B70 add      7D004214   1     A         gr8=gr0,gr8
    0| 000B74 add      7D29BA14   1     A         gr9=gr9,gr23
    0| 000B78 add      7D4ABA14   1     A         gr10=gr10,gr23
    0| 000B7C add      7D6BBA14   1     A         gr11=gr11,gr23
    0| 000B80 add      7D8CBA14   1     A         gr12=gr12,gr23
    0| 000B84 add      7FD7F214   1     A         gr30=gr23,gr30
    0| 000B88 add      7FB7EA14   1     A         gr29=gr23,gr29
    0| 000B8C add      7F80E214   1     A         gr28=gr0,gr28
    0| 000B90 add      7F60DA14   1     A         gr27=gr0,gr27
    0| 000B94 add      7F57D214   1     A         gr26=gr23,gr26
    0| 000B98 add      7F37CA14   1     A         gr25=gr23,gr25
  136| 000B9C bc       4200FF30   1     BCT       ctr=CL.110,taken=100%(100,0)
  136|                              CL.109:
  137| 000BA0 ld       E87F0390   1     L8        gr3=#SPILL25(gr31,912)
    0| 000BA4 ld       E89F0398   1     L8        gr4=#SPILL26(gr31,920)
  137| 000BA8 ld       E8BF0388   1     L8        gr5=#SPILL24(gr31,904)
    0| 000BAC ld       E8DF03A0   1     L8        gr6=#SPILL27(gr31,928)
    0| 000BB0 ld       E8FF03A8   1     L8        gr7=#SPILL28(gr31,936)
    0| 000BB4 ld       E91F03B0   1     L8        gr8=#SPILL29(gr31,944)
    0| 000BB8 ld       E93F03B8   1     L8        gr9=#SPILL30(gr31,952)
    0| 000BBC ld       E95F03C0   1     L8        gr10=#SPILL31(gr31,960)
    0| 000BC0 ld       E97F03C8   1     L8        gr11=#SPILL32(gr31,968)
    0| 000BC4 ld       E99F03D0   1     L8        gr12=#SPILL33(gr31,976)
    0| 000BC8 ld       EBDF03D8   1     L8        gr30=#SPILL34(gr31,984)
  137| 000BCC addi     38630001   1     AI        gr3=gr3,1
    0| 000BD0 add      7C84B214   1     A         gr4=gr4,gr22
  137| 000BD4 std      F87F0390   1     ST8       #SPILL25(gr31,912)=gr3
    0| 000BD8 std      F89F0398   1     ST8       #SPILL26(gr31,920)=gr4
  137| 000BDC cmpld    7F232840   1     CL8       cr6=gr3,gr5
    0| 000BE0 add      7CC6B214   1     A         gr6=gr6,gr22
    0| 000BE4 add      7CE7B214   1     A         gr7=gr7,gr22
    0| 000BE8 std      F8DF03A0   1     ST8       #SPILL27(gr31,928)=gr6
    0| 000BEC std      F8FF03A8   1     ST8       #SPILL28(gr31,936)=gr7
    0| 000BF0 add      7D08B214   1     A         gr8=gr8,gr22
    0| 000BF4 add      7D29B214   1     A         gr9=gr9,gr22
    0| 000BF8 std      F91F03B0   1     ST8       #SPILL29(gr31,944)=gr8
    0| 000BFC add      7D4AB214   1     A         gr10=gr10,gr22
    0| 000C00 std      F93F03B8   1     ST8       #SPILL30(gr31,952)=gr9
    0| 000C04 add      7D6BB214   1     A         gr11=gr11,gr22
    0| 000C08 add      7D8CAA14   1     A         gr12=gr12,gr21
    0| 000C0C add      7FD5F214   1     A         gr30=gr21,gr30
    0| 000C10 std      F95F03C0   1     ST8       #SPILL31(gr31,960)=gr10
    0| 000C14 std      F97F03C8   1     ST8       #SPILL32(gr31,968)=gr11
    0| 000C18 std      F99F03D0   1     ST8       #SPILL33(gr31,976)=gr12
    0| 000C1C std      FBDF03D8   1     ST8       #SPILL34(gr31,984)=gr30
    0| 000C20 add      7E94AA14   1     A         gr20=gr20,gr21
    0| 000C24 add      7E73AA14   1     A         gr19=gr19,gr21
    0| 000C28 add      7E52AA14   1     A         gr18=gr18,gr21
    0| 000C2C add      7E31AA14   1     A         gr17=gr17,gr21
    0| 000C30 add      7E10AA14   1     A         gr16=gr16,gr21
    0| 000C34 add      7DEFAA14   1     A         gr15=gr15,gr21
    0| 000C38 add      7DCEB214   1     A         gr14=gr14,gr22
  137| 000C3C bc       4198FE30   1     BT        CL.108,cr6,0x8/llt,taken=80%(80,20)
  137|                              CL.107:
  138| 000C40 ld       E87F02F0   1     L8        gr3=#SPILL5(gr31,752)
    0| 000C44 ld       E89F02E0   1     L8        gr4=#SPILL3(gr31,736)
    0| 000C48 ld       E8BF0300   1     L8        gr5=#SPILL7(gr31,768)
  138| 000C4C ld       E8DF0380   1     L8        gr6=#SPILL23(gr31,896)
    0| 000C50 ld       E8FF0308   1     L8        gr7=#SPILL8(gr31,776)
    0| 000C54 ld       E91F0310   1     L8        gr8=#SPILL9(gr31,784)
    0| 000C58 ld       E93F0318   1     L8        gr9=#SPILL10(gr31,792)
    0| 000C5C ld       E95F0320   1     L8        gr10=#SPILL11(gr31,800)
    0| 000C60 ld       E97F0328   1     L8        gr11=#SPILL12(gr31,808)
    0| 000C64 ld       E99F02E8   1     L8        gr12=#SPILL4(gr31,744)
    0| 000C68 ld       EBDF0330   1     L8        gr30=#SPILL13(gr31,816)
    0| 000C6C ld       EBBF0338   1     L8        gr29=#SPILL14(gr31,824)
    0| 000C70 ld       EB9F0340   1     L8        gr28=#SPILL15(gr31,832)
    0| 000C74 ld       EB7F0348   1     L8        gr27=#SPILL16(gr31,840)
    0| 000C78 ld       EB5F0350   1     L8        gr26=#SPILL17(gr31,848)
    0| 000C7C ld       EB3F0358   1     L8        gr25=#SPILL18(gr31,856)
    0| 000C80 ld       EB1F0360   1     L8        gr24=#SPILL19(gr31,864)
    0| 000C84 ld       EA9F0368   1     L8        gr20=#SPILL20(gr31,872)
    0| 000C88 ld       EA7F0370   1     L8        gr19=#SPILL21(gr31,880)
    0| 000C8C ld       EA5F0378   1     L8        gr18=#SPILL22(gr31,888)
  138| 000C90 addi     38630001   1     AI        gr3=gr3,1
    0| 000C94 add      7CA42A14   1     A         gr5=gr4,gr5
  138| 000C98 std      F87F02F0   1     ST8       #SPILL5(gr31,752)=gr3
    0| 000C9C std      F8BF0300   1     ST8       #SPILL7(gr31,768)=gr5
  138| 000CA0 cmpld    7F233040   1     CL8       cr6=gr3,gr6
    0| 000CA4 add      7CE43A14   1     A         gr7=gr4,gr7
    0| 000CA8 add      7D044214   1     A         gr8=gr4,gr8
    0| 000CAC std      F8FF0308   1     ST8       #SPILL8(gr31,776)=gr7
    0| 000CB0 std      F91F0310   1     ST8       #SPILL9(gr31,784)=gr8
    0| 000CB4 add      7D244A14   1     A         gr9=gr4,gr9
    0| 000CB8 add      7D445214   1     A         gr10=gr4,gr10
    0| 000CBC std      F93F0318   1     ST8       #SPILL10(gr31,792)=gr9
    0| 000CC0 std      F95F0320   1     ST8       #SPILL11(gr31,800)=gr10
    0| 000CC4 add      7D645A14   1     A         gr11=gr4,gr11
    0| 000CC8 add      7FCCF214   1     A         gr30=gr12,gr30
    0| 000CCC std      F97F0328   1     ST8       #SPILL12(gr31,808)=gr11
    0| 000CD0 std      FBDF0330   1     ST8       #SPILL13(gr31,816)=gr30
    0| 000CD4 add      7FACEA14   1     A         gr29=gr12,gr29
    0| 000CD8 add      7F8CE214   1     A         gr28=gr12,gr28
    0| 000CDC std      FBBF0338   1     ST8       #SPILL14(gr31,824)=gr29
    0| 000CE0 std      FB9F0340   1     ST8       #SPILL15(gr31,832)=gr28
    0| 000CE4 add      7F6CDA14   1     A         gr27=gr12,gr27
    0| 000CE8 add      7F4CD214   1     A         gr26=gr12,gr26
    0| 000CEC std      FB7F0348   1     ST8       #SPILL16(gr31,840)=gr27
    0| 000CF0 std      FB5F0350   1     ST8       #SPILL17(gr31,848)=gr26
    0| 000CF4 add      7F2CCA14   1     A         gr25=gr12,gr25
    0| 000CF8 add      7F0CC214   1     A         gr24=gr12,gr24
    0| 000CFC std      FB3F0358   1     ST8       #SPILL18(gr31,856)=gr25
    0| 000D00 std      FB1F0360   1     ST8       #SPILL19(gr31,864)=gr24
    0| 000D04 add      7E8CA214   1     A         gr20=gr12,gr20
    0| 000D08 add      7E649A14   1     A         gr19=gr4,gr19
    0| 000D0C std      FA9F0368   1     ST8       #SPILL20(gr31,872)=gr20
    0| 000D10 std      FA7F0370   1     ST8       #SPILL21(gr31,880)=gr19
    0| 000D14 add      7E449214   1     A         gr18=gr4,gr18
    0| 000D18 std      FA5F0378   1     ST8       #SPILL22(gr31,888)=gr18
  138| 000D1C bc       4198FCE0   1     BT        CL.106,cr6,0x8/llt,taken=80%(80,20)
  139|                              CL.42:
  140| 000D20 ld       E81F02C8   1     L8        gr0=#SPILL0(gr31,712)
  140| 000D24 cmpwi    2C000002   1     C4        cr0=gr0,2
  140| 000D28 bc       4082069C   1     BF        CL.57,cr0,0x4/eq,taken=50%(0,0)
   84| 000D2C ld       E87F02D0   1     L8        gr3=#SPILL1(gr31,720)
   84| 000D30 sradi    7C601674   1     SRA8CA    gr0,ca=gr3,2
   84| 000D34 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
  141| 000D38 rldicr   78041764   1     SLL8      gr4=gr0,2
  141| 000D3C subf     7C041851   1     S_R       gr0,cr0=gr3,gr4
  141| 000D40 std      F89F02D8   1     ST8       #SPILL2(gr31,728)=gr4
  141| 000D44 crand    4C310A02   1     CR_N      cr0=cr[40],0x2/gt,0x2/gt,0x2/gt,cr0
  141| 000D48 bc       408100E8   1     BF        CL.176,cr0,0x2/gt,taken=50%(0,0)
  142| 000D4C ld       EB220000   1     L8        gr25=.&&N&&param(gr2,0)
  146| 000D50 ld       E8A20000   1     L8        gr5=.&&N&field(gr2,0)
  144| 000D54 ld       E8820000   1     L8        gr4=.&&N&grid(gr2,0)
  141| 000D58 addi     38600000   1     LI        gr3=0
  142| 000D5C lwa      E9990006   1     L4A       gr12=<s11:d4:l4>(gr25,4)
  146| 000D60 ld       E9050000   1     L8        gr8=<s86:d0:l8>(gr5,0)
  145| 000D64 ld       E8C50068   1     L8        gr6=<s86:d104:l8>(gr5,104)
  145| 000D68 ld       E8E50080   1     L8        gr7=<s86:d128:l8>(gr5,128)
  146| 000D6C ld       E9250018   1     L8        gr9=<s86:d24:l8>(gr5,24)
  146| 000D70 ld       EBA50030   1     L8        gr29=<s86:d48:l8>(gr5,48)
  146| 000D74 ld       EB850048   1     L8        gr28=<s86:d72:l8>(gr5,72)
  145| 000D78 ld       EB650098   1     L8        gr27=<s86:d152:l8>(gr5,152)
  145| 000D7C ld       EB4500B0   1     L8        gr26=<s86:d176:l8>(gr5,176)
  143| 000D80 lwa      EBD90002   1     L4A       gr30=<s11:d0:l4>(gr25,0)
  144| 000D84 ld       E9440038   1     L8        gr10=<s216:d56:l8>(gr4,56)
  144| 000D88 ld       E9640050   1     L8        gr11=<s216:d80:l8>(gr4,80)
    0| 000D8C cmpwi    2F0C0000   1     C4        cr6=gr12,0
  146| 000D90 ld       E8850060   1     L8        gr4=<s86:d96:l8>(gr5,96)
  145| 000D94 ld       E8A500C8   1     L8        gr5=<s86:d200:l8>(gr5,200)
    0| 000D98 bc       40990E5C   1     BF        CL.791,cr6,0x2/gt,taken=40%(40,60)
    0| 000D9C add      7D084A14   1     A         gr8=gr8,gr9
    0| 000DA0 add      7D3CEA14   1     A         gr9=gr28,gr29
    0| 000DA4 add      7CC63A14   1     A         gr6=gr6,gr7
    0| 000DA8 add      7CFADA14   1     A         gr7=gr26,gr27
  144| 000DAC add      7F2A5A14   1     A         gr25=gr10,gr11
    0| 000DB0 add      7EA84A14   1     A         gr21=gr8,gr9
    0| 000DB4 add      7F063A14   1     A         gr24=gr6,gr7
    0| 000DB8 cmpdi    2C3E0000   1     C8        cr0=gr30,0
    0| 000DBC ori      60210000   1     XNOP      
    0| 000DC0 ori      60210000   1     XNOP      
    0| 000DC4 ori      60210000   1     XNOP      
  141|                              CL.169:
  142| 000DC8 addi     38C00000   1     LI        gr6=0
    0| 000DCC bc       40810050   1     BF        CL.175,cr0,0x2/gt,taken=50%(0,0)
  144| 000DD0 or       7F27CB78   1     LR        gr7=gr25
    0| 000DD4 or       7F17C378   1     LR        gr23=gr24
    0| 000DD8 or       7EB6AB78   1     LR        gr22=gr21
  142|                              CL.170:
  144| 000DDC lfdu     CC270008   1     LFDU      fp1,gr7=x2a(gr7,8)
    0| 000DE0 mtspr    7FC903A6   1     LCTR      ctr=gr30
    0| 000DE4 addi     38C60001   1     AI        gr6=gr6,1
  149| 000DE8 or       7EC8B378   1     LR        gr8=gr22
  148| 000DEC or       7EE9BB78   1     LR        gr9=gr23
  146| 000DF0 or       7ECAB378   1     LR        gr10=gr22
  145| 000DF4 or       7EEBBB78   1     LR        gr11=gr23
    0| 000DF8 fcmpu    FF01E800   1     CFL       cr6=fp1,fp29
    0| 000DFC bc       41990DE8   1     BT        CL.787,cr6,0x40/fgt,taken=50%(0,0)
    0|                              CL.1162:
  145| 000E00 stfdux   7C4B2DEE   1     STFDU     gr11,e(gr11,gr5,0)=fp2
  146| 000E04 stfdux   7F8A25EE   1     STFDU     gr10,d(gr10,gr4,0)=fp28
    0| 000E08 bc       4200FFF8   1     BCT       ctr=CL.1162,taken=100%(100,0)
  151|                              CL.174:
  152| 000E0C cmpld    7F266040   1     CL8       cr6=gr6,gr12
    0| 000E10 add      7EF7D214   1     A         gr23=gr23,gr26
    0| 000E14 add      7ED6E214   1     A         gr22=gr22,gr28
  152| 000E18 bc       4198FFC4   1     BT        CL.170,cr6,0x8/llt,taken=80%(80,20)
  152|                              CL.175:
  153| 000E1C addi     38630001   1     AI        gr3=gr3,1
    0| 000E20 add      7F18DA14   1     A         gr24=gr24,gr27
  153| 000E24 cmpd     7F201800   1     C8        cr6=gr0,gr3
    0| 000E28 add      7EB5EA14   1     A         gr21=gr21,gr29
  153| 000E2C bc       4199FF9C   1     BT        CL.169,cr6,0x2/gt,taken=80%(80,20)
  153|                              CL.176:
  141| 000E30 ld       E87F02D0   1     L8        gr3=#SPILL1(gr31,720)
  141| 000E34 cmpd     7F230000   1     C8        cr6=gr3,gr0
  141| 000E38 crand    4C31CA02   1     CR_N      cr0=cr[46],0x2/gt,0x2/gt,0x2/gt,cr0
  141| 000E3C bc       40810588   1     BF        CL.57,cr0,0x2/gt,taken=50%(0,0)
  142| 000E40 ld       EB420000   1     L8        gr26=.&&N&&param(gr2,0)
  146| 000E44 ld       E8820000   1     L8        gr4=.&&N&field(gr2,0)
  144| 000E48 ld       E8620000   1     L8        gr3=.&&N&grid(gr2,0)
  141| 000E4C or       7C0B0378   1     LR        gr11=gr0
  142| 000E50 lwa      EB3A0006   1     L4A       gr25=<s11:d4:l4>(gr26,4)
  146| 000E54 ld       E8E40030   1     L8        gr7=<s86:d48:l8>(gr4,48)
  145| 000E58 ld       E8C40098   1     L8        gr6=<s86:d152:l8>(gr4,152)
  146| 000E5C ld       EB040000   1     L8        gr24=<s86:d0:l8>(gr4,0)
  145| 000E60 ld       EAE40068   1     L8        gr23=<s86:d104:l8>(gr4,104)
  145| 000E64 ld       EAC40080   1     L8        gr22=<s86:d128:l8>(gr4,128)
  145| 000E68 sradi    7F250E74   1     SRA8CA    gr5,ca=gr25,1
  146| 000E6C ld       EAA40018   1     L8        gr21=<s86:d24:l8>(gr4,24)
  145| 000E70 addze    7D250194   1     ADDE      gr9,ca=gr5,0,ca
  146| 000E74 ld       E8A40048   1     L8        gr5=<s86:d72:l8>(gr4,72)
  145| 000E78 ld       E90400B0   1     L8        gr8=<s86:d176:l8>(gr4,176)
  142| 000E7C rldicr   792E0FA4   1     SLL8      gr14=gr9,1
  143| 000E80 lwa      EA9A0002   1     L4A       gr20=<s11:d0:l4>(gr26,0)
  144| 000E84 ld       E9E30038   1     L8        gr15=<s216:d56:l8>(gr3,56)
  144| 000E88 ld       E9430050   1     L8        gr10=<s216:d80:l8>(gr3,80)
    0| 000E8C mulld    7FA701D2   1     M         gr29=gr7,gr0
    0| 000E90 mulld    7D8601D2   1     M         gr12=gr6,gr0
    0| 000E94 add      7F95C214   1     A         gr28=gr21,gr24
    0| 000E98 add      7F653A14   1     A         gr27=gr5,gr7
    0| 000E9C add      7C76BA14   1     A         gr3=gr22,gr23
    0| 000EA0 add      7FC64214   1     A         gr30=gr6,gr8
  142| 000EA4 subf     7D2EC851   1     S_R       gr9,cr0=gr25,gr14
  142| 000EA8 cmpwi    2F990000   1     C4        cr7=gr25,0
    0| 000EAC add      7F9CDA14   1     A         gr28=gr28,gr27
    0| 000EB0 add      7FC3F214   1     A         gr30=gr3,gr30
  142| 000EB4 crand    4C3D0A02   1     CR_N      cr0=cr[70],0x2/gt,0x2/gt,0x2/gt,cr0
  143| 000EB8 std      FA9F03D8   1     ST8       #SPILL34(gr31,984)=gr20
  146| 000EBC ld       E8640060   1     L8        gr3=<s86:d96:l8>(gr4,96)
  145| 000EC0 ld       E88400C8   1     L8        gr4=<s86:d200:l8>(gr4,200)
    0| 000EC4 bc       40810094   1     BF        CL.648,cr0,0x2/gt,taken=20%(20,80)
  144| 000EC8 or       7E90A379   1     LR_R      gr16,cr0=gr20
  144| 000ECC add      7E8A7A14   1     A         gr20=gr10,gr15
    0| 000ED0 add      7E7CEA14   1     A         gr19=gr28,gr29
    0| 000ED4 add      7E4CF214   1     A         gr18=gr12,gr30
  141|                              CL.161:
  142| 000ED8 addi     39800000   1     LI        gr12=0
    0| 000EDC bc       40810064   1     BF        CL.182,cr0,0x2/gt,taken=50%(0,0)
  144| 000EE0 or       7E9EA378   1     LR        gr30=gr20
    0| 000EE4 or       7E519378   1     LR        gr17=gr18
    0| 000EE8 or       7E709B78   1     LR        gr16=gr19
  142|                              CL.177:
  144| 000EEC lfdu     CC3E0008   1     LFDU      fp1,gr30=x2a(gr30,8)
    0| 000EF0 ld       EBBF03D8   1     L8        gr29=#SPILL34(gr31,984)
    0| 000EF4 addi     398C0001   1     AI        gr12=gr12,1
  148| 000EF8 or       7E3C8B78   1     LR        gr28=gr17
  146| 000EFC or       7E1B8378   1     LR        gr27=gr16
  145| 000F00 or       7E3A8B78   1     LR        gr26=gr17
    0| 000F04 fcmpu    FF01E800   1     CFL       cr6=fp1,fp29
    0| 000F08 mtspr    7FA903A6   1     LCTR      ctr=gr29
  149| 000F0C or       7E1D8378   1     LR        gr29=gr16
    0| 000F10 bc       41990CC4   1     BT        CL.793,cr6,0x40/fgt,taken=50%(0,0)
    0| 000F14 ld       EBBF03D8   1     L8        gr29=#SPILL34(gr31,984)
    0| 000F18 mtspr    7FA903A6   1     LCTR      ctr=gr29
    0| 000F1C ori      60210000   1     XNOP      
    0| 000F20 ori      60210000   1     XNOP      
    0|                              CL.1164:
  145| 000F24 stfdux   7C5A25EE   1     STFDU     gr26,e(gr26,gr4,0)=fp2
  146| 000F28 stfdux   7F9B1DEE   1     STFDU     gr27,d(gr27,gr3,0)=fp28
    0| 000F2C bc       4200FFF8   1     BCT       ctr=CL.1164,taken=100%(100,0)
  151|                              CL.181:
  152| 000F30 cmpd     7F296000   1     C8        cr6=gr9,gr12
    0| 000F34 add      7E058214   1     A         gr16=gr5,gr16
    0| 000F38 add      7E288A14   1     A         gr17=gr8,gr17
  152| 000F3C bc       4199FFB0   1     BT        CL.177,cr6,0x2/gt,taken=80%(80,20)
  152|                              CL.182:
  153| 000F40 ld       E99F02D0   1     L8        gr12=#SPILL1(gr31,720)
  153| 000F44 addi     396B0001   1     AI        gr11=gr11,1
    0| 000F48 add      7E733A14   1     A         gr19=gr19,gr7
    0| 000F4C add      7E469214   1     A         gr18=gr6,gr18
  153| 000F50 cmpld    7F2B6040   1     CL8       cr6=gr11,gr12
  153| 000F54 bc       4198FF84   1     BT        CL.161,cr6,0x8/llt,taken=80%(80,20)
    0|                              CL.648:
    0| 000F58 add      7FD6BA14   1     A         gr30=gr22,gr23
  153| 000F5C ld       EADF02D8   1     L8        gr22=#SPILL2(gr31,728)
    0| 000F60 mulld    7D6039D2   1     M         gr11=gr0,gr7
    0| 000F64 mulld    7C0031D2   1     M         gr0=gr0,gr6
    0| 000F68 add      7D95C214   1     A         gr12=gr21,gr24
    0| 000F6C mulld    7F6549D2   1     M         gr27=gr5,gr9
    0| 000F70 mulld    7F8849D2   1     M         gr28=gr8,gr9
    0| 000F74 add      7F436214   1     A         gr26=gr3,gr12
    0| 000F78 add      7FC4F214   1     A         gr30=gr4,gr30
  153| 000F7C addi     3BB6FFFF   1     AI        gr29=gr22,-1
    0| 000F80 add      7D6BD214   1     A         gr11=gr11,gr26
    0| 000F84 add      7FC0F214   1     A         gr30=gr0,gr30
  153| 000F88 sradi    7FAC1674   1     SRA8CA    gr12,ca=gr29,2
    0| 000F8C addi     3BAEFFFF   1     AI        gr29=gr14,-1
    0| 000F90 rldicr   78F41764   1     SLL8      gr20=gr7,2
    0| 000F94 add      7D6BDA14   1     A         gr11=gr11,gr27
    0| 000F98 std      FA9F02D8   1     ST8       #SPILL2(gr31,728)=gr20
    0| 000F9C rldicr   78A00FA4   1     SLL8      gr0=gr5,1
    0| 000FA0 rldicr   78D31764   1     SLL8      gr19=gr6,2
    0| 000FA4 rldicr   79150FA4   1     SLL8      gr21=gr8,1
    0| 000FA8 std      FA7F02E0   1     ST8       #SPILL3(gr31,736)=gr19
    0| 000FAC add      7F1CF214   1     A         gr24=gr28,gr30
  153| 000FB0 addze    7D8C0194   1     ADDE      gr12,ca=gr12,0,ca
  142| 000FB4 cmpd     7C394800   1     C8        cr0=gr25,gr9
    0| 000FB8 sradi    7FB90E74   1     SRA8CA    gr25,ca=gr29,1
    0| 000FBC rldicr   793A1F24   1     SLL8      gr26=gr9,3
    0| 000FC0 add      7EEA7A14   1     A         gr23=gr10,gr15
    0| 000FC4 add      7F855A14   1     A         gr28=gr5,gr11
    0| 000FC8 subf     7F67A050   1     S         gr27=gr20,gr7
    0| 000FCC add      7FC05A14   1     A         gr30=gr0,gr11
    0| 000FD0 rldicr   78FD0FA4   1     SLL8      gr29=gr7,1
    0| 000FD4 subf     7D669850   1     S         gr11=gr19,gr6
    0| 000FD8 add      7CB5C214   1     A         gr5=gr21,gr24
    0| 000FDC rldicr   78C90FA4   1     SLL8      gr9=gr6,1
    0| 000FE0 add      7D48C214   1     A         gr10=gr8,gr24
    0| 000FE4 addze    7D190194   1     ADDE      gr8,ca=gr25,0,ca
    0| 000FE8 add      7E37D214   1     A         gr17=gr23,gr26
    0| 000FEC add      7E14E214   1     A         gr16=gr20,gr28
    0| 000FF0 std      FA3F02F0   1     ST8       #SPILL5(gr31,752)=gr17
    0| 000FF4 std      FA1F02F8   1     ST8       #SPILL6(gr31,760)=gr16
    0| 000FF8 add      7DFBF214   1     A         gr15=gr27,gr30
    0| 000FFC add      7DDCEA14   1     A         gr14=gr28,gr29
    0| 001000 std      F9FF0300   1     ST8       #SPILL7(gr31,768)=gr15
    0| 001004 std      F9DF0308   1     ST8       #SPILL8(gr31,776)=gr14
    0| 001008 add      7EDBE214   1     A         gr22=gr27,gr28
    0| 00100C add      7F07E214   1     A         gr24=gr7,gr28
    0| 001010 std      FADF0310   1     ST8       #SPILL9(gr31,784)=gr22
    0| 001014 std      FB1F0318   1     ST8       #SPILL10(gr31,792)=gr24
    0| 001018 add      7F34F214   1     A         gr25=gr20,gr30
    0| 00101C add      7F47F214   1     A         gr26=gr7,gr30
    0| 001020 std      FB3F0320   1     ST8       #SPILL11(gr31,800)=gr25
    0| 001024 std      FB5F0328   1     ST8       #SPILL12(gr31,808)=gr26
    0| 001028 add      7CFDF214   1     A         gr7=gr29,gr30
    0| 00102C add      7EE55A14   1     A         gr23=gr5,gr11
    0| 001030 std      F8FF0330   1     ST8       #SPILL13(gr31,816)=gr7
    0| 001034 std      FAFF0338   1     ST8       #SPILL14(gr31,824)=gr23
    0| 001038 add      7F895214   1     A         gr28=gr9,gr10
    0| 00103C add      7F6A5A14   1     A         gr27=gr10,gr11
    0| 001040 std      FB9F0340   1     ST8       #SPILL15(gr31,832)=gr28
    0| 001044 std      FB7F0348   1     ST8       #SPILL16(gr31,840)=gr27
    0| 001048 add      7FC65214   1     A         gr30=gr6,gr10
    0| 00104C add      7FAA9A14   1     A         gr29=gr10,gr19
    0| 001050 std      FBDF0350   1     ST8       #SPILL17(gr31,848)=gr30
    0| 001054 std      FBBF0358   1     ST8       #SPILL18(gr31,856)=gr29
    0| 001058 add      7D659A14   1     A         gr11=gr5,gr19
    0| 00105C add      7D453214   1     A         gr10=gr5,gr6
    0| 001060 std      F97F0360   1     ST8       #SPILL19(gr31,864)=gr11
    0| 001064 std      F95F0368   1     ST8       #SPILL20(gr31,872)=gr10
    0| 001068 add      7CC54A14   1     A         gr6=gr5,gr9
    0| 00106C addi     38AC0001   1     AI        gr5=gr12,1
    0| 001070 std      F8DF0370   1     ST8       #SPILL21(gr31,880)=gr6
    0| 001074 ld       E99F03D8   1     L8        gr12=#SPILL34(gr31,984)
    0| 001078 std      F8BF0378   1     ST8       #SPILL22(gr31,888)=gr5
  141| 00107C addi     3A400000   1     LI        gr18=0
    0| 001080 addi     39280001   1     AI        gr9=gr8,1
  141| 001084 std      FA5F02E8   1     ST8       #SPILL4(gr31,744)=gr18
    0| 001088 std      F93F0380   1     ST8       #SPILL23(gr31,896)=gr9
  142| 00108C crand    4CBD0A02   1     CR_N      cr1=cr[70],0x2/gt,0x2/gt,0x2/gt,cr1
    0| 001090 crnor    4CA52842   1     CR_NOR    cr1=cr[11],0x2/gt,0x2/gt,0x2/gt,cr1
    0| 001094 cmpdi    2C2C0000   1     C8        cr0=gr12,0
  141|                              CL.112:
  142| 001098 bc       4185024C   1     BT        CL.113,cr1,0x2/gt,taken=20%(20,80)
    0| 00109C ld       E8FF0338   1     L8        gr7=#SPILL14(gr31,824)
    0| 0010A0 ld       E91F0348   1     L8        gr8=#SPILL16(gr31,840)
    0| 0010A4 ld       E93F0350   1     L8        gr9=#SPILL17(gr31,848)
    0| 0010A8 ld       E95F0340   1     L8        gr10=#SPILL15(gr31,832)
    0| 0010AC ld       E97F0360   1     L8        gr11=#SPILL19(gr31,864)
    0| 0010B0 ld       E99F0368   1     L8        gr12=#SPILL20(gr31,872)
    0| 0010B4 std      F8FF0390   1     ST8       #SPILL25(gr31,912)=gr7
    0| 0010B8 std      F91F0398   1     ST8       #SPILL26(gr31,920)=gr8
    0| 0010BC std      F93F03A0   1     ST8       #SPILL27(gr31,928)=gr9
    0| 0010C0 ld       EBDF0370   1     L8        gr30=#SPILL21(gr31,880)
    0| 0010C4 std      F95F03A8   1     ST8       #SPILL28(gr31,936)=gr10
    0| 0010C8 ld       EBBF0358   1     L8        gr29=#SPILL18(gr31,856)
    0| 0010CC ld       EB9F0300   1     L8        gr28=#SPILL7(gr31,768)
    0| 0010D0 std      F97F03B0   1     ST8       #SPILL29(gr31,944)=gr11
    0| 0010D4 std      F99F03B8   1     ST8       #SPILL30(gr31,952)=gr12
  142| 0010D8 addi     38C00000   1     LI        gr6=0
    0| 0010DC std      FBDF03C0   1     ST8       #SPILL31(gr31,960)=gr30
  142| 0010E0 std      F8DF0388   1     ST8       #SPILL24(gr31,904)=gr6
    0| 0010E4 ld       E8BF02F0   1     L8        gr5=#SPILL5(gr31,752)
    0| 0010E8 std      FBBF03C8   1     ST8       #SPILL32(gr31,968)=gr29
    0| 0010EC std      FB9F03D0   1     ST8       #SPILL33(gr31,976)=gr28
    0| 0010F0 ld       EA9F0310   1     L8        gr20=#SPILL9(gr31,784)
    0| 0010F4 ld       EA7F0318   1     L8        gr19=#SPILL10(gr31,792)
    0| 0010F8 ld       EA5F0320   1     L8        gr18=#SPILL11(gr31,800)
    0| 0010FC ld       EA3F0328   1     L8        gr17=#SPILL12(gr31,808)
    0| 001100 ld       EA1F0330   1     L8        gr16=#SPILL13(gr31,816)
    0| 001104 ld       E9FF0308   1     L8        gr15=#SPILL8(gr31,776)
    0| 001108 ld       E9DF02F8   1     L8        gr14=#SPILL6(gr31,760)
  142|                              CL.114:
  143| 00110C bc       40810134   1     BF        CL.115,cr0,0x2/gt,taken=20%(20,80)
    0| 001110 std      F81F03E0   1     ST8       #SPILL35(gr31,992)=gr0
  144| 001114 lfd      C8250008   1     LFL       fp1=x2a(gr5,8)
  144| 001118 lfd      C8650010   1     LFL       fp3=x2a(gr5,16)
    0| 00111C ld       E81F03D8   1     L8        gr0=#SPILL34(gr31,984)
    0| 001120 or       7DC67378   1     LR        gr6=gr14
    0| 001124 or       7E87A378   1     LR        gr7=gr20
    0| 001128 or       7DE87B78   1     LR        gr8=gr15
    0| 00112C or       7E298B78   1     LR        gr9=gr17
    0| 001130 fcmpu    FF01E800   1     CFL       cr6=fp1,fp29
    0| 001134 or       7E6A9B78   2     LR        gr10=gr19
    0| 001138 fcmpu    FF83E800   1     CFL       cr7=fp3,fp29
    0| 00113C or       7E0B8378   2     LR        gr11=gr16
    0| 001140 ld       E99F03C8   1     L8        gr12=#SPILL32(gr31,968)
    0| 001144 ld       EBDF0398   1     L8        gr30=#SPILL26(gr31,920)
    0| 001148 ld       EBBF03A8   1     L8        gr29=#SPILL28(gr31,936)
    0| 00114C ld       EB9F03B8   1     L8        gr28=#SPILL30(gr31,952)
    0| 001150 ld       EB7F03A0   1     L8        gr27=#SPILL27(gr31,928)
    0| 001154 ld       EB5F03C0   1     L8        gr26=#SPILL31(gr31,960)
    0| 001158 or       7E599378   1     LR        gr25=gr18
    0| 00115C ld       EB1F03D0   1     L8        gr24=#SPILL33(gr31,976)
    0| 001160 ld       EAFF03B0   1     L8        gr23=#SPILL29(gr31,944)
    0| 001164 ld       EADF0390   1     L8        gr22=#SPILL25(gr31,912)
    0| 001168 mtspr    7C0903A6   1     LCTR      ctr=gr0
    0| 00116C ld       E81F03E0   1     L8        gr0=#SPILL35(gr31,992)
    0| 001170 ori      60210000   1     XNOP      
    0| 001174 ori      60210000   1     XNOP      
  143|                              CL.116:
  144| 001178 bc       41990A14   1     BT        CL.61,cr6,0x40/fgt,taken=50%(0,0)
  145| 00117C stfd     D85B0000   1     STFL      e(gr27,0)=fp2
  146| 001180 stfd     DB8A0000   1     STFL      d(gr10,0)=fp28
  144| 001184 bc       409D09D4   1     BF        CL.981,cr7,0x40/fgt,taken=50%(0,0)
  148| 001188 stfd     D81C0000   1     STFL      e(gr28,0)=fp0
  149| 00118C stfd     DB490000   1     STFL      d(gr9,0)=fp26
  145| 001190 stfd     D85D0000   1     STFL      e(gr29,0)=fp2
  146| 001194 stfd     DB880000   1     STFL      d(gr8,0)=fp28
  148| 001198 stfd     D81A0000   1     STFL      e(gr26,0)=fp0
  149| 00119C stfd     DB4B0000   1     STFL      d(gr11,0)=fp26
  145| 0011A0 stfd     D85E0000   1     STFL      e(gr30,0)=fp2
  146| 0011A4 stfd     DB870000   1     STFL      d(gr7,0)=fp28
  148| 0011A8 stfd     D8160000   1     STFL      e(gr22,0)=fp0
  149| 0011AC stfd     DB580000   1     STFL      d(gr24,0)=fp26
  145| 0011B0 stfd     D84C0000   1     STFL      e(gr12,0)=fp2
  146| 0011B4 stfd     DB860000   1     STFL      d(gr6,0)=fp28
  148| 0011B8 stfd     D8170000   1     STFL      e(gr23,0)=fp0
  149| 0011BC stfd     DB590000   1     STFL      d(gr25,0)=fp26
  149| 0011C0 b        4800003C   1     B         CL.196,-1
    0|                              CL.907:
  148| 0011C4 stfd     D81C0000   1     STFL      e(gr28,0)=fp0
  149| 0011C8 stfd     DB490000   1     STFL      d(gr9,0)=fp26
  148| 0011CC stfd     D81D0000   1     STFL      e(gr29,0)=fp0
  149| 0011D0 stfd     DB480000   1     STFL      d(gr8,0)=fp26
  148| 0011D4 stfd     D81A0000   1     STFL      e(gr26,0)=fp0
  149| 0011D8 stfd     DB4B0000   1     STFL      d(gr11,0)=fp26
  148| 0011DC stfd     D81E0000   1     STFL      e(gr30,0)=fp0
  149| 0011E0 stfd     DB470000   1     STFL      d(gr7,0)=fp26
  148| 0011E4 stfd     D8160000   1     STFL      e(gr22,0)=fp0
  149| 0011E8 stfd     DB580000   1     STFL      d(gr24,0)=fp26
  148| 0011EC stfd     D80C0000   1     STFL      e(gr12,0)=fp0
  149| 0011F0 stfd     DB460000   1     STFL      d(gr6,0)=fp26
  148| 0011F4 stfd     D8170000   1     STFL      e(gr23,0)=fp0
  149| 0011F8 stfd     DB590000   1     STFL      d(gr25,0)=fp26
  150|                              CL.196:
    0| 0011FC add      7CC33214   1     A         gr6=gr3,gr6
    0| 001200 add      7CE33A14   1     A         gr7=gr3,gr7
    0| 001204 add      7D034214   1     A         gr8=gr3,gr8
    0| 001208 add      7D234A14   1     A         gr9=gr3,gr9
    0| 00120C add      7D435214   1     A         gr10=gr3,gr10
    0| 001210 add      7D635A14   1     A         gr11=gr3,gr11
    0| 001214 add      7D846214   1     A         gr12=gr4,gr12
    0| 001218 add      7FC4F214   1     A         gr30=gr4,gr30
    0| 00121C add      7FA4EA14   1     A         gr29=gr4,gr29
    0| 001220 add      7F84E214   1     A         gr28=gr4,gr28
    0| 001224 add      7F64DA14   1     A         gr27=gr4,gr27
    0| 001228 add      7F44D214   1     A         gr26=gr4,gr26
    0| 00122C add      7F23CA14   1     A         gr25=gr3,gr25
    0| 001230 add      7F03C214   1     A         gr24=gr3,gr24
    0| 001234 add      7EE4BA14   1     A         gr23=gr4,gr23
    0| 001238 add      7EC4B214   1     A         gr22=gr4,gr22
    0| 00123C bc       4200FF3C   1     BCT       ctr=CL.116,taken=100%(100,0)
  151|                              CL.115:
  152| 001240 ld       E8DF0388   1     L8        gr6=#SPILL24(gr31,904)
  152| 001244 ld       E8FF0380   1     L8        gr7=#SPILL23(gr31,896)
    0| 001248 ld       E91F0390   1     L8        gr8=#SPILL25(gr31,912)
    0| 00124C ld       E93F0398   1     L8        gr9=#SPILL26(gr31,920)
    0| 001250 ld       E95F03A0   1     L8        gr10=#SPILL27(gr31,928)
    0| 001254 ld       E97F03A8   1     L8        gr11=#SPILL28(gr31,936)
    0| 001258 ld       E99F03B0   1     L8        gr12=#SPILL29(gr31,944)
    0| 00125C ld       EBDF03B8   1     L8        gr30=#SPILL30(gr31,952)
    0| 001260 ld       EBBF03C0   1     L8        gr29=#SPILL31(gr31,960)
    0| 001264 ld       EB9F03C8   1     L8        gr28=#SPILL32(gr31,968)
    0| 001268 ld       EB7F03D0   1     L8        gr27=#SPILL33(gr31,976)
  152| 00126C addi     38C60001   1     AI        gr6=gr6,1
    0| 001270 add      7D08AA14   1     A         gr8=gr8,gr21
  152| 001274 std      F8DF0388   1     ST8       #SPILL24(gr31,904)=gr6
    0| 001278 std      F91F0390   1     ST8       #SPILL25(gr31,912)=gr8
  152| 00127C cmpld    7F263840   1     CL8       cr6=gr6,gr7
    0| 001280 add      7D29AA14   1     A         gr9=gr9,gr21
    0| 001284 add      7D4AAA14   1     A         gr10=gr10,gr21
    0| 001288 std      F93F0398   1     ST8       #SPILL26(gr31,920)=gr9
    0| 00128C std      F95F03A0   1     ST8       #SPILL27(gr31,928)=gr10
    0| 001290 add      7D6BAA14   1     A         gr11=gr11,gr21
    0| 001294 add      7D8CAA14   1     A         gr12=gr12,gr21
    0| 001298 std      F97F03A8   1     ST8       #SPILL28(gr31,936)=gr11
    0| 00129C add      7FD5F214   1     A         gr30=gr21,gr30
    0| 0012A0 std      F99F03B0   1     ST8       #SPILL29(gr31,944)=gr12
    0| 0012A4 add      7FB5EA14   1     A         gr29=gr21,gr29
    0| 0012A8 add      7F95E214   1     A         gr28=gr21,gr28
    0| 0012AC add      7F60DA14   1     A         gr27=gr0,gr27
    0| 0012B0 std      FBDF03B8   1     ST8       #SPILL30(gr31,952)=gr30
    0| 0012B4 std      FBBF03C0   1     ST8       #SPILL31(gr31,960)=gr29
    0| 0012B8 addi     38A50010   1     AI        gr5=gr5,16
    0| 0012BC std      FB9F03C8   1     ST8       #SPILL32(gr31,968)=gr28
    0| 0012C0 std      FB7F03D0   1     ST8       #SPILL33(gr31,976)=gr27
    0| 0012C4 add      7E80A214   1     A         gr20=gr0,gr20
    0| 0012C8 add      7E609A14   1     A         gr19=gr0,gr19
    0| 0012CC add      7E409214   1     A         gr18=gr0,gr18
    0| 0012D0 add      7E208A14   1     A         gr17=gr0,gr17
    0| 0012D4 add      7E008214   1     A         gr16=gr0,gr16
    0| 0012D8 add      7DE07A14   1     A         gr15=gr0,gr15
    0| 0012DC add      7DC07214   1     A         gr14=gr0,gr14
  152| 0012E0 bc       4198FE2C   1     BT        CL.114,cr6,0x8/llt,taken=80%(80,20)
  152|                              CL.113:
  153| 0012E4 ld       E8BF02E8   1     L8        gr5=#SPILL4(gr31,744)
    0| 0012E8 ld       E8DF02D8   1     L8        gr6=#SPILL2(gr31,728)
    0| 0012EC ld       E8FF02F8   1     L8        gr7=#SPILL6(gr31,760)
  153| 0012F0 ld       E91F0378   1     L8        gr8=#SPILL22(gr31,888)
    0| 0012F4 ld       E93F0300   1     L8        gr9=#SPILL7(gr31,768)
    0| 0012F8 ld       E95F0308   1     L8        gr10=#SPILL8(gr31,776)
    0| 0012FC ld       E97F0310   1     L8        gr11=#SPILL9(gr31,784)
    0| 001300 ld       E99F0318   1     L8        gr12=#SPILL10(gr31,792)
    0| 001304 ld       EBDF0320   1     L8        gr30=#SPILL11(gr31,800)
    0| 001308 ld       EBBF0328   1     L8        gr29=#SPILL12(gr31,808)
    0| 00130C ld       EB9F0330   1     L8        gr28=#SPILL13(gr31,816)
    0| 001310 ld       EB7F02E0   1     L8        gr27=#SPILL3(gr31,736)
    0| 001314 ld       EB5F0338   1     L8        gr26=#SPILL14(gr31,824)
    0| 001318 ld       EB3F0340   1     L8        gr25=#SPILL15(gr31,832)
    0| 00131C ld       EB1F0348   1     L8        gr24=#SPILL16(gr31,840)
    0| 001320 ld       EAFF0350   1     L8        gr23=#SPILL17(gr31,848)
    0| 001324 ld       EADF0358   1     L8        gr22=#SPILL18(gr31,856)
    0| 001328 ld       EA9F0360   1     L8        gr20=#SPILL19(gr31,864)
    0| 00132C ld       EA7F0368   1     L8        gr19=#SPILL20(gr31,872)
    0| 001330 ld       EA5F0370   1     L8        gr18=#SPILL21(gr31,880)
  153| 001334 addi     38A50001   1     AI        gr5=gr5,1
    0| 001338 add      7CE63A14   1     A         gr7=gr6,gr7
  153| 00133C std      F8BF02E8   1     ST8       #SPILL4(gr31,744)=gr5
    0| 001340 std      F8FF02F8   1     ST8       #SPILL6(gr31,760)=gr7
  153| 001344 cmpld    7F254040   1     CL8       cr6=gr5,gr8
    0| 001348 add      7D264A14   1     A         gr9=gr6,gr9
    0| 00134C add      7D465214   1     A         gr10=gr6,gr10
    0| 001350 std      F93F0300   1     ST8       #SPILL7(gr31,768)=gr9
    0| 001354 std      F95F0308   1     ST8       #SPILL8(gr31,776)=gr10
    0| 001358 add      7D665A14   1     A         gr11=gr6,gr11
    0| 00135C add      7D866214   1     A         gr12=gr6,gr12
    0| 001360 std      F97F0310   1     ST8       #SPILL9(gr31,784)=gr11
    0| 001364 std      F99F0318   1     ST8       #SPILL10(gr31,792)=gr12
    0| 001368 add      7FC6F214   1     A         gr30=gr6,gr30
    0| 00136C add      7FA6EA14   1     A         gr29=gr6,gr29
    0| 001370 std      FBDF0320   1     ST8       #SPILL11(gr31,800)=gr30
    0| 001374 std      FBBF0328   1     ST8       #SPILL12(gr31,808)=gr29
    0| 001378 add      7F86E214   1     A         gr28=gr6,gr28
    0| 00137C add      7F5ADA14   1     A         gr26=gr26,gr27
    0| 001380 std      FB9F0330   1     ST8       #SPILL13(gr31,816)=gr28
    0| 001384 std      FB5F0338   1     ST8       #SPILL14(gr31,824)=gr26
    0| 001388 add      7F39DA14   1     A         gr25=gr25,gr27
    0| 00138C add      7F18DA14   1     A         gr24=gr24,gr27
    0| 001390 std      FB3F0340   1     ST8       #SPILL15(gr31,832)=gr25
    0| 001394 std      FB1F0348   1     ST8       #SPILL16(gr31,840)=gr24
    0| 001398 add      7EF7DA14   1     A         gr23=gr23,gr27
    0| 00139C add      7ED6DA14   1     A         gr22=gr22,gr27
    0| 0013A0 std      FAFF0350   1     ST8       #SPILL17(gr31,848)=gr23
    0| 0013A4 std      FADF0358   1     ST8       #SPILL18(gr31,856)=gr22
    0| 0013A8 add      7E94DA14   1     A         gr20=gr20,gr27
    0| 0013AC add      7E73DA14   1     A         gr19=gr19,gr27
    0| 0013B0 std      FA9F0360   1     ST8       #SPILL19(gr31,864)=gr20
    0| 0013B4 std      FA7F0368   1     ST8       #SPILL20(gr31,872)=gr19
    0| 0013B8 add      7E52DA14   1     A         gr18=gr18,gr27
    0| 0013BC std      FA5F0370   1     ST8       #SPILL21(gr31,880)=gr18
  153| 0013C0 bc       4198FCD8   1     BT        CL.112,cr6,0x8/llt,taken=80%(80,20)
  154|                              CL.57:
  155| 0013C4 ld       E81F02C8   1     L8        gr0=#SPILL0(gr31,712)
  155| 0013C8 cmpwi    2C000003   1     C4        cr0=gr0,3
  155| 0013CC bc       40820690   1     BF        CL.245,cr0,0x4/eq,taken=30%(30,70)
   83| 0013D0 ld       E87F02D0   1     L8        gr3=#SPILL1(gr31,720)
   83| 0013D4 sradi    7C601674   1     SRA8CA    gr0,ca=gr3,2
   83| 0013D8 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
  156| 0013DC rldicr   780A1764   1     SLL8      gr10=gr0,2
  156| 0013E0 subf     7CEA1851   1     S_R       gr7,cr0=gr3,gr10
  156| 0013E4 crand    4C310A02   1     CR_N      cr0=cr[40],0x2/gt,0x2/gt,0x2/gt,cr0
  156| 0013E8 bc       408100E0   1     BF        CL.140,cr0,0x2/gt,taken=50%(0,0)
  157| 0013EC ld       EB020000   1     L8        gr24=.&&N&&param(gr2,0)
  161| 0013F0 ld       E8C20000   1     L8        gr6=.&&N&field(gr2,0)
  159| 0013F4 ld       E8820000   1     L8        gr4=.&&N&grid(gr2,0)
  156| 0013F8 addi     38600000   1     LI        gr3=0
  159| 0013FC lfd      C83F00B0   1     LFL       fp1=x30(gr31,176)
  157| 001400 lwa      E8180006   1     L4A       gr0=<s11:d4:l4>(gr24,4)
  161| 001404 ld       E9860000   1     L8        gr12=<s86:d0:l8>(gr6,0)
  160| 001408 ld       E9260068   1     L8        gr9=<s86:d104:l8>(gr6,104)
  160| 00140C ld       E9660080   1     L8        gr11=<s86:d128:l8>(gr6,128)
  161| 001410 ld       EB260018   1     L8        gr25=<s86:d24:l8>(gr6,24)
  161| 001414 ld       EBA60030   1     L8        gr29=<s86:d48:l8>(gr6,48)
  161| 001418 ld       EB860048   1     L8        gr28=<s86:d72:l8>(gr6,72)
  160| 00141C ld       EB660098   1     L8        gr27=<s86:d152:l8>(gr6,152)
  160| 001420 ld       EB4600B0   1     L8        gr26=<s86:d176:l8>(gr6,176)
  158| 001424 lwa      EBD80002   1     L4A       gr30=<s11:d0:l4>(gr24,0)
  159| 001428 ld       E9040070   1     L8        gr8=<s216:d112:l8>(gr4,112)
    0| 00142C cmpwi    2C800000   1     C4        cr1=gr0,0
  159| 001430 ld       E8840088   1     L8        gr4=<s216:d136:l8>(gr4,136)
  161| 001434 ld       E8A60060   1     L8        gr5=<s86:d96:l8>(gr6,96)
  160| 001438 ld       E8C600C8   1     L8        gr6=<s86:d200:l8>(gr6,200)
    0| 00143C bc       40850708   1     BF        CL.806,cr1,0x2/gt,taken=40%(40,60)
    0| 001440 add      7D8CCA14   1     A         gr12=gr12,gr25
    0| 001444 add      7F3CEA14   1     A         gr25=gr28,gr29
    0| 001448 add      7D295A14   1     A         gr9=gr9,gr11
    0| 00144C add      7D7ADA14   1     A         gr11=gr26,gr27
  159| 001450 addi     39080008   1     AI        gr8=gr8,8
    0| 001454 add      7F2CCA14   1     A         gr25=gr12,gr25
    0| 001458 add      7F095A14   1     A         gr24=gr9,gr11
    0| 00145C cmpdi    2C3E0000   1     C8        cr0=gr30,0
  156|                              CL.133:
  157| 001460 addi     39200000   1     LI        gr9=0
    0| 001464 bc       4081004C   1     BF        CL.139,cr0,0x2/gt,taken=50%(0,0)
    0| 001468 lfdx     7C6824AE   1     LFL       fp3=x3a(gr8,gr4,0)
    0| 00146C or       7F17C378   1     LR        gr23=gr24
    0| 001470 or       7F36CB78   1     LR        gr22=gr25
    0| 001474 fcmpu    FC830800   1     CFL       cr1=fp3,fp1
  157|                              CL.134:
    0| 001478 addi     39290001   1     AI        gr9=gr9,1
    0| 00147C bc       418506A8   1     BT        CL.802,cr1,0x40/fgt,taken=50%(0,0)
  161| 001480 or       7ECBB378   1     LR        gr11=gr22
  160| 001484 or       7EECBB78   1     LR        gr12=gr23
    0| 001488 mtspr    7FC903A6   1     LCTR      ctr=gr30
    0| 00148C ori      60210000   1     XNOP      
    0| 001490 ori      60210000   1     XNOP      
    0|                              CL.1166:
  160| 001494 stfdux   7C4C35EE   1     STFDU     gr12,e(gr12,gr6,0)=fp2
  161| 001498 stfdux   7F8B2DEE   1     STFDU     gr11,d(gr11,gr5,0)=fp28
    0| 00149C bc       4200FFF8   1     BCT       ctr=CL.1166,taken=100%(100,0)
  166|                              CL.138:
  167| 0014A0 cmpld    7F290040   1     CL8       cr6=gr9,gr0
    0| 0014A4 add      7EF7D214   1     A         gr23=gr23,gr26
    0| 0014A8 add      7ED6E214   1     A         gr22=gr22,gr28
  167| 0014AC bc       4198FFCC   1     BT        CL.134,cr6,0x8/llt,taken=80%(80,20)
  167|                              CL.139:
  168| 0014B0 addi     38630001   1     AI        gr3=gr3,1
    0| 0014B4 addi     38840008   1     AI        gr4=gr4,8
  168| 0014B8 cmpd     7CA71800   1     C8        cr1=gr7,gr3
    0| 0014BC add      7F18DA14   1     A         gr24=gr24,gr27
    0| 0014C0 add      7F39EA14   1     A         gr25=gr25,gr29
  168| 0014C4 bc       4185FF9C   1     BT        CL.133,cr1,0x2/gt,taken=80%(80,20)
  168|                              CL.140:
  156| 0014C8 ld       E81F02D0   1     L8        gr0=#SPILL1(gr31,720)
  156| 0014CC cmpd     7CA03800   1     C8        cr1=gr0,gr7
  156| 0014D0 crand    4C312A02   1     CR_N      cr0=cr[41],0x2/gt,0x2/gt,0x2/gt,cr0
  156| 0014D4 bc       40810588   1     BF        CL.245,cr0,0x2/gt,taken=30%(30,70)
  157| 0014D8 ld       EA620000   1     L8        gr19=.&&N&&param(gr2,0)
  161| 0014DC ld       E8820000   1     L8        gr4=.&&N&field(gr2,0)
  159| 0014E0 ld       E8620000   1     L8        gr3=.&&N&grid(gr2,0)
    0| 0014E4 rldicr   78FD1F24   1     SLL8      gr29=gr7,3
  156| 0014E8 or       7CEB3B78   1     LR        gr11=gr7
  159| 0014EC lfd      C8DF00B0   1     LFL       fp6=x30(gr31,176)
  157| 0014F0 lwa      E8130006   1     L4A       gr0=<s11:d4:l4>(gr19,4)
  161| 0014F4 ld       E8C40030   1     L8        gr6=<s86:d48:l8>(gr4,48)
  160| 0014F8 ld       E8A40098   1     L8        gr5=<s86:d152:l8>(gr4,152)
  161| 0014FC ld       EB240000   1     L8        gr25=<s86:d0:l8>(gr4,0)
  160| 001500 ld       EB040068   1     L8        gr24=<s86:d104:l8>(gr4,104)
  160| 001504 ld       EAE40080   1     L8        gr23=<s86:d128:l8>(gr4,128)
  160| 001508 sradi    7C080E74   1     SRA8CA    gr8,ca=gr0,1
  161| 00150C ld       EAC40018   1     L8        gr22=<s86:d24:l8>(gr4,24)
  160| 001510 addze    7D880194   1     ADDE      gr12,ca=gr8,0,ca
  161| 001514 ld       E9040048   1     L8        gr8=<s86:d72:l8>(gr4,72)
  160| 001518 ld       E92400B0   1     L8        gr9=<s86:d176:l8>(gr4,176)
  157| 00151C rldicr   798C0FA4   1     SLL8      gr12=gr12,1
  158| 001520 lwa      EA530002   1     L4A       gr18=<s11:d0:l4>(gr19,0)
  159| 001524 ld       E9E30070   1     L8        gr15=<s216:d112:l8>(gr3,112)
  159| 001528 ld       EA030088   1     L8        gr16=<s216:d136:l8>(gr3,136)
    0| 00152C mulld    7F4639D2   1     M         gr26=gr6,gr7
    0| 001530 mulld    7F8539D2   1     M         gr28=gr5,gr7
    0| 001534 add      7F76CA14   1     A         gr27=gr22,gr25
    0| 001538 add      7E864214   1     A         gr20=gr6,gr8
    0| 00153C add      7C77C214   1     A         gr3=gr23,gr24
    0| 001540 add      7FC54A14   1     A         gr30=gr5,gr9
  157| 001544 subf     7EAC0051   1     S_R       gr21,cr0=gr0,gr12
  157| 001548 cmpwi    2F800000   1     C4        cr7=gr0,0
    0| 00154C add      7E94DA14   1     A         gr20=gr20,gr27
    0| 001550 add      7F63F214   1     A         gr27=gr3,gr30
  157| 001554 crand    4C3D0A02   1     CR_N      cr0=cr[70],0x2/gt,0x2/gt,0x2/gt,cr0
  158| 001558 std      FA5F02C8   1     ST8       #SPILL0(gr31,712)=gr18
  161| 00155C ld       E8640060   1     L8        gr3=<s86:d96:l8>(gr4,96)
  160| 001560 ld       E88400C8   1     L8        gr4=<s86:d200:l8>(gr4,200)
    0| 001564 bc       40810088   1     BF        CL.600,cr0,0x2/gt,taken=20%(20,80)
  159| 001568 addi     3BCF0008   1     AI        gr30=gr15,8
    0| 00156C add      7E94D214   1     A         gr20=gr20,gr26
    0| 001570 add      7E7BE214   1     A         gr19=gr27,gr28
    0| 001574 add      7FBD8214   1     A         gr29=gr29,gr16
    0| 001578 cmpdi    2C320000   1     C8        cr0=gr18,0
  156|                              CL.125:
  157| 00157C addi     3B800000   1     LI        gr28=0
    0| 001580 bc       40810050   1     BF        CL.146,cr0,0x2/gt,taken=50%(0,0)
    0| 001584 lfdx     7C3EECAE   1     LFL       fp1=x3a(gr30,gr29,0)
    0| 001588 or       7E729B78   1     LR        gr18=gr19
    0| 00158C or       7E91A378   1     LR        gr17=gr20
    0| 001590 fcmpu    FC813000   1     CFL       cr1=fp1,fp6
  157|                              CL.141:
    0| 001594 addi     3B9C0001   1     AI        gr28=gr28,1
    0| 001598 bc       41850568   1     BT        CL.808,cr1,0x40/fgt,taken=50%(0,0)
    0| 00159C ld       E9DF02C8   1     L8        gr14=#SPILL0(gr31,712)
  161| 0015A0 or       7E3B8B78   1     LR        gr27=gr17
  160| 0015A4 or       7E5A9378   1     LR        gr26=gr18
    0| 0015A8 mtspr    7DC903A6   1     LCTR      ctr=gr14
    0| 0015AC ori      60210000   1     XNOP      
    0| 0015B0 ori      60210000   1     XNOP      
    0|                              CL.1168:
  160| 0015B4 stfdux   7C5A25EE   1     STFDU     gr26,e(gr26,gr4,0)=fp2
  161| 0015B8 stfdux   7F9B1DEE   1     STFDU     gr27,d(gr27,gr3,0)=fp28
    0| 0015BC bc       4200FFF8   1     BCT       ctr=CL.1168,taken=100%(100,0)
  166|                              CL.145:
  167| 0015C0 cmpd     7F35E000   1     C8        cr6=gr21,gr28
    0| 0015C4 add      7E288A14   1     A         gr17=gr8,gr17
    0| 0015C8 add      7E499214   1     A         gr18=gr9,gr18
  167| 0015CC bc       4199FFC8   1     BT        CL.141,cr6,0x2/gt,taken=80%(80,20)
  167|                              CL.146:
  168| 0015D0 ld       EB9F02D0   1     L8        gr28=#SPILL1(gr31,720)
  168| 0015D4 addi     396B0001   1     AI        gr11=gr11,1
    0| 0015D8 add      7E943214   1     A         gr20=gr20,gr6
    0| 0015DC add      7E659A14   1     A         gr19=gr5,gr19
    0| 0015E0 addi     3BBD0008   1     AI        gr29=gr29,8
  168| 0015E4 cmpld    7CABE040   1     CL8       cr1=gr11,gr28
  168| 0015E8 bc       4184FF94   1     BT        CL.125,cr1,0x8/llt,taken=80%(80,20)
    0|                              CL.600:
    0| 0015EC mulld    7D6639D2   1     M         gr11=gr6,gr7
    0| 0015F0 mulld    7FA539D2   1     M         gr29=gr5,gr7
    0| 0015F4 add      7F96CA14   1     A         gr28=gr22,gr25
    0| 0015F8 add      7F77C214   1     A         gr27=gr23,gr24
  168| 0015FC addi     3B4AFFFF   1     AI        gr26=gr10,-1
    0| 001600 mulld    7D48A9D2   1     M         gr10=gr8,gr21
    0| 001604 mulld    7FC9A9D2   1     M         gr30=gr9,gr21
    0| 001608 add      7F83E214   1     A         gr28=gr3,gr28
    0| 00160C add      7F24DA14   1     A         gr25=gr4,gr27
    0| 001610 add      7F9C5A14   1     A         gr28=gr28,gr11
    0| 001614 add      7D79EA14   1     A         gr11=gr25,gr29
  168| 001618 sradi    7F5B1674   1     SRA8CA    gr27,ca=gr26,2
    0| 00161C addi     398CFFFF   1     AI        gr12=gr12,-1
  157| 001620 cmpd     7C20A800   1     C8        cr0=gr0,gr21
    0| 001624 rldicr   78D81764   1     SLL8      gr24=gr6,2
    0| 001628 add      7D4AE214   1     A         gr10=gr10,gr28
    0| 00162C std      FB1F02D0   1     ST8       #SPILL1(gr31,720)=gr24
    0| 001630 rldicr   79000FA4   1     SLL8      gr0=gr8,1
    0| 001634 rldicr   78B71764   1     SLL8      gr23=gr5,2
    0| 001638 rldicr   79360FA4   1     SLL8      gr22=gr9,1
    0| 00163C std      FAFF02D8   1     ST8       #SPILL2(gr31,728)=gr23
    0| 001640 add      7D6BF214   1     A         gr11=gr11,gr30
  168| 001644 addze    7F3B0194   1     ADDE      gr25,ca=gr27,0,ca
    0| 001648 sradi    7D9B0E74   1     SRA8CA    gr27,ca=gr12,1
    0| 00164C subf     7F86C050   1     S         gr28=gr24,gr6
    0| 001650 add      7F485214   1     A         gr26=gr8,gr10
    0| 001654 rldicr   78DD0FA4   1     SLL8      gr29=gr6,1
    0| 001658 add      7FC05214   1     A         gr30=gr0,gr10
    0| 00165C subf     7D45B850   1     S         gr10=gr23,gr5
    0| 001660 add      7D0BB214   1     A         gr8=gr11,gr22
    0| 001664 add      7D695A14   1     A         gr11=gr9,gr11
    0| 001668 rldicr   78A90FA4   1     SLL8      gr9=gr5,1
    0| 00166C rldicr   78EC1F24   1     SLL8      gr12=gr7,3
    0| 001670 add      7CEF8214   1     A         gr7=gr15,gr16
    0| 001674 add      7E9AE214   1     A         gr20=gr26,gr28
    0| 001678 add      7E78D214   1     A         gr19=gr24,gr26
    0| 00167C std      FA9F02E8   1     ST8       #SPILL4(gr31,744)=gr20
    0| 001680 std      FA7F02F0   1     ST8       #SPILL5(gr31,752)=gr19
    0| 001684 add      7E46D214   1     A         gr18=gr6,gr26
    0| 001688 add      7E3AEA14   1     A         gr17=gr26,gr29
    0| 00168C std      FA5F02F8   1     ST8       #SPILL6(gr31,760)=gr18
    0| 001690 std      FA3F0300   1     ST8       #SPILL7(gr31,768)=gr17
    0| 001694 add      7E1CF214   1     A         gr16=gr28,gr30
    0| 001698 add      7DE6F214   1     A         gr15=gr6,gr30
    0| 00169C std      FA1F0308   1     ST8       #SPILL8(gr31,776)=gr16
    0| 0016A0 std      F9FF0310   1     ST8       #SPILL9(gr31,784)=gr15
    0| 0016A4 add      7CDDF214   1     A         gr6=gr29,gr30
    0| 0016A8 add      7DD8F214   1     A         gr14=gr24,gr30
    0| 0016AC std      F8DF0318   1     ST8       #SPILL10(gr31,792)=gr6
    0| 0016B0 std      F9DF0320   1     ST8       #SPILL11(gr31,800)=gr14
    0| 0016B4 add      7F885214   1     A         gr28=gr8,gr10
    0| 0016B8 add      7F455A14   1     A         gr26=gr5,gr11
    0| 0016BC std      FB9F0328   1     ST8       #SPILL12(gr31,808)=gr28
    0| 0016C0 std      FB5F0330   1     ST8       #SPILL13(gr31,816)=gr26
    0| 0016C4 add      7FA95A14   1     A         gr29=gr9,gr11
    0| 0016C8 add      7FCBBA14   1     A         gr30=gr11,gr23
    0| 0016CC std      FBBF0338   1     ST8       #SPILL14(gr31,824)=gr29
    0| 0016D0 std      FBDF0340   1     ST8       #SPILL15(gr31,832)=gr30
    0| 0016D4 add      7D4A5A14   1     A         gr10=gr10,gr11
    0| 0016D8 add      7D684A14   1     A         gr11=gr8,gr9
    0| 0016DC std      F95F0348   1     ST8       #SPILL16(gr31,840)=gr10
    0| 0016E0 std      F97F0350   1     ST8       #SPILL17(gr31,848)=gr11
    0| 0016E4 add      7D28BA14   1     A         gr9=gr8,gr23
    0| 0016E8 add      7CA54214   1     A         gr5=gr5,gr8
    0| 0016EC std      F93F0358   1     ST8       #SPILL18(gr31,856)=gr9
    0| 0016F0 std      F8BF0360   1     ST8       #SPILL19(gr31,864)=gr5
    0| 0016F4 add      7D076214   1     A         gr8=gr7,gr12
    0| 0016F8 addi     39990001   1     AI        gr12=gr25,1
    0| 0016FC std      F91F0368   1     ST8       #SPILL20(gr31,872)=gr8
    0| 001700 ld       EB3F02C8   1     L8        gr25=#SPILL0(gr31,712)
    0| 001704 std      F99F0370   1     ST8       #SPILL21(gr31,880)=gr12
    0| 001708 addze    7F7B0194   1     ADDE      gr27,ca=gr27,0,ca
  156| 00170C addi     3AA00000   1     LI        gr21=0
    0| 001710 addi     38FB0001   1     AI        gr7=gr27,1
  156| 001714 std      FABF02E0   1     ST8       #SPILL3(gr31,736)=gr21
    0| 001718 std      F8FF0378   1     ST8       #SPILL22(gr31,888)=gr7
  157| 00171C crand    4E3D0A02   1     CR_N      cr4=cr[70],0x2/gt,0x2/gt,0x2/gt,cr4
    0| 001720 crnor    4E318842   1     CR_NOR    cr4=cr[44],0x2/gt,0x2/gt,0x2/gt,cr4
    0| 001724 cmpdi    2C390000   1     C8        cr0=gr25,0
  156|                              CL.118:
  157| 001728 bc       41910248   1     BT        CL.119,cr4,0x2/gt,taken=20%(20,80)
    0| 00172C ld       E8DF0358   1     L8        gr6=#SPILL18(gr31,856)
    0| 001730 ld       E8FF0330   1     L8        gr7=#SPILL13(gr31,816)
    0| 001734 ld       E91F0328   1     L8        gr8=#SPILL12(gr31,808)
    0| 001738 ld       E93F0350   1     L8        gr9=#SPILL17(gr31,848)
    0| 00173C ld       E95F0360   1     L8        gr10=#SPILL19(gr31,864)
    0| 001740 ld       E97F0338   1     L8        gr11=#SPILL14(gr31,824)
    0| 001744 std      F8DF0388   1     ST8       #SPILL24(gr31,904)=gr6
    0| 001748 std      F8FF0390   1     ST8       #SPILL25(gr31,912)=gr7
    0| 00174C std      F91F0398   1     ST8       #SPILL26(gr31,920)=gr8
    0| 001750 ld       E99F0340   1     L8        gr12=#SPILL15(gr31,832)
    0| 001754 ld       EBDF0348   1     L8        gr30=#SPILL16(gr31,840)
    0| 001758 std      F93F03A0   1     ST8       #SPILL27(gr31,928)=gr9
    0| 00175C std      F95F03A8   1     ST8       #SPILL28(gr31,936)=gr10
  157| 001760 addi     38A00000   1     LI        gr5=0
    0| 001764 std      F97F03B0   1     ST8       #SPILL29(gr31,944)=gr11
  157| 001768 std      F8BF0380   1     ST8       #SPILL23(gr31,896)=gr5
    0| 00176C std      F99F03B8   1     ST8       #SPILL30(gr31,952)=gr12
    0| 001770 std      FBDF03C0   1     ST8       #SPILL31(gr31,960)=gr30
    0| 001774 ld       EABF0320   1     L8        gr21=#SPILL11(gr31,800)
    0| 001778 ld       EA9F02F8   1     L8        gr20=#SPILL6(gr31,760)
    0| 00177C ld       EA7F0308   1     L8        gr19=#SPILL8(gr31,776)
    0| 001780 ld       EA5F0310   1     L8        gr18=#SPILL9(gr31,784)
    0| 001784 ld       EA3F0318   1     L8        gr17=#SPILL10(gr31,792)
    0| 001788 ld       EA1F0300   1     L8        gr16=#SPILL7(gr31,768)
    0| 00178C ld       E9FF02F0   1     L8        gr15=#SPILL5(gr31,752)
    0| 001790 ld       E9DF02E8   1     L8        gr14=#SPILL4(gr31,744)
    0| 001794 ori      60210000   1     XNOP      
    0| 001798 ori      60210000   1     XNOP      
  157|                              CL.120:
  158| 00179C bc       4081013C   1     BF        CL.121,cr0,0x2/gt,taken=20%(20,80)
    0| 0017A0 std      F81F03E0   1     ST8       #SPILL35(gr31,992)=gr0
  159| 0017A4 ld       EAFF0368   1     L8        gr23=#SPILL20(gr31,872)
    0| 0017A8 ld       E81F02C8   1     L8        gr0=#SPILL0(gr31,712)
    0| 0017AC or       7E058378   1     LR        gr5=gr16
    0| 0017B0 ld       E8DF03B0   1     L8        gr6=#SPILL29(gr31,944)
    0| 0017B4 or       7DE77B78   1     LR        gr7=gr15
    0| 0017B8 or       7DC87378   1     LR        gr8=gr14
  159| 0017BC lfd      C8370008   1     LFL       fp1=x3a(gr23,8)
  159| 0017C0 lfd      C8770010   1     LFL       fp3=x3a(gr23,16)
  159| 0017C4 lfd      C8970018   1     LFL       fp4=x3a(gr23,24)
  159| 0017C8 lfd      C8B70020   1     LFL       fp5=x3a(gr23,32)
    0| 0017CC ld       E93F03B8   1     L8        gr9=#SPILL30(gr31,952)
    0| 0017D0 ld       E95F03C0   1     L8        gr10=#SPILL31(gr31,960)
    0| 0017D4 or       7EABAB78   1     LR        gr11=gr21
    0| 0017D8 fcmpu    FC813000   1     CFL       cr1=fp1,fp6
    0| 0017DC or       7E6C9B78   2     LR        gr12=gr19
    0| 0017E0 fcmpu    FF033000   1     CFL       cr6=fp3,fp6
    0| 0017E4 or       7E3E8B78   2     LR        gr30=gr17
    0| 0017E8 fcmpu    FF843000   1     CFL       cr7=fp4,fp6
    0| 0017EC or       7E9DA378   1     LR        gr29=gr20
    0| 0017F0 fcmpu    FE853000   1     CFL       cr5=fp5,fp6
    0| 0017F4 or       7E5C9378   2     LR        gr28=gr18
    0| 0017F8 ld       EB7F0388   1     L8        gr27=#SPILL24(gr31,904)
    0| 0017FC ld       EB5F0398   1     L8        gr26=#SPILL26(gr31,920)
    0| 001800 ld       EB3F03A0   1     L8        gr25=#SPILL27(gr31,928)
    0| 001804 ld       EB1F0390   1     L8        gr24=#SPILL25(gr31,912)
    0| 001808 ld       EAFF03A8   1     L8        gr23=#SPILL28(gr31,936)
    0| 00180C mtspr    7C0903A6   1     LCTR      ctr=gr0
    0| 001810 ld       E81F03E0   1     L8        gr0=#SPILL35(gr31,992)
  158|                              CL.122:
  159| 001814 bc       418502D4   1     BT        CL.415,cr1,0x40/fgt,taken=50%(0,0)
  160| 001818 stfd     D8580000   1     STFL      e(gr24,0)=fp2
  161| 00181C stfd     DB9D0000   1     STFL      d(gr29,0)=fp28
  160| 001820 stfd     D8570000   1     STFL      e(gr23,0)=fp2
  161| 001824 stfd     DB9C0000   1     STFL      d(gr28,0)=fp28
  159| 001828 bc       4199001C   1     BT        CL.426,cr6,0x40/fgt,taken=50%(0,0)
    0|                              CL.565:
  160| 00182C stfd     D8460000   1     STFL      e(gr6,0)=fp2
  161| 001830 stfd     DB850000   1     STFL      d(gr5,0)=fp28
  160| 001834 stfd     D8590000   1     STFL      e(gr25,0)=fp2
  161| 001838 stfd     DB9E0000   1     STFL      d(gr30,0)=fp28
  159| 00183C bc       419D0034   1     BT        CL.413,cr7,0x40/fgt,taken=50%(0,0)
  160| 001840 b        48000018   1     B         CL.1522,-1
    0|                              CL.426:
  163| 001844 stfd     D8060000   1     STFL      e(gr6,0)=fp0
  164| 001848 stfd     DB450000   1     STFL      d(gr5,0)=fp26
  163| 00184C stfd     D8190000   1     STFL      e(gr25,0)=fp0
  164| 001850 stfd     DB5E0000   1     STFL      d(gr30,0)=fp26
  159| 001854 bc       419D001C   1     BT        CL.413,cr7,0x40/fgt,taken=50%(0,0)
  160|                              CL.1522:
  160| 001858 stfd     D84A0000   1     STFL      e(gr10,0)=fp2
  161| 00185C stfd     DB880000   1     STFL      d(gr8,0)=fp28
  160| 001860 stfd     D85A0000   1     STFL      e(gr26,0)=fp2
  161| 001864 stfd     DB8C0000   1     STFL      d(gr12,0)=fp28
  159| 001868 bc       4195026C   1     BT        CL.412,cr5,0x40/fgt,taken=50%(0,0)
  160| 00186C b        48000018   1     B         CL.1521,-1
  162|                              CL.413:
  163| 001870 stfd     D80A0000   1     STFL      e(gr10,0)=fp0
  164| 001874 stfd     DB480000   1     STFL      d(gr8,0)=fp26
  163| 001878 stfd     D81A0000   1     STFL      e(gr26,0)=fp0
  164| 00187C stfd     DB4C0000   1     STFL      d(gr12,0)=fp26
  159| 001880 bc       41950254   1     BT        CL.412,cr5,0x40/fgt,taken=50%(0,0)
  160|                              CL.1521:
  160| 001884 stfd     D8490000   1     STFL      e(gr9,0)=fp2
  161| 001888 stfd     DB870000   1     STFL      d(gr7,0)=fp28
  160| 00188C stfd     D85B0000   1     STFL      e(gr27,0)=fp2
  161| 001890 stfd     DB8B0000   1     STFL      d(gr11,0)=fp28
  165|                              CL.160:
    0| 001894 add      7CA32A14   1     A         gr5=gr3,gr5
    0| 001898 add      7CC43214   1     A         gr6=gr4,gr6
    0| 00189C add      7CE33A14   1     A         gr7=gr3,gr7
    0| 0018A0 add      7D034214   1     A         gr8=gr3,gr8
    0| 0018A4 add      7D244A14   1     A         gr9=gr4,gr9
    0| 0018A8 add      7D445214   1     A         gr10=gr4,gr10
    0| 0018AC add      7D635A14   1     A         gr11=gr3,gr11
    0| 0018B0 add      7D836214   1     A         gr12=gr3,gr12
    0| 0018B4 add      7FC3F214   1     A         gr30=gr3,gr30
    0| 0018B8 add      7FA3EA14   1     A         gr29=gr3,gr29
    0| 0018BC add      7F83E214   1     A         gr28=gr3,gr28
    0| 0018C0 add      7F64DA14   1     A         gr27=gr4,gr27
    0| 0018C4 add      7F44D214   1     A         gr26=gr4,gr26
    0| 0018C8 add      7F24CA14   1     A         gr25=gr4,gr25
    0| 0018CC add      7F04C214   1     A         gr24=gr4,gr24
    0| 0018D0 add      7EE4BA14   1     A         gr23=gr4,gr23
  166| 0018D4 bc       4200FF40   1     BCT       ctr=CL.122,taken=100%(100,0)
  166|                              CL.121:
  167| 0018D8 ld       E8BF0380   1     L8        gr5=#SPILL23(gr31,896)
    0| 0018DC ld       E8DF0388   1     L8        gr6=#SPILL24(gr31,904)
  167| 0018E0 ld       E8FF0378   1     L8        gr7=#SPILL22(gr31,888)
    0| 0018E4 ld       E91F0390   1     L8        gr8=#SPILL25(gr31,912)
    0| 0018E8 ld       E93F0398   1     L8        gr9=#SPILL26(gr31,920)
    0| 0018EC ld       E95F03A0   1     L8        gr10=#SPILL27(gr31,928)
    0| 0018F0 ld       E97F03A8   1     L8        gr11=#SPILL28(gr31,936)
    0| 0018F4 ld       E99F03B0   1     L8        gr12=#SPILL29(gr31,944)
    0| 0018F8 ld       EBDF03B8   1     L8        gr30=#SPILL30(gr31,952)
    0| 0018FC ld       EBBF03C0   1     L8        gr29=#SPILL31(gr31,960)
  167| 001900 addi     38A50001   1     AI        gr5=gr5,1
    0| 001904 add      7CC6B214   1     A         gr6=gr6,gr22
  167| 001908 std      F8BF0380   1     ST8       #SPILL23(gr31,896)=gr5
    0| 00190C std      F8DF0388   1     ST8       #SPILL24(gr31,904)=gr6
  167| 001910 cmpld    7CA53840   1     CL8       cr1=gr5,gr7
    0| 001914 add      7D08B214   1     A         gr8=gr8,gr22
    0| 001918 add      7D29B214   1     A         gr9=gr9,gr22
    0| 00191C std      F91F0390   1     ST8       #SPILL25(gr31,912)=gr8
    0| 001920 std      F93F0398   1     ST8       #SPILL26(gr31,920)=gr9
    0| 001924 add      7D4AB214   1     A         gr10=gr10,gr22
    0| 001928 add      7D6BB214   1     A         gr11=gr11,gr22
    0| 00192C std      F95F03A0   1     ST8       #SPILL27(gr31,928)=gr10
    0| 001930 add      7D8CB214   1     A         gr12=gr12,gr22
    0| 001934 add      7FD6F214   1     A         gr30=gr22,gr30
    0| 001938 std      F97F03A8   1     ST8       #SPILL28(gr31,936)=gr11
    0| 00193C add      7FB6EA14   1     A         gr29=gr22,gr29
    0| 001940 std      F99F03B0   1     ST8       #SPILL29(gr31,944)=gr12
    0| 001944 std      FBDF03B8   1     ST8       #SPILL30(gr31,952)=gr30
    0| 001948 std      FBBF03C0   1     ST8       #SPILL31(gr31,960)=gr29
    0| 00194C add      7EA0AA14   1     A         gr21=gr0,gr21
    0| 001950 add      7E80A214   1     A         gr20=gr0,gr20
    0| 001954 add      7E609A14   1     A         gr19=gr0,gr19
    0| 001958 add      7E409214   1     A         gr18=gr0,gr18
    0| 00195C add      7E208A14   1     A         gr17=gr0,gr17
    0| 001960 add      7E008214   1     A         gr16=gr0,gr16
    0| 001964 add      7DE07A14   1     A         gr15=gr0,gr15
    0| 001968 add      7DC07214   1     A         gr14=gr0,gr14
  167| 00196C bc       4184FE30   1     BT        CL.120,cr1,0x8/llt,taken=80%(80,20)
  167|                              CL.119:
  168| 001970 ld       E8BF02E0   1     L8        gr5=#SPILL3(gr31,736)
    0| 001974 ld       E8DF02D0   1     L8        gr6=#SPILL1(gr31,720)
    0| 001978 ld       E8FF02E8   1     L8        gr7=#SPILL4(gr31,744)
  168| 00197C ld       E91F0370   1     L8        gr8=#SPILL21(gr31,880)
    0| 001980 ld       E93F02F0   1     L8        gr9=#SPILL5(gr31,752)
    0| 001984 ld       E95F02F8   1     L8        gr10=#SPILL6(gr31,760)
    0| 001988 ld       E97F0300   1     L8        gr11=#SPILL7(gr31,768)
    0| 00198C ld       E99F0308   1     L8        gr12=#SPILL8(gr31,776)
    0| 001990 ld       EBDF0310   1     L8        gr30=#SPILL9(gr31,784)
    0| 001994 ld       EBBF0318   1     L8        gr29=#SPILL10(gr31,792)
    0| 001998 ld       EB9F0320   1     L8        gr28=#SPILL11(gr31,800)
    0| 00199C ld       EB7F02D8   1     L8        gr27=#SPILL2(gr31,728)
    0| 0019A0 ld       EB5F0328   1     L8        gr26=#SPILL12(gr31,808)
    0| 0019A4 ld       EB3F0330   1     L8        gr25=#SPILL13(gr31,816)
    0| 0019A8 ld       EB1F0338   1     L8        gr24=#SPILL14(gr31,824)
    0| 0019AC ld       EAFF0340   1     L8        gr23=#SPILL15(gr31,832)
    0| 0019B0 ld       EABF0348   1     L8        gr21=#SPILL16(gr31,840)
    0| 0019B4 ld       EA9F0350   1     L8        gr20=#SPILL17(gr31,848)
    0| 0019B8 ld       EA7F0358   1     L8        gr19=#SPILL18(gr31,856)
    0| 0019BC ld       EA5F0360   1     L8        gr18=#SPILL19(gr31,864)
    0| 0019C0 ld       EA3F0368   1     L8        gr17=#SPILL20(gr31,872)
  168| 0019C4 addi     38A50001   1     AI        gr5=gr5,1
    0| 0019C8 add      7CE63A14   1     A         gr7=gr6,gr7
  168| 0019CC std      F8BF02E0   1     ST8       #SPILL3(gr31,736)=gr5
    0| 0019D0 std      F8FF02E8   1     ST8       #SPILL4(gr31,744)=gr7
  168| 0019D4 cmpld    7CA54040   1     CL8       cr1=gr5,gr8
    0| 0019D8 add      7D264A14   1     A         gr9=gr6,gr9
    0| 0019DC add      7D465214   1     A         gr10=gr6,gr10
    0| 0019E0 std      F93F02F0   1     ST8       #SPILL5(gr31,752)=gr9
    0| 0019E4 std      F95F02F8   1     ST8       #SPILL6(gr31,760)=gr10
    0| 0019E8 add      7D665A14   1     A         gr11=gr6,gr11
    0| 0019EC add      7D866214   1     A         gr12=gr6,gr12
    0| 0019F0 std      F97F0300   1     ST8       #SPILL7(gr31,768)=gr11
    0| 0019F4 std      F99F0308   1     ST8       #SPILL8(gr31,776)=gr12
    0| 0019F8 add      7FC6F214   1     A         gr30=gr6,gr30
    0| 0019FC add      7FA6EA14   1     A         gr29=gr6,gr29
    0| 001A00 std      FBDF0310   1     ST8       #SPILL9(gr31,784)=gr30
    0| 001A04 std      FBBF0318   1     ST8       #SPILL10(gr31,792)=gr29
    0| 001A08 add      7F86E214   1     A         gr28=gr6,gr28
    0| 001A0C add      7F5ADA14   1     A         gr26=gr26,gr27
    0| 001A10 std      FB9F0320   1     ST8       #SPILL11(gr31,800)=gr28
    0| 001A14 std      FB5F0328   1     ST8       #SPILL12(gr31,808)=gr26
    0| 001A18 add      7F39DA14   1     A         gr25=gr25,gr27
    0| 001A1C add      7F18DA14   1     A         gr24=gr24,gr27
    0| 001A20 std      FB3F0330   1     ST8       #SPILL13(gr31,816)=gr25
    0| 001A24 std      FB1F0338   1     ST8       #SPILL14(gr31,824)=gr24
    0| 001A28 add      7EF7DA14   1     A         gr23=gr23,gr27
    0| 001A2C add      7EB5DA14   1     A         gr21=gr21,gr27
    0| 001A30 std      FAFF0340   1     ST8       #SPILL15(gr31,832)=gr23
    0| 001A34 std      FABF0348   1     ST8       #SPILL16(gr31,840)=gr21
    0| 001A38 add      7E94DA14   1     A         gr20=gr20,gr27
    0| 001A3C add      7E73DA14   1     A         gr19=gr19,gr27
    0| 001A40 std      FA9F0350   1     ST8       #SPILL17(gr31,848)=gr20
    0| 001A44 std      FA7F0358   1     ST8       #SPILL18(gr31,856)=gr19
    0| 001A48 add      7E52DA14   1     A         gr18=gr18,gr27
    0| 001A4C addi     3A310020   1     AI        gr17=gr17,32
    0| 001A50 std      FA5F0360   1     ST8       #SPILL19(gr31,864)=gr18
    0| 001A54 std      FA3F0368   1     ST8       #SPILL20(gr31,872)=gr17
  168| 001A58 bc       4184FCD0   1     BT        CL.118,cr1,0x8/llt,taken=80%(80,20)
  172|                              CL.245:
  172| 001A5C ld       E8210000   1     L8        gr1=#stack(gr1,0),gr31"
  172| 001A60 ld       E8010010   1     L8        gr0=#stack(gr1,16)
  172| 001A64 lwa      E981000A   1     L4A       gr12=#stack(gr1,8)
  172| 001A68 ld       E9C1FF40   1     L8        gr14=#stack(gr1,-192)
  172| 001A6C ld       E9E1FF48   1     L8        gr15=#stack(gr1,-184)
  172| 001A70 ld       EA01FF50   1     L8        gr16=#stack(gr1,-176)
  172| 001A74 ld       EA21FF58   1     L8        gr17=#stack(gr1,-168)
  172| 001A78 mtspr    7C0803A6   1     LLR       lr=gr0
  172| 001A7C ld       EA41FF60   1     L8        gr18=#stack(gr1,-160)
  172| 001A80 ld       EA61FF68   1     L8        gr19=#stack(gr1,-152)
  172| 001A84 ld       EA81FF70   1     L8        gr20=#stack(gr1,-144)
  172| 001A88 ld       EAA1FF78   1     L8        gr21=#stack(gr1,-136)
  172| 001A8C ld       EAC1FF80   1     L8        gr22=#stack(gr1,-128)
  172| 001A90 ld       EAE1FF88   1     L8        gr23=#stack(gr1,-120)
  172| 001A94 ld       EB01FF90   1     L8        gr24=#stack(gr1,-112)
  172| 001A98 ld       EB21FF98   1     L8        gr25=#stack(gr1,-104)
  172| 001A9C ld       EB41FFA0   1     L8        gr26=#stack(gr1,-96)
  172| 001AA0 ld       EB61FFA8   1     L8        gr27=#stack(gr1,-88)
  172| 001AA4 ld       EB81FFB0   1     L8        gr28=#stack(gr1,-80)
  172| 001AA8 ld       EBA1FFB8   1     L8        gr29=#stack(gr1,-72)
  172| 001AAC ld       EBC1FFC0   1     L8        gr30=#stack(gr1,-64)
  172| 001AB0 ld       EBE1FFC8   1     L8        gr31=#stack(gr1,-56)
  172| 001AB4 mtcrf    7D808120   1     MTCRF     cr4=gr12
  172| 001AB8 lfd      CBE1FFF8   1     LFL       fp31=#stack(gr1,-8)
  172| 001ABC lfd      CBC1FFF0   1     LFL       fp30=#stack(gr1,-16)
  172| 001AC0 lfd      CBA1FFE8   1     LFL       fp29=#stack(gr1,-24)
  172| 001AC4 lfd      CB81FFE0   1     LFL       fp28=#stack(gr1,-32)
  172| 001AC8 lfd      CB61FFD8   1     LFL       fp27=#stack(gr1,-40)
  172| 001ACC lfd      CB41FFD0   1     LFL       fp26=#stack(gr1,-48)
  172| 001AD0 bclr     4E800020   1     BA        lr
  162|                              CL.412:
  163| 001AD4 stfd     D8090000   1     STFL      e(gr9,0)=fp0
  164| 001AD8 stfd     DB470000   1     STFL      d(gr7,0)=fp26
  163| 001ADC stfd     D81B0000   1     STFL      e(gr27,0)=fp0
  164| 001AE0 stfd     DB4B0000   1     STFL      d(gr11,0)=fp26
    0| 001AE4 b        4BFFFDB0   1     B         CL.160,-1
  162|                              CL.415:
  163| 001AE8 stfd     D8180000   1     STFL      e(gr24,0)=fp0
  164| 001AEC stfd     DB5D0000   1     STFL      d(gr29,0)=fp26
  163| 001AF0 stfd     D8170000   1     STFL      e(gr23,0)=fp0
  164| 001AF4 stfd     DB5C0000   1     STFL      d(gr28,0)=fp26
  159| 001AF8 bc       4099FD34   1     BF        CL.565,cr6,0x40/fgt,taken=50%(0,0)
  163| 001AFC b        4BFFFD48   1     B         CL.426,-1
    0|                              CL.808:
    0| 001B00 ld       E9DF02C8   1     L8        gr14=#SPILL0(gr31,712)
  164| 001B04 or       7E3B8B78   1     LR        gr27=gr17
  163| 001B08 or       7E5A9378   1     LR        gr26=gr18
    0| 001B0C mtspr    7DC903A6   1     LCTR      ctr=gr14
    0| 001B10 ori      60210000   1     XNOP      
    0|                              CL.1169:
  163| 001B14 stfdux   7C1A25EE   1     STFDU     gr26,e(gr26,gr4,0)=fp0
  164| 001B18 stfdux   7F5B1DEE   1     STFDU     gr27,d(gr27,gr3,0)=fp26
    0| 001B1C bc       4200FFF8   1     BCT       ctr=CL.1169,taken=100%(100,0)
    0| 001B20 b        4BFFFAA0   1     B         CL.145,-1
    0|                              CL.802:
  164| 001B24 or       7ECBB378   1     LR        gr11=gr22
  163| 001B28 or       7EECBB78   1     LR        gr12=gr23
    0| 001B2C mtspr    7FC903A6   1     LCTR      ctr=gr30
    0| 001B30 ori      60210000   1     XNOP      
    0|                              CL.1167:
  163| 001B34 stfdux   7C0C35EE   1     STFDU     gr12,e(gr12,gr6,0)=fp0
  164| 001B38 stfdux   7F4B2DEE   1     STFDU     gr11,d(gr11,gr5,0)=fp26
    0| 001B3C bc       4200FFF8   1     BCT       ctr=CL.1167,taken=100%(100,0)
    0| 001B40 b        4BFFF960   1     B         CL.138,-1
  167|                              CL.806:
    0| 001B44 mtspr    7CE903A6   1     LCTR      ctr=gr7
  167|                              CL.633:
  168| 001B48 addi     38630001   1     AI        gr3=gr3,1
  168| 001B4C cmpd     7CA33800   1     C8        cr1=gr3,gr7
  168| 001B50 bc       4104FFF8   1     BCTT      ctr=CL.633,cr1,0x1/lt,taken=80%(80,20)
    0| 001B54 b        4BFFF974   1     B         CL.140,-1
  131|                              CL.981:
  145| 001B58 stfd     D85C0000   1     STFL      e(gr28,0)=fp2
  146| 001B5C stfd     DB890000   1     STFL      d(gr9,0)=fp28
  145| 001B60 stfd     D85D0000   1     STFL      e(gr29,0)=fp2
  146| 001B64 stfd     DB880000   1     STFL      d(gr8,0)=fp28
  145| 001B68 stfd     D85A0000   1     STFL      e(gr26,0)=fp2
  146| 001B6C stfd     DB8B0000   1     STFL      d(gr11,0)=fp28
  145| 001B70 stfd     D85E0000   1     STFL      e(gr30,0)=fp2
  146| 001B74 stfd     DB870000   1     STFL      d(gr7,0)=fp28
  145| 001B78 stfd     D8560000   1     STFL      e(gr22,0)=fp2
  146| 001B7C stfd     DB980000   1     STFL      d(gr24,0)=fp28
  145| 001B80 stfd     D84C0000   1     STFL      e(gr12,0)=fp2
  146| 001B84 stfd     DB860000   1     STFL      d(gr6,0)=fp28
    0| 001B88 b        48000040   1     B         CL.319,-1
  147|                              CL.61:
  148| 001B8C stfd     D81B0000   1     STFL      e(gr27,0)=fp0
  149| 001B90 stfd     DB4A0000   1     STFL      d(gr10,0)=fp26
  144| 001B94 bc       419DF630   1     BT        CL.907,cr7,0x40/fgt,taken=50%(0,0)
  145| 001B98 stfd     D85C0000   1     STFL      e(gr28,0)=fp2
  146| 001B9C stfd     DB890000   1     STFL      d(gr9,0)=fp28
  148| 001BA0 stfd     D81D0000   1     STFL      e(gr29,0)=fp0
  149| 001BA4 stfd     DB480000   1     STFL      d(gr8,0)=fp26
  145| 001BA8 stfd     D85A0000   1     STFL      e(gr26,0)=fp2
  146| 001BAC stfd     DB8B0000   1     STFL      d(gr11,0)=fp28
  148| 001BB0 stfd     D81E0000   1     STFL      e(gr30,0)=fp0
  149| 001BB4 stfd     DB470000   1     STFL      d(gr7,0)=fp26
  145| 001BB8 stfd     D8560000   1     STFL      e(gr22,0)=fp2
  146| 001BBC stfd     DB980000   1     STFL      d(gr24,0)=fp28
  148| 001BC0 stfd     D80C0000   1     STFL      e(gr12,0)=fp0
  149| 001BC4 stfd     DB460000   1     STFL      d(gr6,0)=fp26
    0|                              CL.319:
  145| 001BC8 stfd     D8570000   1     STFL      e(gr23,0)=fp2
  146| 001BCC stfd     DB990000   1     STFL      d(gr25,0)=fp28
    0| 001BD0 b        4BFFF62C   1     B         CL.196,-1
    0|                              CL.793:
  148| 001BD4 stfdux   7C1C25EE   1     STFDU     gr28,e(gr28,gr4,0)=fp0
  149| 001BD8 stfdux   7F5D1DEE   1     STFDU     gr29,d(gr29,gr3,0)=fp26
    0| 001BDC bc       4200FFF8   1     BCT       ctr=CL.793,taken=100%(100,0)
    0| 001BE0 b        4BFFF350   1     B         CL.181,-1
    0|                              CL.787:
  148| 001BE4 stfdux   7C092DEE   1     STFDU     gr9,e(gr9,gr5,0)=fp0
  149| 001BE8 stfdux   7F4825EE   1     STFDU     gr8,d(gr8,gr4,0)=fp26
    0| 001BEC bc       4200FFF8   1     BCT       ctr=CL.787,taken=100%(100,0)
    0| 001BF0 b        4BFFF21C   1     B         CL.174,-1
  152|                              CL.791:
    0| 001BF4 mtspr    7C0903A6   1     LCTR      ctr=gr0
  152|                              CL.681:
  153| 001BF8 addi     38630001   1     AI        gr3=gr3,1
  153| 001BFC cmpd     7F230000   1     C8        cr6=gr3,gr0
  153| 001C00 bc       4118FFF8   1     BCTT      ctr=CL.681,cr6,0x1/lt,taken=80%(80,20)
    0| 001C04 b        4BFFF22C   1     B         CL.176,-1
  137|                              CL.777:
    0| 001C08 mtspr    7F8903A6   1     LCTR      ctr=gr28
  137|                              CL.724:
  138| 001C0C addi     38630001   1     AI        gr3=gr3,1
  138| 001C10 cmpd     7F23E000   1     C8        cr6=gr3,gr28
  138| 001C14 bc       4118FFF8   1     BCTT      ctr=CL.724,cr6,0x1/lt,taken=80%(80,20)
    0| 001C18 b        4BFFEB5C   1     B         CL.212,-1
   86|                              CL.767:
    0| 001C1C mtspr    7C8903A6   1     LCTR      ctr=gr4
   86|                              CL.756:
   87| 001C20 addi     38A50001   1     AI        gr5=gr5,1
   87| 001C24 cmpd     7CA52000   1     C8        cr1=gr5,gr4
   87| 001C28 bc       4104FFF8   1     BCTT      ctr=CL.756,cr1,0x1/lt,taken=80%(80,20)
    0| 001C2C b        4BFFE860   1     B         CL.244,-1
     |               Tag Table
     | 001C30        00000000 00012223 86120000 00001C30 1F
     |               Instruction count         1804
     |               Straight-line exec time   1817
     |               Constant Area
     | 000000        736F642E 66393000 7067656E 78313049 78323049 70306430
     | 000018        70316431 69646972 65637449 78333049 736F642E 66393049
     | 000030        3F000000 3F800000 3E000000 49424D20 3FB99999 9999999A
     | 000048        00000000

 
 
>>>>> COMPILATION UNIT EPILOGUE SECTION <<<<<
 
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** sodres   === End of Compilation 2 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<




   181|         SUBROUTINE sodres ()
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 4))
                  _alloca((max(int(%VAL(ijkn)),0) * 8))
                  |pgen%nlitems%type.off32 = 4
                  |pgen%nlitems%kind.off40 = 
                  |pgen%nlitems%size.off48 = 
                  |pgen%nlitems%name_addr.off56 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 4
                  |pgen%nlitems%name_len.off64 = 3
                  |pgen%nlitems%item_addr.off72 = loc(x10)
                  |pgen%nlitems%type.off80 = 4
                  |pgen%nlitems%kind.off88 = 
                  |pgen%nlitems%size.off96 = 
                  |pgen%nlitems%name_addr.off104 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 8
                  |pgen%nlitems%name_len.off112 = 3
                  |pgen%nlitems%item_addr.off120 = loc(x20)
                  |pgen%nlitems%type.off128 = 4
                  |pgen%nlitems%kind.off136 = 
                  |pgen%nlitems%size.off144 = 
                  |pgen%nlitems%name_addr.off152 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 12
                  |pgen%nlitems%name_len.off160 = 2
                  |pgen%nlitems%item_addr.off168 = loc(p0)
                  |pgen%nlitems%type.off176 = 4
                  |pgen%nlitems%kind.off184 = 
                  |pgen%nlitems%size.off192 = 
                  |pgen%nlitems%name_addr.off200 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 14
                  |pgen%nlitems%name_len.off208 = 2
                  |pgen%nlitems%item_addr.off216 = loc(d0)
                  |pgen%nlitems%type.off224 = 4
                  |pgen%nlitems%kind.off232 = 
                  |pgen%nlitems%size.off240 = 
                  |pgen%nlitems%name_addr.off248 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 16
                  |pgen%nlitems%name_len.off256 = 2
                  |pgen%nlitems%item_addr.off264 = loc(p1)
                  |pgen%nlitems%type.off272 = 4
                  |pgen%nlitems%kind.off280 = 
                  |pgen%nlitems%size.off288 = 
                  |pgen%nlitems%name_addr.off296 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 18
                  |pgen%nlitems%name_len.off304 = 2
                  |pgen%nlitems%item_addr.off312 = loc(d1)
   209|           x10 =  5.0000000000000000E-001
   210|           x20 =  5.0000000000000000E-001
   212|           d0 =  1.0000000000000000E+000
   213|           p0 =  1.0000000000000000E+000
   214|           d1 =  1.2500000000000000E-001
   215|           p1 =  1.0000000000000000E-001
   217|           IF ((myid == 0)) THEN
   181|             |pgen%version = 129
                    |pgen%name_addr = "pgenx10Ix20Ip0d0p1d1idirectIsod.f90"
                    |pgen%name_len = 4
                    |pgen%num_of_items = 7
                    |pgen%nlitems%type.off320 = 0
                    |pgen%nlitems%kind.off328 = 
                    |pgen%nlitems%size.off336 = 
                    |pgen%nlitems%name_addr.off344 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 20
                    |pgen%nlitems%name_len.off352 = 7
                    |pgen%nlitems%item_addr.off360 = loc(idirect)
   218|             |pgen%name_flags = 0
                    #9 = _xlfBeginIO(1,2,#8,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#9))
   219|             |pgen%name_flags = 0
                    #11 = _xlfBeginIO(2,258,#10,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#11))
   220|             buf_in[].off1744 = x10
   221|             buf_in[].off1752 = x20
   222|             buf_in[].off1760 = d0
   223|             buf_in[].off1768 = p0
   224|             buf_in[].off1776 = d1
   225|             buf_in[].off1784 = p1
   226|             ibuf_in[].off144 = idirect
   227|           ENDIF
   228|           T_9 = 6
                  T_10 = 1275070495
                  T_11 = 0
                  CALL mpi_bcast(buf_in,T_9,T_10,T_11,comm3d,ierr)
   230|           T_12 = 1
                  T_13 = 1275069467
                  T_14 = 0
                  CALL mpi_bcast(ibuf_in,T_12,T_13,T_14,comm3d,ierr)
   232|           IF ((myid <> 0)) THEN
   233|             x10 = buf_in[].off1744
   240|           ENDIF
   243|           RETURN
                END SUBROUTINE sodres


   181|         SUBROUTINE sodres ()
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 4)
                  _alloca(max(int(%VAL(ijkn)),0) * 8)
                  |pgen%nlitems%type.off32 = 4
                  |pgen%nlitems%kind.off40 = 
                  |pgen%nlitems%size.off48 = 
                  |pgen%nlitems%name_addr.off56 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 4
                  |pgen%nlitems%name_len.off64 = 3
                  |pgen%nlitems%item_addr.off72 = loc(x10)
                  |pgen%nlitems%type.off80 = 4
                  |pgen%nlitems%kind.off88 = 
                  |pgen%nlitems%size.off96 = 
                  |pgen%nlitems%name_addr.off104 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 8
                  |pgen%nlitems%name_len.off112 = 3
                  |pgen%nlitems%item_addr.off120 = loc(x20)
                  |pgen%nlitems%type.off128 = 4
                  |pgen%nlitems%kind.off136 = 
                  |pgen%nlitems%size.off144 = 
                  |pgen%nlitems%name_addr.off152 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 12
                  |pgen%nlitems%name_len.off160 = 2
                  |pgen%nlitems%item_addr.off168 = loc(p0)
                  |pgen%nlitems%type.off176 = 4
                  |pgen%nlitems%kind.off184 = 
                  |pgen%nlitems%size.off192 = 
                  |pgen%nlitems%name_addr.off200 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 14
                  |pgen%nlitems%name_len.off208 = 2
                  |pgen%nlitems%item_addr.off216 = loc(d0)
                  |pgen%nlitems%type.off224 = 4
                  |pgen%nlitems%kind.off232 = 
                  |pgen%nlitems%size.off240 = 
                  |pgen%nlitems%name_addr.off248 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 16
                  |pgen%nlitems%name_len.off256 = 2
                  |pgen%nlitems%item_addr.off264 = loc(p1)
                  |pgen%nlitems%type.off272 = 4
                  |pgen%nlitems%kind.off280 = 
                  |pgen%nlitems%size.off288 = 
                  |pgen%nlitems%name_addr.off296 = &
                &   "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 18
                  |pgen%nlitems%name_len.off304 = 2
                  |pgen%nlitems%item_addr.off312 = loc(d1)
   209|           x10 =  5.0000000000000000E-001
   210|           x20 =  5.0000000000000000E-001
   212|           d0 =  1.0000000000000000E+000
   213|           p0 =  1.0000000000000000E+000
   214|           d1 =  1.2500000000000000E-001
   215|           p1 =  1.0000000000000000E-001
   217|           IF ((myid == 0)) THEN
   181|             |pgen%version = 129
                    |pgen%name_addr = "pgenx10Ix20Ip0d0p1d1idirectIsod.f90"
                    |pgen%name_len = 4
                    |pgen%num_of_items = 7
                    |pgen%nlitems%type.off320 = 0
                    |pgen%nlitems%kind.off328 = 
                    |pgen%nlitems%size.off336 = 
                    |pgen%nlitems%name_addr.off344 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIsod.f90" + 20
                    |pgen%nlitems%name_len.off352 = 7
                    |pgen%nlitems%item_addr.off360 = loc(idirect)
   218|             |pgen%name_flags = 0
                    #9 = _xlfBeginIO(1,2,#8,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#9))
   219|             |pgen%name_flags = 0
                    #11 = _xlfBeginIO(2,258,#10,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#11))
   220|             buf_in[].off1744 = x10
   221|             buf_in[].off1752 = x20
   222|             buf_in[].off1760 = d0
   223|             buf_in[].off1768 = p0
   224|             buf_in[].off1776 = d1
   225|             buf_in[].off1784 = p1
   226|             ibuf_in[].off144 = idirect
   227|           ENDIF
   228|           T_9 = 6
                  T_10 = 1275070495
                  T_11 = 0
                  CALL mpi_bcast(buf_in,T_9,T_10,T_11,comm3d,ierr)
   230|           T_12 = 1
                  T_13 = 1275069467
                  T_14 = 0
                  CALL mpi_bcast(ibuf_in,T_12,T_13,T_14,comm3d,ierr)
   232|           IF ((myid <> 0)) THEN
   233|             x10 = buf_in[].off1744
   240|           ENDIF
   243|           RETURN
                END SUBROUTINE sodres

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   suus ssss ssss s---  ---- ---- ---- ssss
 FPR's set/used:   ssss ssss ssss ss--  ---- ---- ---- ----
 CCR's set/used:   ss-- -sss
     | 000000                           PDEF     sodres
  181|                                  PROC      
    0| 000000 std      FBE1FFF8   1     ST8       #stack(gr1,-8)=gr31
    0| 000004 std      FBC1FFF0   1     ST8       #stack(gr1,-16)=gr30
    0| 000008 std      FBA1FFE8   1     ST8       #stack(gr1,-24)=gr29
    0| 00000C std      FB81FFE0   1     ST8       #stack(gr1,-32)=gr28
    0| 000010 mfspr    7C0802A6   1     LFLR      gr0=lr
    0| 000014 std      F8010010   1     ST8       #stack(gr1,16)=gr0
    0| 000018 stdu     F821FD41   1     ST8U      gr1,#stack(gr1,-704)=gr1
    0| 00001C or       7C3F0B78   1     LR        gr31=gr1
    0| 000020 ld       E8C20000   1     L8        gr6=.+CONSTANT_AREA(gr2,0)
  217| 000024 ld       EB820000   1     L8        gr28=.&&N&&mpipar(gr2,0)
  209| 000028 addi     386001FF   1     LI        gr3=511
  212| 00002C addi     380003FF   1     LI        gr0=1023
  209| 000030 rldicr   7864AA86   1     SLL8      gr4=gr3,53
  214| 000034 addi     38A000FF   1     LI        gr5=255
  209| 000038 std      F89F00A0   1     ST8       x10(gr31,160)=gr4
  210| 00003C std      F89F00A8   1     ST8       x20(gr31,168)=gr4
    0| 000040 addi     38E6000C   1     AI        gr7=gr6,12
    0| 000044 addi     39060010   1     AI        gr8=gr6,16
    0| 000048 std      F8FF0118   1     ST8       <a1:d280:l8>(gr31,280)=gr7
    0| 00004C std      F91F0148   1     ST8       <a1:d328:l8>(gr31,328)=gr8
    0| 000050 addi     38FF00A0   1     AI        gr7=gr31,160
  217| 000054 lwz      807C0004   1     L4Z       gr3=<s91:d4:l4>(gr28,4)
    0| 000058 std      F8FF0128   1     ST8       <a1:d296:l8>(gr31,296)=gr7
  215| 00005C lfd      C8060030   1     LFL       fp0=+CONSTANT_AREA(gr6,48)
    0| 000060 addi     38FF00A8   1     AI        gr7=gr31,168
    0| 000064 addi     39060014   1     AI        gr8=gr6,20
    0| 000068 std      F8FF0158   1     ST8       <a1:d344:l8>(gr31,344)=gr7
    0| 00006C std      F91F0178   1     ST8       <a1:d376:l8>(gr31,376)=gr8
  212| 000070 rldicr   7800A2C6   1     SLL8      gr0=gr0,52
  214| 000074 rldicr   78A4B246   1     SLL8      gr4=gr5,54
  212| 000078 std      F81F00B8   1     ST8       d0(gr31,184)=gr0
  213| 00007C std      F81F00B0   1     ST8       p0(gr31,176)=gr0
  214| 000080 std      F89F00C8   1     ST8       d1(gr31,200)=gr4
  215| 000084 stfd     D81F00C0   1     STFL      p1(gr31,192)=fp0
    0| 000088 addi     38A00003   1     LI        gr5=3
    0| 00008C addi     38FF00B0   1     AI        gr7=gr31,176
    0| 000090 std      F8BF0120   1     ST8       <a1:d288:l8>(gr31,288)=gr5
    0| 000094 std      F8BF0150   1     ST8       <a1:d336:l8>(gr31,336)=gr5
    0| 000098 std      F8FF0188   1     ST8       <a1:d392:l8>(gr31,392)=gr7
    0| 00009C addi     39260016   1     AI        gr9=gr6,22
    0| 0000A0 addi     391F00B8   1     AI        gr8=gr31,184
    0| 0000A4 std      F93F01A8   1     ST8       <a1:d424:l8>(gr31,424)=gr9
    0| 0000A8 std      F91F01B8   1     ST8       <a1:d440:l8>(gr31,440)=gr8
    0| 0000AC addi     38000004   1     LI        gr0=4
    0| 0000B0 addi     38800008   1     LI        gr4=8
    0| 0000B4 std      F81F0100   1     ST8       <a1:d256:l8>(gr31,256)=gr0
    0| 0000B8 std      F89F0108   1     ST8       <a1:d264:l8>(gr31,264)=gr4
    0| 0000BC std      F89F0110   1     ST8       <a1:d272:l8>(gr31,272)=gr4
    0| 0000C0 std      F81F0130   1     ST8       <a1:d304:l8>(gr31,304)=gr0
    0| 0000C4 std      F89F0138   1     ST8       <a1:d312:l8>(gr31,312)=gr4
    0| 0000C8 std      F89F0140   1     ST8       <a1:d320:l8>(gr31,320)=gr4
    0| 0000CC std      F81F0160   1     ST8       <a1:d352:l8>(gr31,352)=gr0
    0| 0000D0 std      F89F0168   1     ST8       <a1:d360:l8>(gr31,360)=gr4
    0| 0000D4 std      F89F0170   1     ST8       <a1:d368:l8>(gr31,368)=gr4
    0| 0000D8 std      F81F0190   1     ST8       <a1:d400:l8>(gr31,400)=gr0
    0| 0000DC std      F89F0198   1     ST8       <a1:d408:l8>(gr31,408)=gr4
    0| 0000E0 std      F81F01F0   1     ST8       <a1:d496:l8>(gr31,496)=gr0
    0| 0000E4 std      F89F01F8   1     ST8       <a1:d504:l8>(gr31,504)=gr4
    0| 0000E8 addi     38A00002   1     LI        gr5=2
    0| 0000EC addi     38E60018   1     AI        gr7=gr6,24
    0| 0000F0 std      F8BF01E0   1     ST8       <a1:d480:l8>(gr31,480)=gr5
    0| 0000F4 addi     395F00C0   1     AI        gr10=gr31,192
    0| 0000F8 std      F89F0200   1     ST8       <a1:d512:l8>(gr31,512)=gr4
    0| 0000FC addi     3906001A   1     AI        gr8=gr6,26
    0| 000100 std      F95F01E8   1     ST8       <a1:d488:l8>(gr31,488)=gr10
    0| 000104 addi     393F00C8   1     AI        gr9=gr31,200
    0| 000108 std      F91F0208   1     ST8       <a1:d520:l8>(gr31,520)=gr8
  217| 00010C cmpdi    2C230000   1     C8        cr0=gr3,0
    0| 000110 std      F89F01A0   1     ST8       <a1:d416:l8>(gr31,416)=gr4
    0| 000114 std      F81F01C0   1     ST8       <a1:d448:l8>(gr31,448)=gr0
    0| 000118 std      F89F01C8   1     ST8       <a1:d456:l8>(gr31,456)=gr4
    0| 00011C std      F8BF0180   1     ST8       <a1:d384:l8>(gr31,384)=gr5
    0| 000120 std      F8BF01B0   1     ST8       <a1:d432:l8>(gr31,432)=gr5
    0| 000124 std      F89F01D0   1     ST8       <a1:d464:l8>(gr31,464)=gr4
    0| 000128 std      F8FF01D8   1     ST8       <a1:d472:l8>(gr31,472)=gr7
    0| 00012C std      F8BF0210   1     ST8       <a1:d528:l8>(gr31,528)=gr5
    0| 000130 std      F93F0218   1     ST8       <a1:d536:l8>(gr31,536)=gr9
  217| 000134 bc       408200E0   1     BF        CL.1,cr0,0x4/eq,taken=60%(60,40)
  218| 000138 ld       EBC20000   1     L8        gr30=.$STATIC(gr2,0)
    0| 00013C addi     38600000   1     LI        gr3=0
    0| 000140 addi     38800081   1     LI        gr4=129
    0| 000144 addi     38A60008   1     AI        gr5=gr6,8
    0| 000148 addi     39000007   1     LI        gr8=7
    0| 00014C addi     38C6001C   1     AI        gr6=gr6,28
    0| 000150 addi     38FF0080   1     AI        gr7=gr31,128
  218| 000154 ori      607D8000   1     OIL       gr29=gr3,0x8000
    0| 000158 stw      909F00E0   1     ST4Z      <a1:d224:l4>(gr31,224)=gr4
    0| 00015C std      F8BF00E8   1     ST8       <a1:d232:l8>(gr31,232)=gr5
    0| 000160 std      F81F00F0   1     ST8       <a1:d240:l8>(gr31,240)=gr0
    0| 000164 std      F91F00F8   1     ST8       <a1:d248:l8>(gr31,248)=gr8
    0| 000168 std      F87F0220   1     ST8       <a1:d544:l8>(gr31,544)=gr3
    0| 00016C std      F81F0228   1     ST8       <a1:d552:l8>(gr31,552)=gr0
    0| 000170 std      F81F0230   1     ST8       <a1:d560:l8>(gr31,560)=gr0
    0| 000174 std      F8DF0238   1     ST8       <a1:d568:l8>(gr31,568)=gr6
    0| 000178 std      F91F0240   1     ST8       <a1:d576:l8>(gr31,576)=gr8
    0| 00017C std      F8FF0248   1     ST8       <a1:d584:l8>(gr31,584)=gr7
  218| 000180 stw      907F00E4   1     ST4Z      <a1:d228:l4>(gr31,228)=gr3
  218| 000184 addi     38600001   1     LI        gr3=1
  218| 000188 addi     38800002   1     LI        gr4=2
  218| 00018C or       7FC5F378   1     LR        gr5=gr30
  218| 000190 or       7FA6EB78   1     LR        gr6=gr29
  218| 000194 addi     38E00000   1     LI        gr7=0
  218| 000198 addi     39000000   1     LI        gr8=0
  218| 00019C addi     393F00E0   1     AI        gr9=gr31,224
  218| 0001A0 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#8",gr5,gr6,@PALI_SHADOW_CONST.rns9.,gr7,gr8,|pgen,gr9,#def_xlfBeginIO11",_xlfBeginIO",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  218| 0001A4 ori      60000000   1
  218| 0001A8 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  218| 0001AC ori      60000000   1
  219| 0001B0 addi     38BE0040   1     AI        gr5=gr30,64
  219| 0001B4 addi     38600002   1     LI        gr3=2
  219| 0001B8 addi     38800102   1     LI        gr4=258
  219| 0001BC or       7FA6EB78   1     LR        gr6=gr29
  219| 0001C0 addi     38E00000   1     LI        gr7=0
  219| 0001C4 addi     39000000   1     LI        gr8=0
  219| 0001C8 addi     393F00E0   1     AI        gr9=gr31,224
  219| 0001CC bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#10",gr5,gr6,@PALI_SHADOW_CONST.rns9.,gr7,gr8,|pgen,gr9,#use_xlfBeginIO21,_xlfBeginIO",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  219| 0001D0 ori      60000000   1
  219| 0001D4 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  219| 0001D8 ori      60000000   1
  220| 0001DC lfd      C81F00A0   1     LFL       fp0=x10(gr31,160)
  221| 0001E0 lfd      C83F00A8   1     LFL       fp1=x20(gr31,168)
  222| 0001E4 lfd      C85F00B8   1     LFL       fp2=d0(gr31,184)
  223| 0001E8 lfd      C87F00B0   1     LFL       fp3=p0(gr31,176)
  224| 0001EC lfd      C89F00C8   1     LFL       fp4=d1(gr31,200)
  225| 0001F0 lfd      C8BF00C0   1     LFL       fp5=p1(gr31,192)
  226| 0001F4 lwz      801F0080   1     L4Z       gr0=idirect(gr31,128)
  220| 0001F8 stfd     D81C06D0   1     STFL      <s91:d1744:l8>(gr28,1744)=fp0
  221| 0001FC stfd     D83C06D8   1     STFL      <s91:d1752:l8>(gr28,1752)=fp1
  222| 000200 stfd     D85C06E0   1     STFL      <s91:d1760:l8>(gr28,1760)=fp2
  223| 000204 stfd     D87C06E8   1     STFL      <s91:d1768:l8>(gr28,1768)=fp3
  224| 000208 stfd     D89C06F0   1     STFL      <s91:d1776:l8>(gr28,1776)=fp4
  225| 00020C stfd     D8BC06F8   1     STFL      <s91:d1784:l8>(gr28,1784)=fp5
  226| 000210 stw      901C0090   1     ST4Z      <s91:d144:l4>(gr28,144)=gr0
  227|                              CL.1:
  228| 000214 addis    3FC04C00   1     LIU       gr30=19456
  228| 000218 addi     38000006   1     LI        gr0=6
  228| 00021C addi     387E081F   1     AI        gr3=gr30,2079
  228| 000220 addi     3BA00000   1     LI        gr29=0
  228| 000224 stw      907F0088   1     ST4Z      T_10(gr31,136)=gr3
  228| 000228 addi     387C06D0   1     AI        gr3=gr28,1744
  228| 00022C stw      901F0084   1     ST4Z      T_9(gr31,132)=gr0
  228| 000230 addi     38DF008C   1     AI        gr6=gr31,140
  228| 000234 stw      93BF008C   1     ST4Z      T_11(gr31,140)=gr29
  228| 000238 addi     38BF0088   1     AI        gr5=gr31,136
  228| 00023C addi     389F0084   1     AI        gr4=gr31,132
  228| 000240 addi     38FC0020   1     AI        gr7=gr28,32
  228| 000244 addi     391C0014   1     AI        gr8=gr28,20
  228| 000248 bl       48000001   1     CALL      mpi_bcast,6,buf_in[]",gr3,T_9",gr4,T_10",gr5,T_11",gr6,comm3d",gr7,ierr",gr8,#ProcAlias",mpi_bcast",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  228| 00024C ori      60000000   1
  230| 000250 addi     38000001   1     LI        gr0=1
  230| 000254 addi     387E041B   1     AI        gr3=gr30,1051
  230| 000258 stw      93BF0098   1     ST4Z      T_14(gr31,152)=gr29
  230| 00025C stw      901F0090   1     ST4Z      T_12(gr31,144)=gr0
  230| 000260 stw      907F0094   1     ST4Z      T_13(gr31,148)=gr3
  230| 000264 addi     38DF0098   1     AI        gr6=gr31,152
  230| 000268 addi     38BF0094   1     AI        gr5=gr31,148
  230| 00026C addi     389F0090   1     AI        gr4=gr31,144
  230| 000270 addi     387C0090   1     AI        gr3=gr28,144
  230| 000274 addi     38FC0020   1     AI        gr7=gr28,32
  230| 000278 addi     391C0014   1     AI        gr8=gr28,20
  230| 00027C bl       48000001   1     CALL      mpi_bcast,6,ibuf_in[]",gr3,T_12",gr4,T_13",gr5,T_14",gr6,comm3d",gr7,ierr",gr8,#ProcAlias",mpi_bcast",fcr",#MX_TEMP1",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  230| 000280 ori      60000000   1
  243| 000284 ld       E8210000   1     L8        gr1=#stack(gr1,0),gr31"
  243| 000288 ld       E9810010   1     L8        gr12=#stack(gr1,16)
  243| 00028C ld       EB81FFE0   1     L8        gr28=#stack(gr1,-32)
  243| 000290 ld       EBA1FFE8   1     L8        gr29=#stack(gr1,-24)
  243| 000294 ld       EBC1FFF0   1     L8        gr30=#stack(gr1,-16)
  243| 000298 ld       EBE1FFF8   1     L8        gr31=#stack(gr1,-8)
  243| 00029C mtspr    7D8803A6   1     LLR       lr=gr12
  243| 0002A0 bclr     4E800020   1     BA        lr
     |               Tag Table
     | 0002A4        00000000 00012221 80040000 000002A4 1F
     |               Instruction count          169
     |               Straight-line exec time    169
     |               Constant Area
     | 000000        736F642E 66393000 7067656E 78313049 78323049 70306430
     | 000018        70316431 69646972 65637449 736F642E 66393049 424D2049
     | 000030        3FB99999 9999999A

 
 
>>>>> COMPILATION UNIT EPILOGUE SECTION <<<<<
 
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    sod.f90                     07/08/15   15:48:47
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
 
    Source records read.......................................     243
1501-510  Compilation successful for file sod.f90.
1501-543  Object file created.
