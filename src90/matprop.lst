IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- matprop.f90 07/08/15 15:48:13
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** matprop   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-534 (I) Loop (loop index 1) at matprop.f90 <line 52> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 2) at matprop.f90 <line 53> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 3) at matprop.f90 <line 54> was not SIMD vectorized because it is not profitable to vectorize.
1586-554 (I) Loop (loop index 3) at matprop.f90 <line 56> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 3) at matprop.f90 <line 55> was not SIMD vectorized because it contains operation in (.gam->gam -  1.0000000000000000E+000) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][2ll + (($$CIVF * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 3) at matprop.f90 <line 55> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 3) at matprop.f90 <line 55> was not SIMD vectorized because it contains operation in (.gam->gam -  1.0000000000000000E+000) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][1ll + (($$CIVF * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 3) at matprop.f90 <line 55> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at matprop.f90 <line 56> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 3) at matprop.f90 <line 55> was not SIMD vectorized because it contains operation in (.gam->gam -  1.0000000000000000E+000) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][3ll + (($$CIVF * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 3) at matprop.f90 <line 55> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at matprop.f90 <line 56> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 3) at matprop.f90 <line 55> was not SIMD vectorized because it contains operation in (.gam->gam -  1.0000000000000000E+000) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][($$CIVF * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 3) at matprop.f90 <line 55> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at matprop.f90 <line 56> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 4) at matprop.f90 <line 65> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 5) at matprop.f90 <line 66> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 6) at matprop.f90 <line 67> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 6) at matprop.f90 <line 68> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at matprop.f90 <line 68> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at matprop.f90 <line 69> was not SIMD vectorized because it contains operation in ((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][2ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at matprop.f90 <line 69> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at matprop.f90 <line 68> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][2ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][2ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at matprop.f90 <line 68> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at matprop.f90 <line 68> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][1ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][1ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at matprop.f90 <line 68> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at matprop.f90 <line 69> was not SIMD vectorized because it contains operation in ((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][1ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at matprop.f90 <line 69> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at matprop.f90 <line 69> was not SIMD vectorized because it contains operation in ((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][3ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at matprop.f90 <line 69> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at matprop.f90 <line 69> was not SIMD vectorized because it contains operation in ((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at matprop.f90 <line 69> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at matprop.f90 <line 68> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][3ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][3ll + (($$CIV10 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at matprop.f90 <line 68> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 7) at matprop.f90 <line 74> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 8) at matprop.f90 <line 75> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 9) at matprop.f90 <line 76> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 79> was not SIMD vectorized because it contains operation in  4.0000000000000000E+000 * ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][1ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 78> was not SIMD vectorized because it contains operation in ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] * ((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 78> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because it contains operation in  1.8035657040422665E-005 * (((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][3ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] EXPI  3) which is not suitable for SIMD vectorization.
1586-551 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because it contains unsupported vector data types.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 79> was not SIMD vectorized because it contains operation in  4.0000000000000000E+000 * ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][2ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 78> was not SIMD vectorized because it contains operation in ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][3ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] * ((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][3ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 78> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because it contains operation in  1.8035657040422665E-005 * (((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] EXPI  3) which is not suitable for SIMD vectorization.
1586-551 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because it contains unsupported vector data types.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 79> was not SIMD vectorized because it contains operation in  4.0000000000000000E+000 * ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][3ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because it contains operation in  1.8035657040422665E-005 * (((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][2ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] EXPI  3) which is not suitable for SIMD vectorization.
1586-551 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because it contains unsupported vector data types.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 79> was not SIMD vectorized because it contains operation in  4.0000000000000000E+000 * ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 78> was not SIMD vectorized because it contains operation in ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][2ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] * ((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][2ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 78> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because it contains operation in  1.8035657040422665E-005 * (((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][1ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] EXPI  3) which is not suitable for SIMD vectorization.
1586-551 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because it contains unsupported vector data types.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 77> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at matprop.f90 <line 78> was not SIMD vectorized because it contains operation in ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][1ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] * ((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][1ll + (($$CIV11 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 9) at matprop.f90 <line 78> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 10) at matprop.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 11) at matprop.f90 <line 85> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 12) at matprop.f90 <line 86> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 12) at matprop.f90 <line 87> was not SIMD vectorized because it contains operation in (( 1.0000000000000000E+000 / rmfp0) * (((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][1ll + (($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / rho0 EXP   xnu)) * (((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][1ll + (($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / t_0 EXP   - powr) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 12) at matprop.f90 <line 87> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 12) at matprop.f90 <line 89> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 12) at matprop.f90 <line 90> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 12) at matprop.f90 <line 90> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 12) at matprop.f90 <line 89> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 12) at matprop.f90 <line 87> was not SIMD vectorized because it contains operation in (( 1.0000000000000000E+000 / rmfp0) * (((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / rho0 EXP   xnu)) * (((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / t_0 EXP   - powr) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 12) at matprop.f90 <line 87> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 12) at matprop.f90 <line 91> was not SIMD vectorized because it contains operation in - ((powr * ((double *)((char *).kp  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kp[][($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9]) / ((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 12) at matprop.f90 <line 91> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 12) at matprop.f90 <line 91> was not SIMD vectorized because it contains operation in - ((powr * ((double *)((char *).kp  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kp[][1ll + (($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9]) / ((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][1ll + (($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 12) at matprop.f90 <line 91> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 13) at matprop.f90 <line 93> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 14) at matprop.f90 <line 94> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 15) at matprop.f90 <line 95> was not SIMD vectorized because it is not profitable to vectorize.
1586-554 (I) Loop (loop index 15) at matprop.f90 <line 96> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 15) at matprop.f90 <line 97> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 15) at matprop.f90 <line 96> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 15) at matprop.f90 <line 97> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 15) at matprop.f90 <line 97> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 15) at matprop.f90 <line 97> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 15) at matprop.f90 <line 96> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 15) at matprop.f90 <line 96> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 19) at matprop.f90 <line 93> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 20) at matprop.f90 <line 94> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 21) at matprop.f90 <line 95> was not SIMD vectorized because it is not profitable to vectorize.
1586-554 (I) Loop (loop index 21) at matprop.f90 <line 97> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 21) at matprop.f90 <line 96> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 25) at matprop.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 26) at matprop.f90 <line 85> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 27) at matprop.f90 <line 86> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 27) at matprop.f90 <line 91> was not SIMD vectorized because it contains operation in - ((powr * ((double *)((char *).kp  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kp[][(long long) .kbeg->kbeg + $$CIVB][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9]) / ((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][(long long) .kbeg->kbeg + $$CIVB][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 27) at matprop.f90 <line 91> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 27) at matprop.f90 <line 87> was not SIMD vectorized because it contains operation in (( 1.0000000000000000E+000 / rmfp0) * (((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][(long long) .kbeg->kbeg + $$CIVB][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / rho0 EXP   xnu)) * (((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][(long long) .kbeg->kbeg + $$CIVB][(long long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / t_0 EXP   - powr) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 27) at matprop.f90 <line 87> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 27) at matprop.f90 <line 90> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 27) at matprop.f90 <line 89> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 31) at matprop.f90 <line 74> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 32) at matprop.f90 <line 75> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 33) at matprop.f90 <line 76> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 33) at matprop.f90 <line 78> was not SIMD vectorized because it contains operation in ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][(long long) .kbeg->kbeg + $$CIV8][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] * ((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][(long long) .kbeg->kbeg + $$CIV8][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 33) at matprop.f90 <line 78> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 33) at matprop.f90 <line 79> was not SIMD vectorized because it contains operation in  4.0000000000000000E+000 * ((double *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->dbbdt[][(long long) .kbeg->kbeg + $$CIV8][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 33) at matprop.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 33) at matprop.f90 <line 77> was not SIMD vectorized because it contains operation in  1.8035657040422665E-005 * (((double *)((char *).t  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[][(long long) .kbeg->kbeg + $$CIV8][(long long) .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + $$CIV6] EXPI  3) which is not suitable for SIMD vectorization.
1586-551 (I) Loop (loop index 33) at matprop.f90 <line 77> was not SIMD vectorized because it contains unsupported vector data types.
1586-554 (I) Loop (loop index 33) at matprop.f90 <line 77> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 37) at matprop.f90 <line 65> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 38) at matprop.f90 <line 66> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 39) at matprop.f90 <line 67> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 39) at matprop.f90 <line 68> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 39) at matprop.f90 <line 68> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 39) at matprop.f90 <line 69> was not SIMD vectorized because it contains operation in ((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 39) at matprop.f90 <line 69> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 43) at matprop.f90 <line 52> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 44) at matprop.f90 <line 53> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 45) at matprop.f90 <line 54> was not SIMD vectorized because it is not profitable to vectorize.
1586-554 (I) Loop (loop index 45) at matprop.f90 <line 56> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 45) at matprop.f90 <line 55> was not SIMD vectorized because it contains operation in (.gam->gam -  1.0000000000000000E+000) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][(long long) .kbeg->kbeg + $$CIV2][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 45) at matprop.f90 <line 55> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"10">. Total number of the innermost loops SIMD vectorized <"0">.


    11|         SUBROUTINE matprop (e, er, d, gam, t, dtde, p, bb, dbbdt, kr, kp, sg, dkpdt, km, dkedt, dpde, ibeg, iend, jbeg, jend, kbeg, kend)
    51|           IF (.NOT.(leos == 1)) GOTO lab_1
    52|           IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV2 = 0
       Id=43        DO $$CIV2 = $$CIV2, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(4))-1
    53|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV1 = 0
       Id=44            DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    54|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV0 = 0
       Id=45                DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    55|                       p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(kbeg) &
                &               + $$CIV2) = (gam -  1.0000000000000000E+000) * e(&
                &               int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(kbeg) + &
                &               $$CIV2)
    56|                       dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(&
                &               kbeg) + $$CIV2) = gam -  1.0000000000000000E+000
    57|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    52|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                    $$CIVF = int(0)
       Id=1         DO $$CIVF = $$CIVF, int(((int(kend) - (MOD((1 + (int(kend)&
                &        - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    53|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    54|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    55|                       p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,($$CIVF * &
                &               4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &               kbeg)) = (gam -  1.0000000000000000E+000) * e(int(&
                &               ibeg) + $$CIV0,int(jbeg) + $$CIV1,($$CIVF * 4 + &
                &               MOD((1 + (int(kend) - int(kbeg))), 4)) + int(kbeg)&
                &               )
    56|                       dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,(&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)) = gam -  1.0000000000000000E+000
    55|                       p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = (gam -  1.0000000000000000E+000)&
                &                * e(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
    56|                       dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = gam -  1.0000000000000000E+000
    55|                       p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = (gam -  1.0000000000000000E+000)&
                &                * e(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
    56|                       dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = gam -  1.0000000000000000E+000
    55|                       p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = (gam -  1.0000000000000000E+000)&
                &                * e(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
    56|                       dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + ((&
                &               $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = gam -  1.0000000000000000E+000
    57|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    65|           IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV5 = 0
       Id=37        DO $$CIV5 = $$CIV5, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(4))-1
    66|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV4 = 0
       Id=38            DO $$CIV4 = $$CIV4, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    67|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV3 = 0
       Id=39                DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    68|                       t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg) &
                &               + $$CIV5) = (((((gam -  1.0000000000000000E+000) &
                &               * mmw) *  1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,int(kbeg) + $$CIV5)) / d(int(&
                &               ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg) + &
                &               $$CIV5)
    69|                       dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(&
                &               kbeg) + $$CIV5) = ((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) / d(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,int(kbeg) + $$CIV5)
    72|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    65|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                    $$CIV10 = int(0)
       Id=4         DO $$CIV10 = $$CIV10, int(((int(kend) - (MOD((1 + (int(&
                &       kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    66|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV4 = 0
       Id=5             DO $$CIV4 = $$CIV4, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    67|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV3 = 0
       Id=6                 DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    68|                       t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIV10 &
                &               * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + &
                &               int(kbeg)) = (((((gam -  1.0000000000000000E+000) &
                &               * mmw) *  1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,($$CIV10 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg))) / d(int(&
                &               ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIV10 * 4 + &
                &               MOD((1 + (int(kend) - int(kbeg))), 4)) + int(kbeg)&
                &               )
    69|                       dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,(&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)) = ((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) / d(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,($$CIV10 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg))
    68|                       t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,1 + (($$CIV10 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)))
    69|                       dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = ((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) / d(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,1 + (($$CIV10 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))
    68|                       t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,2 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,2 + (($$CIV10 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,2 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)))
    69|                       dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,2 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = ((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) / d(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,2 + (($$CIV10 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))
    68|                       t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,3 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,3 + (($$CIV10 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,3 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)))
    69|                       dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,3 + ((&
                &               $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = ((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) / d(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,3 + (($$CIV10 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))
    72|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    74|           IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV8 = 0
       Id=31        DO $$CIV8 = $$CIV8, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(4))-1
    75|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV7 = 0
       Id=32            DO $$CIV7 = $$CIV7, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    76|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV6 = 0
       Id=33                DO $$CIV6 = $$CIV6, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    77|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &               kbeg) + $$CIV8) =  1.8035657040422665E-005 * (t(&
                &               int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(kbeg) + &
                &               $$CIV8) ** 3)
    78|                       bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(kbeg)&
                &                + $$CIV8) = dbbdt(int(ibeg) + $$CIV6,int(jbeg) + &
                &               $$CIV7,int(kbeg) + $$CIV8) * t(int(ibeg) + $$CIV6,&
                &               int(jbeg) + $$CIV7,int(kbeg) + $$CIV8)
    79|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &               kbeg) + $$CIV8) =  4.0000000000000000E+000 * &
                &               dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &               kbeg) + $$CIV8)
    80|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    74|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                    $$CIV11 = int(0)
       Id=7         DO $$CIV11 = $$CIV11, int(((int(kend) - (MOD((1 + (int(&
                &       kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    75|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV7 = 0
       Id=8             DO $$CIV7 = $$CIV7, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    76|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV6 = 0
       Id=9                 DO $$CIV6 = $$CIV6, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    77|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,(&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)) =  1.8035657040422665E-005 * (t(&
                &               int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,($$CIV11 * &
                &               4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &               kbeg)) ** 3)
    78|                       bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,($$CIV11 &
                &               * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + &
                &               int(kbeg)) = dbbdt(int(ibeg) + $$CIV6,int(jbeg) + &
                &               $$CIV7,($$CIV11 * 4 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 4)) + int(kbeg)) * t(int(ibeg) + $$CIV6,&
                &               int(jbeg) + $$CIV7,($$CIV11 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg))
    79|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,(&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)) =  4.0000000000000000E+000 * &
                &               dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,(&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))
    77|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) =  1.8035657040422665E-005 * (t(&
                &               int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) ** 3)
    78|                       bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = dbbdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,1 + (($$CIV11 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg))) * t(int(&
                &               ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + (($$CIV11 * &
                &               4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &               kbeg)))
    79|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) =  4.0000000000000000E+000 * &
                &               dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)))
    77|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) =  1.8035657040422665E-005 * (t(&
                &               int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) ** 3)
    78|                       bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = dbbdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,2 + (($$CIV11 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg))) * t(int(&
                &               ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + (($$CIV11 * &
                &               4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &               kbeg)))
    79|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) =  4.0000000000000000E+000 * &
                &               dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)))
    77|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) =  1.8035657040422665E-005 * (t(&
                &               int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) ** 3)
    78|                       bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = dbbdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,3 + (($$CIV11 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg))) * t(int(&
                &               ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + (($$CIV11 * &
                &               4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &               kbeg)))
    79|                       dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) =  4.0000000000000000E+000 * &
                &               dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)))
    80|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    84|           IF ((MOD((1 + (int(kend) - int(kbeg))), 2) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIVB = 0
       Id=25        DO $$CIVB = $$CIVB, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(2))-1
    85|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIVA = 0
       Id=26            DO $$CIVA = $$CIVA, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    86|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV9 = 0
       Id=27                DO $$CIV9 = $$CIV9, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    87|                       kr(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(kbeg)&
                &                + $$CIVB) = (( 1.0000000000000000E+000 / rmfp0) &
                &               * (d(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(&
                &               kbeg) + $$CIVB) / rho0 ** xnu)) * (t(int(ibeg) + &
                &               $$CIV9,int(jbeg) + $$CIVA,int(kbeg) + $$CIVB) / &
                &               t_0 ** (-powr))
    89|                       sg(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(kbeg)&
                &                + $$CIVB) =  0.0000000000000000E+000
    90|                       kp(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(kbeg)&
                &                + $$CIVB) = kr(int(ibeg) + $$CIV9,int(jbeg) + &
                &               $$CIVA,int(kbeg) + $$CIVB)
    91|                       dkpdt(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(&
                &               kbeg) + $$CIVB) = -((powr * kp(int(ibeg) + $$CIV9,&
                &               int(jbeg) + $$CIVA,int(kbeg) + $$CIVB)) / t(int(&
                &               ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(kbeg) + &
                &               $$CIVB))
    92|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    84|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 2))) THEN
                    $$CIV12 = int(0)
       Id=10        DO $$CIV12 = $$CIV12, int(((int(kend) - (MOD((1 + (int(&
                &       kend) - int(kbeg))), 2) + int(kbeg))) / 2 + 1))-1
    85|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIVA = 0
       Id=11            DO $$CIVA = $$CIVA, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    86|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV9 = 0
       Id=12                DO $$CIV9 = $$CIV9, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    87|                       kr(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,($$CIV12 &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = (( 1.0000000000000000E+000 / rmfp0) &
                &               * (d(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,(&
                &               $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))), &
                &               2)) + int(kbeg)) / rho0 ** xnu)) * (t(int(ibeg) + &
                &               $$CIV9,int(jbeg) + $$CIVA,($$CIV12 * 2 + MOD((1 + &
                &               (int(kend) - int(kbeg))), 2)) + int(kbeg)) / t_0 &
                &               ** (-powr))
    89|                       sg(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,($$CIV12 &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) =  0.0000000000000000E+000
    90|                       kp(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,($$CIV12 &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = kr(int(ibeg) + $$CIV9,int(jbeg) + &
                &               $$CIVA,($$CIV12 * 2 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 2)) + int(kbeg))
    91|                       dkpdt(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,(&
                &               $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))), &
                &               2)) + int(kbeg)) = -((powr * kp(int(ibeg) + &
                &               $$CIV9,int(jbeg) + $$CIVA,($$CIV12 * 2 + MOD((1 + &
                &               (int(kend) - int(kbeg))), 2)) + int(kbeg))) / t(&
                &               int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,($$CIV12 * &
                &               2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + int(&
                &               kbeg)))
    87|                       kr(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &               $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))), &
                &               2)) + int(kbeg))) = (( 1.0000000000000000E+000 / &
                &               rmfp0) * (d(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,&
                &               1 + (($$CIV12 * 2 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 2)) + int(kbeg))) / rho0 ** xnu)) * (t(&
                &               int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &               $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))), &
                &               2)) + int(kbeg))) / t_0 ** (-powr))
    89|                       sg(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &               $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))), &
                &               2)) + int(kbeg))) =  0.0000000000000000E+000
    90|                       kp(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &               $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))), &
                &               2)) + int(kbeg))) = kr(int(ibeg) + $$CIV9,int(&
                &               jbeg) + $$CIVA,1 + (($$CIV12 * 2 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 2)) + int(kbeg)))
    91|                       dkpdt(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &               $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))), &
                &               2)) + int(kbeg))) = -((powr * kp(int(ibeg) + &
                &               $$CIV9,int(jbeg) + $$CIVA,1 + (($$CIV12 * 2 + MOD(&
                &               (1 + (int(kend) - int(kbeg))), 2)) + int(kbeg)))) &
                &               / t(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &               $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))), &
                &               2)) + int(kbeg))))
    92|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    93|           IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIVE = 0
       Id=19        DO $$CIVE = $$CIVE, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(4))-1
    94|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIVD = 0
       Id=20            DO $$CIVD = $$CIVD, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    95|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIVC = 0
       Id=21                DO $$CIVC = $$CIVC, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    96|                       km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,int(kbeg)&
                &                + $$CIVE) = kp(int(ibeg) + $$CIVC,int(jbeg) + &
                &               $$CIVD,int(kbeg) + $$CIVE)
    97|                       dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,int(&
                &               kbeg) + $$CIVE) = dkpdt(int(ibeg) + $$CIVC,int(&
                &               jbeg) + $$CIVD,int(kbeg) + $$CIVE)
    98|                     ENDDO
                          ENDIF
    99|                 ENDDO
                      ENDIF
   100|             ENDDO
                  ENDIF
    93|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                    $$CIV13 = int(0)
       Id=13        DO $$CIV13 = $$CIV13, int(((int(kend) - (MOD((1 + (int(&
                &       kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    94|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIVD = 0
       Id=14            DO $$CIVD = $$CIVD, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    95|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIVC = 0
       Id=15                DO $$CIVC = $$CIVC, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    96|                       km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,($$CIV13 &
                &               * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + &
                &               int(kbeg)) = kp(int(ibeg) + $$CIVC,int(jbeg) + &
                &               $$CIVD,($$CIV13 * 4 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 4)) + int(kbeg))
    97|                       dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,(&
                &               $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg)) = dkpdt(int(ibeg) + $$CIVC,int(&
                &               jbeg) + $$CIVD,($$CIV13 * 4 + MOD((1 + (int(kend) &
                &               - int(kbeg))), 4)) + int(kbeg))
    96|                       km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,1 + ((&
                &               $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = kp(int(ibeg) + $$CIVC,int(&
                &               jbeg) + $$CIVD,1 + (($$CIV13 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    97|                       dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,1 + ((&
                &               $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = dkpdt(int(ibeg) + $$CIVC,int(&
                &               jbeg) + $$CIVD,1 + (($$CIV13 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    96|                       km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,2 + ((&
                &               $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = kp(int(ibeg) + $$CIVC,int(&
                &               jbeg) + $$CIVD,2 + (($$CIV13 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    97|                       dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,2 + ((&
                &               $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = dkpdt(int(ibeg) + $$CIVC,int(&
                &               jbeg) + $$CIVD,2 + (($$CIV13 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    96|                       km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,3 + ((&
                &               $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = kp(int(ibeg) + $$CIVC,int(&
                &               jbeg) + $$CIVD,3 + (($$CIV13 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    97|                       dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,3 + ((&
                &               $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &               4)) + int(kbeg))) = dkpdt(int(ibeg) + $$CIVC,int(&
                &               jbeg) + $$CIVD,3 + (($$CIV13 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    98|                     ENDDO
                          ENDIF
    99|                 ENDDO
                      ENDIF
   100|             ENDDO
                  ENDIF
   103|           GOTO lab_96
    61|           lab_96
                  RETURN
    58|           lab_1
    59|           IF ((myid == 0)) THEN
                    |fmt_args%version = 129
                    |fmt_args%fmt_string_addr = NULL
                    |fmt_args%fmt_string_len = int(")
                    |fmt_args%stack_frame = NULL
                    |fmt_args%call_back = NULL
                    #107 = _xlfBeginIO(6,259,#106,32772,NULL,0,|fmt_args)
                    _xlfEndIO(%VAL(#107))
                  ENDIF
    60|           CALL mpi_finalize(ierr)
    61|           CALL _xlfStop(NULL,0)
                  RETURN
   103|         END SUBROUTINE matprop


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0            52            43    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            53            44    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            54            45    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            55                  Loop was not SIMD vectorized because it contains 
                                          operation in (.gam->gam -  1.0000000000000000E+000) * 
                                          ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][(long long) 
                                          .kbeg->kbeg + $$CIV2][(long long) .jbeg->jbeg + 
                                          $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is 
                                          not  suitable for SIMD vectorization.
         0            55                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            56                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            52             1    Outer loop has been unrolled 4 time(s).
         0            52             1    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            53             2    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            54             3    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            55                  Loop was not SIMD vectorized because it contains 
                                          operation in (.gam->gam -  1.0000000000000000E+000) * 
                                          ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][($$CIVF * 4ll + (1ll 
                                          + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long 
                                          long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + 
                                          $$CIV0] which is not  suitable for SIMD vectorization.
         0            55                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            56                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            55                  Loop was not SIMD vectorized because it contains 
                                          operation in (.gam->gam -  1.0000000000000000E+000) * 
                                          ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][1ll + (($$CIVF * 4ll 
                                          + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long 
                                          long) .ibeg->ibeg + $$CIV0] which is not  suitable 
                                          for SIMD vectorization.
         0            55                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            56                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            55                  Loop was not SIMD vectorized because it contains 
                                          operation in (.gam->gam -  1.0000000000000000E+000) * 
                                          ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][2ll + (($$CIVF * 4ll 
                                          + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long 
                                          long) .ibeg->ibeg + $$CIV0] which is not  suitable 
                                          for SIMD vectorization.
         0            55                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            56                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            55                  Loop was not SIMD vectorized because it contains 
                                          operation in (.gam->gam -  1.0000000000000000E+000) * 
                                          ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][3ll + (($$CIVF * 4ll 
                                          + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long 
                                          long) .ibeg->ibeg + $$CIV0] which is not  suitable 
                                          for SIMD vectorization.
         0            55                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            56                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65            37    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            66            38    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            67            39    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            68                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][(long long) 
                                          .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double 
                                          *)((char *).d  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->d[][(long long) .kbeg->kbeg + 
                                          $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) 
                                          .ibeg->ibeg + $$CIV3] which is not  suitable for SIMD 
                                          vectorization.
         0            68                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            69                  Loop was not SIMD vectorized because it contains 
                                          operation in ((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          / ((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][(long long) 
                                          .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is 
                                          not  suitable for SIMD vectorization.
         0            69                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65             4    Outer loop has been unrolled 4 time(s).
         0            65             4    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            66             5    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            67             6    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            68                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][($$CIV10 * 4ll + 
                                          (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long 
                                          long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3]) / ((double *)((char *).d  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->d[][($$CIV10 * 4ll + (1ll + ((long long) 
                                          .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + 
                                          (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3] which is 
                                          not  suitable for SIMD vectorization.
         0            68                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            69                  Loop was not SIMD vectorized because it contains 
                                          operation in ((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          / ((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][($$CIV10 * 4ll + 
                                          (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long 
                                          long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3] which is not  suitable for SIMD vectorization.
         0            69                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            68                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][1ll + (($$CIV10 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *).d 
                                          + -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->d[][1ll + (($$CIV10 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3] which is not  suitable for SIMD vectorization.
         0            68                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            69                  Loop was not SIMD vectorized because it contains 
                                          operation in ((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          / ((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][1ll + (($$CIV10 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3] which is not  suitable 
                                          for SIMD vectorization.
         0            69                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            68                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][2ll + (($$CIV10 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *).d 
                                          + -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->d[][2ll + (($$CIV10 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3] which is not  suitable for SIMD vectorization.
         0            68                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            69                  Loop was not SIMD vectorized because it contains 
                                          operation in ((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          / ((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][2ll + (($$CIV10 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3] which is not  suitable 
                                          for SIMD vectorization.
         0            69                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            68                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][3ll + (($$CIV10 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *).d 
                                          + -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->d[][3ll + (($$CIV10 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3] which is not  suitable for SIMD vectorization.
         0            68                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            69                  Loop was not SIMD vectorized because it contains 
                                          operation in ((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          / ((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][3ll + (($$CIV10 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3] which is not  suitable 
                                          for SIMD vectorization.
         0            69                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            74            31    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            75            32    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            76            33    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          operation in  1.8035657040422665E-005 * (((double 
                                          *)((char *).t  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->t[][(long long) .kbeg->kbeg + 
                                          $$CIV8][(long long) .jbeg->jbeg + $$CIV7][(long long) 
                                          .ibeg->ibeg + $$CIV6] EXPI  3) which is not  suitable 
                                          for SIMD vectorization.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.
         0            77                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            78                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *).dbbdt  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->dbbdt[][(long long) .kbeg->kbeg + 
                                          $$CIV8][(long long) .jbeg->jbeg + $$CIV7][(long long) 
                                          .ibeg->ibeg + $$CIV6] * ((double *)((char *).t  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->t[][(long long) .kbeg->kbeg + 
                                          $$CIV8][(long long) .jbeg->jbeg + $$CIV7][(long long) 
                                          .ibeg->ibeg + $$CIV6] which is not  suitable for SIMD 
                                          vectorization.
         0            78                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            79                  Loop was not SIMD vectorized because it contains 
                                          operation in  4.0000000000000000E+000 * ((double 
                                          *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) 
                                          * 8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->dbbdt[][(long long) .kbeg->kbeg + 
                                          $$CIV8][(long long) .jbeg->jbeg + $$CIV7][(long long) 
                                          .ibeg->ibeg + $$CIV6] which is not  suitable for SIMD 
                                          vectorization.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            74             7    Outer loop has been unrolled 4 time(s).
         0            74             7    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            75             8    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            76             9    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          operation in  1.8035657040422665E-005 * (((double 
                                          *)((char *).t  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->t[][($$CIV11 * 4ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) 
                                          + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV7][(long long) .ibeg->ibeg + $$CIV6] EXPI  3) 
                                          which is not  suitable for SIMD vectorization.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.
         0            77                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            78                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *).dbbdt  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->dbbdt[][($$CIV11 * 4ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) 
                                          + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV7][(long long) .ibeg->ibeg + $$CIV6] * ((double 
                                          *)((char *).t  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->t[][($$CIV11 * 4ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) 
                                          + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV7][(long long) .ibeg->ibeg + $$CIV6] which is 
                                          not  suitable for SIMD vectorization.
         0            78                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            79                  Loop was not SIMD vectorized because it contains 
                                          operation in  4.0000000000000000E+000 * ((double 
                                          *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) 
                                          * 8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->dbbdt[][($$CIV11 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg][(long long) 
                                          .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + 
                                          $$CIV6] which is not  suitable for SIMD vectorization.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          operation in  1.8035657040422665E-005 * (((double 
                                          *)((char *).t  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->t[][1ll + (($$CIV11 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + 
                                          $$CIV6] EXPI  3) which is not  suitable for SIMD 
                                          vectorization.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.
         0            77                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            78                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *).dbbdt  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->dbbdt[][1ll + (($$CIV11 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + 
                                          $$CIV6] * ((double *)((char *).t  + -8ll - (max((long 
                                          long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) 
                                          * max((long long) in,0ll)))))->t[][1ll + (($$CIV11 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long 
                                          long) .ibeg->ibeg + $$CIV6] which is not  suitable 
                                          for SIMD vectorization.
         0            78                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            79                  Loop was not SIMD vectorized because it contains 
                                          operation in  4.0000000000000000E+000 * ((double 
                                          *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) 
                                          * 8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->dbbdt[][1ll + (($$CIV11 * 4ll + 
                                          (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long 
                                          long) .ibeg->ibeg + $$CIV6] which is not  suitable 
                                          for SIMD vectorization.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          operation in  1.8035657040422665E-005 * (((double 
                                          *)((char *).t  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->t[][2ll + (($$CIV11 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + 
                                          $$CIV6] EXPI  3) which is not  suitable for SIMD 
                                          vectorization.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.
         0            77                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            78                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *).dbbdt  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->dbbdt[][2ll + (($$CIV11 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + 
                                          $$CIV6] * ((double *)((char *).t  + -8ll - (max((long 
                                          long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) 
                                          * max((long long) in,0ll)))))->t[][2ll + (($$CIV11 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long 
                                          long) .ibeg->ibeg + $$CIV6] which is not  suitable 
                                          for SIMD vectorization.
         0            78                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            79                  Loop was not SIMD vectorized because it contains 
                                          operation in  4.0000000000000000E+000 * ((double 
                                          *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) 
                                          * 8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->dbbdt[][2ll + (($$CIV11 * 4ll + 
                                          (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long 
                                          long) .ibeg->ibeg + $$CIV6] which is not  suitable 
                                          for SIMD vectorization.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          operation in  1.8035657040422665E-005 * (((double 
                                          *)((char *).t  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->t[][3ll + (($$CIV11 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + 
                                          $$CIV6] EXPI  3) which is not  suitable for SIMD 
                                          vectorization.
         0            77                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.
         0            77                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            78                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *).dbbdt  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->dbbdt[][3ll + (($$CIV11 * 4ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 4ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV7][(long long) .ibeg->ibeg + 
                                          $$CIV6] * ((double *)((char *).t  + -8ll - (max((long 
                                          long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) 
                                          * max((long long) in,0ll)))))->t[][3ll + (($$CIV11 * 
                                          4ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long 
                                          long) .ibeg->ibeg + $$CIV6] which is not  suitable 
                                          for SIMD vectorization.
         0            78                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            79                  Loop was not SIMD vectorized because it contains 
                                          operation in  4.0000000000000000E+000 * ((double 
                                          *)((char *).dbbdt  + -8ll - (max((long long) in,0ll) 
                                          * 8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->dbbdt[][3ll + (($$CIV11 * 4ll + 
                                          (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV7][(long 
                                          long) .ibeg->ibeg + $$CIV6] which is not  suitable 
                                          for SIMD vectorization.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            84            25    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            85            26    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            86            27    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            87                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 1.0000000000000000E+000 / rmfp0) * 
                                          (((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][(long long) 
                                          .kbeg->kbeg + $$CIVB][(long long) .jbeg->jbeg + 
                                          $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / rho0 EXP  
                                          xnu)) * (((double *)((char *).t  + -8ll - (max((long 
                                          long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) 
                                          * max((long long) in,0ll)))))->t[][(long long) 
                                          .kbeg->kbeg + $$CIVB][(long long) .jbeg->jbeg + 
                                          $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / t_0 EXP   
                                          - powr) which is not  suitable for SIMD vectorization.
         0            87                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            89                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            90                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            91                  Loop was not SIMD vectorized because it contains 
                                          operation in - ((powr * ((double *)((char *).kp  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kp[][(long long) .kbeg->kbeg + 
                                          $$CIVB][(long long) .jbeg->jbeg + $$CIVA][(long long) 
                                          .ibeg->ibeg + $$CIV9]) / ((double *)((char *).t  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->t[][(long long) .kbeg->kbeg + 
                                          $$CIVB][(long long) .jbeg->jbeg + $$CIVA][(long long) 
                                          .ibeg->ibeg + $$CIV9]) which is not  suitable for 
                                          SIMD vectorization.
         0            91                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            84            10    Outer loop has been unrolled 2 time(s).
         0            84            10    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            85            11    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            86            12    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            87                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 1.0000000000000000E+000 / rmfp0) * 
                                          (((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][($$CIV12 * 2ll + 
                                          (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long 
                                          long) .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + 
                                          $$CIV9] / rho0 EXP   xnu)) * (((double *)((char *).t  
                                          + -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->t[][($$CIV12 * 2ll + (1ll + ((long long) 
                                          .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + 
                                          (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIVA][(long long) .ibeg->ibeg + $$CIV9] / t_0 EXP   
                                          - powr) which is not  suitable for SIMD vectorization.
         0            87                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            89                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            90                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            91                  Loop was not SIMD vectorized because it contains 
                                          operation in - ((powr * ((double *)((char *).kp  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kp[][($$CIV12 * 2ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) 
                                          + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIVA][(long long) .ibeg->ibeg + $$CIV9]) / ((double 
                                          *)((char *).t  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->t[][($$CIV12 * 2ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) 
                                          + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIVA][(long long) .ibeg->ibeg + $$CIV9]) which is 
                                          not  suitable for SIMD vectorization.
         0            91                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            87                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 1.0000000000000000E+000 / rmfp0) * 
                                          (((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][1ll + (($$CIV12 * 
                                          2ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 2ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIVA][(long 
                                          long) .ibeg->ibeg + $$CIV9] / rho0 EXP   xnu)) * 
                                          (((double *)((char *).t  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->t[][1ll + (($$CIV12 * 
                                          2ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 2ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIVA][(long 
                                          long) .ibeg->ibeg + $$CIV9] / t_0 EXP   - powr) which 
                                          is not  suitable for SIMD vectorization.
         0            87                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            89                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            90                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            91                  Loop was not SIMD vectorized because it contains 
                                          operation in - ((powr * ((double *)((char *).kp  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kp[][1ll + (($$CIV12 * 2ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 2ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIVA][(long long) .ibeg->ibeg + 
                                          $$CIV9]) / ((double *)((char *).t  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) in,0ll)))))->t[][1ll 
                                          + (($$CIV12 * 2ll + (1ll + ((long long) .kend->kend - 
                                          (long long) .kbeg->kbeg)) % 2ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIVA][(long 
                                          long) .ibeg->ibeg + $$CIV9]) which is not  suitable 
                                          for SIMD vectorization.
         0            91                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            93            19    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            94            20    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            95            21    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            96                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            97                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            93            13    Outer loop has been unrolled 4 time(s).
         0            93            13    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            94            14    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            95            15    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            96                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            97                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            96                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            97                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            96                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            97                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            96                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            97                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.


    11|         SUBROUTINE matprop (e, er, d, gam, t, dtde, p, bb, dbbdt, kr, kp, sg, dkpdt, km, dkedt, dpde, ibeg, iend, jbeg, jend, kbeg, kend)
    51|           IF ((leos == 1)) THEN
    52|             IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &     int(kend) - int(kbeg)) > 0)) THEN
                      $$CIV2 = 0
       Id=43          DO $$CIV2 = $$CIV2, MOD((1 + (int(kend) - int(kbeg))), &
                &         int(4))-1
    53|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV1 = 0
       Id=44              DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    54|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV0 = 0
       Id=45                  DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    55|                         p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(&
                &                 kbeg) + $$CIV2) = (gam -  &
                &                 1.0000000000000000E+000) * e(int(ibeg) + $$CIV0,&
                &                 int(jbeg) + $$CIV1,int(kbeg) + $$CIV2)
    56|                         dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(&
                &                 kbeg) + $$CIV2) = gam -  &
                &                 1.0000000000000000E+000
    57|                       ENDDO
                            ENDIF
                          ENDDO
                        ENDIF
                      ENDDO
                    ENDIF
    52|             IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) &
                &     - int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                      $$CIVF = int(0)
       Id=1           DO $$CIVF = $$CIVF, int(((int(kend) - (MOD((1 + (int(&
                &         kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    53|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV1 = 0
       Id=2               DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    54|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV0 = 0
       Id=3                   DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    55|                         p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,($$CIVF &
                &                 * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + &
                &                 int(kbeg)) = (gam -  1.0000000000000000E+000) * &
                &                 e(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,($$CIVF &
                &                 * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + &
                &                 int(kbeg))
    56|                         dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,(&
                &                 $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &                 4)) + int(kbeg)) = gam -  &
                &                 1.0000000000000000E+000
    55|                         p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + ((&
                &                 $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &                 4)) + int(kbeg))) = (gam -  &
                &                 1.0000000000000000E+000) * e(int(ibeg) + $$CIV0,&
                &                 int(jbeg) + $$CIV1,1 + (($$CIVF * 4 + MOD((1 + (&
                &                 int(kend) - int(kbeg))), 4)) + int(kbeg)))
    56|                         dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + (&
                &                 ($$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = gam -  &
                &                 1.0000000000000000E+000
    55|                         p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + ((&
                &                 $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &                 4)) + int(kbeg))) = (gam -  &
                &                 1.0000000000000000E+000) * e(int(ibeg) + $$CIV0,&
                &                 int(jbeg) + $$CIV1,2 + (($$CIVF * 4 + MOD((1 + (&
                &                 int(kend) - int(kbeg))), 4)) + int(kbeg)))
    56|                         dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + (&
                &                 ($$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = gam -  &
                &                 1.0000000000000000E+000
    55|                         p(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + ((&
                &                 $$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &                 4)) + int(kbeg))) = (gam -  &
                &                 1.0000000000000000E+000) * e(int(ibeg) + $$CIV0,&
                &                 int(jbeg) + $$CIV1,3 + (($$CIVF * 4 + MOD((1 + (&
                &                 int(kend) - int(kbeg))), 4)) + int(kbeg)))
    56|                         dpde(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + (&
                &                 ($$CIVF * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = gam -  &
                &                 1.0000000000000000E+000
    57|                       ENDDO
                            ENDIF
                          ENDDO
                        ENDIF
                      ENDDO
                    ENDIF
    65|             IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &     int(kend) - int(kbeg)) > 0)) THEN
                      $$CIV5 = 0
       Id=37          DO $$CIV5 = $$CIV5, MOD((1 + (int(kend) - int(kbeg))), &
                &         int(4))-1
    66|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV4 = 0
       Id=38              DO $$CIV4 = $$CIV4, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    67|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV3 = 0
       Id=39                  DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    68|                         $$csx0 = d(int(ibeg) + $$CIV3,int(jbeg) + &
                &                 $$CIV4,int(kbeg) + $$CIV5)
                                t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(&
                &                 kbeg) + $$CIV5) = (((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &                 int(jbeg) + $$CIV4,int(kbeg) + $$CIV5)) / &
                &                 $$csx0
    69|                         dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(&
                &                 kbeg) + $$CIV5) = ((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) / $$csx0
    72|                       ENDDO
                            ENDIF
                          ENDDO
                        ENDIF
                      ENDDO
                    ENDIF
    65|             IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) &
                &     - int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                      $$CIV10 = int(0)
       Id=4           DO $$CIV10 = $$CIV10, int(((int(kend) - (MOD((1 + (int(&
                &         kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    66|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV4 = 0
       Id=5               DO $$CIV4 = $$CIV4, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    67|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV3 = 0
       Id=6                   DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    68|                         $$csx1 = d(int(ibeg) + $$CIV3,int(jbeg) + &
                &                 $$CIV4,($$CIV10 * 4 + MOD((1 + (int(kend) - int(&
                &                 kbeg))), 4)) + int(kbeg))
                                t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,(&
                &                 $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg)) = (((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &                 int(jbeg) + $$CIV4,($$CIV10 * 4 + MOD((1 + (int(&
                &                 kend) - int(kbeg))), 4)) + int(kbeg))) / $$csx1
    69|                         dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,(&
                &                 $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg)) = ((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) / $$csx1
    68|                         $$csx2 = d(int(ibeg) + $$CIV3,int(jbeg) + &
                &                 $$CIV4,1 + (($$CIV10 * 4 + MOD((1 + (int(kend) &
                &                 - int(kbeg))), 4)) + int(kbeg)))
                                t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &                 $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = (((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &                 int(jbeg) + $$CIV4,1 + (($$CIV10 * 4 + MOD((1 + &
                &                 (int(kend) - int(kbeg))), 4)) + int(kbeg)))) / &
                &                 $$csx2
    69|                         dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + (&
                &                 ($$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg)))&
                &                 , 4)) + int(kbeg))) = ((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) / $$csx2
    68|                         $$csx3 = d(int(ibeg) + $$CIV3,int(jbeg) + &
                &                 $$CIV4,2 + (($$CIV10 * 4 + MOD((1 + (int(kend) &
                &                 - int(kbeg))), 4)) + int(kbeg)))
                                t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,2 + ((&
                &                 $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = (((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &                 int(jbeg) + $$CIV4,2 + (($$CIV10 * 4 + MOD((1 + &
                &                 (int(kend) - int(kbeg))), 4)) + int(kbeg)))) / &
                &                 $$csx3
    69|                         dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,2 + (&
                &                 ($$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg)))&
                &                 , 4)) + int(kbeg))) = ((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) / $$csx3
    68|                         $$csx4 = d(int(ibeg) + $$CIV3,int(jbeg) + &
                &                 $$CIV4,3 + (($$CIV10 * 4 + MOD((1 + (int(kend) &
                &                 - int(kbeg))), 4)) + int(kbeg)))
                                t(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,3 + ((&
                &                 $$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = (((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) * e(int(ibeg) + $$CIV3,&
                &                 int(jbeg) + $$CIV4,3 + (($$CIV10 * 4 + MOD((1 + &
                &                 (int(kend) - int(kbeg))), 4)) + int(kbeg)))) / &
                &                 $$csx4
    69|                         dtde(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,3 + (&
                &                 ($$CIV10 * 4 + MOD((1 + (int(kend) - int(kbeg)))&
                &                 , 4)) + int(kbeg))) = ((((gam -  &
                &                 1.0000000000000000E+000) * mmw) *  &
                &                 1.6605299201696573E-024) *  &
                &                 7.2429128189679120E+015) / $$csx4
    72|                       ENDDO
                            ENDIF
                          ENDDO
                        ENDIF
                      ENDDO
                    ENDIF
    74|             IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &     int(kend) - int(kbeg)) > 0)) THEN
                      $$CIV8 = 0
       Id=31          DO $$CIV8 = $$CIV8, MOD((1 + (int(kend) - int(kbeg))), &
                &         int(4))-1
    75|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV7 = 0
       Id=32              DO $$CIV7 = $$CIV7, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    76|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV6 = 0
       Id=33                  DO $$CIV6 = $$CIV6, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    77|                         $$csx5 = t(int(ibeg) + $$CIV6,int(jbeg) + &
                &                 $$CIV7,int(kbeg) + $$CIV8)
                                dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &                 kbeg) + $$CIV8) =  1.8035657040422665E-005 * (&
                &                 $$csx5 ** 3)
    78|                         bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &                 kbeg) + $$CIV8) = dbbdt(int(ibeg) + $$CIV6,int(&
                &                 jbeg) + $$CIV7,int(kbeg) + $$CIV8) * $$csx5
    79|                         dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &                 kbeg) + $$CIV8) =  4.0000000000000000E+000 * &
                &                 dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &                 kbeg) + $$CIV8)
    80|                       ENDDO
                            ENDIF
                          ENDDO
                        ENDIF
                      ENDDO
                    ENDIF
    74|             IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) &
                &     - int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                      $$CIV11 = int(0)
       Id=7           DO $$CIV11 = $$CIV11, int(((int(kend) - (MOD((1 + (int(&
                &         kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    75|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV7 = 0
       Id=8               DO $$CIV7 = $$CIV7, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    76|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV6 = 0
       Id=9                   DO $$CIV6 = $$CIV6, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    77|                         $$csx6 =  1.8035657040422665E-005 * (t(int(ibeg)&
                &                  + $$CIV6,int(jbeg) + $$CIV7,($$CIV11 * 4 + MOD(&
                &                 (1 + (int(kend) - int(kbeg))), 4)) + int(kbeg)) &
                &                 ** 3)
                                dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,(&
                &                 $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg)) = $$csx6
    78|                         bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,(&
                &                 $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg)) = $$csx6 * t(int(ibeg) + &
                &                 $$CIV6,int(jbeg) + $$CIV7,($$CIV11 * 4 + MOD((1 &
                &                 + (int(kend) - int(kbeg))), 4)) + int(kbeg))
    79|                         dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,(&
                &                 $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg)) =  4.0000000000000000E+000 * &
                &                 $$csx6
    77|                         $$csx7 =  1.8035657040422665E-005 * (t(int(ibeg)&
                &                  + $$CIV6,int(jbeg) + $$CIV7,1 + (($$CIV11 * 4 &
                &                 + MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &                 kbeg))) ** 3)
                                dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + &
                &                 (($$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) = $$csx7
    78|                         bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &                 $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = $$csx7 * t(int(ibeg) + &
                &                 $$CIV6,int(jbeg) + $$CIV7,1 + (($$CIV11 * 4 + &
                &                 MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &                 kbeg)))
    79|                         dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + &
                &                 (($$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) =  4.0000000000000000E+000 &
                &                 * $$csx7
    77|                         $$csx8 =  1.8035657040422665E-005 * (t(int(ibeg)&
                &                  + $$CIV6,int(jbeg) + $$CIV7,2 + (($$CIV11 * 4 &
                &                 + MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &                 kbeg))) ** 3)
                                dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + &
                &                 (($$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) = $$csx8
    78|                         bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &                 $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = $$csx8 * t(int(ibeg) + &
                &                 $$CIV6,int(jbeg) + $$CIV7,2 + (($$CIV11 * 4 + &
                &                 MOD((1 + (int(kend) - int(kbeg))), 4)) + int(&
                &                 kbeg)))
    79|                         dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + &
                &                 (($$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) =  4.0000000000000000E+000 &
                &                 * $$csx8
    77|                         $$csx9 = t(int(ibeg) + $$CIV6,int(jbeg) + &
                &                 $$CIV7,3 + (($$CIV11 * 4 + MOD((1 + (int(kend) &
                &                 - int(kbeg))), 4)) + int(kbeg)))
                                dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + &
                &                 (($$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) =  1.8035657040422665E-005 &
                &                 * ($$csx9 ** 3)
    78|                         bb(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &                 $$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = dbbdt(int(ibeg) + $$CIV6,&
                &                 int(jbeg) + $$CIV7,3 + (($$CIV11 * 4 + MOD((1 + &
                &                 (int(kend) - int(kbeg))), 4)) + int(kbeg))) * &
                &                 $$csx9
    79|                         dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + &
                &                 (($$CIV11 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) =  4.0000000000000000E+000 &
                &                 * dbbdt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 &
                &                 + (($$CIV11 * 4 + MOD((1 + (int(kend) - int(&
                &                 kbeg))), 4)) + int(kbeg)))
    80|                       ENDDO
                            ENDIF
                          ENDDO
                        ENDIF
                      ENDDO
                    ENDIF
    84|             IF ((MOD((1 + (int(kend) - int(kbeg))), 2) > 0  .AND.  1 + (&
                &     int(kend) - int(kbeg)) > 0)) THEN
                      $$CIVB = 0
       Id=25          DO $$CIVB = $$CIVB, MOD((1 + (int(kend) - int(kbeg))), &
                &         int(2))-1
    85|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIVA = 0
       Id=26              DO $$CIVA = $$CIVA, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    86|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV9 = 0
       Id=27                  DO $$CIV9 = $$CIV9, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    87|                         $$csxA = t(int(ibeg) + $$CIV9,int(jbeg) + &
                &                 $$CIVA,int(kbeg) + $$CIVB)
                                $$csxB = (( 1.0000000000000000E+000 / rmfp0) * (&
                &                 d(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(&
                &                 kbeg) + $$CIVB) / rho0 ** xnu)) * ($$csxA / t_0 &
                &                 ** (-powr))
                                kr(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(&
                &                 kbeg) + $$CIVB) = $$csxB
    89|                         sg(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(&
                &                 kbeg) + $$CIVB) =  0.0000000000000000E+000
    90|                         kp(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(&
                &                 kbeg) + $$CIVB) = $$csxB
    91|                         dkpdt(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,int(&
                &                 kbeg) + $$CIVB) = -((powr * $$csxB) / $$csxA)
    92|                       ENDDO
                            ENDIF
                          ENDDO
                        ENDIF
                      ENDDO
                    ENDIF
    84|             IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) &
                &     - int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 2))) THEN
                      $$CIV12 = int(0)
       Id=10          DO $$CIV12 = $$CIV12, int(((int(kend) - (MOD((1 + (int(&
                &         kend) - int(kbeg))), 2) + int(kbeg))) / 2 + 1))-1
    85|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIVA = 0
       Id=11              DO $$CIVA = $$CIVA, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    86|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV9 = 0
       Id=12                  DO $$CIV9 = $$CIV9, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    87|                         $$csxC = t(int(ibeg) + $$CIV9,int(jbeg) + &
                &                 $$CIVA,($$CIV12 * 2 + MOD((1 + (int(kend) - int(&
                &                 kbeg))), 2)) + int(kbeg))
                                $$csxD = (( 1.0000000000000000E+000 / rmfp0) * (&
                &                 d(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,(&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg)) / rho0 ** xnu)) * ($$csxC / &
                &                 t_0 ** (-powr))
                                kr(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,(&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg)) = $$csxD
    89|                         sg(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,(&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg)) =  0.0000000000000000E+000
    90|                         kp(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,(&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg)) = $$csxD
    91|                         dkpdt(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,(&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg)) = -((powr * $$csxD) / $$csxC)
    87|                         $$csxE = t(int(ibeg) + $$CIV9,int(jbeg) + &
                &                 $$CIVA,1 + (($$CIV12 * 2 + MOD((1 + (int(kend) &
                &                 - int(kbeg))), 2)) + int(kbeg)))
                                $$csxF = (( 1.0000000000000000E+000 / rmfp0) * (&
                &                 d(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg))) / rho0 ** xnu)) * ($$csxE / &
                &                 t_0 ** (-powr))
                                kr(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg))) = $$csxF
    89|                         sg(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg))) =  0.0000000000000000E+000
    90|                         kp(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + ((&
                &                 $$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  2)) + int(kbeg))) = $$csxF
    91|                         dkpdt(int(ibeg) + $$CIV9,int(jbeg) + $$CIVA,1 + &
                &                 (($$CIV12 * 2 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 2)) + int(kbeg))) = -((powr * $$csxF) / &
                &                 $$csxE)
    92|                       ENDDO
                            ENDIF
                          ENDDO
                        ENDIF
                      ENDDO
                    ENDIF
    93|             IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &     int(kend) - int(kbeg)) > 0)) THEN
                      $$CIVE = 0
       Id=19          DO $$CIVE = $$CIVE, MOD((1 + (int(kend) - int(kbeg))), &
                &         int(4))-1
    94|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIVD = 0
       Id=20              DO $$CIVD = $$CIVD, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    95|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIVC = 0
       Id=21                  DO $$CIVC = $$CIVC, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    96|                         km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,int(&
                &                 kbeg) + $$CIVE) = kp(int(ibeg) + $$CIVC,int(&
                &                 jbeg) + $$CIVD,int(kbeg) + $$CIVE)
    97|                         dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,int(&
                &                 kbeg) + $$CIVE) = dkpdt(int(ibeg) + $$CIVC,int(&
                &                 jbeg) + $$CIVD,int(kbeg) + $$CIVE)
    98|                       ENDDO
                            ENDIF
    99|                   ENDDO
                        ENDIF
   100|               ENDDO
                    ENDIF
    93|             IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) &
                &     - int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                      $$CIV13 = int(0)
       Id=13          DO $$CIV13 = $$CIV13, int(((int(kend) - (MOD((1 + (int(&
                &         kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    94|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIVD = 0
       Id=14              DO $$CIVD = $$CIVD, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    95|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIVC = 0
       Id=15                  DO $$CIVC = $$CIVC, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    96|                         km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,(&
                &                 $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg)) = kp(int(ibeg) + $$CIVC,int(&
                &                 jbeg) + $$CIVD,($$CIV13 * 4 + MOD((1 + (int(&
                &                 kend) - int(kbeg))), 4)) + int(kbeg))
    97|                         dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,(&
                &                 $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg)) = dkpdt(int(ibeg) + $$CIVC,&
                &                 int(jbeg) + $$CIVD,($$CIV13 * 4 + MOD((1 + (int(&
                &                 kend) - int(kbeg))), 4)) + int(kbeg))
    96|                         km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,1 + ((&
                &                 $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = kp(int(ibeg) + $$CIVC,int(&
                &                 jbeg) + $$CIVD,1 + (($$CIV13 * 4 + MOD((1 + (&
                &                 int(kend) - int(kbeg))), 4)) + int(kbeg)))
    97|                         dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,1 + &
                &                 (($$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) = dkpdt(int(ibeg) + $$CIVC,&
                &                 int(jbeg) + $$CIVD,1 + (($$CIV13 * 4 + MOD((1 + &
                &                 (int(kend) - int(kbeg))), 4)) + int(kbeg)))
    96|                         km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,2 + ((&
                &                 $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = kp(int(ibeg) + $$CIVC,int(&
                &                 jbeg) + $$CIVD,2 + (($$CIV13 * 4 + MOD((1 + (&
                &                 int(kend) - int(kbeg))), 4)) + int(kbeg)))
    97|                         dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,2 + &
                &                 (($$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) = dkpdt(int(ibeg) + $$CIVC,&
                &                 int(jbeg) + $$CIVD,2 + (($$CIV13 * 4 + MOD((1 + &
                &                 (int(kend) - int(kbeg))), 4)) + int(kbeg)))
    96|                         km(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,3 + ((&
                &                 $$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) = kp(int(ibeg) + $$CIVC,int(&
                &                 jbeg) + $$CIVD,3 + (($$CIV13 * 4 + MOD((1 + (&
                &                 int(kend) - int(kbeg))), 4)) + int(kbeg)))
    97|                         dkedt(int(ibeg) + $$CIVC,int(jbeg) + $$CIVD,3 + &
                &                 (($$CIV13 * 4 + MOD((1 + (int(kend) - int(kbeg))&
                &                 ), 4)) + int(kbeg))) = dkpdt(int(ibeg) + $$CIVC,&
                &                 int(jbeg) + $$CIVD,3 + (($$CIV13 * 4 + MOD((1 + &
                &                 (int(kend) - int(kbeg))), 4)) + int(kbeg)))
    98|                       ENDDO
                            ENDIF
    99|                   ENDDO
                        ENDIF
   100|               ENDDO
                    ENDIF
   103|           ELSE
    59|             IF ((myid == 0)) THEN
                      |fmt_args%version = 129
                      |fmt_args%fmt_string_addr = NULL
                      |fmt_args%fmt_string_len = int(")
                      |fmt_args%stack_frame = NULL
                      |fmt_args%call_back = NULL
                      #107 = _xlfBeginIO(6,259,#106,32772,NULL,0,|fmt_args)
                      _xlfEndIO(%VAL(#107))
                    ENDIF
    60|             CALL mpi_finalize(ierr)
    61|             CALL _xlfStop(NULL,0)
                  ENDIF
                  RETURN
   103|         END SUBROUTINE matprop

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   ssus ssss ssss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ss--  -sss ssss ssss ssss
 CCR's set/used:   ssss ssss
     | 000000                           PDEF     matprop
   11|                                  PROC      .e,.er,.d,.gam,.t,.dtde,.p,.bb,.dbbdt,.kr,.kp,.sg,.dkpdt,.km,.dkedt,.dpde,.ibeg,.iend,.jbeg,.jend,.kbeg,.kend,gr3-gr10
    0| 000000 stfd     DBE1FFF8   1     STFL      #stack(gr1,-8)=fp31
    0| 000004 stfd     DBC1FFF0   1     STFL      #stack(gr1,-16)=fp30
    0| 000008 stfd     DBA1FFE8   1     STFL      #stack(gr1,-24)=fp29
    0| 00000C stfd     DB81FFE0   1     STFL      #stack(gr1,-32)=fp28
    0| 000010 stfd     DB61FFD8   1     STFL      #stack(gr1,-40)=fp27
    0| 000014 stfd     DB41FFD0   1     STFL      #stack(gr1,-48)=fp26
    0| 000018 stfd     DB21FFC8   1     STFL      #stack(gr1,-56)=fp25
    0| 00001C stfd     DB01FFC0   1     STFL      #stack(gr1,-64)=fp24
    0| 000020 stfd     DAE1FFB8   1     STFL      #stack(gr1,-72)=fp23
    0| 000024 stfd     DAC1FFB0   1     STFL      #stack(gr1,-80)=fp22
    0| 000028 stfd     DAA1FFA8   1     STFL      #stack(gr1,-88)=fp21
    0| 00002C stfd     DA81FFA0   1     STFL      #stack(gr1,-96)=fp20
    0| 000030 stfd     DA61FF98   1     STFL      #stack(gr1,-104)=fp19
    0| 000034 stfd     DA41FF90   1     STFL      #stack(gr1,-112)=fp18
    0| 000038 stfd     DA21FF88   1     STFL      #stack(gr1,-120)=fp17
    0| 00003C std      FBE1FF80   1     ST8       #stack(gr1,-128)=gr31
    0| 000040 std      FBC1FF78   1     ST8       #stack(gr1,-136)=gr30
    0| 000044 std      FBA1FF70   1     ST8       #stack(gr1,-144)=gr29
    0| 000048 std      FB81FF68   1     ST8       #stack(gr1,-152)=gr28
    0| 00004C std      FB61FF60   1     ST8       #stack(gr1,-160)=gr27
    0| 000050 std      FB41FF58   1     ST8       #stack(gr1,-168)=gr26
    0| 000054 std      FB21FF50   1     ST8       #stack(gr1,-176)=gr25
    0| 000058 std      FB01FF48   1     ST8       #stack(gr1,-184)=gr24
    0| 00005C std      FAE1FF40   1     ST8       #stack(gr1,-192)=gr23
    0| 000060 std      FAC1FF38   1     ST8       #stack(gr1,-200)=gr22
    0| 000064 std      FAA1FF30   1     ST8       #stack(gr1,-208)=gr21
    0| 000068 std      FA81FF28   1     ST8       #stack(gr1,-216)=gr20
    0| 00006C std      FA61FF20   1     ST8       #stack(gr1,-224)=gr19
    0| 000070 std      FA41FF18   1     ST8       #stack(gr1,-232)=gr18
    0| 000074 std      FA21FF10   1     ST8       #stack(gr1,-240)=gr17
    0| 000078 std      FA01FF08   1     ST8       #stack(gr1,-248)=gr16
    0| 00007C std      F9E1FF00   1     ST8       #stack(gr1,-256)=gr15
    0| 000080 std      F9C1FEF8   1     ST8       #stack(gr1,-264)=gr14
    0| 000084 mfspr    7C0802A6   1     LFLR      gr0=lr
    0| 000088 mfcr     7D800026   1     LFCR      gr12=cr[234],2
    0| 00008C stw      91810008   1     ST4A      #stack(gr1,8)=gr12
    0| 000090 std      F8010010   1     ST8       #stack(gr1,16)=gr0
    0| 000094 stdu     F821FD01   1     ST8U      gr1,#stack(gr1,-768)=gr1
   48| 000098 lfd      C8060000   1     LFL       fp0=gam(gr6,0)
    0| 00009C std      F8A100B0   1     ST8       #SPILL0(gr1,176)=gr5
    0| 0000A0 ld       E8820000   1     L8        gr4=.&&N&&param(gr2,0)
   51| 0000A4 ld       E9620000   1     L8        gr11=.&&N&&config(gr2,0)
    0| 0000A8 std      F8E100B8   1     ST8       #SPILL1(gr1,184)=gr7
    0| 0000AC lwa      E8040006   1     L4A       gr0=<s33:d4:l4>(gr4,4)
    0| 0000B0 lwa      E8840002   1     L4A       gr4=<s33:d0:l4>(gr4,0)
   51| 0000B4 lwz      80CB0020   1     L4Z       gr6=<s88:d32:l4>(gr11,32)
    0| 0000B8 sradi    7C07FE76   1     SRA8      gr7=gr0,63,ca"
    0| 0000BC sradi    7C85FE76   1     SRA8      gr5=gr4,63,ca"
   51| 0000C0 cmpwi    2C060001   1     C4        cr0=gr6,1
    0| 0000C4 andc     7C0C3878   1     ANDC      gr12=gr0,gr7
    0| 0000C8 andc     7C9F2878   1     ANDC      gr31=gr4,gr5
    0| 0000CC std      F98100C0   1     ST8       #SPILL2(gr1,192)=gr12
    0| 0000D0 std      FBE100C8   1     ST8       #SPILL3(gr1,200)=gr31
   51| 0000D4 bc       40821CE0   1     BF        CL.1,cr0,0x4/eq,taken=50%(0,0)
   51| 0000D8 ld       E8A103D0   1     L8        gr5=.kbeg(gr1,976)
   51| 0000DC ld       E88103D8   1     L8        gr4=.kend(gr1,984)
   51| 0000E0 lwa      E8C50002   1     L4A       gr6=kbeg(gr5,0)
   51| 0000E4 lwa      E8040002   1     L4A       gr0=kend(gr4,0)
   51| 0000E8 std      F8C100D0   1     ST8       #SPILL4(gr1,208)=gr6
   51| 0000EC subf     7C860050   1     S         gr4=gr0,gr6
   51| 0000F0 addi     38E40001   1     AI        gr7=gr4,1
   51| 0000F4 sradi    7CE01674   1     SRA8CA    gr0,ca=gr7,2
   52| 0000F8 cmpdi    2CA70000   1     C8        cr1=gr7,0
   51| 0000FC addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
   51| 000100 std      F8E100D8   1     ST8       #SPILL5(gr1,216)=gr7
   52| 000104 rldicr   780B1764   1     SLL8      gr11=gr0,2
   52| 000108 subf     7FCB3851   1     S_R       gr30,cr0=gr7,gr11
   52| 00010C std      F96100E0   1     ST8       #SPILL6(gr1,224)=gr11
   52| 000110 crand    4E012A02   1     CR_N      cr4=cr[01],0x1/lt,0x2/gt,0x2/gt,cr4
   52| 000114 std      FBC101D0   1     ST8       #SPILL36(gr1,464)=gr30
   52| 000118 bc       40900124   1     BF        CL.156,cr4,0x1/lt,taken=50%(0,0)
   52| 00011C ld       E8A103C0   1     L8        gr5=.jbeg(gr1,960)
   52| 000120 ld       E8C103C8   1     L8        gr6=.jend(gr1,968)
   52| 000124 addi     38800000   1     LI        gr4=0
   52| 000128 lwa      E8A50002   1     L4A       gr5=jbeg(gr5,0)
   52| 00012C lwa      E8060002   1     L4A       gr0=jend(gr6,0)
   52| 000130 subf     7CC50050   1     S         gr6=gr0,gr5
   52| 000134 addic.   34060001   1     AI_R      gr0,cr0=gr6,1,ca"
    0| 000138 bc       40811C64   1     BF        CL.492,cr0,0x2/gt,taken=50%(0,0)
    0| 00013C rldicr   79861F24   1     SLL8      gr6=gr12,3
    0| 000140 rldicr   7BEC1F24   1     SLL8      gr12=gr31,3
    0| 000144 or       7FEEFB78   1     LR        gr14=gr31
    0| 000148 mulld    7FFF31D2   1     M         gr31=gr31,gr6
    0| 00014C ld       EB0100D0   1     L8        gr24=#SPILL4(gr1,208)
    0| 000150 ld       EBC103B0   1     L8        gr30=.ibeg(gr1,944)
    0| 000154 ld       E8E103B8   1     L8        gr7=.iend(gr1,952)
    0| 000158 neg      7D6600D0   1     COMP      gr11=gr6
    0| 00015C mulld    7CA561D2   1     M         gr5=gr5,gr12
    0| 000160 mulld    7CD8F9D2   1     M         gr6=gr24,gr31
    0| 000164 lwa      EBDE0002   1     L4A       gr30=ibeg(gr30,0)
    0| 000168 lwa      EBA70002   1     L4A       gr29=iend(gr7,0)
    0| 00016C mulld    7D6B71D2   1     M         gr11=gr11,gr14
    0| 000170 addi     38E5FFF0   1     AI        gr7=gr5,-16
    0| 000174 subf     7CCC3050   1     S         gr6=gr6,gr12
    0| 000178 ld       E8A20000   1     L8        gr5=.+CONSTANT_AREA(gr2,0)
    0| 00017C add      7CE63A14   1     A         gr7=gr6,gr7
    0| 000180 subf     7CDEE850   1     S         gr6=gr29,gr30
    0| 000184 add      7F875A14   1     A         gr28=gr7,gr11
    0| 000188 addic.   34C60001   1     AI_R      gr6,cr0=gr6,1,ca"
    0| 00018C add      7F63E214   1     A         gr27=gr3,gr28
    0| 000190 add      7F49E214   1     A         gr26=gr9,gr28
    0| 000194 lfs      C0250088   1     LFS       fp1=+CONSTANT_AREA(gr5,136)
    0| 000198 ld       EB2103A8   1     L8        gr25=.dpde(gr1,936)
    0| 00019C mcrf     4C800000   1     LRCR      cr1=cr0
   52|                              CL.151:
    0| 0001A0 rldicr   7BC61F24   1     SLL8      gr6=gr30,3
   53| 0001A4 addi     38A00000   1     LI        gr5=0
    0| 0001A8 bc       40850078   1     BF        CL.155,cr1,0x2/gt,taken=20%(20,80)
    0| 0001AC fadd     FC80082A   1     AFL       fp4=fp0,fp1,fcr
    0| 0001B0 subfic   20FE0001   1     SFI       gr7=1,gr30,ca"
    0| 0001B4 add      7F06E214   1     A         gr24=gr6,gr28
    0| 0001B8 add      7EFD3A15   1     A_R       gr23,cr0=gr29,gr7
    0| 0001BC add      7EC6D214   1     A         gr22=gr6,gr26
    0| 0001C0 add      7EA6DA14   1     A         gr21=gr6,gr27
   53|                              CL.152:
   55| 0001C4 or       7EA6AB78   1     LR        gr6=gr21
    0| 0001C8 mtspr    7EE903A6   1     LCTR      ctr=gr23
   55| 0001CC lfdu     CC460008   1     LFDU      fp2,gr6=e[](gr6,8)
   56| 0001D0 add      7CF8CA14   1     A         gr7=gr24,gr25
   55| 0001D4 or       7ECBB378   1     LR        gr11=gr22
   55| 0001D8 fmul     FC4400B2   1     MFL       fp2=fp4,fp2,fcr
    0| 0001DC bc       42400024   1     BCF       ctr=CL.763,taken=0%(0,100)
    0| 0001E0 ori      60210000   1     XNOP      
    0| 0001E4 ori      60210000   1     XNOP      
    0| 0001E8 ori      60210000   1     XNOP      
    0|                              CL.764:
   55| 0001EC lfdu     CC660008   1     LFDU      fp3,gr6=e[](gr6,8)
   56| 0001F0 stfdu    DC870008   1     STFDU     gr7,dpde[](gr7,8)=fp4
   55| 0001F4 stfdu    DC4B0008   1     STFDU     gr11,p[](gr11,8)=fp2
   55| 0001F8 fmul     FC4400F2   1     MFL       fp2=fp4,fp3,fcr
    0| 0001FC bc       4200FFF0   1     BCT       ctr=CL.764,taken=100%(100,0)
    0|                              CL.763:
   55| 000200 stfdu    DC4B0008   1     STFDU     gr11,p[](gr11,8)=fp2
   57| 000204 addi     38A50001   1     AI        gr5=gr5,1
   56| 000208 stfdu    DC870008   1     STFDU     gr7,dpde[](gr7,8)=fp4
   57| 00020C cmpld    7C250040   1     CL8       cr0=gr5,gr0
    0| 000210 add      7F0CC214   1     A         gr24=gr12,gr24
    0| 000214 add      7ECCB214   1     A         gr22=gr12,gr22
    0| 000218 add      7EACAA14   1     A         gr21=gr12,gr21
   57| 00021C bc       4180FFA8   1     BT        CL.152,cr0,0x8/llt,taken=80%(80,20)
   57|                              CL.155:
   57| 000220 ld       E8A101D0   1     L8        gr5=#SPILL36(gr1,464)
   57| 000224 addi     38840001   1     AI        gr4=gr4,1
    0| 000228 add      7F9CFA14   1     A         gr28=gr28,gr31
    0| 00022C add      7F5AFA14   1     A         gr26=gr26,gr31
    0| 000230 add      7F7BFA14   1     A         gr27=gr27,gr31
   57| 000234 cmpd     7C252000   1     C8        cr0=gr5,gr4
   57| 000238 bc       4181FF68   1     BT        CL.151,cr0,0x2/gt,taken=80%(80,20)
   57|                              CL.156:
   52| 00023C ld       E80100D8   1     L8        gr0=#SPILL5(gr1,216)
   52| 000240 ld       E88101D0   1     L8        gr4=#SPILL36(gr1,464)
   52| 000244 cmpdi    2C200000   1     C8        cr0=gr0,0
   52| 000248 cmpd     7DA02000   1     C8        cr3=gr0,gr4
   52| 00024C crand    4DA16A02   1     CR_N      cr3=cr[03],0x2/gt,0x2/gt,0x2/gt,cr3
   52| 000250 bc       408D0364   1     BF        CL.64,cr3,0x2/gt,taken=50%(0,0)
    0| 000254 ld       E98100C0   1     L8        gr12=#SPILL2(gr1,192)
    0| 000258 ld       EB8100C8   1     L8        gr28=#SPILL3(gr1,200)
   52| 00025C ld       E8E103C0   1     L8        gr7=.jbeg(gr1,960)
   52| 000260 ld       E96103C8   1     L8        gr11=.jend(gr1,968)
   57| 000264 ld       EBA100E0   1     L8        gr29=#SPILL6(gr1,224)
    0| 000268 ld       EB6100D0   1     L8        gr27=#SPILL4(gr1,208)
    0| 00026C rldicr   79841F24   1     SLL8      gr4=gr12,3
    0| 000270 rldicr   7B801F24   1     SLL8      gr0=gr28,3
   52| 000274 lwa      E8E70002   1     L4A       gr7=jbeg(gr7,0)
   52| 000278 lwa      E96B0002   1     L4A       gr11=jend(gr11,0)
   57| 00027C addi     38BDFFFF   1     AI        gr5=gr29,-1
    0| 000280 mulld    7CC4E1D2   1     M         gr6=gr4,gr28
   57| 000284 sradi    7CA51674   1     SRA8CA    gr5,ca=gr5,2
   52| 000288 subf     7D675850   1     S         gr11=gr11,gr7
   57| 00028C addze    7CA50194   1     ADDE      gr5,ca=gr5,0,ca
   52| 000290 addic.   374B0001   1     AI_R      gr26,cr0=gr11,1,ca"
   52| 000294 addi     3B200000   1     LI        gr25=0
   52| 000298 std      FB4100E8   1     ST8       #SPILL7(gr1,232)=gr26
   52| 00029C std      FB2100F0   1     ST8       #SPILL8(gr1,240)=gr25
    0| 0002A0 mulld    7FC6D9D2   1     M         gr30=gr6,gr27
    0| 0002A4 mulld    7FE039D2   1     M         gr31=gr0,gr7
    0| 0002A8 bc       4081030C   1     BF        CL.64,cr0,0x2/gt,taken=20%(20,80)
    0| 0002AC ld       EAE101D0   1     L8        gr23=#SPILL36(gr1,464)
    0| 0002B0 ld       EB0100C0   1     L8        gr24=#SPILL2(gr1,192)
    0| 0002B4 neg      7D6400D0   1     COMP      gr11=gr4
    0| 0002B8 addi     3BFFFFF0   1     AI        gr31=gr31,-16
    0| 0002BC subf     7FC0F050   1     S         gr30=gr30,gr0
    0| 0002C0 ld       EBA103B0   1     L8        gr29=.ibeg(gr1,944)
    0| 0002C4 mulld    7C86B9D2   1     M         gr4=gr6,gr23
    0| 0002C8 rldicr   7B0726E4   1     SLL8      gr7=gr24,4
    0| 0002CC ld       E98103B8   1     L8        gr12=.iend(gr1,952)
    0| 0002D0 add      7FDEFA14   1     A         gr30=gr30,gr31
    0| 0002D4 rldicr   7B1F2EA4   1     SLL8      gr31=gr24,5
    0| 0002D8 mulld    7D6BE1D2   1     M         gr11=gr11,gr28
    0| 0002DC mulld    7CE7E1D2   1     M         gr7=gr7,gr28
    0| 0002E0 add      7E84F214   1     A         gr20=gr4,gr30
    0| 0002E4 lwa      EADD0002   1     L4A       gr22=ibeg(gr29,0)
    0| 0002E8 std      FA810108   1     ST8       #SPILL11(gr1,264)=gr20
    0| 0002EC lwa      EAAC0002   1     L4A       gr21=iend(gr12,0)
    0| 0002F0 add      7E69A214   1     A         gr19=gr9,gr20
    0| 0002F4 add      7D23A214   1     A         gr9=gr3,gr20
    0| 0002F8 std      FA610110   1     ST8       #SPILL12(gr1,272)=gr19
    0| 0002FC std      FAC100F8   1     ST8       #SPILL9(gr1,248)=gr22
    0| 000300 std      F9210118   1     ST8       #SPILL13(gr1,280)=gr9
    0| 000304 std      FAA10100   1     ST8       #SPILL10(gr1,256)=gr21
    0| 000308 ld       E9820000   1     L8        gr12=.+CONSTANT_AREA(gr2,0)
    0| 00030C mulld    7E5CF9D2   1     M         gr18=gr28,gr31
    0| 000310 add      7E269A14   1     A         gr17=gr6,gr19
    0| 000314 std      FA410120   1     ST8       #SPILL14(gr1,288)=gr18
    0| 000318 std      FA210128   1     ST8       #SPILL15(gr1,296)=gr17
    0| 00031C add      7E0B9A14   1     A         gr16=gr11,gr19
    0| 000320 add      7DE79A14   1     A         gr15=gr7,gr19
    0| 000324 std      FA010130   1     ST8       #SPILL16(gr1,304)=gr16
    0| 000328 std      F9E10138   1     ST8       #SPILL17(gr1,312)=gr15
    0| 00032C add      7DC6A214   1     A         gr14=gr6,gr20
    0| 000330 add      7FABA214   1     A         gr29=gr11,gr20
    0| 000334 std      F9C10140   1     ST8       #SPILL18(gr1,320)=gr14
    0| 000338 std      FBA10148   1     ST8       #SPILL19(gr1,328)=gr29
    0| 00033C add      7FC95A14   1     A         gr30=gr9,gr11
    0| 000340 add      7FE7A214   1     A         gr31=gr7,gr20
    0| 000344 std      FBC10150   1     ST8       #SPILL20(gr1,336)=gr30
    0| 000348 std      FBE10158   1     ST8       #SPILL21(gr1,344)=gr31
    0| 00034C add      7D674A14   1     A         gr11=gr7,gr9
    0| 000350 add      7CE64A14   1     A         gr7=gr6,gr9
    0| 000354 std      F9610160   1     ST8       #SPILL22(gr1,352)=gr11
    0| 000358 std      F8E10168   1     ST8       #SPILL23(gr1,360)=gr7
    0| 00035C addi     38C50001   1     AI        gr6=gr5,1
    0| 000360 ld       E8A103A8   1     L8        gr5=.dpde(gr1,936)
    0| 000364 std      F8C10170   1     ST8       #SPILL24(gr1,368)=gr6
    0| 000368 subf     7C96A850   1     S         gr4=gr21,gr22
    0| 00036C lfs      C02C0088   1     LFS       fp1=+CONSTANT_AREA(gr12,136)
    0| 000370 addic.   34840001   1     AI_R      gr4,cr0=gr4,1,ca"
    0| 000374 std      F8A10178   1     ST8       #SPILL25(gr1,376)=gr5
   52|                              CL.65:
    0| 000378 ld       E8C100F8   1     L8        gr6=#SPILL9(gr1,248)
   53| 00037C addi     38800000   1     LI        gr4=0
    0| 000380 rldicr   78C51F24   1     SLL8      gr5=gr6,3
    0| 000384 bc       40810184   1     BF        CL.66,cr0,0x2/gt,taken=20%(20,80)
    0| 000388 fadd     FC40082A   1     AFL       fp2=fp0,fp1,fcr
    0| 00038C ld       E9210100   1     L8        gr9=#SPILL10(gr1,256)
    0| 000390 ld       E9E10128   1     L8        gr15=#SPILL15(gr1,296)
    0| 000394 ld       E9C10138   1     L8        gr14=#SPILL17(gr1,312)
    0| 000398 subfic   20C60001   1     SFI       gr6=1,gr6,ca"
    0| 00039C ld       E8E10158   1     L8        gr7=#SPILL21(gr1,344)
    0| 0003A0 ld       E9810140   1     L8        gr12=#SPILL18(gr1,320)
    0| 0003A4 add      7D664A14   1     A         gr11=gr6,gr9
    0| 0003A8 ld       EBE10148   1     L8        gr31=#SPILL19(gr1,328)
    0| 0003AC ld       EBC10108   1     L8        gr30=#SPILL11(gr1,264)
    0| 0003B0 ld       EBA10168   1     L8        gr29=#SPILL23(gr1,360)
    0| 0003B4 ld       EB810160   1     L8        gr28=#SPILL22(gr1,352)
    0| 0003B8 ld       EB610150   1     L8        gr27=#SPILL20(gr1,336)
    0| 0003BC ld       EB410118   1     L8        gr26=#SPILL13(gr1,280)
    0| 0003C0 ld       E8C10110   1     L8        gr6=#SPILL12(gr1,272)
    0| 0003C4 add      7E057A14   1     A         gr16=gr5,gr15
    0| 0003C8 add      7DE57214   1     A         gr15=gr5,gr14
    0| 0003CC ld       E9C10130   1     L8        gr14=#SPILL16(gr1,304)
    0| 0003D0 std      F9610180   1     ST8       #SPILL26(gr1,384)=gr11
    0| 0003D4 add      7F253A14   1     A         gr25=gr5,gr7
    0| 0003D8 add      7F056214   1     A         gr24=gr5,gr12
    0| 0003DC add      7EE5FA14   1     A         gr23=gr5,gr31
    0| 0003E0 add      7EC5F214   1     A         gr22=gr5,gr30
    0| 0003E4 add      7EA5EA14   1     A         gr21=gr5,gr29
    0| 0003E8 add      7E85E214   1     A         gr20=gr5,gr28
    0| 0003EC add      7E65DA14   1     A         gr19=gr5,gr27
    0| 0003F0 add      7E45D214   1     A         gr18=gr5,gr26
    0| 0003F4 add      7E253214   1     A         gr17=gr5,gr6
    0| 0003F8 add      7DCE2A14   1     A         gr14=gr14,gr5
   53|                              CL.67:
   55| 0003FC or       7E659B78   1     LR        gr5=gr19
   55| 000400 or       7E469378   1     LR        gr6=gr18
   55| 000404 or       7EA7AB78   1     LR        gr7=gr21
   56| 000408 ld       EB410178   1     L8        gr26=#SPILL25(gr1,376)
    0| 00040C ld       EBC10180   1     L8        gr30=#SPILL26(gr1,384)
   55| 000410 lfdu     CC650008   1     LFDU      fp3,gr5=e[](gr5,8)
   55| 000414 lfdu     CC860008   1     LFDU      fp4,gr6=e[](gr6,8)
   55| 000418 lfdu     CCA70008   1     LFDU      fp5,gr7=e[](gr7,8)
   55| 00041C or       7E89A378   1     LR        gr9=gr20
   56| 000420 add      7D77D214   1     A         gr11=gr23,gr26
   56| 000424 add      7D96D214   1     A         gr12=gr22,gr26
   56| 000428 stfdu    DC4B0008   1     STFDU     gr11,dpde[](gr11,8)=fp2
   55| 00042C fmul     FC6200F2   1     MFL       fp3=fp2,fp3,fcr
   56| 000430 add      7FF8D214   1     A         gr31=gr24,gr26
   55| 000434 fmul     FC820132   1     MFL       fp4=fp2,fp4,fcr
    0| 000438 mtspr    7FC903A6   1     LCTR      ctr=gr30
   55| 00043C fmul     FCE20172   1     MFL       fp7=fp2,fp5,fcr
   56| 000440 stfdu    DC4C0008   2     STFDU     gr12,dpde[](gr12,8)=fp2
   56| 000444 stfdu    DC5F0008   1     STFDU     gr31,dpde[](gr31,8)=fp2
   55| 000448 lfdu     CCA90008   1     LFDU      fp5,gr9=e[](gr9,8)
   55| 00044C or       7DDE7378   1     LR        gr30=gr14
   55| 000450 or       7E3D8B78   1     LR        gr29=gr17
   55| 000454 or       7E1C8378   1     LR        gr28=gr16
   56| 000458 add      7F79D214   1     A         gr27=gr25,gr26
   55| 00045C or       7DFA7B78   1     LR        gr26=gr15
    0| 000460 bc       42400050   1     BCF       ctr=CL.765,taken=0%(0,100)
    0| 000464 ori      60210000   1     XNOP      
    0| 000468 ori      60210000   1     XNOP      
    0|                              CL.766:
   55| 00046C lfdu     CCC50008   1     LFDU      fp6,gr5=e[](gr5,8)
   55| 000470 fmul     FCA20172   1     MFL       fp5=fp2,fp5,fcr
   55| 000474 stfdu    DC7E0008   2     STFDU     gr30,p[](gr30,8)=fp3
   55| 000478 stfdu    DC9D0008   1     STFDU     gr29,p[](gr29,8)=fp4
   55| 00047C stfdu    DCFC0008   1     STFDU     gr28,p[](gr28,8)=fp7
   55| 000480 lfdu     CC860008   1     LFDU      fp4,gr6=e[](gr6,8)
   55| 000484 lfdu     CCE70008   1     LFDU      fp7,gr7=e[](gr7,8)
   55| 000488 stfdu    DCBA0008   1     STFDU     gr26,p[](gr26,8)=fp5
   56| 00048C stfdu    DC5B0008   1     STFDU     gr27,dpde[](gr27,8)=fp2
   56| 000490 stfdu    DC4B0008   1     STFDU     gr11,dpde[](gr11,8)=fp2
   55| 000494 lfdu     CCA90008   1     LFDU      fp5,gr9=e[](gr9,8)
   55| 000498 fmul     FC6201B2   1     MFL       fp3=fp2,fp6,fcr
   55| 00049C fmul     FC820132   2     MFL       fp4=fp2,fp4,fcr
   55| 0004A0 fmul     FCE201F2   2     MFL       fp7=fp2,fp7,fcr
   56| 0004A4 stfdu    DC4C0008   2     STFDU     gr12,dpde[](gr12,8)=fp2
   56| 0004A8 stfdu    DC5F0008   1     STFDU     gr31,dpde[](gr31,8)=fp2
    0| 0004AC bc       4200FFC0   1     BCT       ctr=CL.766,taken=100%(100,0)
    0|                              CL.765:
   56| 0004B0 stfdu    DC5B0008   1     STFDU     gr27,dpde[](gr27,8)=fp2
   57| 0004B4 ld       E8A100E8   1     L8        gr5=#SPILL7(gr1,232)
   55| 0004B8 stfdu    DC7E0008   1     STFDU     gr30,p[](gr30,8)=fp3
   55| 0004BC fmul     FC620172   1     MFL       fp3=fp2,fp5,fcr
   57| 0004C0 addi     38840001   1     AI        gr4=gr4,1
   55| 0004C4 stfdu    DC9D0008   1     STFDU     gr29,p[](gr29,8)=fp4
   55| 0004C8 stfdu    DCFC0008   1     STFDU     gr28,p[](gr28,8)=fp7
   57| 0004CC cmpld    7CA42840   1     CL8       cr1=gr4,gr5
    0| 0004D0 add      7F390214   1     A         gr25=gr25,gr0
    0| 0004D4 add      7F180214   1     A         gr24=gr24,gr0
   55| 0004D8 stfdu    DC7A0008   1     STFDU     gr26,p[](gr26,8)=fp3
    0| 0004DC add      7EF70214   1     A         gr23=gr23,gr0
    0| 0004E0 add      7ED60214   1     A         gr22=gr22,gr0
    0| 0004E4 add      7EB50214   1     A         gr21=gr21,gr0
    0| 0004E8 add      7E940214   1     A         gr20=gr20,gr0
    0| 0004EC add      7E730214   1     A         gr19=gr19,gr0
    0| 0004F0 add      7E520214   1     A         gr18=gr18,gr0
    0| 0004F4 add      7E310214   1     A         gr17=gr17,gr0
    0| 0004F8 add      7E100214   1     A         gr16=gr16,gr0
    0| 0004FC add      7DEF0214   1     A         gr15=gr15,gr0
    0| 000500 add      7DCE0214   1     A         gr14=gr14,gr0
   57| 000504 bc       4184FEF8   1     BT        CL.67,cr1,0x8/llt,taken=80%(80,20)
   57|                              CL.66:
   57| 000508 ld       E88100F0   1     L8        gr4=#SPILL8(gr1,240)
    0| 00050C ld       E8A10120   1     L8        gr5=#SPILL14(gr1,288)
    0| 000510 ld       E8C10128   1     L8        gr6=#SPILL15(gr1,296)
   57| 000514 ld       E8E10170   1     L8        gr7=#SPILL24(gr1,368)
    0| 000518 ld       E9210130   1     L8        gr9=#SPILL16(gr1,304)
    0| 00051C ld       E9610138   1     L8        gr11=#SPILL17(gr1,312)
    0| 000520 ld       E9810140   1     L8        gr12=#SPILL18(gr1,320)
    0| 000524 ld       EBE10110   1     L8        gr31=#SPILL12(gr1,272)
    0| 000528 ld       EBC10148   1     L8        gr30=#SPILL19(gr1,328)
    0| 00052C ld       EBA10150   1     L8        gr29=#SPILL20(gr1,336)
    0| 000530 ld       EB810158   1     L8        gr28=#SPILL21(gr1,344)
    0| 000534 ld       EB610108   1     L8        gr27=#SPILL11(gr1,264)
    0| 000538 ld       EB410160   1     L8        gr26=#SPILL22(gr1,352)
    0| 00053C ld       EB210168   1     L8        gr25=#SPILL23(gr1,360)
    0| 000540 ld       EB010118   1     L8        gr24=#SPILL13(gr1,280)
   57| 000544 addi     38840001   1     AI        gr4=gr4,1
    0| 000548 add      7CC53214   1     A         gr6=gr5,gr6
   57| 00054C std      F88100F0   1     ST8       #SPILL8(gr1,240)=gr4
    0| 000550 std      F8C10128   1     ST8       #SPILL15(gr1,296)=gr6
   57| 000554 cmpld    7CA43840   1     CL8       cr1=gr4,gr7
    0| 000558 add      7D254A14   1     A         gr9=gr5,gr9
    0| 00055C add      7D655A14   1     A         gr11=gr5,gr11
    0| 000560 std      F9210130   1     ST8       #SPILL16(gr1,304)=gr9
    0| 000564 std      F9610138   1     ST8       #SPILL17(gr1,312)=gr11
    0| 000568 add      7D856214   1     A         gr12=gr5,gr12
    0| 00056C add      7FE5FA14   1     A         gr31=gr5,gr31
    0| 000570 std      F9810140   1     ST8       #SPILL18(gr1,320)=gr12
    0| 000574 std      FBE10110   1     ST8       #SPILL12(gr1,272)=gr31
    0| 000578 add      7FC5F214   1     A         gr30=gr5,gr30
    0| 00057C add      7FA5EA14   1     A         gr29=gr5,gr29
    0| 000580 std      FBC10148   1     ST8       #SPILL19(gr1,328)=gr30
    0| 000584 std      FBA10150   1     ST8       #SPILL20(gr1,336)=gr29
    0| 000588 add      7F85E214   1     A         gr28=gr5,gr28
    0| 00058C add      7F65DA14   1     A         gr27=gr5,gr27
    0| 000590 std      FB810158   1     ST8       #SPILL21(gr1,344)=gr28
    0| 000594 std      FB610108   1     ST8       #SPILL11(gr1,264)=gr27
    0| 000598 add      7F45D214   1     A         gr26=gr5,gr26
    0| 00059C add      7F25CA14   1     A         gr25=gr5,gr25
    0| 0005A0 std      FB410160   1     ST8       #SPILL22(gr1,352)=gr26
    0| 0005A4 std      FB210168   1     ST8       #SPILL23(gr1,360)=gr25
    0| 0005A8 add      7F05C214   1     A         gr24=gr5,gr24
    0| 0005AC std      FB010118   1     ST8       #SPILL13(gr1,280)=gr24
   57| 0005B0 bc       4184FDC8   1     BT        CL.65,cr1,0x8/llt,taken=80%(80,20)
   57|                              CL.64:
   65| 0005B4 bc       409001C0   1     BF        CL.144,cr4,0x1/lt,taken=50%(0,0)
   65| 0005B8 ld       E8A103C0   1     L8        gr5=.jbeg(gr1,960)
   65| 0005BC ld       E8C103C8   1     L8        gr6=.jend(gr1,968)
   68| 0005C0 ld       E8E20000   1     L8        gr7=.&&N&&cons(gr2,0)
   65| 0005C4 addi     38800000   1     LI        gr4=0
   65| 0005C8 lwa      E8A50002   1     L4A       gr5=jbeg(gr5,0)
   65| 0005CC lwa      E8060002   1     L4A       gr0=jend(gr6,0)
   68| 0005D0 lfd      C8270008   1     LFL       fp1=<s111:d8:l8>(gr7,8)
   65| 0005D4 subf     7CC50050   1     S         gr6=gr0,gr5
   65| 0005D8 addic.   34060001   1     AI_R      gr0,cr0=gr6,1,ca"
    0| 0005DC bc       408117A8   1     BF        CL.502,cr0,0x2/gt,taken=50%(0,0)
    0| 0005E0 ld       EB0100C0   1     L8        gr24=#SPILL2(gr1,192)
    0| 0005E4 ld       EAE100C8   1     L8        gr23=#SPILL3(gr1,200)
    0| 0005E8 ld       EAC100D0   1     L8        gr22=#SPILL4(gr1,208)
    0| 0005EC ld       E96103B0   1     L8        gr11=.ibeg(gr1,944)
    0| 0005F0 ld       E8E103B8   1     L8        gr7=.iend(gr1,952)
    0| 0005F4 ld       EAA100B8   1     L8        gr21=#SPILL1(gr1,184)
    0| 0005F8 rldicr   7B061F24   1     SLL8      gr6=gr24,3
    0| 0005FC rldicr   7AEC1F24   1     SLL8      gr12=gr23,3
    0| 000600 mulld    7FE6B9D2   1     M         gr31=gr6,gr23
    0| 000604 neg      7D2600D0   1     COMP      gr9=gr6
    0| 000608 mulld    7CA561D2   1     M         gr5=gr5,gr12
    0| 00060C mulld    7CD6F9D2   1     M         gr6=gr22,gr31
    0| 000610 lwa      EBCB0002   1     L4A       gr30=ibeg(gr11,0)
    0| 000614 lwa      EBA70002   1     L4A       gr29=iend(gr7,0)
    0| 000618 mulld    7D29B9D2   1     M         gr9=gr9,gr23
    0| 00061C addi     38E5FFF0   1     AI        gr7=gr5,-16
    0| 000620 subf     7CCC3050   1     S         gr6=gr6,gr12
    0| 000624 ld       E8A20000   1     L8        gr5=.+CONSTANT_AREA(gr2,0)
    0| 000628 ld       EA8100B0   1     L8        gr20=#SPILL0(gr1,176)
    0| 00062C add      7CC63A14   1     A         gr6=gr6,gr7
    0| 000630 subf     7CFEE850   1     S         gr7=gr29,gr30
    0| 000634 add      7CC64A14   1     A         gr6=gr6,gr9
    0| 000638 addic.   34E70001   1     AI_R      gr7,cr0=gr7,1,ca"
    0| 00063C add      7F833214   1     A         gr28=gr3,gr6
    0| 000640 add      7F66AA14   1     A         gr27=gr6,gr21
    0| 000644 add      7F464214   1     A         gr26=gr6,gr8
    0| 000648 add      7F26A214   1     A         gr25=gr6,gr20
    0| 00064C lfs      C0450088   1     LFS       fp2=+CONSTANT_AREA(gr5,136)
    0| 000650 lfs      C065008C   1     LFS       fp3=+CONSTANT_AREA(gr5,140)
    0| 000654 lfd      C8850090   1     LFL       fp4=+CONSTANT_AREA(gr5,144)
    0| 000658 lfs      C0A50098   1     LFS       fp5=+CONSTANT_AREA(gr5,152)
    0| 00065C mcrf     4C800000   1     LRCR      cr1=cr0
   65|                              CL.139:
   66| 000660 addi     38A00000   1     LI        gr5=0
    0| 000664 bc       408500F0   1     BF        CL.143,cr1,0x2/gt,taken=20%(20,80)
    0| 000668 fadd     FCC0102A   1     AFL       fp6=fp0,fp2,fcr
    0| 00066C subfic   20FE0001   1     SFI       gr7=1,gr30,ca"
    0| 000670 rldicr   7BC61F24   1     SLL8      gr6=gr30,3
    0| 000674 add      7F1D3A14   1     A         gr24=gr29,gr7
    0| 000678 add      7EE6DA14   1     A         gr23=gr6,gr27
    0| 00067C add      7EC6D214   1     A         gr22=gr6,gr26
    0| 000680 fmul     FCC60072   1     MFL       fp6=fp6,fp1,fcr
    0| 000684 add      7EA6CA14   1     A         gr21=gr6,gr25
    0| 000688 add      7E86E214   1     A         gr20=gr6,gr28
    0| 00068C fmul     FCC600F2   1     MFL       fp6=fp6,fp3,fcr
    0| 000690 fmul     FCC60132   2     MFL       fp6=fp6,fp4,fcr
   66|                              CL.140:
   68| 000694 or       7EA6AB78   1     LR        gr6=gr21
   68| 000698 or       7E87A378   1     LR        gr7=gr20
   68| 00069C lfdu     CCE60008   1     LFDU      fp7,gr6=d[](gr6,8)
    0| 0006A0 mtspr    7F0903A6   1     LCTR      ctr=gr24
   68| 0006A4 lfdu     CDA70008   1     LFDU      fp13,gr7=e[](gr7,8)
   69| 0006A8 or       7EC9B378   1     LR        gr9=gr22
   68| 0006AC or       7EEBBB78   1     LR        gr11=gr23
   68| 0006B0 qvfre    11003830   1     QVFRE     fp8=fp7
   68| 0006B4 fmsub    FD272A38   1     FMS       fp9=fp5,fp7,fp8,fcr
   68| 0006B8 fnmsub   FD68427C   2     FNMS      fp11=fp8,fp8,fp9,fcr
   68| 0006BC fmsub    FD472AF8   2     FMS       fp10=fp5,fp7,fp11,fcr
    0| 0006C0 bc       42400050   1     BCF       ctr=CL.767,taken=0%(0,100)
    0| 0006C4 ori      60210000   1     XNOP      
    0|                              CL.768:
   68| 0006C8 lfdu     CD060008   1     LFDU      fp8,gr6=d[](gr6,8)
   68| 0006CC fmul     FD260372   1     MFL       fp9=fp6,fp13,fcr
   68| 0006D0 fnmsub   FD4B5ABC   2     FNMS      fp10=fp11,fp11,fp10,fcr
   68| 0006D4 qvfre    11604030   1     QVFRE     fp11=fp8
   68| 0006D8 fmul     FD8902B2   1     MFL       fp12=fp9,fp10,fcr
   69| 0006DC fmul     FDA602B2   2     MFL       fp13=fp6,fp10,fcr
   68| 0006E0 fmsub    FFE82AF8   2     FMS       fp31=fp5,fp8,fp11,fcr
   68| 0006E4 fmsub    FD274B38   2     FMS       fp9=fp9,fp7,fp12,fcr
   69| 0006E8 fmsub    FCE73378   2     FMS       fp7=fp6,fp7,fp13,fcr
   68| 0006EC fnmsub   FD6B5FFC   2     FNMS      fp11=fp11,fp11,fp31,fcr
   68| 0006F0 fnmsub   FD2A627C   2     FNMS      fp9=fp12,fp10,fp9,fcr
   69| 0006F4 fnmsub   FD8A69FC   2     FNMS      fp12=fp13,fp10,fp7,fcr
   68| 0006F8 lfdu     CDA70008   1     LFDU      fp13,gr7=e[](gr7,8)
    0| 0006FC fmr      FCE04090   1     LRFL      fp7=fp8
   68| 000700 fmsub    FD482AF8   2     FMS       fp10=fp5,fp8,fp11,fcr
   68| 000704 stfdu    DD2B0008   2     STFDU     gr11,t[](gr11,8)=fp9
   69| 000708 stfdu    DD890008   1     STFDU     gr9,dtde[](gr9,8)=fp12
    0| 00070C bc       4200FFBC   1     BCT       ctr=CL.768,taken=100%(100,0)
    0|                              CL.767:
   68| 000710 fmul     FD060372   1     MFL       fp8=fp6,fp13,fcr
   72| 000714 addi     38A50001   1     AI        gr5=gr5,1
   68| 000718 fnmsub   FD2B5ABC   1     FNMS      fp9=fp11,fp11,fp10,fcr
   72| 00071C cmpld    7C250040   1     CL8       cr0=gr5,gr0
    0| 000720 add      7EF76214   1     A         gr23=gr23,gr12
    0| 000724 add      7ED66214   1     A         gr22=gr22,gr12
    0| 000728 add      7EB56214   1     A         gr21=gr21,gr12
    0| 00072C add      7E946214   1     A         gr20=gr20,gr12
   68| 000730 fmul     FD480272   1     MFL       fp10=fp8,fp9,fcr
   69| 000734 fmul     FD660272   2     MFL       fp11=fp6,fp9,fcr
   68| 000738 fmsub    FD0742B8   2     FMS       fp8=fp8,fp7,fp10,fcr
   69| 00073C fmsub    FCE732F8   2     FMS       fp7=fp6,fp7,fp11,fcr
   68| 000740 fnmsub   FD09523C   2     FNMS      fp8=fp10,fp9,fp8,fcr
   69| 000744 fnmsub   FCE959FC   2     FNMS      fp7=fp11,fp9,fp7,fcr
   68| 000748 stfdu    DD0B0008   2     STFDU     gr11,t[](gr11,8)=fp8
   69| 00074C stfdu    DCE90008   1     STFDU     gr9,dtde[](gr9,8)=fp7
   72| 000750 bc       4180FF44   1     BT        CL.140,cr0,0x8/llt,taken=80%(80,20)
   72|                              CL.143:
   72| 000754 ld       E8A101D0   1     L8        gr5=#SPILL36(gr1,464)
   72| 000758 addi     38840001   1     AI        gr4=gr4,1
    0| 00075C add      7F39FA14   1     A         gr25=gr25,gr31
    0| 000760 add      7F5AFA14   1     A         gr26=gr26,gr31
    0| 000764 add      7F7BFA14   1     A         gr27=gr27,gr31
    0| 000768 add      7F9CFA14   1     A         gr28=gr28,gr31
   72| 00076C cmpd     7C252000   1     C8        cr0=gr5,gr4
   72| 000770 bc       4181FEF0   1     BT        CL.139,cr0,0x2/gt,taken=80%(80,20)
   72|                              CL.144:
   65| 000774 bc       408D05F0   1     BF        CL.70,cr3,0x2/gt,taken=50%(0,0)
    0| 000778 ld       EBE100C0   1     L8        gr31=#SPILL2(gr1,192)
   65| 00077C ld       E92103C0   1     L8        gr9=.jbeg(gr1,960)
    0| 000780 ld       EBA100C8   1     L8        gr29=#SPILL3(gr1,200)
   65| 000784 ld       E8A103C8   1     L8        gr5=.jend(gr1,968)
   72| 000788 ld       EBC100E0   1     L8        gr30=#SPILL6(gr1,224)
    0| 00078C ld       EB8100D0   1     L8        gr28=#SPILL4(gr1,208)
    0| 000790 rldicr   7BE61F24   1     SLL8      gr6=gr31,3
   65| 000794 lwa      E9290002   1     L4A       gr9=jbeg(gr9,0)
    0| 000798 rldicr   7BA01F24   1     SLL8      gr0=gr29,3
   65| 00079C lwa      E9850002   1     L4A       gr12=jend(gr5,0)
   72| 0007A0 addi     389EFFFF   1     AI        gr4=gr30,-1
    0| 0007A4 mulld    7CE6E9D2   1     M         gr7=gr6,gr29
   72| 0007A8 sradi    7C841674   1     SRA8CA    gr4,ca=gr4,2
   68| 0007AC ld       E8A20000   1     L8        gr5=.&&N&&cons(gr2,0)
    0| 0007B0 mulld    7D6049D2   1     M         gr11=gr0,gr9
   65| 0007B4 subf     7D296050   1     S         gr9=gr12,gr9
   72| 0007B8 addze    7C840194   1     ADDE      gr4,ca=gr4,0,ca
   65| 0007BC addic.   37690001   1     AI_R      gr27,cr0=gr9,1,ca"
   65| 0007C0 addi     3B400000   1     LI        gr26=0
   65| 0007C4 std      FB6100E8   1     ST8       #SPILL7(gr1,232)=gr27
   65| 0007C8 std      FB4100F0   1     ST8       #SPILL8(gr1,240)=gr26
    0| 0007CC mulld    7D87E1D2   1     M         gr12=gr7,gr28
   68| 0007D0 lfd      C8250008   1     LFL       fp1=<s111:d8:l8>(gr5,8)
    0| 0007D4 bc       40810590   1     BF        CL.70,cr0,0x2/gt,taken=20%(20,80)
    0| 0007D8 ld       EB2101D0   1     L8        gr25=#SPILL36(gr1,464)
    0| 0007DC neg      7CC600D0   1     COMP      gr6=gr6
    0| 0007E0 rldicr   7BE526E4   1     SLL8      gr5=gr31,4
    0| 0007E4 ld       E92103B8   1     L8        gr9=.iend(gr1,952)
    0| 0007E8 ld       EAC100C0   1     L8        gr22=#SPILL2(gr1,192)
    0| 0007EC addi     396BFFF0   1     AI        gr11=gr11,-16
    0| 0007F0 mulld    7FE7C9D2   1     M         gr31=gr7,gr25
    0| 0007F4 subf     7D806050   1     S         gr12=gr12,gr0
    0| 0007F8 mulld    7CC6E9D2   1     M         gr6=gr6,gr29
    0| 0007FC mulld    7CA5E9D2   1     M         gr5=gr5,gr29
    0| 000800 lwa      EAE90002   1     L4A       gr23=iend(gr9,0)
    0| 000804 add      7D2B6214   1     A         gr9=gr11,gr12
    0| 000808 rldicr   7ACB2EA4   1     SLL8      gr11=gr22,5
    0| 00080C ld       EBC103B0   1     L8        gr30=.ibeg(gr1,944)
    0| 000810 add      7D29FA14   1     A         gr9=gr9,gr31
    0| 000814 mulld    7EABE9D2   1     M         gr21=gr11,gr29
    0| 000818 std      FAE10100   1     ST8       #SPILL10(gr1,256)=gr23
    0| 00081C std      FAA10108   1     ST8       #SPILL11(gr1,264)=gr21
    0| 000820 add      7CC64A14   1     A         gr6=gr6,gr9
    0| 000824 add      7D674A14   1     A         gr11=gr7,gr9
    0| 000828 add      7CE54A14   1     A         gr7=gr5,gr9
    0| 00082C lwa      EB1E0002   1     L4A       gr24=ibeg(gr30,0)
    0| 000830 add      7E864214   1     A         gr20=gr6,gr8
    0| 000834 add      7E685A14   1     A         gr19=gr8,gr11
    0| 000838 std      FA810110   1     ST8       #SPILL12(gr1,272)=gr20
    0| 00083C std      FA610118   1     ST8       #SPILL13(gr1,280)=gr19
    0| 000840 add      7E474214   1     A         gr18=gr7,gr8
    0| 000844 std      FB0100F8   1     ST8       #SPILL9(gr1,248)=gr24
    0| 000848 std      FA410120   1     ST8       #SPILL14(gr1,288)=gr18
    0| 00084C add      7E284A14   1     A         gr17=gr8,gr9
    0| 000850 ld       E90100B8   1     L8        gr8=#SPILL1(gr1,184)
    0| 000854 std      FA210128   1     ST8       #SPILL15(gr1,296)=gr17
    0| 000858 ld       EBC100B0   1     L8        gr30=#SPILL0(gr1,176)
    0| 00085C ld       E9820000   1     L8        gr12=.+CONSTANT_AREA(gr2,0)
    0| 000860 subf     7CB8B850   1     S         gr5=gr23,gr24
    0| 000864 add      7DC33214   1     A         gr14=gr3,gr6
    0| 000868 add      7E085A14   1     A         gr16=gr8,gr11
    0| 00086C std      F9C10140   1     ST8       #SPILL18(gr1,320)=gr14
    0| 000870 std      FA010130   1     ST8       #SPILL16(gr1,304)=gr16
    0| 000874 add      7DE64214   1     A         gr15=gr6,gr8
    0| 000878 add      7FE7F214   1     A         gr31=gr7,gr30
    0| 00087C std      F9E10138   1     ST8       #SPILL17(gr1,312)=gr15
    0| 000880 std      FBE10148   1     ST8       #SPILL19(gr1,328)=gr31
    0| 000884 add      7EC35A14   1     A         gr22=gr3,gr11
    0| 000888 add      7F284A14   1     A         gr25=gr8,gr9
    0| 00088C std      FAC10150   1     ST8       #SPILL20(gr1,336)=gr22
    0| 000890 std      FB210158   1     ST8       #SPILL21(gr1,344)=gr25
    0| 000894 add      7F434A14   1     A         gr26=gr3,gr9
    0| 000898 add      7C633A14   1     A         gr3=gr3,gr7
    0| 00089C std      FB410160   1     ST8       #SPILL22(gr1,352)=gr26
    0| 0008A0 std      F8610168   1     ST8       #SPILL23(gr1,360)=gr3
    0| 0008A4 add      7D6BF214   1     A         gr11=gr11,gr30
    0| 0008A8 add      7D29F214   1     A         gr9=gr9,gr30
    0| 0008AC std      F9610170   1     ST8       #SPILL24(gr1,368)=gr11
    0| 0008B0 std      F9210178   1     ST8       #SPILL25(gr1,376)=gr9
    0| 0008B4 add      7CE74214   1     A         gr7=gr7,gr8
    0| 0008B8 add      7CC6F214   1     A         gr6=gr6,gr30
    0| 0008BC std      F8E10180   1     ST8       #SPILL26(gr1,384)=gr7
    0| 0008C0 addi     38840001   1     AI        gr4=gr4,1
    0| 0008C4 std      F8C10188   1     ST8       #SPILL27(gr1,392)=gr6
    0| 0008C8 std      F8810190   1     ST8       #SPILL28(gr1,400)=gr4
    0| 0008CC lfs      C04C0088   1     LFS       fp2=+CONSTANT_AREA(gr12,136)
    0| 0008D0 lfs      C06C008C   1     LFS       fp3=+CONSTANT_AREA(gr12,140)
    0| 0008D4 lfd      C88C0090   1     LFL       fp4=+CONSTANT_AREA(gr12,144)
    0| 0008D8 lfs      C0AC0098   1     LFS       fp5=+CONSTANT_AREA(gr12,152)
    0| 0008DC addic.   34650001   1     AI_R      gr3,cr0=gr5,1,ca"
   65|                              CL.71:
   66| 0008E0 addi     38600000   1     LI        gr3=0
   66| 0008E4 std      F8610198   1     ST8       #SPILL29(gr1,408)=gr3
    0| 0008E8 bc       408103A0   1     BF        CL.72,cr0,0x2/gt,taken=20%(20,80)
    0| 0008EC fadd     FCC0102A   1     AFL       fp6=fp0,fp2,fcr
    0| 0008F0 ld       E8A100F8   1     L8        gr5=#SPILL9(gr1,248)
    0| 0008F4 ld       E8C10100   1     L8        gr6=#SPILL10(gr1,256)
    0| 0008F8 ld       EAA10120   1     L8        gr21=#SPILL14(gr1,288)
    0| 0008FC ld       EA810150   1     L8        gr20=#SPILL20(gr1,336)
    0| 000900 ld       EA610130   1     L8        gr19=#SPILL16(gr1,304)
    0| 000904 fmul     FCC60072   1     MFL       fp6=fp6,fp1,fcr
    0| 000908 ld       EA410118   1     L8        gr18=#SPILL13(gr1,280)
    0| 00090C ld       EA210180   1     L8        gr17=#SPILL26(gr1,384)
    0| 000910 ld       EA010168   1     L8        gr16=#SPILL23(gr1,360)
    0| 000914 ld       E9E10140   1     L8        gr15=#SPILL18(gr1,320)
    0| 000918 ld       E9C10138   1     L8        gr14=#SPILL17(gr1,312)
    0| 00091C fmul     FCC600F2   1     MFL       fp6=fp6,fp3,fcr
    0| 000920 subfic   20850001   1     SFI       gr4=1,gr5,ca"
    0| 000924 rldicr   78A31F24   1     SLL8      gr3=gr5,3
    0| 000928 ld       E9010170   1     L8        gr8=#SPILL24(gr1,368)
    0| 00092C ld       E9610148   1     L8        gr11=#SPILL19(gr1,328)
    0| 000930 ld       EBE10188   1     L8        gr31=#SPILL27(gr1,392)
    0| 000934 fmul     FCC60132   1     MFL       fp6=fp6,fp4,fcr
    0| 000938 ld       EBA10178   1     L8        gr29=#SPILL25(gr1,376)
    0| 00093C ld       EB610158   1     L8        gr27=#SPILL21(gr1,344)
    0| 000940 add      7CE43214   1     A         gr7=gr4,gr6
    0| 000944 ld       EB210160   1     L8        gr25=#SPILL22(gr1,352)
    0| 000948 std      F8E101A0   1     ST8       #SPILL30(gr1,416)=gr7
    0| 00094C ld       E8810128   1     L8        gr4=#SPILL15(gr1,296)
    0| 000950 add      7EC3AA14   1     A         gr22=gr3,gr21
    0| 000954 add      7EA3A214   1     A         gr21=gr3,gr20
    0| 000958 add      7E839A14   1     A         gr20=gr3,gr19
    0| 00095C add      7E639214   1     A         gr19=gr3,gr18
    0| 000960 add      7E438A14   1     A         gr18=gr3,gr17
    0| 000964 add      7E238214   1     A         gr17=gr3,gr16
    0| 000968 add      7E037A14   1     A         gr16=gr3,gr15
    0| 00096C add      7DE37214   1     A         gr15=gr3,gr14
    0| 000970 ld       E9C10110   1     L8        gr14=#SPILL12(gr1,272)
    0| 000974 add      7D234214   1     A         gr9=gr3,gr8
    0| 000978 add      7D835A14   1     A         gr12=gr3,gr11
    0| 00097C std      F92101A8   1     ST8       #SPILL31(gr1,424)=gr9
    0| 000980 std      F98101B0   1     ST8       #SPILL32(gr1,432)=gr12
    0| 000984 add      7FC3FA14   1     A         gr30=gr3,gr31
    0| 000988 add      7F83EA14   1     A         gr28=gr3,gr29
    0| 00098C std      FBC101B8   1     ST8       #SPILL33(gr1,440)=gr30
    0| 000990 std      FB8101C0   1     ST8       #SPILL34(gr1,448)=gr28
    0| 000994 add      7F43DA14   1     A         gr26=gr3,gr27
    0| 000998 add      7F03CA14   1     A         gr24=gr3,gr25
    0| 00099C std      FB4101C8   1     ST8       #SPILL35(gr1,456)=gr26
    0| 0009A0 add      7EE32214   1     A         gr23=gr3,gr4
    0| 0009A4 add      7DCE1A14   1     A         gr14=gr14,gr3
   66|                              CL.73:
   68| 0009A8 ld       E86101B8   1     L8        gr3=#SPILL33(gr1,440)
   68| 0009AC ld       E88101C0   1     L8        gr4=#SPILL34(gr1,448)
   68| 0009B0 ld       E8A101A8   1     L8        gr5=#SPILL31(gr1,424)
   68| 0009B4 ld       E8C101B0   1     L8        gr6=#SPILL32(gr1,432)
    0| 0009B8 ld       E8E101A0   1     L8        gr7=#SPILL30(gr1,416)
   68| 0009BC or       7F08C378   1     LR        gr8=gr24
   68| 0009C0 lfdu     CCE30008   1     LFDU      fp7,gr3=d[](gr3,8)
   68| 0009C4 lfdu     CD040008   1     LFDU      fp8,gr4=d[](gr4,8)
   68| 0009C8 lfdu     CD250008   1     LFDU      fp9,gr5=d[](gr5,8)
   68| 0009CC lfdu     CD460008   1     LFDU      fp10,gr6=d[](gr6,8)
    0| 0009D0 mtspr    7CE903A6   1     LCTR      ctr=gr7
   68| 0009D4 or       7E078378   1     LR        gr7=gr16
   68| 0009D8 or       7EA9AB78   1     LR        gr9=gr21
   68| 0009DC qvfre    11803830   1     QVFRE     fp12=fp7
   68| 0009E0 or       7E2B8B78   1     LR        gr11=gr17
   68| 0009E4 qvfre    13804030   1     QVFRE     fp28=fp8
   68| 0009E8 lfdu     CDA70008   1     LFDU      fp13,gr7=e[](gr7,8)
   68| 0009EC qvfre    13404830   1     QVFRE     fp26=fp9
   68| 0009F0 lfdu     CFE80008   1     LFDU      fp31,gr8=e[](gr8,8)
   68| 0009F4 qvfre    13205030   1     QVFRE     fp25=fp10
   68| 0009F8 lfdu     CFA90008   1     LFDU      fp29,gr9=e[](gr9,8)
   68| 0009FC fmsub    FFC72B38   1     FMS       fp30=fp5,fp7,fp12,fcr
   68| 000A00 lfdu     CF6B0008   1     LFDU      fp27,gr11=e[](gr11,8)
   68| 000A04 fmsub    FEE82F38   1     FMS       fp23=fp5,fp8,fp28,fcr
   69| 000A08 or       7DCC7378   1     LR        gr12=gr14
   68| 000A0C or       7DFF7B78   1     LR        gr31=gr15
   69| 000A10 or       7EFEBB78   1     LR        gr30=gr23
   68| 000A14 ld       EBA101C8   1     L8        gr29=#SPILL35(gr1,456)
   69| 000A18 or       7E7C9B78   1     LR        gr28=gr19
   68| 000A1C or       7E9BA378   1     LR        gr27=gr20
   69| 000A20 or       7EDAB378   1     LR        gr26=gr22
   68| 000A24 or       7E599378   1     LR        gr25=gr18
    0| 000A28 bc       42400118   1     BCF       ctr=CL.769,taken=0%(0,100)
    0| 000A2C ori      60210000   1     XNOP      
    0| 000A30 ori      60210000   1     XNOP      
    0|                              CL.770:
   68| 000A34 lfdu     CD630008   1     LFDU      fp11,gr3=d[](gr3,8)
   68| 000A38 fmsub    FEC92EB8   1     FMS       fp22=fp5,fp9,fp26,fcr
   68| 000A3C fmsub    FF0A2E78   2     FMS       fp24=fp5,fp10,fp25,fcr
   68| 000A40 fnmsub   FFCC67BC   2     FNMS      fp30=fp12,fp12,fp30,fcr
    0| 000A44 fmr      FD804090   2     LRFL      fp12=fp8
   68| 000A48 fnmsub   FF9CE5FC   2     FNMS      fp28=fp28,fp28,fp23,fcr
   68| 000A4C lfdu     CD040008   1     LFDU      fp8,gr4=d[](gr4,8)
   68| 000A50 fnmsub   FF5AD5BC   1     FNMS      fp26=fp26,fp26,fp22,fcr
   68| 000A54 fnmsub   FF39CE3C   2     FNMS      fp25=fp25,fp25,fp24,fcr
   68| 000A58 fmsub    FEA72FB8   2     FMS       fp21=fp5,fp7,fp30,fcr
   68| 000A5C fmul     FDA60372   2     MFL       fp13=fp6,fp13,fcr
   68| 000A60 fmsub    FECC2F38   2     FMS       fp22=fp5,fp12,fp28,fcr
   68| 000A64 fmul     FFE607F2   2     MFL       fp31=fp6,fp31,fcr
   68| 000A68 fmsub    FEE92EB8   2     FMS       fp23=fp5,fp9,fp26,fcr
   68| 000A6C fmsub    FF0A2E78   2     FMS       fp24=fp5,fp10,fp25,fcr
   68| 000A70 fnmsub   FFDEF57C   2     FNMS      fp30=fp30,fp30,fp21,fcr
   68| 000A74 fmul     FFA60772   2     MFL       fp29=fp6,fp29,fcr
   68| 000A78 fnmsub   FF9CE5BC   2     FNMS      fp28=fp28,fp28,fp22,fcr
   68| 000A7C fmul     FF6606F2   2     MFL       fp27=fp6,fp27,fcr
   68| 000A80 fnmsub   FF5AD5FC   2     FNMS      fp26=fp26,fp26,fp23,fcr
   68| 000A84 fnmsub   FF39CE3C   2     FNMS      fp25=fp25,fp25,fp24,fcr
   68| 000A88 fmul     FF0D07B2   2     MFL       fp24=fp13,fp30,fcr
   69| 000A8C fmul     FEE607B2   2     MFL       fp23=fp6,fp30,fcr
   68| 000A90 fmul     FEDF0732   2     MFL       fp22=fp31,fp28,fcr
   69| 000A94 fmul     FEA60732   2     MFL       fp21=fp6,fp28,fcr
   68| 000A98 fmul     FE9D06B2   2     MFL       fp20=fp29,fp26,fcr
   69| 000A9C fmul     FE6606B2   2     MFL       fp19=fp6,fp26,fcr
   68| 000AA0 fmul     FE5B0672   2     MFL       fp18=fp27,fp25,fcr
   69| 000AA4 fmul     FE260672   2     MFL       fp17=fp6,fp25,fcr
   68| 000AA8 fmsub    FDA76E38   2     FMS       fp13=fp13,fp7,fp24,fcr
   69| 000AAC fmsub    FCE735F8   2     FMS       fp7=fp6,fp7,fp23,fcr
   68| 000AB0 fmsub    FFECFDB8   2     FMS       fp31=fp31,fp12,fp22,fcr
   69| 000AB4 fmsub    FD8C3578   2     FMS       fp12=fp6,fp12,fp21,fcr
   68| 000AB8 fmsub    FFA9ED38   2     FMS       fp29=fp29,fp9,fp20,fcr
   69| 000ABC fmsub    FD2934F8   2     FMS       fp9=fp6,fp9,fp19,fcr
   68| 000AC0 fmsub    FF6ADCB8   2     FMS       fp27=fp27,fp10,fp18,fcr
   69| 000AC4 fmsub    FD4A3478   2     FMS       fp10=fp6,fp10,fp17,fcr
   68| 000AC8 fnmsub   FDBEC37C   2     FNMS      fp13=fp24,fp30,fp13,fcr
   69| 000ACC fnmsub   FCFEB9FC   2     FNMS      fp7=fp23,fp30,fp7,fcr
   68| 000AD0 fnmsub   FFFCB7FC   2     FNMS      fp31=fp22,fp28,fp31,fcr
   69| 000AD4 fnmsub   FD9CAB3C   2     FNMS      fp12=fp21,fp28,fp12,fcr
   68| 000AD8 fnmsub   FFDAA77C   2     FNMS      fp30=fp20,fp26,fp29,fcr
   69| 000ADC fnmsub   FD3A9A7C   2     FNMS      fp9=fp19,fp26,fp9,fcr
   68| 000AE0 fnmsub   FFB996FC   2     FNMS      fp29=fp18,fp25,fp27,fcr
   69| 000AE4 fnmsub   FD598ABC   2     FNMS      fp10=fp17,fp25,fp10,fcr
   68| 000AE8 stfdu    DDBF0008   2     STFDU     gr31,t[](gr31,8)=fp13
   69| 000AEC stfdu    DCEC0008   1     STFDU     gr12,dtde[](gr12,8)=fp7
   68| 000AF0 stfdu    DFFD0008   1     STFDU     gr29,t[](gr29,8)=fp31
   69| 000AF4 stfdu    DD9E0008   1     STFDU     gr30,dtde[](gr30,8)=fp12
   68| 000AF8 stfdu    DFDB0008   1     STFDU     gr27,t[](gr27,8)=fp30
   69| 000AFC stfdu    DD3C0008   1     STFDU     gr28,dtde[](gr28,8)=fp9
   68| 000B00 stfdu    DFB90008   1     STFDU     gr25,t[](gr25,8)=fp29
   69| 000B04 stfdu    DD5A0008   1     STFDU     gr26,dtde[](gr26,8)=fp10
   68| 000B08 lfdu     CDA70008   1     LFDU      fp13,gr7=e[](gr7,8)
   68| 000B0C lfdu     CD250008   1     LFDU      fp9,gr5=d[](gr5,8)
   68| 000B10 lfdu     CD460008   1     LFDU      fp10,gr6=d[](gr6,8)
   68| 000B14 lfdu     CFE80008   1     LFDU      fp31,gr8=e[](gr8,8)
   68| 000B18 qvfre    11805830   1     QVFRE     fp12=fp11
   68| 000B1C lfdu     CFA90008   1     LFDU      fp29,gr9=e[](gr9,8)
   68| 000B20 qvfre    13804030   1     QVFRE     fp28=fp8
   68| 000B24 lfdu     CF6B0008   1     LFDU      fp27,gr11=e[](gr11,8)
   68| 000B28 qvfre    13404830   1     QVFRE     fp26=fp9
   68| 000B2C qvfre    13205030   1     QVFRE     fp25=fp10
   68| 000B30 fmsub    FFCB2B38   1     FMS       fp30=fp5,fp11,fp12,fcr
    0| 000B34 fmr      FCE05890   2     LRFL      fp7=fp11
   68| 000B38 fmsub    FEE82F38   2     FMS       fp23=fp5,fp8,fp28,fcr
    0| 000B3C bc       4200FEF8   1     BCT       ctr=CL.770,taken=100%(100,0)
    0|                              CL.769:
   68| 000B40 fmsub    FF092EB8   1     FMS       fp24=fp5,fp9,fp26,fcr
   72| 000B44 ld       E8610198   1     L8        gr3=#SPILL29(gr1,408)
   68| 000B48 fmsub    FD6A2E78   1     FMS       fp11=fp5,fp10,fp25,fcr
   72| 000B4C ld       E88100E8   1     L8        gr4=#SPILL7(gr1,232)
   68| 000B50 fnmsub   FEAC67BC   1     FNMS      fp21=fp12,fp12,fp30,fcr
    0| 000B54 ld       E8A101A8   1     L8        gr5=#SPILL31(gr1,424)
   68| 000B58 fnmsub   FFDCE5FC   1     FNMS      fp30=fp28,fp28,fp23,fcr
    0| 000B5C ld       E8C101B0   1     L8        gr6=#SPILL32(gr1,432)
   68| 000B60 fnmsub   FF9AD63C   1     FNMS      fp28=fp26,fp26,fp24,fcr
    0| 000B64 ld       E8E101B8   1     L8        gr7=#SPILL33(gr1,440)
   68| 000B68 fnmsub   FF59CAFC   1     FNMS      fp26=fp25,fp25,fp11,fcr
    0| 000B6C ld       E90101C0   1     L8        gr8=#SPILL34(gr1,448)
   68| 000B70 fmsub    FEC72D78   1     FMS       fp22=fp5,fp7,fp21,fcr
    0| 000B74 ld       E92101C8   1     L8        gr9=#SPILL35(gr1,456)
   68| 000B78 fmsub    FEE82FB8   1     FMS       fp23=fp5,fp8,fp30,fcr
   72| 000B7C addi     38630001   1     AI        gr3=gr3,1
   68| 000B80 fmsub    FF092F38   1     FMS       fp24=fp5,fp9,fp28,fcr
   72| 000B84 std      F8610198   1     ST8       #SPILL29(gr1,408)=gr3
   68| 000B88 fmsub    FF2A2EB8   1     FMS       fp25=fp5,fp10,fp26,fcr
   72| 000B8C cmpld    7CA32040   1     CL8       cr1=gr3,gr4
   68| 000B90 fmul     FD660372   1     MFL       fp11=fp6,fp13,fcr
    0| 000B94 add      7CA50214   1     A         gr5=gr5,gr0
   68| 000B98 fmul     FD8607F2   1     MFL       fp12=fp6,fp31,fcr
    0| 000B9C std      F8A101A8   1     ST8       #SPILL31(gr1,424)=gr5
   68| 000BA0 fmul     FDA60772   1     MFL       fp13=fp6,fp29,fcr
    0| 000BA4 add      7CC60214   1     A         gr6=gr6,gr0
   68| 000BA8 fnmsub   FFF5ADBC   1     FNMS      fp31=fp21,fp21,fp22,fcr
    0| 000BAC std      F8C101B0   1     ST8       #SPILL32(gr1,432)=gr6
   68| 000BB0 fnmsub   FFDEF5FC   1     FNMS      fp30=fp30,fp30,fp23,fcr
    0| 000BB4 add      7CE70214   1     A         gr7=gr7,gr0
   68| 000BB8 fmul     FFA606F2   1     MFL       fp29=fp6,fp27,fcr
    0| 000BBC std      F8E101B8   1     ST8       #SPILL33(gr1,440)=gr7
   68| 000BC0 fnmsub   FF9CE63C   1     FNMS      fp28=fp28,fp28,fp24,fcr
    0| 000BC4 add      7D080214   1     A         gr8=gr8,gr0
   68| 000BC8 fnmsub   FF7AD67C   1     FNMS      fp27=fp26,fp26,fp25,fcr
    0| 000BCC std      F90101C0   1     ST8       #SPILL34(gr1,448)=gr8
   68| 000BD0 fmul     FF4B07F2   1     MFL       fp26=fp11,fp31,fcr
    0| 000BD4 add      7D290214   1     A         gr9=gr9,gr0
   69| 000BD8 fmul     FF2607F2   1     MFL       fp25=fp6,fp31,fcr
    0| 000BDC std      F92101C8   1     ST8       #SPILL35(gr1,456)=gr9
   68| 000BE0 fmul     FF0C07B2   1     MFL       fp24=fp12,fp30,fcr
    0| 000BE4 add      7F180214   1     A         gr24=gr24,gr0
   69| 000BE8 fmul     FEE607B2   1     MFL       fp23=fp6,fp30,fcr
    0| 000BEC add      7EF70214   1     A         gr23=gr23,gr0
   68| 000BF0 fmul     FECD0732   1     MFL       fp22=fp13,fp28,fcr
    0| 000BF4 add      7ED60214   1     A         gr22=gr22,gr0
   69| 000BF8 fmul     FEA60732   1     MFL       fp21=fp6,fp28,fcr
    0| 000BFC add      7EB50214   1     A         gr21=gr21,gr0
   68| 000C00 fmul     FE9D06F2   1     MFL       fp20=fp29,fp27,fcr
    0| 000C04 add      7E940214   1     A         gr20=gr20,gr0
   69| 000C08 fmul     FE6606F2   1     MFL       fp19=fp6,fp27,fcr
    0| 000C0C add      7E730214   1     A         gr19=gr19,gr0
   68| 000C10 fmsub    FD675EB8   1     FMS       fp11=fp11,fp7,fp26,fcr
    0| 000C14 add      7E520214   1     A         gr18=gr18,gr0
   69| 000C18 fmsub    FCE73678   1     FMS       fp7=fp6,fp7,fp25,fcr
    0| 000C1C add      7E310214   1     A         gr17=gr17,gr0
   68| 000C20 fmsub    FD886638   1     FMS       fp12=fp12,fp8,fp24,fcr
    0| 000C24 add      7E100214   1     A         gr16=gr16,gr0
   69| 000C28 fmsub    FD0835F8   1     FMS       fp8=fp6,fp8,fp23,fcr
    0| 000C2C add      7DEF0214   1     A         gr15=gr15,gr0
   68| 000C30 fmsub    FDA96DB8   1     FMS       fp13=fp13,fp9,fp22,fcr
    0| 000C34 add      7DCE0214   1     A         gr14=gr14,gr0
   69| 000C38 fmsub    FD293578   1     FMS       fp9=fp6,fp9,fp21,fcr
   68| 000C3C fmsub    FFAAED38   2     FMS       fp29=fp29,fp10,fp20,fcr
   69| 000C40 fmsub    FD4A34F8   2     FMS       fp10=fp6,fp10,fp19,fcr
   68| 000C44 fnmsub   FD7FD2FC   2     FNMS      fp11=fp26,fp31,fp11,fcr
   69| 000C48 fnmsub   FCFFC9FC   2     FNMS      fp7=fp25,fp31,fp7,fcr
   68| 000C4C fnmsub   FD9EC33C   2     FNMS      fp12=fp24,fp30,fp12,fcr
   69| 000C50 fnmsub   FD1EBA3C   2     FNMS      fp8=fp23,fp30,fp8,fcr
   68| 000C54 fnmsub   FDBCB37C   2     FNMS      fp13=fp22,fp28,fp13,fcr
   69| 000C58 fnmsub   FD3CAA7C   2     FNMS      fp9=fp21,fp28,fp9,fcr
   68| 000C5C fnmsub   FFFBA77C   2     FNMS      fp31=fp20,fp27,fp29,fcr
   68| 000C60 stfdu    DD7F0008   2     STFDU     gr31,t[](gr31,8)=fp11
   69| 000C64 fnmsub   FD5B9ABC   1     FNMS      fp10=fp19,fp27,fp10,fcr
   69| 000C68 stfdu    DCEC0008   2     STFDU     gr12,dtde[](gr12,8)=fp7
   68| 000C6C stfdu    DD9D0008   1     STFDU     gr29,t[](gr29,8)=fp12
   69| 000C70 stfdu    DD1E0008   1     STFDU     gr30,dtde[](gr30,8)=fp8
   68| 000C74 stfdu    DDBB0008   1     STFDU     gr27,t[](gr27,8)=fp13
   69| 000C78 stfdu    DD3C0008   1     STFDU     gr28,dtde[](gr28,8)=fp9
   68| 000C7C stfdu    DFF90008   1     STFDU     gr25,t[](gr25,8)=fp31
   69| 000C80 stfdu    DD5A0008   1     STFDU     gr26,dtde[](gr26,8)=fp10
   72| 000C84 bc       4184FD24   1     BT        CL.73,cr1,0x8/llt,taken=80%(80,20)
   72|                              CL.72:
   72| 000C88 ld       E86100F0   1     L8        gr3=#SPILL8(gr1,240)
    0| 000C8C ld       E8810108   1     L8        gr4=#SPILL11(gr1,264)
    0| 000C90 ld       E8A10110   1     L8        gr5=#SPILL12(gr1,272)
   72| 000C94 ld       E8C10190   1     L8        gr6=#SPILL28(gr1,400)
    0| 000C98 ld       E8E10118   1     L8        gr7=#SPILL13(gr1,280)
    0| 000C9C ld       E9010120   1     L8        gr8=#SPILL14(gr1,288)
    0| 000CA0 ld       E9210128   1     L8        gr9=#SPILL15(gr1,296)
    0| 000CA4 ld       E9610130   1     L8        gr11=#SPILL16(gr1,304)
    0| 000CA8 ld       E9810138   1     L8        gr12=#SPILL17(gr1,312)
    0| 000CAC ld       EBE10140   1     L8        gr31=#SPILL18(gr1,320)
    0| 000CB0 ld       EBC10148   1     L8        gr30=#SPILL19(gr1,328)
    0| 000CB4 ld       EBA10150   1     L8        gr29=#SPILL20(gr1,336)
    0| 000CB8 ld       EB810158   1     L8        gr28=#SPILL21(gr1,344)
    0| 000CBC ld       EB610160   1     L8        gr27=#SPILL22(gr1,352)
    0| 000CC0 ld       EB410168   1     L8        gr26=#SPILL23(gr1,360)
    0| 000CC4 ld       EB210170   1     L8        gr25=#SPILL24(gr1,368)
    0| 000CC8 ld       EB010178   1     L8        gr24=#SPILL25(gr1,376)
    0| 000CCC ld       EAE10180   1     L8        gr23=#SPILL26(gr1,384)
    0| 000CD0 ld       EAC10188   1     L8        gr22=#SPILL27(gr1,392)
   72| 000CD4 addi     38630001   1     AI        gr3=gr3,1
    0| 000CD8 add      7CA42A14   1     A         gr5=gr4,gr5
   72| 000CDC std      F86100F0   1     ST8       #SPILL8(gr1,240)=gr3
    0| 000CE0 std      F8A10110   1     ST8       #SPILL12(gr1,272)=gr5
   72| 000CE4 cmpld    7CA33040   1     CL8       cr1=gr3,gr6
    0| 000CE8 add      7CE43A14   1     A         gr7=gr4,gr7
    0| 000CEC add      7D044214   1     A         gr8=gr4,gr8
    0| 000CF0 std      F8E10118   1     ST8       #SPILL13(gr1,280)=gr7
    0| 000CF4 std      F9010120   1     ST8       #SPILL14(gr1,288)=gr8
    0| 000CF8 add      7D244A14   1     A         gr9=gr4,gr9
    0| 000CFC add      7D645A14   1     A         gr11=gr4,gr11
    0| 000D00 std      F9210128   1     ST8       #SPILL15(gr1,296)=gr9
    0| 000D04 std      F9610130   1     ST8       #SPILL16(gr1,304)=gr11
    0| 000D08 add      7D846214   1     A         gr12=gr4,gr12
    0| 000D0C add      7FE4FA14   1     A         gr31=gr4,gr31
    0| 000D10 std      F9810138   1     ST8       #SPILL17(gr1,312)=gr12
    0| 000D14 std      FBE10140   1     ST8       #SPILL18(gr1,320)=gr31
    0| 000D18 add      7FC4F214   1     A         gr30=gr4,gr30
    0| 000D1C add      7FA4EA14   1     A         gr29=gr4,gr29
    0| 000D20 std      FBC10148   1     ST8       #SPILL19(gr1,328)=gr30
    0| 000D24 std      FBA10150   1     ST8       #SPILL20(gr1,336)=gr29
    0| 000D28 add      7F84E214   1     A         gr28=gr4,gr28
    0| 000D2C add      7F64DA14   1     A         gr27=gr4,gr27
    0| 000D30 std      FB810158   1     ST8       #SPILL21(gr1,344)=gr28
    0| 000D34 std      FB610160   1     ST8       #SPILL22(gr1,352)=gr27
    0| 000D38 add      7F44D214   1     A         gr26=gr4,gr26
    0| 000D3C add      7F24CA14   1     A         gr25=gr4,gr25
    0| 000D40 std      FB410168   1     ST8       #SPILL23(gr1,360)=gr26
    0| 000D44 std      FB210170   1     ST8       #SPILL24(gr1,368)=gr25
    0| 000D48 add      7F04C214   1     A         gr24=gr4,gr24
    0| 000D4C add      7EE4BA14   1     A         gr23=gr4,gr23
    0| 000D50 std      FB010178   1     ST8       #SPILL25(gr1,376)=gr24
    0| 000D54 std      FAE10180   1     ST8       #SPILL26(gr1,384)=gr23
    0| 000D58 add      7EC4B214   1     A         gr22=gr4,gr22
    0| 000D5C std      FAC10188   1     ST8       #SPILL27(gr1,392)=gr22
   72| 000D60 bc       4184FB80   1     BT        CL.71,cr1,0x8/llt,taken=80%(80,20)
   72|                              CL.70:
   74| 000D64 bc       40900148   1     BF        CL.132,cr4,0x1/lt,taken=50%(0,0)
   74| 000D68 ld       E88103C0   1     L8        gr4=.jbeg(gr1,960)
   74| 000D6C ld       E8A103C8   1     L8        gr5=.jend(gr1,968)
   74| 000D70 addi     38600000   1     LI        gr3=0
   74| 000D74 lwa      E8840002   1     L4A       gr4=jbeg(gr4,0)
   74| 000D78 lwa      E8050002   1     L4A       gr0=jend(gr5,0)
   74| 000D7C subf     7CA40050   1     S         gr5=gr0,gr4
   74| 000D80 addic.   34050001   1     AI_R      gr0,cr0=gr5,1,ca"
    0| 000D84 bc       40810FE8   1     BF        CL.512,cr0,0x2/gt,taken=50%(0,0)
    0| 000D88 ld       EB6100C0   1     L8        gr27=#SPILL2(gr1,192)
    0| 000D8C ld       EB4100C8   1     L8        gr26=#SPILL3(gr1,200)
    0| 000D90 ld       EB2100D0   1     L8        gr25=#SPILL4(gr1,208)
    0| 000D94 ld       E96103B0   1     L8        gr11=.ibeg(gr1,944)
    0| 000D98 ld       E8C103B8   1     L8        gr6=.iend(gr1,952)
    0| 000D9C ld       EB0100B8   1     L8        gr24=#SPILL1(gr1,184)
    0| 000DA0 rldicr   7B651F24   1     SLL8      gr5=gr27,3
    0| 000DA4 rldicr   7B481F24   1     SLL8      gr8=gr26,3
    0| 000DA8 mulld    7D25D1D2   1     M         gr9=gr5,gr26
    0| 000DAC neg      7CE500D0   1     COMP      gr7=gr5
    0| 000DB0 mulld    7C8441D2   1     M         gr4=gr4,gr8
    0| 000DB4 mulld    7CA9C9D2   1     M         gr5=gr9,gr25
    0| 000DB8 lwa      E96B0002   1     L4A       gr11=ibeg(gr11,0)
    0| 000DBC lwa      E9860002   1     L4A       gr12=iend(gr6,0)
    0| 000DC0 mulld    7CE7D1D2   1     M         gr7=gr7,gr26
    0| 000DC4 addi     38C4FFF0   1     AI        gr6=gr4,-16
    0| 000DC8 subf     7CA82850   1     S         gr5=gr5,gr8
    0| 000DCC ld       E8820000   1     L8        gr4=.+CONSTANT_AREA(gr2,0)
    0| 000DD0 add      7CC53214   1     A         gr6=gr5,gr6
    0| 000DD4 subf     7CAB6050   1     S         gr5=gr12,gr11
    0| 000DD8 add      7FE63A14   1     A         gr31=gr6,gr7
    0| 000DDC addic.   34A50001   1     AI_R      gr5,cr0=gr5,1,ca"
    0| 000DE0 add      7FD8FA14   1     A         gr30=gr24,gr31
    0| 000DE4 add      7FAAFA14   1     A         gr29=gr10,gr31
    0| 000DE8 ld       EB810370   1     L8        gr28=.dbbdt(gr1,880)
    0| 000DEC lfd      C80400A0   1     LFL       fp0=+CONSTANT_AREA(gr4,160)
    0| 000DF0 lfs      C02400A8   1     LFS       fp1=+CONSTANT_AREA(gr4,168)
    0| 000DF4 mcrf     4C800000   1     LRCR      cr1=cr0
   74|                              CL.127:
    0| 000DF8 rldicr   79651F24   1     SLL8      gr5=gr11,3
   75| 000DFC addi     38800000   1     LI        gr4=0
    0| 000E00 bc       40850090   1     BF        CL.131,cr1,0x2/gt,taken=20%(20,80)
    0| 000E04 subfic   20CB0001   1     SFI       gr6=1,gr11,ca"
    0| 000E08 add      7F65FA14   1     A         gr27=gr5,gr31
    0| 000E0C add      7F466214   1     A         gr26=gr6,gr12
    0| 000E10 add      7F05EA14   1     A         gr24=gr5,gr29
    0| 000E14 add      7F25F214   1     A         gr25=gr5,gr30
    0| 000E18 ori      60210000   1     XNOP      
   75|                              CL.128:
   77| 000E1C or       7F25CB78   1     LR        gr5=gr25
    0| 000E20 mtspr    7F4903A6   1     LCTR      ctr=gr26
   77| 000E24 lfdu     CC450008   1     LFDU      fp2,gr5=t[](gr5,8)
   79| 000E28 add      7CDBE214   1     A         gr6=gr27,gr28
   78| 000E2C or       7F07C378   1     LR        gr7=gr24
   77| 000E30 fmul     FC6200B2   1     MFL       fp3=fp2,fp2,fcr
   77| 000E34 fmul     FC6200F2   2     MFL       fp3=fp2,fp3,fcr
    0| 000E38 bc       4240002C   1     BCF       ctr=CL.771,taken=0%(0,100)
    0|                              CL.772:
   77| 000E3C lfdu     CC850008   1     LFDU      fp4,gr5=t[](gr5,8)
   77| 000E40 fmul     FCC30032   1     MFL       fp6=fp3,fp0,fcr
   77| 000E44 fmul     FC640132   2     MFL       fp3=fp4,fp4,fcr
   78| 000E48 fmul     FCA201B2   2     MFL       fp5=fp2,fp6,fcr
   79| 000E4C fmul     FCC60072   2     MFL       fp6=fp6,fp1,fcr
    0| 000E50 fmr      FC402090   2     LRFL      fp2=fp4
   77| 000E54 fmul     FC6400F2   2     MFL       fp3=fp4,fp3,fcr
   78| 000E58 stfdu    DCA70008   2     STFDU     gr7,bb[](gr7,8)=fp5
   79| 000E5C stfdu    DCC60008   1     STFDU     gr6,dbbdt[](gr6,8)=fp6
    0| 000E60 bc       4200FFDC   1     BCT       ctr=CL.772,taken=100%(100,0)
    0|                              CL.771:
   77| 000E64 fmul     FC630032   1     MFL       fp3=fp3,fp0,fcr
   80| 000E68 addi     38840001   1     AI        gr4=gr4,1
    0| 000E6C add      7F7B4214   1     A         gr27=gr27,gr8
   80| 000E70 cmpld    7C240040   1     CL8       cr0=gr4,gr0
    0| 000E74 add      7F184214   1     A         gr24=gr24,gr8
    0| 000E78 add      7F394214   1     A         gr25=gr25,gr8
   78| 000E7C fmul     FC4200F2   1     MFL       fp2=fp2,fp3,fcr
   79| 000E80 fmul     FC630072   2     MFL       fp3=fp3,fp1,fcr
   78| 000E84 stfdu    DC470008   2     STFDU     gr7,bb[](gr7,8)=fp2
   79| 000E88 stfdu    DC660008   1     STFDU     gr6,dbbdt[](gr6,8)=fp3
   80| 000E8C bc       4180FF90   1     BT        CL.128,cr0,0x8/llt,taken=80%(80,20)
   80|                              CL.131:
   80| 000E90 ld       E88101D0   1     L8        gr4=#SPILL36(gr1,464)
   80| 000E94 addi     38630001   1     AI        gr3=gr3,1
    0| 000E98 add      7FE9FA14   1     A         gr31=gr9,gr31
    0| 000E9C add      7FA9EA14   1     A         gr29=gr9,gr29
    0| 000EA0 add      7FC9F214   1     A         gr30=gr9,gr30
   80| 000EA4 cmpd     7C241800   1     C8        cr0=gr4,gr3
   80| 000EA8 bc       4181FF50   1     BT        CL.127,cr0,0x2/gt,taken=80%(80,20)
   80|                              CL.132:
   74| 000EAC bc       408D046C   1     BF        CL.76,cr3,0x2/gt,taken=50%(0,0)
    0| 000EB0 ld       E92100C0   1     L8        gr9=#SPILL2(gr1,192)
    0| 000EB4 ld       EBE100C8   1     L8        gr31=#SPILL3(gr1,200)
   74| 000EB8 ld       E8A103C0   1     L8        gr5=.jbeg(gr1,960)
   74| 000EBC ld       E86103C8   1     L8        gr3=.jend(gr1,968)
   80| 000EC0 ld       E98100E0   1     L8        gr12=#SPILL6(gr1,224)
    0| 000EC4 ld       EBA100D0   1     L8        gr29=#SPILL4(gr1,208)
    0| 000EC8 rldicr   79241F24   1     SLL8      gr4=gr9,3
   74| 000ECC addi     3BC00000   1     LI        gr30=0
   74| 000ED0 lwa      E8E50002   1     L4A       gr7=jbeg(gr5,0)
   74| 000ED4 std      FBC100E8   1     ST8       #SPILL7(gr1,232)=gr30
   74| 000ED8 lwa      E8630002   1     L4A       gr3=jend(gr3,0)
   80| 000EDC addi     380CFFFF   1     AI        gr0=gr12,-1
    0| 000EE0 mulld    7CC4F9D2   1     M         gr6=gr4,gr31
   80| 000EE4 sradi    7C051674   1     SRA8CA    gr5,ca=gr0,2
    0| 000EE8 rldicr   7BE01F24   1     SLL8      gr0=gr31,3
   74| 000EEC subf     7C671850   1     S         gr3=gr3,gr7
   80| 000EF0 addze    7CA50194   1     ADDE      gr5,ca=gr5,0,ca
   74| 000EF4 addic.   34630001   1     AI_R      gr3,cr0=gr3,1,ca"
    0| 000EF8 mulld    7D0039D2   1     M         gr8=gr0,gr7
    0| 000EFC mulld    7D66E9D2   1     M         gr11=gr6,gr29
    0| 000F00 neg      7CE400D0   1     COMP      gr7=gr4
    0| 000F04 bc       40810414   1     BF        CL.76,cr0,0x2/gt,taken=20%(20,80)
    0| 000F08 ld       EB8101D0   1     L8        gr28=#SPILL36(gr1,464)
    0| 000F0C ld       E98103B8   1     L8        gr12=.iend(gr1,952)
    0| 000F10 rldicr   792426E4   1     SLL8      gr4=gr9,4
    0| 000F14 addi     3908FFF0   1     AI        gr8=gr8,-16
    0| 000F18 ld       EB0100C0   1     L8        gr24=#SPILL2(gr1,192)
    0| 000F1C or       7FEEFB78   1     LR        gr14=gr31
    0| 000F20 mulld    7D26E1D2   1     M         gr9=gr6,gr28
    0| 000F24 lwa      EB2C0002   1     L4A       gr25=iend(gr12,0)
    0| 000F28 subf     7D805850   1     S         gr12=gr11,gr0
    0| 000F2C ld       EBE103B0   1     L8        gr31=.ibeg(gr1,944)
    0| 000F30 add      7D8C4214   1     A         gr12=gr12,gr8
    0| 000F34 rldicr   7B0B2EA4   1     SLL8      gr11=gr24,5
    0| 000F38 add      7EE96214   1     A         gr23=gr9,gr12
    0| 000F3C std      FB2100F8   1     ST8       #SPILL9(gr1,248)=gr25
    0| 000F40 std      FAE10100   1     ST8       #SPILL10(gr1,256)=gr23
    0| 000F44 lwa      EB5F0002   1     L4A       gr26=ibeg(gr31,0)
    0| 000F48 add      7ECABA14   1     A         gr22=gr10,gr23
    0| 000F4C ld       E94100B8   1     L8        gr10=#SPILL1(gr1,184)
    0| 000F50 std      FAC10108   1     ST8       #SPILL11(gr1,264)=gr22
    0| 000F54 mulld    7D0771D2   1     M         gr8=gr7,gr14
    0| 000F58 std      FB4100F0   1     ST8       #SPILL8(gr1,240)=gr26
    0| 000F5C mulld    7CE471D2   1     M         gr7=gr4,gr14
    0| 000F60 ld       E8820000   1     L8        gr4=.+CONSTANT_AREA(gr2,0)
    0| 000F64 mulld    7E8B71D2   1     M         gr20=gr11,gr14
    0| 000F68 subf     7D3AC850   1     S         gr9=gr25,gr26
    0| 000F6C std      FA810118   1     ST8       #SPILL13(gr1,280)=gr20
    0| 000F70 add      7EAABA14   1     A         gr21=gr10,gr23
    0| 000F74 addic.   35290001   1     AI_R      gr9,cr0=gr9,1,ca"
    0| 000F78 std      FAA10110   1     ST8       #SPILL12(gr1,272)=gr21
    0| 000F7C add      7E66B214   1     A         gr19=gr6,gr22
    0| 000F80 add      7E48B214   1     A         gr18=gr8,gr22
    0| 000F84 std      FA610120   1     ST8       #SPILL14(gr1,288)=gr19
    0| 000F88 std      FA410128   1     ST8       #SPILL15(gr1,296)=gr18
    0| 000F8C add      7E27B214   1     A         gr17=gr7,gr22
    0| 000F90 add      7E06BA14   1     A         gr16=gr6,gr23
    0| 000F94 std      FA210130   1     ST8       #SPILL16(gr1,304)=gr17
    0| 000F98 std      FA010138   1     ST8       #SPILL17(gr1,312)=gr16
    0| 000F9C add      7DE8BA14   1     A         gr15=gr8,gr23
    0| 000FA0 add      7FE8AA14   1     A         gr31=gr8,gr21
    0| 000FA4 std      F9E10140   1     ST8       #SPILL18(gr1,320)=gr15
    0| 000FA8 std      FBE10148   1     ST8       #SPILL19(gr1,328)=gr31
    0| 000FAC add      7D67BA14   1     A         gr11=gr7,gr23
    0| 000FB0 add      7D87AA14   1     A         gr12=gr7,gr21
    0| 000FB4 std      F9610150   1     ST8       #SPILL20(gr1,336)=gr11
    0| 000FB8 std      F9810158   1     ST8       #SPILL21(gr1,344)=gr12
    0| 000FBC add      7D06AA14   1     A         gr8=gr6,gr21
    0| 000FC0 addi     38C50001   1     AI        gr6=gr5,1
    0| 000FC4 std      F9010160   1     ST8       #SPILL22(gr1,352)=gr8
    0| 000FC8 std      F8C10168   1     ST8       #SPILL23(gr1,360)=gr6
    0| 000FCC ld       EB610370   1     L8        gr27=.dbbdt(gr1,880)
    0| 000FD0 lfd      C80400A0   1     LFL       fp0=+CONSTANT_AREA(gr4,160)
    0| 000FD4 lfs      C02400A8   1     LFS       fp1=+CONSTANT_AREA(gr4,168)
    0| 000FD8 mcrf     4F800000   1     LRCR      cr7=cr0
   74|                              CL.77:
    0| 000FDC ld       E8C100F0   1     L8        gr6=#SPILL8(gr1,240)
   75| 000FE0 addi     38800000   1     LI        gr4=0
    0| 000FE4 rldicr   78C51F24   1     SLL8      gr5=gr6,3
    0| 000FE8 bc       409D0284   1     BF        CL.78,cr7,0x2/gt,taken=20%(20,80)
    0| 000FEC ld       E9E10120   1     L8        gr15=#SPILL14(gr1,288)
    0| 000FF0 ld       E9C10130   1     L8        gr14=#SPILL16(gr1,304)
    0| 000FF4 ld       E90100F8   1     L8        gr8=#SPILL9(gr1,248)
    0| 000FF8 subfic   20C60001   1     SFI       gr6=1,gr6,ca"
    0| 000FFC ld       E8E10150   1     L8        gr7=#SPILL20(gr1,336)
    0| 001000 ld       E9210138   1     L8        gr9=#SPILL17(gr1,312)
    0| 001004 ld       E9410140   1     L8        gr10=#SPILL18(gr1,320)
    0| 001008 ld       E9610100   1     L8        gr11=#SPILL10(gr1,256)
    0| 00100C ld       E9810160   1     L8        gr12=#SPILL22(gr1,352)
    0| 001010 ld       EBE10158   1     L8        gr31=#SPILL21(gr1,344)
    0| 001014 ld       EBC10148   1     L8        gr30=#SPILL19(gr1,328)
    0| 001018 ld       EBA10110   1     L8        gr29=#SPILL12(gr1,272)
    0| 00101C ld       EB810108   1     L8        gr28=#SPILL11(gr1,264)
    0| 001020 add      7E057A14   1     A         gr16=gr5,gr15
    0| 001024 add      7DE57214   1     A         gr15=gr5,gr14
    0| 001028 ld       E9C10128   1     L8        gr14=#SPILL15(gr1,296)
    0| 00102C add      7CC64214   1     A         gr6=gr6,gr8
    0| 001030 add      7F453A14   1     A         gr26=gr5,gr7
    0| 001034 rldicl   78D8F842   1     SRL8      gr24=gr6,1
    0| 001038 add      7F254A14   1     A         gr25=gr5,gr9
    0| 00103C add      7EE55214   1     A         gr23=gr5,gr10
    0| 001040 add      7EC55A14   1     A         gr22=gr5,gr11
    0| 001044 add      7EA56214   1     A         gr21=gr5,gr12
    0| 001048 add      7E85FA14   1     A         gr20=gr5,gr31
    0| 00104C add      7E65F214   1     A         gr19=gr5,gr30
    0| 001050 add      7E45EA14   1     A         gr18=gr5,gr29
    0| 001054 add      7E25E214   1     A         gr17=gr5,gr28
    0| 001058 add      7DCE2A14   1     A         gr14=gr14,gr5
    0| 00105C andi.    70C50001   1     RN4_R     gr5,cr0=gr6,0,0x1
    0| 001060 cmpdi    2CB80000   1     C8        cr1=gr24,0
   75|                              CL.79:
   77| 001064 or       7E659B78   1     LR        gr5=gr19
   77| 001068 or       7E469378   1     LR        gr6=gr18
   77| 00106C or       7EA7AB78   1     LR        gr7=gr21
   77| 001070 or       7E88A378   1     LR        gr8=gr20
   79| 001074 add      7D37DA14   1     A         gr9=gr23,gr27
   78| 001078 or       7DCA7378   1     LR        gr10=gr14
   79| 00107C add      7D76DA14   1     A         gr11=gr22,gr27
   78| 001080 or       7E2C8B78   1     LR        gr12=gr17
   79| 001084 add      7FF9DA14   1     A         gr31=gr25,gr27
   78| 001088 or       7E1E8378   1     LR        gr30=gr16
   79| 00108C add      7FBADA14   1     A         gr29=gr26,gr27
   78| 001090 or       7DFC7B78   1     LR        gr28=gr15
    0| 001094 mtspr    7F0903A6   1     LCTR      ctr=gr24
    0| 001098 bc       41820094   1     BT        CL.745,cr0,0x4/eq,taken=50%(0,0)
   77| 00109C lfdu     CC450008   1     LFDU      fp2,gr5=t[](gr5,8)
   77| 0010A0 lfdu     CC660008   1     LFDU      fp3,gr6=t[](gr6,8)
   77| 0010A4 lfdu     CC870008   1     LFDU      fp4,gr7=t[](gr7,8)
   77| 0010A8 lfdu     CCA80008   1     LFDU      fp5,gr8=t[](gr8,8)
   77| 0010AC fmul     FCC200B2   1     MFL       fp6=fp2,fp2,fcr
   77| 0010B0 fmul     FCE300F2   2     MFL       fp7=fp3,fp3,fcr
   77| 0010B4 fmul     FD040132   2     MFL       fp8=fp4,fp4,fcr
   77| 0010B8 fmul     FD250172   2     MFL       fp9=fp5,fp5,fcr
   77| 0010BC fmul     FCC201B2   2     MFL       fp6=fp2,fp6,fcr
   77| 0010C0 fmul     FCE301F2   2     MFL       fp7=fp3,fp7,fcr
   77| 0010C4 fmul     FD040232   2     MFL       fp8=fp4,fp8,fcr
   77| 0010C8 fmul     FD250272   2     MFL       fp9=fp5,fp9,fcr
   77| 0010CC fmul     FCC60032   2     MFL       fp6=fp6,fp0,fcr
   77| 0010D0 fmul     FCE70032   2     MFL       fp7=fp7,fp0,fcr
   77| 0010D4 fmul     FD080032   2     MFL       fp8=fp8,fp0,fcr
   77| 0010D8 fmul     FD290032   2     MFL       fp9=fp9,fp0,fcr
   78| 0010DC fmul     FC4201B2   2     MFL       fp2=fp2,fp6,fcr
   79| 0010E0 fmul     FCC60072   2     MFL       fp6=fp6,fp1,fcr
   78| 0010E4 fmul     FC6301F2   2     MFL       fp3=fp3,fp7,fcr
   79| 0010E8 fmul     FCE70072   2     MFL       fp7=fp7,fp1,fcr
   78| 0010EC fmul     FC840232   2     MFL       fp4=fp4,fp8,fcr
   79| 0010F0 fmul     FD080072   2     MFL       fp8=fp8,fp1,fcr
   78| 0010F4 fmul     FCA50272   2     MFL       fp5=fp5,fp9,fcr
   78| 0010F8 stfdu    DC4A0008   2     STFDU     gr10,bb[](gr10,8)=fp2
   79| 0010FC fmul     FC490072   1     MFL       fp2=fp9,fp1,fcr
   79| 001100 stfdu    DCC90008   2     STFDU     gr9,dbbdt[](gr9,8)=fp6
   78| 001104 stfdu    DC6C0008   1     STFDU     gr12,bb[](gr12,8)=fp3
   79| 001108 stfdu    DCEB0008   1     STFDU     gr11,dbbdt[](gr11,8)=fp7
   78| 00110C stfdu    DC9E0008   1     STFDU     gr30,bb[](gr30,8)=fp4
   79| 001110 stfdu    DD1F0008   1     STFDU     gr31,dbbdt[](gr31,8)=fp8
   78| 001114 stfdu    DCBC0008   1     STFDU     gr28,bb[](gr28,8)=fp5
   79| 001118 stfdu    DC5D0008   1     STFDU     gr29,dbbdt[](gr29,8)=fp2
    0| 00111C bc       41860114   1     BT        CL.678,cr1,0x4/eq,taken=20%(20,80)
    0| 001120 ori      60210000   1     XNOP      
    0| 001124 ori      60210000   1     XNOP      
    0| 001128 ori      60210000   1     XNOP      
    0|                              CL.745:
   77| 00112C lfd      C8450008   1     LFL       fp2=t[](gr5,8)
   77| 001130 lfd      C8660008   1     LFL       fp3=t[](gr6,8)
   77| 001134 lfd      C8870008   1     LFL       fp4=t[](gr7,8)
   77| 001138 lfd      C8A80008   1     LFL       fp5=t[](gr8,8)
   77| 00113C lfdu     CCC50010   1     LFDU      fp6,gr5=t[](gr5,16)
   77| 001140 lfdu     CCE60010   1     LFDU      fp7,gr6=t[](gr6,16)
   77| 001144 lfdu     CD070010   1     LFDU      fp8,gr7=t[](gr7,16)
   77| 001148 lfdu     CD280010   1     LFDU      fp9,gr8=t[](gr8,16)
   77| 00114C fmul     FD4200B2   1     MFL       fp10=fp2,fp2,fcr
   77| 001150 fmul     FD6300F2   2     MFL       fp11=fp3,fp3,fcr
   77| 001154 fmul     FD840132   2     MFL       fp12=fp4,fp4,fcr
   77| 001158 fmul     FDA50172   2     MFL       fp13=fp5,fp5,fcr
   77| 00115C fmul     FFE601B2   2     MFL       fp31=fp6,fp6,fcr
   77| 001160 fmul     FFC701F2   2     MFL       fp30=fp7,fp7,fcr
   77| 001164 fmul     FFA80232   2     MFL       fp29=fp8,fp8,fcr
   77| 001168 fmul     FF890272   2     MFL       fp28=fp9,fp9,fcr
   77| 00116C fmul     FD4202B2   2     MFL       fp10=fp2,fp10,fcr
   77| 001170 fmul     FD6302F2   2     MFL       fp11=fp3,fp11,fcr
   77| 001174 fmul     FD840332   2     MFL       fp12=fp4,fp12,fcr
   77| 001178 fmul     FDA50372   2     MFL       fp13=fp5,fp13,fcr
   77| 00117C fmul     FFE607F2   2     MFL       fp31=fp6,fp31,fcr
   77| 001180 fmul     FFC707B2   2     MFL       fp30=fp7,fp30,fcr
   77| 001184 fmul     FFA80772   2     MFL       fp29=fp8,fp29,fcr
   77| 001188 fmul     FF890732   2     MFL       fp28=fp9,fp28,fcr
   77| 00118C fmul     FD4A0032   2     MFL       fp10=fp10,fp0,fcr
   77| 001190 fmul     FD6B0032   2     MFL       fp11=fp11,fp0,fcr
   77| 001194 fmul     FD8C0032   2     MFL       fp12=fp12,fp0,fcr
   77| 001198 fmul     FDAD0032   2     MFL       fp13=fp13,fp0,fcr
   77| 00119C fmul     FFFF0032   2     MFL       fp31=fp31,fp0,fcr
   77| 0011A0 fmul     FFDE0032   2     MFL       fp30=fp30,fp0,fcr
   77| 0011A4 fmul     FFBD0032   2     MFL       fp29=fp29,fp0,fcr
   77| 0011A8 fmul     FF9C0032   2     MFL       fp28=fp28,fp0,fcr
   78| 0011AC fmul     FC4202B2   2     MFL       fp2=fp2,fp10,fcr
   79| 0011B0 fmul     FD4A0072   2     MFL       fp10=fp10,fp1,fcr
   78| 0011B4 fmul     FC6302F2   2     MFL       fp3=fp3,fp11,fcr
   79| 0011B8 fmul     FD6B0072   2     MFL       fp11=fp11,fp1,fcr
   78| 0011BC fmul     FC840332   2     MFL       fp4=fp4,fp12,fcr
   79| 0011C0 fmul     FD8C0072   2     MFL       fp12=fp12,fp1,fcr
   78| 0011C4 fmul     FCA50372   2     MFL       fp5=fp5,fp13,fcr
   79| 0011C8 fmul     FDAD0072   2     MFL       fp13=fp13,fp1,fcr
   78| 0011CC fmul     FCC607F2   2     MFL       fp6=fp6,fp31,fcr
   79| 0011D0 fmul     FFFF0072   2     MFL       fp31=fp31,fp1,fcr
   78| 0011D4 fmul     FCE707B2   2     MFL       fp7=fp7,fp30,fcr
   79| 0011D8 fmul     FFDE0072   2     MFL       fp30=fp30,fp1,fcr
   78| 0011DC fmul     FD080772   2     MFL       fp8=fp8,fp29,fcr
   79| 0011E0 fmul     FFBD0072   2     MFL       fp29=fp29,fp1,fcr
   78| 0011E4 fmul     FD290732   2     MFL       fp9=fp9,fp28,fcr
   79| 0011E8 fmul     FF9C0072   2     MFL       fp28=fp28,fp1,fcr
   78| 0011EC stfd     D84A0008   1     STFL      bb[](gr10,8)=fp2
   79| 0011F0 stfd     D9490008   1     STFL      dbbdt[](gr9,8)=fp10
   78| 0011F4 stfd     D86C0008   1     STFL      bb[](gr12,8)=fp3
   79| 0011F8 stfd     D96B0008   1     STFL      dbbdt[](gr11,8)=fp11
   78| 0011FC stfd     D89E0008   1     STFL      bb[](gr30,8)=fp4
   79| 001200 stfd     D99F0008   1     STFL      dbbdt[](gr31,8)=fp12
   78| 001204 stfd     D8BC0008   1     STFL      bb[](gr28,8)=fp5
   79| 001208 stfd     D9BD0008   1     STFL      dbbdt[](gr29,8)=fp13
   78| 00120C stfdu    DCCA0010   1     STFDU     gr10,bb[](gr10,16)=fp6
   79| 001210 stfdu    DFE90010   1     STFDU     gr9,dbbdt[](gr9,16)=fp31
   78| 001214 stfdu    DCEC0010   1     STFDU     gr12,bb[](gr12,16)=fp7
   79| 001218 stfdu    DFCB0010   1     STFDU     gr11,dbbdt[](gr11,16)=fp30
   78| 00121C stfdu    DD1E0010   1     STFDU     gr30,bb[](gr30,16)=fp8
   79| 001220 stfdu    DFBF0010   1     STFDU     gr31,dbbdt[](gr31,16)=fp29
   78| 001224 stfdu    DD3C0010   1     STFDU     gr28,bb[](gr28,16)=fp9
   79| 001228 stfdu    DF9D0010   1     STFDU     gr29,dbbdt[](gr29,16)=fp28
    0| 00122C bc       4200FF00   1     BCT       ctr=CL.745,taken=100%(100,0)
    0|                              CL.678:
   80| 001230 addi     38840001   1     AI        gr4=gr4,1
    0| 001234 add      7F5A0214   1     A         gr26=gr26,gr0
   80| 001238 cmpld    7F241840   1     CL8       cr6=gr4,gr3
    0| 00123C add      7F390214   1     A         gr25=gr25,gr0
    0| 001240 add      7EF70214   1     A         gr23=gr23,gr0
    0| 001244 add      7ED60214   1     A         gr22=gr22,gr0
    0| 001248 add      7EB50214   1     A         gr21=gr21,gr0
    0| 00124C add      7E940214   1     A         gr20=gr20,gr0
    0| 001250 add      7E730214   1     A         gr19=gr19,gr0
    0| 001254 add      7E520214   1     A         gr18=gr18,gr0
    0| 001258 add      7E310214   1     A         gr17=gr17,gr0
    0| 00125C add      7E100214   1     A         gr16=gr16,gr0
    0| 001260 add      7DEF0214   1     A         gr15=gr15,gr0
    0| 001264 add      7DCE0214   1     A         gr14=gr14,gr0
   80| 001268 bc       4198FDFC   1     BT        CL.79,cr6,0x8/llt,taken=80%(80,20)
   80|                              CL.78:
   80| 00126C ld       E88100E8   1     L8        gr4=#SPILL7(gr1,232)
    0| 001270 ld       E8A10118   1     L8        gr5=#SPILL13(gr1,280)
    0| 001274 ld       E8C10120   1     L8        gr6=#SPILL14(gr1,288)
   80| 001278 ld       E8E10168   1     L8        gr7=#SPILL23(gr1,360)
    0| 00127C ld       E9010128   1     L8        gr8=#SPILL15(gr1,296)
    0| 001280 ld       E9210130   1     L8        gr9=#SPILL16(gr1,304)
    0| 001284 ld       E9410138   1     L8        gr10=#SPILL17(gr1,312)
    0| 001288 ld       E9610108   1     L8        gr11=#SPILL11(gr1,264)
    0| 00128C ld       E9810140   1     L8        gr12=#SPILL18(gr1,320)
    0| 001290 ld       EBE10148   1     L8        gr31=#SPILL19(gr1,328)
    0| 001294 ld       EBC10150   1     L8        gr30=#SPILL20(gr1,336)
    0| 001298 ld       EBA10100   1     L8        gr29=#SPILL10(gr1,256)
    0| 00129C ld       EB810158   1     L8        gr28=#SPILL21(gr1,344)
    0| 0012A0 ld       EB410160   1     L8        gr26=#SPILL22(gr1,352)
    0| 0012A4 ld       EB210110   1     L8        gr25=#SPILL12(gr1,272)
   80| 0012A8 addi     38840001   1     AI        gr4=gr4,1
    0| 0012AC add      7CC53214   1     A         gr6=gr5,gr6
   80| 0012B0 std      F88100E8   1     ST8       #SPILL7(gr1,232)=gr4
    0| 0012B4 std      F8C10120   1     ST8       #SPILL14(gr1,288)=gr6
   80| 0012B8 cmpld    7C243840   1     CL8       cr0=gr4,gr7
    0| 0012BC add      7D054214   1     A         gr8=gr5,gr8
    0| 0012C0 add      7D254A14   1     A         gr9=gr5,gr9
    0| 0012C4 std      F9010128   1     ST8       #SPILL15(gr1,296)=gr8
    0| 0012C8 std      F9210130   1     ST8       #SPILL16(gr1,304)=gr9
    0| 0012CC add      7D455214   1     A         gr10=gr5,gr10
    0| 0012D0 add      7D655A14   1     A         gr11=gr5,gr11
    0| 0012D4 std      F9410138   1     ST8       #SPILL17(gr1,312)=gr10
    0| 0012D8 std      F9610108   1     ST8       #SPILL11(gr1,264)=gr11
    0| 0012DC add      7D856214   1     A         gr12=gr5,gr12
    0| 0012E0 add      7FE5FA14   1     A         gr31=gr5,gr31
    0| 0012E4 std      F9810140   1     ST8       #SPILL18(gr1,320)=gr12
    0| 0012E8 std      FBE10148   1     ST8       #SPILL19(gr1,328)=gr31
    0| 0012EC add      7FC5F214   1     A         gr30=gr5,gr30
    0| 0012F0 add      7FA5EA14   1     A         gr29=gr5,gr29
    0| 0012F4 std      FBC10150   1     ST8       #SPILL20(gr1,336)=gr30
    0| 0012F8 std      FBA10100   1     ST8       #SPILL10(gr1,256)=gr29
    0| 0012FC add      7F85E214   1     A         gr28=gr5,gr28
    0| 001300 add      7F45D214   1     A         gr26=gr5,gr26
    0| 001304 std      FB810158   1     ST8       #SPILL21(gr1,344)=gr28
    0| 001308 std      FB410160   1     ST8       #SPILL22(gr1,352)=gr26
    0| 00130C add      7F25CA14   1     A         gr25=gr5,gr25
    0| 001310 std      FB210110   1     ST8       #SPILL12(gr1,272)=gr25
   80| 001314 bc       4180FCC8   1     BT        CL.77,cr0,0x8/llt,taken=80%(80,20)
   80|                              CL.76:
   80| 001318 ld       E8620000   1     L8        gr3=.&&N&&opac_law(gr2,0)
   80| 00131C ld       E8820000   1     L8        gr4=.+CONSTANT_AREA(gr2,0)
   80| 001320 ld       E8A100D8   1     L8        gr5=#SPILL5(gr1,216)
   80| 001324 lfd      C8430028   1     LFL       fp2=<s114:d40:l8>(gr3,40)
   80| 001328 lfs      C3E40098   1     LFS       fp31=+CONSTANT_AREA(gr4,152)
   80| 00132C sradi    7CA00E74   1     SRA8CA    gr0,ca=gr5,1
   84| 001330 cmpdi    2CA50000   1     C8        cr1=gr5,0
   80| 001334 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
   84| 001338 rldicr   78060FA4   1     SLL8      gr6=gr0,1
   80| 00133C qvfre    10001030   1     QVFRE     fp0=fp2
   84| 001340 std      F8C100E8   1     ST8       #SPILL7(gr1,232)=gr6
   84| 001344 subf     7CE62851   1     S_R       gr7,cr0=gr5,gr6
   84| 001348 crand    4C250A02   1     CR_N      cr0=cr[10],0x2/gt,0x2/gt,0x2/gt,cr0
   84| 00134C std      F8E10100   1     ST8       #SPILL10(gr1,256)=gr7
   80| 001350 fmsub    FC22F838   1     FMS       fp1=fp31,fp2,fp0,fcr
   80| 001354 fnmsub   FC00007C   2     FNMS      fp0=fp0,fp0,fp1,fcr
   80| 001358 fmsub    FC22F838   2     FMS       fp1=fp31,fp2,fp0,fcr
   80| 00135C fnmsub   FC00007C   2     FNMS      fp0=fp0,fp0,fp1,fcr
   80| 001360 fmsub    FC22F838   2     FMS       fp1=fp31,fp2,fp0,fcr
   80| 001364 fnmsub   FE40007C   2     FNMS      fp18=fp0,fp0,fp1,fcr
   84| 001368 bc       40810220   1     BF        CL.120,cr0,0x2/gt,taken=50%(0,0)
   84| 00136C ld       E88103C0   1     L8        gr4=.jbeg(gr1,960)
   84| 001370 ld       E86103C8   1     L8        gr3=.jend(gr1,968)
   87| 001374 ld       E9220000   1     L8        gr9=.&&N&&opac_law(gr2,0)
   84| 001378 addi     39000000   1     LI        gr8=0
   84| 00137C std      F90100F0   1     ST8       #SPILL8(gr1,240)=gr8
   84| 001380 lwa      E8840002   1     L4A       gr4=jbeg(gr4,0)
   84| 001384 lwa      E8030002   1     L4A       gr0=jend(gr3,0)
   87| 001388 lfd      CBC90040   1     LFL       fp30=<s114:d64:l8>(gr9,64)
   87| 00138C lfd      CBA90030   1     LFL       fp29=<s114:d48:l8>(gr9,48)
   87| 001390 lfd      CB890048   1     LFL       fp28=<s114:d72:l8>(gr9,72)
   87| 001394 lfd      CB690038   1     LFL       fp27=<s114:d56:l8>(gr9,56)
   84| 001398 subf     7C640050   1     S         gr3=gr0,gr4
   84| 00139C addic.   37E30001   1     AI_R      gr31,cr0=gr3,1,ca"
    0| 0013A0 bc       408109B0   1     BF        CL.522,cr0,0x2/gt,taken=50%(0,0)
    0| 0013A4 fneg     FF40D850   1     COMPFL    fp26=fp27
    0| 0013A8 ld       E94100C0   1     L8        gr10=#SPILL2(gr1,192)
    0| 0013AC qvfre    1320F030   1     QVFRE     fp25=fp30
    0| 0013B0 ld       E96100C8   1     L8        gr11=#SPILL3(gr1,200)
    0| 0013B4 qvfre    1300E030   1     QVFRE     fp24=fp28
    0| 0013B8 ld       EB0100D0   1     L8        gr24=#SPILL4(gr1,208)
    0| 0013BC ld       E8A103B0   1     L8        gr5=.ibeg(gr1,944)
    0| 0013C0 rldicr   79401F24   1     SLL8      gr0=gr10,3
    0| 0013C4 ld       E86103B8   1     L8        gr3=.iend(gr1,952)
    0| 0013C8 mulld    7D8059D2   1     M         gr12=gr0,gr11
    0| 0013CC rldicr   797E1F24   1     SLL8      gr30=gr11,3
    0| 0013D0 std      F98100F8   1     ST8       #SPILL9(gr1,248)=gr12
    0| 0013D4 neg      7C0000D0   1     COMP      gr0=gr0
    0| 0013D8 mulld    7C84F1D2   1     M         gr4=gr4,gr30
    0| 0013DC mulld    7CCCC1D2   1     M         gr6=gr12,gr24
    0| 0013E0 lwa      EAE50002   1     L4A       gr23=ibeg(gr5,0)
    0| 0013E4 lwa      E8630002   1     L4A       gr3=iend(gr3,0)
    0| 0013E8 mulld    7C0059D2   1     M         gr0=gr0,gr11
    0| 0013EC std      FAE10108   1     ST8       #SPILL11(gr1,264)=gr23
    0| 0013F0 addi     3884FFF0   1     AI        gr4=gr4,-16
    0| 0013F4 subf     7CBE3050   1     S         gr5=gr6,gr30
    0| 0013F8 ld       EAA100B8   1     L8        gr21=#SPILL1(gr1,184)
    0| 0013FC ld       EA6100B0   1     L8        gr19=#SPILL0(gr1,176)
    0| 001400 add      7C842A14   1     A         gr4=gr4,gr5
    0| 001404 ld       EA220000   1     L8        gr17=.+CONSTANT_AREA(gr2,0)
    0| 001408 subf     7C771850   1     S         gr3=gr3,gr23
    0| 00140C add      7EC02214   1     A         gr22=gr0,gr4
    0| 001410 addic.   37A30001   1     AI_R      gr29,cr0=gr3,1,ca"
    0| 001414 std      FAC10110   1     ST8       #SPILL12(gr1,272)=gr22
    0| 001418 add      7E95B214   1     A         gr20=gr21,gr22
    0| 00141C add      7E53B214   1     A         gr18=gr19,gr22
    0| 001420 std      FA810118   1     ST8       #SPILL13(gr1,280)=gr20
    0| 001424 std      FA410120   1     ST8       #SPILL14(gr1,288)=gr18
    0| 001428 ld       EB810378   1     L8        gr28=.kr(gr1,888)
    0| 00142C ld       EB610388   1     L8        gr27=.sg(gr1,904)
    0| 001430 ld       EB410380   1     L8        gr26=.kp(gr1,896)
    0| 001434 ld       EB210390   1     L8        gr25=.dkpdt(gr1,912)
    0| 001438 lfs      C2F100AC   1     LFS       fp23=+CONSTANT_AREA(gr17,172)
    0| 00143C mcrf     4D000000   1     LRCR      cr2=cr0
   84|                              CL.115:
   85| 001440 addi     3B000000   1     LI        gr24=0
    0| 001444 bc       40890104   1     BF        CL.119,cr2,0x2/gt,taken=20%(20,80)
    0| 001448 fmsub    FC3EFE78   1     FMS       fp1=fp31,fp30,fp25,fcr
    0| 00144C ld       E8610108   1     L8        gr3=#SPILL11(gr1,264)
    0| 001450 fmsub    FC1CFE38   1     FMS       fp0=fp31,fp28,fp24,fcr
    0| 001454 ld       E8810110   1     L8        gr4=#SPILL12(gr1,272)
    0| 001458 ld       E8A10120   1     L8        gr5=#SPILL14(gr1,288)
    0| 00145C ld       E8C10118   1     L8        gr6=#SPILL13(gr1,280)
    0| 001460 fnmsub   FC79C87C   1     FNMS      fp3=fp25,fp25,fp1,fcr
    0| 001464 rldicr   78601F24   2     SLL8      gr0=gr3,3
    0| 001468 fnmsub   FC18C03C   1     FNMS      fp0=fp24,fp24,fp0,fcr
    0| 00146C add      7EE02214   1     A         gr23=gr0,gr4
    0| 001470 add      7EC02A14   1     A         gr22=gr0,gr5
    0| 001474 add      7EA03214   1     A         gr21=gr0,gr6
    0| 001478 fmsub    FC5EF8F8   1     FMS       fp2=fp31,fp30,fp3,fcr
    0| 00147C fmsub    FC3CF838   2     FMS       fp1=fp31,fp28,fp0,fcr
    0| 001480 fnmsub   FEC318BC   2     FNMS      fp22=fp3,fp3,fp2,fcr
    0| 001484 fnmsub   FEA0007C   2     FNMS      fp21=fp0,fp0,fp1,fcr
   85|                              CL.116:
   87| 001488 add      7E97E214   1     A         gr20=gr23,gr28
   87| 00148C or       7EB3AB78   1     LR        gr19=gr21
   89| 001490 add      7E57DA14   1     A         gr18=gr23,gr27
   87| 001494 or       7ED1B378   1     LR        gr17=gr22
   91| 001498 add      7E17CA14   1     A         gr16=gr23,gr25
   90| 00149C add      7DF7D214   1     A         gr15=gr23,gr26
   86| 0014A0 addi     39C00000   1     LI        gr14=0
    0| 0014A4 ori      60210000   1     XNOP      
    0| 0014A8 ori      60210000   1     XNOP      
    0| 0014AC ori      60210000   1     XNOP      
   86|                              CL.117:
   87| 0014B0 lfdu     CC110008   1     LFDU      fp0,gr17=d[](gr17,8)
   87| 0014B4 fmr      FC40E890   1     LRFL      fp2=fp29
   87| 0014B8 lfdu     CE930008   2     LFDU      fp20,gr19=t[](gr19,8)
   87| 0014BC fmul     FC2005B2   1     MFL       fp1=fp0,fp22,fcr
   87| 0014C0 fmsub    FC1E0078   2     FMS       fp0=fp0,fp30,fp1,fcr
   87| 0014C4 fnmsub   FC36083C   2     FNMS      fp1=fp1,fp22,fp0,fcr
   87| 0014C8 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   87| 0014CC ori      60000000   1
   87| 0014D0 fmul     FC140572   1     MFL       fp0=fp20,fp21,fcr
   87| 0014D4 fmr      FC40D090   2     LRFL      fp2=fp26
   87| 0014D8 fmul     FE720072   2     MFL       fp19=fp18,fp1,fcr
   87| 0014DC fmsub    FC3CA038   2     FMS       fp1=fp20,fp28,fp0,fcr
   87| 0014E0 fnmsub   FC35007C   2     FNMS      fp1=fp0,fp21,fp1,fcr
   87| 0014E4 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   87| 0014E8 ori      60000000   1
   91| 0014EC qvfre    1000A030   1     QVFRE     fp0=fp20
   89| 0014F0 stfdu    DEF20008   1     STFDU     gr18,sg[](gr18,8)=fp23
   92| 0014F4 addi     39CE0001   1     AI        gr14=gr14,1
   87| 0014F8 fmul     FC330072   1     MFL       fp1=fp19,fp1,fcr
   92| 0014FC cmpld    7CAEE840   1     CL8       cr1=gr14,gr29
   91| 001500 fmsub    FC54F838   1     FMS       fp2=fp31,fp20,fp0,fcr
   91| 001504 fmul     FC7B0072   2     MFL       fp3=fp27,fp1,fcr
   87| 001508 stfdu    DC340008   2     STFDU     gr20,kr[](gr20,8)=fp1
   91| 00150C fnmsub   FC0000BC   1     FNMS      fp0=fp0,fp0,fp2,fcr
   90| 001510 stfdu    DC2F0008   2     STFDU     gr15,kp[](gr15,8)=fp1
   91| 001514 fmsub    FC34F838   1     FMS       fp1=fp31,fp20,fp0,fcr
   91| 001518 fnmsub   FC00007C   2     FNMS      fp0=fp0,fp0,fp1,fcr
   91| 00151C fmul     FC230032   2     MFL       fp1=fp3,fp0,fcr
   91| 001520 fmsub    FC541878   2     FMS       fp2=fp3,fp20,fp1,fcr
   91| 001524 fmsub    FC0008B8   2     FMS       fp0=fp1,fp0,fp2,fcr
   91| 001528 stfdu    DC100008   2     STFDU     gr16,dkpdt[](gr16,8)=fp0
   92| 00152C bc       4184FF84   1     BT        CL.117,cr1,0x8/llt,taken=80%(80,20)
   92| 001530 addi     3B180001   1     AI        gr24=gr24,1
    0| 001534 add      7EF7F214   1     A         gr23=gr23,gr30
   92| 001538 cmpld    7CB8F840   1     CL8       cr1=gr24,gr31
    0| 00153C add      7ED6F214   1     A         gr22=gr22,gr30
    0| 001540 add      7EB5F214   1     A         gr21=gr21,gr30
   92| 001544 bc       4184FF44   1     BT        CL.116,cr1,0x8/llt,taken=80%(80,20)
   92|                              CL.119:
   92| 001548 ld       E86100F0   1     L8        gr3=#SPILL8(gr1,240)
    0| 00154C ld       E80100F8   1     L8        gr0=#SPILL9(gr1,248)
    0| 001550 ld       E8810110   1     L8        gr4=#SPILL12(gr1,272)
   92| 001554 ld       E8A10100   1     L8        gr5=#SPILL10(gr1,256)
    0| 001558 ld       E8C10120   1     L8        gr6=#SPILL14(gr1,288)
    0| 00155C ld       E8E10118   1     L8        gr7=#SPILL13(gr1,280)
   92| 001560 addi     38630001   1     AI        gr3=gr3,1
   92| 001564 std      F86100F0   1     ST8       #SPILL8(gr1,240)=gr3
    0| 001568 add      7C802214   1     A         gr4=gr0,gr4
   92| 00156C cmpd     7CA51800   1     C8        cr1=gr5,gr3
    0| 001570 std      F8810110   1     ST8       #SPILL12(gr1,272)=gr4
    0| 001574 add      7CC03214   1     A         gr6=gr0,gr6
    0| 001578 add      7CE03A14   1     A         gr7=gr0,gr7
    0| 00157C std      F8C10120   1     ST8       #SPILL14(gr1,288)=gr6
    0| 001580 std      F8E10118   1     ST8       #SPILL13(gr1,280)=gr7
   92| 001584 bc       4185FEBC   1     BT        CL.115,cr1,0x2/gt,taken=80%(80,20)
   92|                              CL.120:
   84| 001588 ld       E80100D8   1     L8        gr0=#SPILL5(gr1,216)
   84| 00158C ld       E8610100   1     L8        gr3=#SPILL10(gr1,256)
   84| 001590 cmpdi    2F200000   1     C8        cr6=gr0,0
   84| 001594 cmpd     7CA01800   1     C8        cr1=gr0,gr3
   84| 001598 crand    4C392A02   1     CR_N      cr0=cr[61],0x2/gt,0x2/gt,0x2/gt,cr0
   84| 00159C bc       4081039C   1     BF        CL.82,cr0,0x2/gt,taken=50%(0,0)
   84| 0015A0 ld       E8A103C0   1     L8        gr5=.jbeg(gr1,960)
   84| 0015A4 ld       E86103C8   1     L8        gr3=.jend(gr1,968)
   92| 0015A8 ld       E92100E8   1     L8        gr9=#SPILL7(gr1,232)
    0| 0015AC ld       E90100C0   1     L8        gr8=#SPILL2(gr1,192)
    0| 0015B0 ld       E94100C8   1     L8        gr10=#SPILL3(gr1,200)
   87| 0015B4 ld       EBE20000   1     L8        gr31=.&&N&&opac_law(gr2,0)
   84| 0015B8 lwa      E8A50002   1     L4A       gr5=jbeg(gr5,0)
   84| 0015BC lwa      E8C30002   1     L4A       gr6=jend(gr3,0)
   92| 0015C0 addi     38E9FFFF   1     AI        gr7=gr9,-1
    0| 0015C4 rldicr   79041F24   1     SLL8      gr4=gr8,3
   92| 0015C8 sradi    7CE30E74   1     SRA8CA    gr3,ca=gr7,1
    0| 0015CC rldicr   794B1F24   1     SLL8      gr11=gr10,3
   92| 0015D0 addze    7C630194   1     ADDE      gr3,ca=gr3,0,ca
    0| 0015D4 std      F96100D8   1     ST8       #SPILL5(gr1,216)=gr11
   84| 0015D8 subf     7CC53050   1     S         gr6=gr6,gr5
   84| 0015DC addi     39800000   1     LI        gr12=0
   84| 0015E0 addic.   37C60001   1     AI_R      gr30,cr0=gr6,1,ca"
   84| 0015E4 std      F98100E8   1     ST8       #SPILL7(gr1,232)=gr12
   84| 0015E8 std      FBC100F0   1     ST8       #SPILL8(gr1,240)=gr30
    0| 0015EC mulld    7C0451D2   1     M         gr0=gr4,gr10
   87| 0015F0 lfd      CBDF0040   1     LFL       fp30=<s114:d64:l8>(gr31,64)
   87| 0015F4 lfd      CBBF0030   1     LFL       fp29=<s114:d48:l8>(gr31,48)
   87| 0015F8 lfd      CB9F0048   1     LFL       fp28=<s114:d72:l8>(gr31,72)
   87| 0015FC lfd      CB7F0038   1     LFL       fp27=<s114:d56:l8>(gr31,56)
    0| 001600 bc       40810338   1     BF        CL.82,cr0,0x2/gt,taken=20%(20,80)
    0| 001604 ld       E92100D0   1     L8        gr9=#SPILL4(gr1,208)
    0| 001608 mulld    7CA559D2   1     M         gr5=gr5,gr11
    0| 00160C qvfre    1340F030   1     QVFRE     fp26=fp30
    0| 001610 qvfre    1320E030   1     QVFRE     fp25=fp28
    0| 001614 fneg     FF00D850   1     COMPFL    fp24=fp27
    0| 001618 mulld    7CE049D2   1     M         gr7=gr0,gr9
    0| 00161C ld       EB810100   1     L8        gr28=#SPILL10(gr1,256)
    0| 001620 neg      7C8400D0   1     COMP      gr4=gr4
    0| 001624 ld       EB6100C0   1     L8        gr27=#SPILL2(gr1,192)
    0| 001628 ld       E90103B0   1     L8        gr8=.ibeg(gr1,944)
    0| 00162C ld       E8C103B8   1     L8        gr6=.iend(gr1,952)
    0| 001630 addi     38A5FFF0   1     AI        gr5=gr5,-16
    0| 001634 subf     7CEB3850   1     S         gr7=gr7,gr11
    0| 001638 mulld    7C8451D2   1     M         gr4=gr4,gr10
    0| 00163C add      7CA53A14   1     A         gr5=gr5,gr7
    0| 001640 rldicr   7B6726E4   1     SLL8      gr7=gr27,4
    0| 001644 lwa      EBA80002   1     L4A       gr29=ibeg(gr8,0)
    0| 001648 lwa      E8C60002   1     L4A       gr6=iend(gr6,0)
    0| 00164C mulld    7C00E1D2   1     M         gr0=gr0,gr28
    0| 001650 std      FBA100F8   1     ST8       #SPILL9(gr1,248)=gr29
    0| 001654 ld       EB4100B0   1     L8        gr26=#SPILL0(gr1,176)
    0| 001658 ld       EB0100B8   1     L8        gr24=#SPILL1(gr1,184)
    0| 00165C add      7C842A14   1     A         gr4=gr4,gr5
    0| 001660 mulld    7EE751D2   1     M         gr23=gr7,gr10
    0| 001664 addi     3A230001   1     AI        gr17=gr3,1
    0| 001668 std      FAE100B8   1     ST8       #SPILL1(gr1,184)=gr23
    0| 00166C std      FA210128   1     ST8       #SPILL15(gr1,296)=gr17
    0| 001670 ld       E8610378   1     L8        gr3=.kr(gr1,888)
    0| 001674 ld       EA010388   1     L8        gr16=.sg(gr1,904)
    0| 001678 ld       E9E10380   1     L8        gr15=.kp(gr1,896)
    0| 00167C ld       E9C10390   1     L8        gr14=.dkpdt(gr1,912)
    0| 001680 ld       EB820000   1     L8        gr28=.+CONSTANT_AREA(gr2,0)
    0| 001684 subf     7D1D3050   1     S         gr8=gr6,gr29
    0| 001688 std      F8610130   1     ST8       #SPILL16(gr1,304)=gr3
    0| 00168C std      FA010138   1     ST8       #SPILL17(gr1,312)=gr16
    0| 001690 std      F9E10140   1     ST8       #SPILL18(gr1,320)=gr15
    0| 001694 std      F9C10148   1     ST8       #SPILL19(gr1,328)=gr14
    0| 001698 add      7CC4D214   1     A         gr6=gr4,gr26
    0| 00169C add      7F202A14   1     A         gr25=gr0,gr5
    0| 0016A0 add      7CA4C214   1     A         gr5=gr4,gr24
    0| 0016A4 std      FB2100B0   1     ST8       #SPILL0(gr1,176)=gr25
    0| 0016A8 addic.   37E80001   1     AI_R      gr31,cr0=gr8,1,ca"
    0| 0016AC add      7EC03214   1     A         gr22=gr0,gr6
    0| 0016B0 add      7EB8CA14   1     A         gr21=gr24,gr25
    0| 0016B4 std      FAC10100   1     ST8       #SPILL10(gr1,256)=gr22
    0| 0016B8 std      FAA10108   1     ST8       #SPILL11(gr1,264)=gr21
    0| 0016BC add      7E802A14   1     A         gr20=gr0,gr5
    0| 0016C0 add      7E602214   1     A         gr19=gr0,gr4
    0| 0016C4 std      FA810110   1     ST8       #SPILL12(gr1,272)=gr20
    0| 0016C8 std      FA610118   1     ST8       #SPILL13(gr1,280)=gr19
    0| 0016CC add      7E59D214   1     A         gr18=gr25,gr26
    0| 0016D0 lfs      C2FC00AC   1     LFS       fp23=+CONSTANT_AREA(gr28,172)
    0| 0016D4 std      FA410120   1     ST8       #SPILL14(gr1,288)=gr18
    0| 0016D8 mcrf     4D000000   1     LRCR      cr2=cr0
   84|                              CL.83:
   85| 0016DC addi     38000000   1     LI        gr0=0
   85| 0016E0 std      F8010150   1     ST8       #SPILL20(gr1,336)=gr0
    0| 0016E4 bc       408901F0   1     BF        CL.84,cr2,0x2/gt,taken=20%(20,80)
    0| 0016E8 fmsub    FC3EFEB8   1     FMS       fp1=fp31,fp30,fp26,fcr
    0| 0016EC ld       E86100F8   1     L8        gr3=#SPILL9(gr1,248)
    0| 0016F0 fmsub    FC1CFE78   1     FMS       fp0=fp31,fp28,fp25,fcr
    0| 0016F4 ld       E8C10120   1     L8        gr6=#SPILL14(gr1,288)
    0| 0016F8 ld       E9010110   1     L8        gr8=#SPILL12(gr1,272)
    0| 0016FC ld       E8810118   1     L8        gr4=#SPILL13(gr1,280)
    0| 001700 fnmsub   FC7AD07C   1     FNMS      fp3=fp26,fp26,fp1,fcr
    0| 001704 ld       E8A100B0   1     L8        gr5=#SPILL0(gr1,176)
    0| 001708 fnmsub   FC19C83C   1     FNMS      fp0=fp25,fp25,fp0,fcr
    0| 00170C ld       E9410100   1     L8        gr10=#SPILL10(gr1,256)
    0| 001710 ld       E9610108   1     L8        gr11=#SPILL11(gr1,264)
    0| 001714 rldicr   78601F24   1     SLL8      gr0=gr3,3
    0| 001718 fmsub    FC5EF8F8   1     FMS       fp2=fp31,fp30,fp3,fcr
    0| 00171C add      7CE03214   1     A         gr7=gr0,gr6
    0| 001720 fmsub    FC3CF838   1     FMS       fp1=fp31,fp28,fp0,fcr
    0| 001724 std      F8E10158   1     ST8       #SPILL21(gr1,344)=gr7
    0| 001728 add      7D204214   1     A         gr9=gr0,gr8
    0| 00172C add      7FC02214   1     A         gr30=gr0,gr4
    0| 001730 fnmsub   FEC318BC   1     FNMS      fp22=fp3,fp3,fp2,fcr
    0| 001734 std      F9210160   1     ST8       #SPILL22(gr1,352)=gr9
    0| 001738 fnmsub   FEA0007C   1     FNMS      fp21=fp0,fp0,fp1,fcr
    0| 00173C add      7FA02A14   1     A         gr29=gr0,gr5
    0| 001740 add      7F805214   1     A         gr28=gr0,gr10
    0| 001744 add      7F605A14   1     A         gr27=gr0,gr11
   85|                              CL.85:
   91| 001748 ld       E8010148   1     L8        gr0=#SPILL19(gr1,328)
   87| 00174C fmr      FC40E890   1     LRFL      fp2=fp29
   87| 001750 ld       E8610130   1     L8        gr3=#SPILL16(gr1,304)
   89| 001754 ld       E8810138   1     L8        gr4=#SPILL17(gr1,312)
   90| 001758 ld       E8A10140   1     L8        gr5=#SPILL18(gr1,320)
   87| 00175C or       7F79DB78   1     LR        gr25=gr27
   91| 001760 add      7F40EA14   1     A         gr26=gr0,gr29
   87| 001764 ld       EB010158   1     L8        gr24=#SPILL21(gr1,344)
   87| 001768 add      7EE3EA14   1     A         gr23=gr3,gr29
   89| 00176C add      7EC4EA14   1     A         gr22=gr4,gr29
   91| 001770 add      7EA0F214   1     A         gr21=gr0,gr30
   90| 001774 add      7E85EA14   1     A         gr20=gr5,gr29
   90| 001778 add      7E65F214   1     A         gr19=gr5,gr30
   87| 00177C ld       EA410160   1     L8        gr18=#SPILL22(gr1,352)
   87| 001780 or       7F91E378   1     LR        gr17=gr28
   87| 001784 add      7E03F214   1     A         gr16=gr3,gr30
   89| 001788 add      7DE4F214   1     A         gr15=gr4,gr30
   86| 00178C addi     39C00000   1     LI        gr14=0
    0| 001790 ori      60210000   1     XNOP      
    0| 001794 ori      60210000   1     XNOP      
    0| 001798 ori      60210000   1     XNOP      
   86|                              CL.87:
   87| 00179C lfdu     CC110008   1     LFDU      fp0,gr17=d[](gr17,8)
   87| 0017A0 lfdu     CE920008   1     LFDU      fp20,gr18=t[](gr18,8)
   87| 0017A4 fmul     FC2005B2   1     MFL       fp1=fp0,fp22,fcr
   87| 0017A8 fmsub    FC1E0078   2     FMS       fp0=fp0,fp30,fp1,fcr
   87| 0017AC fnmsub   FC36083C   2     FNMS      fp1=fp1,fp22,fp0,fcr
   87| 0017B0 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   87| 0017B4 ori      60000000   1
   87| 0017B8 fmul     FC140572   1     MFL       fp0=fp20,fp21,fcr
   87| 0017BC fmr      FC40C090   2     LRFL      fp2=fp24
   87| 0017C0 fmul     FE720072   2     MFL       fp19=fp18,fp1,fcr
   87| 0017C4 fmsub    FC3CA038   2     FMS       fp1=fp20,fp28,fp0,fcr
   87| 0017C8 fnmsub   FC35007C   2     FNMS      fp1=fp0,fp21,fp1,fcr
   87| 0017CC bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   87| 0017D0 ori      60000000   1
   91| 0017D4 qvfre    1000A030   1     QVFRE     fp0=fp20
   89| 0017D8 stfdu    DEEF0008   1     STFDU     gr15,sg[](gr15,8)=fp23
   87| 0017DC fmr      FC40E890   1     LRFL      fp2=fp29
   87| 0017E0 lfdu     CC780008   1     LFDU      fp3,gr24=d[](gr24,8)
   87| 0017E4 fmul     FCB30072   1     MFL       fp5=fp19,fp1,fcr
   87| 0017E8 lfdu     CE790008   1     LFDU      fp19,gr25=t[](gr25,8)
   91| 0017EC fmsub    FC34F838   1     FMS       fp1=fp31,fp20,fp0,fcr
   91| 0017F0 fmul     FC9B0172   2     MFL       fp4=fp27,fp5,fcr
   87| 0017F4 stfdu    DCB00008   2     STFDU     gr16,kr[](gr16,8)=fp5
   91| 0017F8 fnmsub   FC00007C   1     FNMS      fp0=fp0,fp0,fp1,fcr
   90| 0017FC stfdu    DCB30008   2     STFDU     gr19,kp[](gr19,8)=fp5
   87| 001800 fmul     FC2305B2   1     MFL       fp1=fp3,fp22,fcr
   91| 001804 fmsub    FCB4F838   2     FMS       fp5=fp31,fp20,fp0,fcr
   87| 001808 fmsub    FC7E1878   2     FMS       fp3=fp3,fp30,fp1,fcr
   91| 00180C fnmsub   FC00017C   2     FNMS      fp0=fp0,fp0,fp5,fcr
   87| 001810 fnmsub   FC3608FC   2     FNMS      fp1=fp1,fp22,fp3,fcr
   91| 001814 fmul     FC640032   2     MFL       fp3=fp4,fp0,fcr
   91| 001818 fmsub    FC9420F8   2     FMS       fp4=fp4,fp20,fp3,fcr
   91| 00181C fmsub    FC001938   2     FMS       fp0=fp3,fp0,fp4,fcr
   91| 001820 stfdu    DC150008   2     STFDU     gr21,dkpdt[](gr21,8)=fp0
   87| 001824 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   87| 001828 ori      60000000   1
   87| 00182C fmul     FC130572   1     MFL       fp0=fp19,fp21,fcr
   87| 001830 fmul     FE920072   2     MFL       fp20=fp18,fp1,fcr
   87| 001834 fmr      FC40C090   2     LRFL      fp2=fp24
   87| 001838 fmsub    FC3C9838   2     FMS       fp1=fp19,fp28,fp0,fcr
   87| 00183C fnmsub   FC35007C   2     FNMS      fp1=fp0,fp21,fp1,fcr
   87| 001840 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   87| 001844 ori      60000000   1
   91| 001848 qvfre    10009830   1     QVFRE     fp0=fp19
   89| 00184C stfdu    DEF60008   1     STFDU     gr22,sg[](gr22,8)=fp23
   87| 001850 fmr      FC40E890   1     LRFL      fp2=fp29
   92| 001854 addi     39CE0001   1     AI        gr14=gr14,1
   87| 001858 fmul     FC340072   1     MFL       fp1=fp20,fp1,fcr
   92| 00185C cmpld    7C2EF840   1     CL8       cr0=gr14,gr31
   91| 001860 fmsub    FC73F838   1     FMS       fp3=fp31,fp19,fp0,fcr
   91| 001864 fmul     FC9B0072   2     MFL       fp4=fp27,fp1,fcr
   87| 001868 stfdu    DC370008   2     STFDU     gr23,kr[](gr23,8)=fp1
   91| 00186C fnmsub   FC0000FC   1     FNMS      fp0=fp0,fp0,fp3,fcr
   90| 001870 stfdu    DC340008   2     STFDU     gr20,kp[](gr20,8)=fp1
   91| 001874 fmsub    FC33F838   1     FMS       fp1=fp31,fp19,fp0,fcr
   91| 001878 fnmsub   FC00007C   2     FNMS      fp0=fp0,fp0,fp1,fcr
   91| 00187C fmul     FC240032   2     MFL       fp1=fp4,fp0,fcr
   91| 001880 fmsub    FC732078   2     FMS       fp3=fp4,fp19,fp1,fcr
   91| 001884 fmsub    FC0008F8   2     FMS       fp0=fp1,fp0,fp3,fcr
   91| 001888 stfdu    DC1A0008   2     STFDU     gr26,dkpdt[](gr26,8)=fp0
   92| 00188C bc       4180FF10   1     BT        CL.87,cr0,0x8/llt,taken=80%(80,20)
   92| 001890 ld       E8610150   1     L8        gr3=#SPILL20(gr1,336)
    0| 001894 ld       E80100D8   1     L8        gr0=#SPILL5(gr1,216)
   92| 001898 ld       E88100F0   1     L8        gr4=#SPILL8(gr1,240)
    0| 00189C ld       E8A10158   1     L8        gr5=#SPILL21(gr1,344)
    0| 0018A0 ld       E8C10160   1     L8        gr6=#SPILL22(gr1,352)
   92| 0018A4 addi     38630001   1     AI        gr3=gr3,1
    0| 0018A8 add      7FDE0214   1     A         gr30=gr30,gr0
   92| 0018AC std      F8610150   1     ST8       #SPILL20(gr1,336)=gr3
   92| 0018B0 cmpld    7C232040   1     CL8       cr0=gr3,gr4
    0| 0018B4 add      7CA50214   1     A         gr5=gr5,gr0
    0| 0018B8 add      7CC60214   1     A         gr6=gr6,gr0
    0| 0018BC std      F8A10158   1     ST8       #SPILL21(gr1,344)=gr5
    0| 0018C0 std      F8C10160   1     ST8       #SPILL22(gr1,352)=gr6
    0| 0018C4 add      7FBD0214   1     A         gr29=gr29,gr0
    0| 0018C8 add      7F9C0214   1     A         gr28=gr28,gr0
    0| 0018CC add      7F7B0214   1     A         gr27=gr27,gr0
   92| 0018D0 bc       4180FE78   1     BT        CL.85,cr0,0x8/llt,taken=80%(80,20)
   92|                              CL.84:
   92| 0018D4 ld       E86100E8   1     L8        gr3=#SPILL7(gr1,232)
    0| 0018D8 ld       E80100B8   1     L8        gr0=#SPILL1(gr1,184)
    0| 0018DC ld       E8810100   1     L8        gr4=#SPILL10(gr1,256)
   92| 0018E0 ld       E8A10128   1     L8        gr5=#SPILL15(gr1,296)
    0| 0018E4 ld       E8C10108   1     L8        gr6=#SPILL11(gr1,264)
    0| 0018E8 ld       E8E10110   1     L8        gr7=#SPILL12(gr1,272)
    0| 0018EC ld       E90100B0   1     L8        gr8=#SPILL0(gr1,176)
    0| 0018F0 ld       E9210118   1     L8        gr9=#SPILL13(gr1,280)
    0| 0018F4 ld       E9410120   1     L8        gr10=#SPILL14(gr1,288)
   92| 0018F8 addi     38630001   1     AI        gr3=gr3,1
    0| 0018FC add      7C802214   1     A         gr4=gr0,gr4
   92| 001900 std      F86100E8   1     ST8       #SPILL7(gr1,232)=gr3
    0| 001904 std      F8810100   1     ST8       #SPILL10(gr1,256)=gr4
   92| 001908 cmpld    7C232840   1     CL8       cr0=gr3,gr5
    0| 00190C add      7CC03214   1     A         gr6=gr0,gr6
    0| 001910 add      7CE03A14   1     A         gr7=gr0,gr7
    0| 001914 std      F8C10108   1     ST8       #SPILL11(gr1,264)=gr6
    0| 001918 std      F8E10110   1     ST8       #SPILL12(gr1,272)=gr7
    0| 00191C add      7D004214   1     A         gr8=gr0,gr8
    0| 001920 add      7D204A14   1     A         gr9=gr0,gr9
    0| 001924 std      F90100B0   1     ST8       #SPILL0(gr1,176)=gr8
    0| 001928 std      F9210118   1     ST8       #SPILL13(gr1,280)=gr9
    0| 00192C add      7D405214   1     A         gr10=gr0,gr10
    0| 001930 std      F9410120   1     ST8       #SPILL14(gr1,288)=gr10
   92| 001934 bc       4180FDA8   1     BT        CL.83,cr0,0x8/llt,taken=80%(80,20)
   92|                              CL.82:
   93| 001938 bc       4090010C   1     BF        CL.108,cr4,0x1/lt,taken=50%(0,0)
   93| 00193C ld       E88103C0   1     L8        gr4=.jbeg(gr1,960)
   93| 001940 ld       E8A103C8   1     L8        gr5=.jend(gr1,968)
   93| 001944 addi     38600000   1     LI        gr3=0
   93| 001948 lwa      E8840002   1     L4A       gr4=jbeg(gr4,0)
   93| 00194C lwa      E8050002   1     L4A       gr0=jend(gr5,0)
   93| 001950 subf     7CA40050   1     S         gr5=gr0,gr4
   93| 001954 addic.   34050001   1     AI_R      gr0,cr0=gr5,1,ca"
    0| 001958 bc       408103E0   1     BF        CL.532,cr0,0x2/gt,taken=50%(0,0)
    0| 00195C ld       EB4100C0   1     L8        gr26=#SPILL2(gr1,192)
    0| 001960 ld       EB2100C8   1     L8        gr25=#SPILL3(gr1,200)
    0| 001964 ld       EB0100D0   1     L8        gr24=#SPILL4(gr1,208)
    0| 001968 ld       E90103B0   1     L8        gr8=.ibeg(gr1,944)
    0| 00196C ld       E8C103B8   1     L8        gr6=.iend(gr1,952)
    0| 001970 ld       EBE10380   1     L8        gr31=.kp(gr1,896)
    0| 001974 rldicr   7B451F24   1     SLL8      gr5=gr26,3
    0| 001978 rldicr   7B291F24   1     SLL8      gr9=gr25,3
    0| 00197C mulld    7D45C9D2   1     M         gr10=gr5,gr25
    0| 001980 neg      7CE500D0   1     COMP      gr7=gr5
    0| 001984 mulld    7C8449D2   1     M         gr4=gr4,gr9
    0| 001988 mulld    7CAAC1D2   1     M         gr5=gr10,gr24
    0| 00198C lwa      E9680002   1     L4A       gr11=ibeg(gr8,0)
    0| 001990 lwa      E9860002   1     L4A       gr12=iend(gr6,0)
    0| 001994 mulld    7CC7C9D2   1     M         gr6=gr7,gr25
    0| 001998 addi     38E4FFF0   1     AI        gr7=gr4,-16
    0| 00199C subf     7CA92850   1     S         gr5=gr5,gr9
    0| 0019A0 subf     7C8B6050   1     S         gr4=gr12,gr11
    0| 0019A4 add      7CA53A14   1     A         gr5=gr5,gr7
    0| 0019A8 ld       EBA10390   1     L8        gr29=.dkpdt(gr1,912)
    0| 0019AC add      7FC53214   1     A         gr30=gr5,gr6
    0| 0019B0 ld       EB810398   1     L8        gr28=.km(gr1,920)
    0| 0019B4 ld       EB6103A0   1     L8        gr27=.dkedt(gr1,928)
    0| 0019B8 addic.   34840001   1     AI_R      gr4,cr0=gr4,1,ca"
   93|                              CL.103:
    0| 0019BC rldicr   79661F24   1     SLL8      gr6=gr11,3
   94| 0019C0 addi     38800000   1     LI        gr4=0
    0| 0019C4 bc       4081006C   1     BF        CL.107,cr0,0x2/gt,taken=20%(20,80)
    0| 0019C8 subfic   20AB0001   1     SFI       gr5=1,gr11,ca"
    0| 0019CC add      7F26F214   1     A         gr25=gr6,gr30
    0| 0019D0 add      7F456214   1     A         gr26=gr5,gr12
    0| 0019D4 ori      60210000   1     XNOP      
    0| 0019D8 ori      60210000   1     XNOP      
   94|                              CL.104:
   96| 0019DC add      7CB9FA14   1     A         gr5=gr25,gr31
   97| 0019E0 add      7CD9EA14   1     A         gr6=gr25,gr29
    0| 0019E4 mtspr    7F4903A6   1     LCTR      ctr=gr26
   96| 0019E8 lfdu     CC050008   1     LFDU      fp0,gr5=kp[](gr5,8)
   97| 0019EC lfdu     CC260008   1     LFDU      fp1,gr6=dkpdt[](gr6,8)
   97| 0019F0 add      7CF9DA14   1     A         gr7=gr25,gr27
   96| 0019F4 add      7D19E214   1     A         gr8=gr25,gr28
    0| 0019F8 bc       42400020   1     BCF       ctr=CL.774,taken=0%(0,100)
    0|                              CL.775:
   96| 0019FC lfdu     CC450008   1     LFDU      fp2,gr5=kp[](gr5,8)
   96| 001A00 stfdu    DC080008   1     STFDU     gr8,km[](gr8,8)=fp0
    0| 001A04 fmr      FC000890   1     LRFL      fp0=fp1
   97| 001A08 lfdu     CC260008   1     LFDU      fp1,gr6=dkpdt[](gr6,8)
   97| 001A0C stfdu    DC070008   1     STFDU     gr7,dkedt[](gr7,8)=fp0
    0| 001A10 fmr      FC001090   1     LRFL      fp0=fp2
    0| 001A14 bc       4200FFE8   1     BCT       ctr=CL.775,taken=100%(100,0)
    0|                              CL.774:
   97| 001A18 stfdu    DC270008   1     STFDU     gr7,dkedt[](gr7,8)=fp1
   99| 001A1C addi     38840001   1     AI        gr4=gr4,1
   96| 001A20 stfdu    DC080008   1     STFDU     gr8,km[](gr8,8)=fp0
   99| 001A24 cmpld    7CA40040   1     CL8       cr1=gr4,gr0
    0| 001A28 add      7F394A14   1     A         gr25=gr25,gr9
   99| 001A2C bc       4184FFB0   1     BT        CL.104,cr1,0x8/llt,taken=80%(80,20)
   99|                              CL.107:
  100| 001A30 ld       E88101D0   1     L8        gr4=#SPILL36(gr1,464)
  100| 001A34 addi     38630001   1     AI        gr3=gr3,1
    0| 001A38 add      7FCAF214   1     A         gr30=gr10,gr30
  100| 001A3C cmpd     7CA41800   1     C8        cr1=gr4,gr3
  100| 001A40 bc       4185FF7C   1     BT        CL.103,cr1,0x2/gt,taken=80%(80,20)
  100|                              CL.108:
   93| 001A44 bc       408D0250   1     BF        CL.157,cr3,0x2/gt,taken=30%(30,70)
    0| 001A48 ld       E94100C0   1     L8        gr10=#SPILL2(gr1,192)
    0| 001A4C ld       E98100C8   1     L8        gr12=#SPILL3(gr1,200)
   93| 001A50 ld       E8C103C0   1     L8        gr6=.jbeg(gr1,960)
   93| 001A54 ld       E88103C8   1     L8        gr4=.jend(gr1,968)
  100| 001A58 ld       E96100E0   1     L8        gr11=#SPILL6(gr1,224)
    0| 001A5C ld       EBC100D0   1     L8        gr30=#SPILL4(gr1,208)
    0| 001A60 rldicr   79431F24   1     SLL8      gr3=gr10,3
   93| 001A64 addi     3BE00000   1     LI        gr31=0
   93| 001A68 lwa      E9060002   1     L4A       gr8=jbeg(gr6,0)
   93| 001A6C std      FBE100B0   1     ST8       #SPILL0(gr1,176)=gr31
   93| 001A70 lwa      E8C40002   1     L4A       gr6=jend(gr4,0)
  100| 001A74 addi     380BFFFF   1     AI        gr0=gr11,-1
    0| 001A78 mulld    7CA361D2   1     M         gr5=gr3,gr12
  100| 001A7C sradi    7C041674   1     SRA8CA    gr4,ca=gr0,2
    0| 001A80 rldicr   79801F24   1     SLL8      gr0=gr12,3
   93| 001A84 subf     7CC83050   1     S         gr6=gr6,gr8
  100| 001A88 addze    7C840194   1     ADDE      gr4,ca=gr4,0,ca
   93| 001A8C addic.   37060001   1     AI_R      gr24,cr0=gr6,1,ca"
    0| 001A90 mulld    7CE041D2   1     M         gr7=gr0,gr8
    0| 001A94 mulld    7D25F1D2   1     M         gr9=gr5,gr30
    0| 001A98 neg      7CC300D0   1     COMP      gr6=gr3
    0| 001A9C bc       408101F8   1     BF        CL.157,cr0,0x2/gt,taken=20%(20,80)
    0| 001AA0 ld       EBC100C0   1     L8        gr30=#SPILL2(gr1,192)
    0| 001AA4 ld       EBA101D0   1     L8        gr29=#SPILL36(gr1,464)
    0| 001AA8 ld       E96103B0   1     L8        gr11=.ibeg(gr1,944)
    0| 001AAC ld       E94103B8   1     L8        gr10=.iend(gr1,952)
    0| 001AB0 addi     3A440001   1     AI        gr18=gr4,1
    0| 001AB4 ld       EAC10380   1     L8        gr22=.kp(gr1,896)
    0| 001AB8 std      FA4100E8   1     ST8       #SPILL7(gr1,232)=gr18
    0| 001ABC rldicr   7BC326E4   1     SLL8      gr3=gr30,4
    0| 001AC0 lwa      EB8B0002   1     L4A       gr28=ibeg(gr11,0)
    0| 001AC4 subf     7D604850   1     S         gr11=gr9,gr0
    0| 001AC8 rldicr   7BC92EA4   1     SLL8      gr9=gr30,5
    0| 001ACC mulld    7D05E9D2   1     M         gr8=gr5,gr29
    0| 001AD0 std      FB8100B8   1     ST8       #SPILL1(gr1,184)=gr28
    0| 001AD4 lwa      EB6A0002   1     L4A       gr27=iend(gr10,0)
    0| 001AD8 addi     3947FFF0   1     AI        gr10=gr7,-16
    0| 001ADC mulld    7CE661D2   1     M         gr7=gr6,gr12
    0| 001AE0 std      FB6100C0   1     ST8       #SPILL2(gr1,192)=gr27
    0| 001AE4 mulld    7CC361D2   1     M         gr6=gr3,gr12
    0| 001AE8 add      7D4A5A14   1     A         gr10=gr10,gr11
    0| 001AEC mulld    7D8C49D2   1     M         gr12=gr12,gr9
    0| 001AF0 add      7EE85214   1     A         gr23=gr8,gr10
    0| 001AF4 std      F98100C8   1     ST8       #SPILL3(gr1,200)=gr12
    0| 001AF8 subf     7C7CD850   1     S         gr3=gr27,gr28
    0| 001AFC add      7F45BA14   1     A         gr26=gr5,gr23
    0| 001B00 add      7CA7BA14   1     A         gr5=gr7,gr23
    0| 001B04 std      FB4100D0   1     ST8       #SPILL4(gr1,208)=gr26
    0| 001B08 std      F8A100D8   1     ST8       #SPILL5(gr1,216)=gr5
    0| 001B0C add      7F26BA14   1     A         gr25=gr6,gr23
    0| 001B10 ld       EAA10390   1     L8        gr21=.dkpdt(gr1,912)
    0| 001B14 std      FB2100E0   1     ST8       #SPILL6(gr1,224)=gr25
    0| 001B18 ld       EA810398   1     L8        gr20=.km(gr1,920)
    0| 001B1C ld       EA6103A0   1     L8        gr19=.dkedt(gr1,928)
    0| 001B20 addic.   34630001   1     AI_R      gr3,cr0=gr3,1,ca"
   93|                              CL.89:
    0| 001B24 ld       E8A100B8   1     L8        gr5=#SPILL1(gr1,184)
   94| 001B28 addi     38600000   1     LI        gr3=0
    0| 001B2C rldicr   78A41F24   1     SLL8      gr4=gr5,3
    0| 001B30 bc       40810120   1     BF        CL.90,cr0,0x2/gt,taken=20%(20,80)
    0| 001B34 ld       E8C100C0   1     L8        gr6=#SPILL2(gr1,192)
    0| 001B38 ld       E8E100E0   1     L8        gr7=#SPILL6(gr1,224)
    0| 001B3C ld       E90100D8   1     L8        gr8=#SPILL5(gr1,216)
    0| 001B40 ld       E92100D0   1     L8        gr9=#SPILL4(gr1,208)
    0| 001B44 subfic   20A50001   1     SFI       gr5=1,gr5,ca"
    0| 001B48 add      7E44BA14   1     A         gr18=gr4,gr23
    0| 001B4C add      7E253214   1     A         gr17=gr5,gr6
    0| 001B50 add      7E043A14   1     A         gr16=gr4,gr7
    0| 001B54 add      7DE44214   1     A         gr15=gr4,gr8
    0| 001B58 add      7DC44A14   1     A         gr14=gr4,gr9
    0| 001B5C ori      60210000   1     XNOP      
    0| 001B60 ori      60210000   1     XNOP      
    0| 001B64 ori      60210000   1     XNOP      
   94|                              CL.91:
   96| 001B68 add      7C8FB214   1     A         gr4=gr15,gr22
   96| 001B6C add      7CB2B214   1     A         gr5=gr18,gr22
   96| 001B70 add      7CCEB214   1     A         gr6=gr14,gr22
   96| 001B74 lfdu     CC040008   1     LFDU      fp0,gr4=kp[](gr4,8)
   96| 001B78 lfdu     CC450008   1     LFDU      fp2,gr5=kp[](gr5,8)
   96| 001B7C lfdu     CC260008   1     LFDU      fp1,gr6=kp[](gr6,8)
   97| 001B80 add      7CEFAA14   1     A         gr7=gr15,gr21
   97| 001B84 add      7D12AA14   1     A         gr8=gr18,gr21
   97| 001B88 add      7D2EAA14   1     A         gr9=gr14,gr21
   96| 001B8C add      7D50B214   1     A         gr10=gr16,gr22
   96| 001B90 add      7D6FA214   1     A         gr11=gr15,gr20
   96| 001B94 add      7D92A214   1     A         gr12=gr18,gr20
   96| 001B98 stfdu    DC0B0008   1     STFDU     gr11,km[](gr11,8)=fp0
   96| 001B9C add      7FEEA214   1     A         gr31=gr14,gr20
    0| 001BA0 mtspr    7E2903A6   1     LCTR      ctr=gr17
   96| 001BA4 stfdu    DC4C0008   1     STFDU     gr12,km[](gr12,8)=fp2
   97| 001BA8 lfdu     CC070008   1     LFDU      fp0,gr7=dkpdt[](gr7,8)
   97| 001BAC add      7FD0AA14   1     A         gr30=gr16,gr21
   96| 001BB0 stfdu    DC3F0008   1     STFDU     gr31,km[](gr31,8)=fp1
   97| 001BB4 lfdu     CC680008   1     LFDU      fp3,gr8=dkpdt[](gr8,8)
   97| 001BB8 lfdu     CC890008   1     LFDU      fp4,gr9=dkpdt[](gr9,8)
   96| 001BBC lfdu     CC2A0008   1     LFDU      fp1,gr10=kp[](gr10,8)
   97| 001BC0 add      7FAF9A14   1     A         gr29=gr15,gr19
   97| 001BC4 add      7F929A14   1     A         gr28=gr18,gr19
   97| 001BC8 add      7F6E9A14   1     A         gr27=gr14,gr19
   97| 001BCC add      7F509A14   1     A         gr26=gr16,gr19
   96| 001BD0 add      7F30A214   1     A         gr25=gr16,gr20
    0| 001BD4 bc       42400048   1     BCF       ctr=CL.776,taken=0%(0,100)
    0|                              CL.777:
   96| 001BD8 lfdu     CC440008   1     LFDU      fp2,gr4=kp[](gr4,8)
   96| 001BDC stfdu    DC390008   1     STFDU     gr25,km[](gr25,8)=fp1
   97| 001BE0 lfdu     CC3E0008   1     LFDU      fp1,gr30=dkpdt[](gr30,8)
   97| 001BE4 stfdu    DC1D0008   1     STFDU     gr29,dkedt[](gr29,8)=fp0
   97| 001BE8 stfdu    DC7C0008   1     STFDU     gr28,dkedt[](gr28,8)=fp3
   97| 001BEC stfdu    DC9B0008   1     STFDU     gr27,dkedt[](gr27,8)=fp4
   96| 001BF0 lfdu     CC650008   1     LFDU      fp3,gr5=kp[](gr5,8)
   96| 001BF4 lfdu     CC860008   1     LFDU      fp4,gr6=kp[](gr6,8)
   97| 001BF8 lfdu     CC070008   1     LFDU      fp0,gr7=dkpdt[](gr7,8)
   97| 001BFC stfdu    DC3A0008   1     STFDU     gr26,dkedt[](gr26,8)=fp1
   96| 001C00 lfdu     CC2A0008   1     LFDU      fp1,gr10=kp[](gr10,8)
   96| 001C04 stfdu    DC4B0008   1     STFDU     gr11,km[](gr11,8)=fp2
   96| 001C08 stfdu    DC6C0008   1     STFDU     gr12,km[](gr12,8)=fp3
   96| 001C0C stfdu    DC9F0008   1     STFDU     gr31,km[](gr31,8)=fp4
   97| 001C10 lfdu     CC680008   1     LFDU      fp3,gr8=dkpdt[](gr8,8)
   97| 001C14 lfdu     CC890008   1     LFDU      fp4,gr9=dkpdt[](gr9,8)
    0| 001C18 bc       4200FFC0   1     BCT       ctr=CL.777,taken=100%(100,0)
    0|                              CL.776:
   96| 001C1C stfdu    DC390008   1     STFDU     gr25,km[](gr25,8)=fp1
   97| 001C20 lfdu     CC3E0008   1     LFDU      fp1,gr30=dkpdt[](gr30,8)
   97| 001C24 stfdu    DC1D0008   1     STFDU     gr29,dkedt[](gr29,8)=fp0
   99| 001C28 addi     38630001   1     AI        gr3=gr3,1
   97| 001C2C stfdu    DC7C0008   1     STFDU     gr28,dkedt[](gr28,8)=fp3
   99| 001C30 cmpld    7CA3C040   1     CL8       cr1=gr3,gr24
   97| 001C34 stfdu    DC9B0008   1     STFDU     gr27,dkedt[](gr27,8)=fp4
    0| 001C38 add      7E520214   1     A         gr18=gr18,gr0
    0| 001C3C add      7E100214   1     A         gr16=gr16,gr0
   97| 001C40 stfdu    DC3A0008   1     STFDU     gr26,dkedt[](gr26,8)=fp1
    0| 001C44 add      7DEF0214   1     A         gr15=gr15,gr0
    0| 001C48 add      7DCE0214   1     A         gr14=gr14,gr0
   99| 001C4C bc       4184FF1C   1     BT        CL.91,cr1,0x8/llt,taken=80%(80,20)
   99|                              CL.90:
  100| 001C50 ld       E86100B0   1     L8        gr3=#SPILL0(gr1,176)
    0| 001C54 ld       E88100C8   1     L8        gr4=#SPILL3(gr1,200)
    0| 001C58 ld       E8A100D0   1     L8        gr5=#SPILL4(gr1,208)
  100| 001C5C ld       E8C100E8   1     L8        gr6=#SPILL7(gr1,232)
    0| 001C60 ld       E8E100D8   1     L8        gr7=#SPILL5(gr1,216)
    0| 001C64 ld       E90100E0   1     L8        gr8=#SPILL6(gr1,224)
  100| 001C68 addi     38630001   1     AI        gr3=gr3,1
    0| 001C6C add      7EE4BA14   1     A         gr23=gr4,gr23
  100| 001C70 std      F86100B0   1     ST8       #SPILL0(gr1,176)=gr3
    0| 001C74 add      7CA42A14   1     A         gr5=gr4,gr5
  100| 001C78 cmpld    7CA33040   1     CL8       cr1=gr3,gr6
    0| 001C7C std      F8A100D0   1     ST8       #SPILL4(gr1,208)=gr5
    0| 001C80 add      7CE43A14   1     A         gr7=gr4,gr7
    0| 001C84 add      7D044214   1     A         gr8=gr4,gr8
    0| 001C88 std      F8E100D8   1     ST8       #SPILL5(gr1,216)=gr7
    0| 001C8C std      F90100E0   1     ST8       #SPILL6(gr1,224)=gr8
  100| 001C90 bc       4184FE94   1     BT        CL.89,cr1,0x8/llt,taken=80%(80,20)
   61|                              CL.157:
  103| 001C94 ld       E8010310   1     L8        gr0=#stack(gr1,784)
  103| 001C98 lwa      E981030A   1     L4A       gr12=#stack(gr1,776)
  103| 001C9C lfd      CBE102F8   1     LFL       fp31=#stack(gr1,760)
  103| 001CA0 lfd      CBC102F0   1     LFL       fp30=#stack(gr1,752)
  103| 001CA4 lfd      CBA102E8   1     LFL       fp29=#stack(gr1,744)
  103| 001CA8 lfd      CB8102E0   1     LFL       fp28=#stack(gr1,736)
  103| 001CAC lfd      CB6102D8   1     LFL       fp27=#stack(gr1,728)
  103| 001CB0 lfd      CB4102D0   1     LFL       fp26=#stack(gr1,720)
  103| 001CB4 lfd      CB2102C8   1     LFL       fp25=#stack(gr1,712)
  103| 001CB8 lfd      CB0102C0   1     LFL       fp24=#stack(gr1,704)
  103| 001CBC lfd      CAE102B8   1     LFL       fp23=#stack(gr1,696)
  103| 001CC0 lfd      CAC102B0   1     LFL       fp22=#stack(gr1,688)
  103| 001CC4 lfd      CAA102A8   1     LFL       fp21=#stack(gr1,680)
  103| 001CC8 lfd      CA8102A0   1     LFL       fp20=#stack(gr1,672)
  103| 001CCC lfd      CA610298   1     LFL       fp19=#stack(gr1,664)
  103| 001CD0 lfd      CA410290   1     LFL       fp18=#stack(gr1,656)
  103| 001CD4 lfd      CA210288   1     LFL       fp17=#stack(gr1,648)
  103| 001CD8 addi     38210300   1     AI        gr1=gr1,768
  103| 001CDC mtspr    7C0803A6   1     LLR       lr=gr0
  103| 001CE0 mtcrf    7D820120   1     MTCRF     cr2=gr12
  103| 001CE4 mtcrf    7D810120   1     MTCRF     cr3=gr12
  103| 001CE8 mtcrf    7D808120   1     MTCRF     cr4=gr12
  103| 001CEC ld       E9C1FEF8   1     L8        gr14=#stack(gr1,-264)
  103| 001CF0 ld       E9E1FF00   1     L8        gr15=#stack(gr1,-256)
  103| 001CF4 ld       EA01FF08   1     L8        gr16=#stack(gr1,-248)
  103| 001CF8 ld       EA21FF10   1     L8        gr17=#stack(gr1,-240)
  103| 001CFC ld       EA41FF18   1     L8        gr18=#stack(gr1,-232)
  103| 001D00 ld       EA61FF20   1     L8        gr19=#stack(gr1,-224)
  103| 001D04 ld       EA81FF28   1     L8        gr20=#stack(gr1,-216)
  103| 001D08 ld       EAA1FF30   1     L8        gr21=#stack(gr1,-208)
  103| 001D0C ld       EAC1FF38   1     L8        gr22=#stack(gr1,-200)
  103| 001D10 ld       EAE1FF40   1     L8        gr23=#stack(gr1,-192)
  103| 001D14 ld       EB01FF48   1     L8        gr24=#stack(gr1,-184)
  103| 001D18 ld       EB21FF50   1     L8        gr25=#stack(gr1,-176)
  103| 001D1C ld       EB41FF58   1     L8        gr26=#stack(gr1,-168)
  103| 001D20 ld       EB61FF60   1     L8        gr27=#stack(gr1,-160)
  103| 001D24 ld       EB81FF68   1     L8        gr28=#stack(gr1,-152)
  103| 001D28 ld       EBA1FF70   1     L8        gr29=#stack(gr1,-144)
  103| 001D2C ld       EBC1FF78   1     L8        gr30=#stack(gr1,-136)
  103| 001D30 ld       EBE1FF80   1     L8        gr31=#stack(gr1,-128)
  103| 001D34 bclr     4E800020   1     BA        lr
   99|                              CL.532:
    0| 001D38 ld       E80101D0   1     L8        gr0=#SPILL36(gr1,464)
    0| 001D3C mtspr    7C0903A6   1     LCTR      ctr=gr0
   99|                              CL.361:
  100| 001D40 addi     38630001   1     AI        gr3=gr3,1
  100| 001D44 cmpd     7C230000   1     C8        cr0=gr3,gr0
  100| 001D48 bc       4100FFF8   1     BCTT      ctr=CL.361,cr0,0x1/lt,taken=80%(80,20)
    0| 001D4C b        4BFFFCF8   1     B         CL.108,-1
   92|                              CL.522:
    0| 001D50 mtspr    7CE903A6   1     LCTR      ctr=gr7
    0| 001D54 addi     38600000   1     LI        gr3=0
    0| 001D58 or       7CE03B78   1     LR        gr0=gr7
   92|                              CL.391:
   92| 001D5C addi     38630001   1     AI        gr3=gr3,1
   92| 001D60 cmpd     7CA30000   1     C8        cr1=gr3,gr0
   92| 001D64 bc       4104FFF8   1     BCTT      ctr=CL.391,cr1,0x1/lt,taken=80%(80,20)
    0| 001D68 b        4BFFF820   1     B         CL.120,-1
   80|                              CL.512:
    0| 001D6C ld       E80101D0   1     L8        gr0=#SPILL36(gr1,464)
    0| 001D70 mtspr    7C0903A6   1     LCTR      ctr=gr0
   80|                              CL.421:
   80| 001D74 addi     38630001   1     AI        gr3=gr3,1
   80| 001D78 cmpd     7C230000   1     C8        cr0=gr3,gr0
   80| 001D7C bc       4100FFF8   1     BCTT      ctr=CL.421,cr0,0x1/lt,taken=80%(80,20)
    0| 001D80 b        4BFFF12C   1     B         CL.132,-1
   72|                              CL.502:
    0| 001D84 ld       E80101D0   1     L8        gr0=#SPILL36(gr1,464)
    0| 001D88 mtspr    7C0903A6   1     LCTR      ctr=gr0
   72|                              CL.451:
   72| 001D8C addi     38840001   1     AI        gr4=gr4,1
   72| 001D90 cmpd     7C240000   1     C8        cr0=gr4,gr0
   72| 001D94 bc       4100FFF8   1     BCTT      ctr=CL.451,cr0,0x1/lt,taken=80%(80,20)
    0| 001D98 b        4BFFE9DC   1     B         CL.144,-1
   57|                              CL.492:
    0| 001D9C mtspr    7FC903A6   1     LCTR      ctr=gr30
    0| 001DA0 or       7FC0F378   1     LR        gr0=gr30
   57|                              CL.481:
   57| 001DA4 addi     38840001   1     AI        gr4=gr4,1
   57| 001DA8 cmpd     7C240000   1     C8        cr0=gr4,gr0
   57| 001DAC bc       4100FFF8   1     BCTT      ctr=CL.481,cr0,0x1/lt,taken=80%(80,20)
    0| 001DB0 b        4BFFE48C   1     B         CL.156,-1
   58|                              CL.1:
   59| 001DB4 ld       EBE20000   1     L8        gr31=.&&N&&mpipar(gr2,0)
   59| 001DB8 lwz      801F0004   1     L4Z       gr0=<s91:d4:l4>(gr31,4)
   59| 001DBC cmpdi    2C200000   1     C8        cr0=gr0,0
   59| 001DC0 bc       41820024   1     BT        CL.1087,cr0,0x4/eq,taken=40%(40,60)
   59|                              CL.15:
   60| 001DC4 addi     387F0014   1     AI        gr3=gr31,20
   60| 001DC8 bl       48000001   1     CALL      mpi_finalize,1,ierr",gr3,#ProcAlias",mpi_finalize",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   60| 001DCC ori      60000000   1
   61| 001DD0 addi     38600000   1     LI        gr3=0
   61| 001DD4 addi     38800000   1     LI        gr4=0
   61| 001DD8 bl       48000001   1     CALL      _xlfStop,2,@PALI_SHADOW_CONST.rns0.,gr3,gr4,_xlfStop",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   61| 001DDC ori      60000000   1
   61| 001DE0 tw       7C8E7008   1     TRAP      9
    0|                              CL.1087:
   59| 001DE4 ld       E8620000   1     L8        gr3=.+CONSTANT_AREA(gr2,0)
   59| 001DE8 addi     38800081   1     LI        gr4=129
   59| 001DEC addi     38000000   1     LI        gr0=0
   59| 001DF0 stw      90810080   1     ST4Z      <a1:d128:l4>(gr1,128)=gr4
   59| 001DF4 std      F8010088   1     ST8       <a1:d136:l8>(gr1,136)=gr0
   59| 001DF8 std      F8010098   1     ST8       <a1:d152:l8>(gr1,152)=gr0
   59| 001DFC addi     3863000C   1     AI        gr3=gr3,12
   59| 001E00 std      F80100A0   1     ST8       <a1:d160:l8>(gr1,160)=gr0
   59| 001E04 std      F8610090   1     ST8       <a1:d144:l8>(gr1,144)=gr3
   59| 001E08 ld       E8A20000   1     L8        gr5=.$STATIC(gr2,0)
   59| 001E0C addi     39210080   1     AI        gr9=gr1,128
   59| 001E10 addi     38600006   1     LI        gr3=6
   59| 001E14 addi     38800103   1     LI        gr4=259
   59| 001E18 ori      60068004   1     OIL       gr6=gr0,0x8004
   59| 001E1C addi     38E00000   1     LI        gr7=0
   59| 001E20 addi     39000000   1     LI        gr8=0
   59| 001E24 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#106",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,|fmt_args,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   59| 001E28 ori      60000000   1
   59| 001E2C bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   59| 001E30 ori      60000000   1
    0| 001E34 b        4BFFFF90   1     B         CL.15,-1
     |               Tag Table
     | 001E38        00000000 00012203 8F120000 00001E38
     |               Instruction count         1934
     |               Straight-line exec time   2134
     |               Constant Area
     | 000000        6D617470 726F702E 66393000 00000000 80010000 00000000
     | 000018        0000000E 00000000 00000001 00000000 00000006 00000000
     | 000030        00000000 00000000 80020000 00000000 802F0011 00000000
     | 000048        0000001D 00000000 00000007 4D415450 524F503A 20496C6C
     | 000060        6567616C 20454F53 206F7074 696F6E21 21000000 00000000
     | 000078        80050000 6D617470 726F702E 66393049 BF800000 18007A2F
     | 000090        4339BB64 0DB6B568 3F800000 49424D20 3EF2E968 EA16A12C
     | 0000A8        40800000 00000000

 
 
>>>>> COMPILATION UNIT EPILOGUE SECTION <<<<<
 
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    matprop.f90                 07/08/15   15:48:13
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
 
    Source records read.......................................     108
1501-510  Compilation successful for file matprop.f90.
1501-543  Object file created.
