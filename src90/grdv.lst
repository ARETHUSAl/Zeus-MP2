IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- grdv.f90 07/08/15 15:47:45
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** grdv   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-534 (I) Loop (loop index 1) at grdv.f90 <line 76> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 2) at grdv.f90 <line 77> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 3) at grdv.f90 <line 78> was not SIMD vectorized because it is not profitable to vectorize.
1586-554 (I) Loop (loop index 3) at grdv.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at grdv.f90 <line 80> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at grdv.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at grdv.f90 <line 80> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at grdv.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at grdv.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at grdv.f90 <line 80> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 3) at grdv.f90 <line 80> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 4) at grdv.f90 <line 88> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 5) at grdv.f90 <line 89> was not SIMD vectorized because the loop is not the innermost loop.
1586-535 (I) Loop (loop index 6) at grdv.f90 <line 96> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 6) at grdv.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dv11%addr  + -8ll))->dv11[].rns0.[(long long) .ibeg->ibeg + $$CIV3] = (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][1ll + ($$CIV3 + (long long) .ibeg->ibeg)] - ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV3]) * ((double *)((char *)d-dx1ai%addr  + d-dx1ai%rvo))->dx1ai[].rns1.[(long long) .ibeg->ibeg + $$CIV3]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 6) at grdv.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dv22%addr  + -8ll))->dv22[].rns3.[(long long) .ibeg->ibeg + $$CIV3] = (( 5.0000000000000000E-001 * (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][1ll + ($$CIV3 + (long long) .ibeg->ibeg)] + ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV3])) * ((double *)((char *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long long) .ibeg->ibeg + $$CIV3]) * ((double *)((char *)d-dg2bd1%addr  + d-dg2bd1%rvo))->dg2bd1[].rns4.[(long long) .ibeg->ibeg + $$CIV3]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 6) at grdv.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dv33%addr  + -8ll))->dv33[].rns6.[(long long) .ibeg->ibeg + $$CIV3] = (( 5.0000000000000000E-001 * (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][1ll + ($$CIV3 + (long long) .ibeg->ibeg)] + ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV3])) * ((double *)((char *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns8.[(long long) .ibeg->ibeg + $$CIV3]) * ((double *)((char *)d-dg31bd1%addr  + d-dg31bd1%rvo))->dg31bd1[].rns7.[(long long) .ibeg->ibeg + $$CIV3]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 6) at grdv.f90 <line 97> was not SIMD vectorized because it contains memory references ((char *)d-dv11%addr  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV3)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 6) at grdv.f90 <line 97> was not SIMD vectorized because it contains operation in (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][1ll + ($$CIV3 + (long long) .ibeg->ibeg)] - ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV3]) * ((double *)((char *)d-dx1ai%addr  + d-dx1ai%rvo))->dx1ai[].rns1.[(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 6) at grdv.f90 <line 97> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg + $$CIVA) + (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg + $$CIV9) + (d-v1%bounds%mult[].off512)*(1ll + ($$CIV3 + (long long) .ibeg->ibeg))) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at grdv.f90 <line 97> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 6) at grdv.f90 <line 98> was not SIMD vectorized because it contains memory references ((char *)d-dv22%addr  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV3)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 6) at grdv.f90 <line 98> was not SIMD vectorized because it contains operation in (( 5.0000000000000000E-001 * (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][1ll + ($$CIV3 + (long long) .ibeg->ibeg)] + ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV3])) * ((double *)((char *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long long) .ibeg->ibeg + $$CIV3]) * ((double *)((char *)d-dg2bd1%addr  + d-dg2bd1%rvo))->dg2bd1[].rns4.[(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 6) at grdv.f90 <line 98> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg + $$CIVA) + (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg + $$CIV9) + (d-v1%bounds%mult[].off512)*(1ll + ($$CIV3 + (long long) .ibeg->ibeg))) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at grdv.f90 <line 98> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 6) at grdv.f90 <line 101> was not SIMD vectorized because it contains memory references ((char *)d-dv33%addr  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV3)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 6) at grdv.f90 <line 101> was not SIMD vectorized because it contains operation in (( 5.0000000000000000E-001 * (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][1ll + ($$CIV3 + (long long) .ibeg->ibeg)] + ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV3])) * ((double *)((char *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns8.[(long long) .ibeg->ibeg + $$CIV3]) * ((double *)((char *)d-dg31bd1%addr  + d-dg31bd1%rvo))->dg31bd1[].rns7.[(long long) .ibeg->ibeg + $$CIV3] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 6) at grdv.f90 <line 101> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg + $$CIVA) + (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg + $$CIV9) + (d-v1%bounds%mult[].off512)*(1ll + ($$CIV3 + (long long) .ibeg->ibeg))) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at grdv.f90 <line 101> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-535 (I) Loop (loop index 7) at grdv.f90 <line 106> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 7) at grdv.f90 <line 106> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dv22%addr  + -8ll))->dv22[].rns3.[(long long) .ibeg->ibeg + $$CIV4] = ((double *)((char *)d-dv22%addr  + -8ll))->dv22[].rns3.[(long long) .ibeg->ibeg + $$CIV4] + ((((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long long) .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV4] - ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV4]) * ((double *)((char *)d-dx2ai%addr  + d-dx2ai%rvo))->dx2ai[].rns9.[(long long) .jbeg->jbeg + $$CIV9]) * ((double *)((char *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long long) .ibeg->ibeg + $$CIV4]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 7) at grdv.f90 <line 106> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dv33%addr  + -8ll))->dv33[].rns6.[(long long) .ibeg->ibeg + $$CIV4] = (((double *)((char *)d-dv33%addr  + -8ll))->dv33[].rns6.[(long long) .ibeg->ibeg + $$CIV4] + ((( 5.0000000000000000E-001 * (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long long) .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV4] + ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV4])) * ((double *)((char *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns11.[(long long) .jbeg->jbeg + $$CIV9]) * ((double *)((char *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long long) .ibeg->ibeg + $$CIV4]) * ((double *)((char *)d-dg32bd2%addr  + d-dg32bd2%rvo))->dg32bd2[].rns14.[(long long) .jbeg->jbeg + $$CIV9]) + (((((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV4] - ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV4]) * ((double *)((char *)d-dx3ai%addr  + d-dx3ai%rvo))->dx3ai[].rns12.[(long long) .kbeg->kbeg + $$CIVA]) * ((double *)((char *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns8.[(long long) .ibeg->ibeg + $$CIV4]) * ((double *)((char *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns11.[(long long) .jbeg->jbeg + $$CIV9]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 7) at grdv.f90 <line 107> was not SIMD vectorized because it contains memory references ((char *)d-dv22%addr  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV4)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 7) at grdv.f90 <line 107> was not SIMD vectorized because it contains operation in ((double *)((char *)d-dv22%addr  + -8ll))->dv22[].rns3.[(long long) .ibeg->ibeg + $$CIV4] + ((((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long long) .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV4] - ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV4]) * ((double *)((char *)d-dx2ai%addr  + d-dx2ai%rvo))->dx2ai[].rns9.[(long long) .jbeg->jbeg + $$CIV9]) * ((double *)((char *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long long) .ibeg->ibeg + $$CIV4] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 7) at grdv.f90 <line 107> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg + $$CIVA) + (d-v2%bounds%mult[].off592)*(1ll + ($$CIV9 + (long long) .jbeg->jbeg)) + (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg + $$CIV4)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 7) at grdv.f90 <line 107> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 7) at grdv.f90 <line 110> was not SIMD vectorized because it contains memory references ((char *)d-dv33%addr  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV4)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 7) at grdv.f90 <line 110> was not SIMD vectorized because it contains operation in (((double *)((char *)d-dv33%addr  + -8ll))->dv33[].rns6.[(long long) .ibeg->ibeg + $$CIV4] + ((( 5.0000000000000000E-001 * (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long long) .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV4] + ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV4])) * ((double *)((char *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns11.[(long long) .jbeg->jbeg + $$CIV9]) * ((double *)((char *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long long) .ibeg->ibeg + $$CIV4]) * ((double *)((char *)d-dg32bd2%addr  + d-dg32bd2%rvo))->dg32bd2[].rns14.[(long long) .jbeg->jbeg + $$CIV9]) + (((((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV4] - ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV4]) * ((double *)((char *)d-dx3ai%addr  + d-dx3ai%rvo))->dx3ai[].rns12.[(long long) .kbeg->kbeg + $$CIVA]) * ((double *)((char *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns8.[(long long) .ibeg->ibeg + $$CIV4]) * ((double *)((char *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns11.[(long long) .jbeg->jbeg + $$CIV9] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 7) at grdv.f90 <line 110> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg + $$CIVA) + (d-v2%bounds%mult[].off592)*(1ll + ($$CIV9 + (long long) .jbeg->jbeg)) + (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg + $$CIV4)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 7) at grdv.f90 <line 110> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-538 (I) Loop (loop index 8) at grdv.f90 <line 117> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 8) at grdv.f90 <line 117> was not SIMD vectorized because it contains control flow.
1586-538 (I) Loop (loop index 9) at grdv.f90 <line 153> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 9) at grdv.f90 <line 153> was not SIMD vectorized because it contains control flow.
1586-535 (I) Loop (loop index 10) at grdv.f90 <line 171> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 10) at grdv.f90 <line 171> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dv31%addr  + -8ll))->dv31[].rns26.[(long long) .ibeg->ibeg + $$CIV7] = ((double *)((char *)d-dv31%addr  + -8ll))->dv31[].rns26.[(long long) .ibeg->ibeg + $$CIV7] - (( 2.5000000000000000E-001 * (((((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV7] + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll]) + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV7]) + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll])) * ((double *)((char *)d-g31ai%addr  + d-g31ai%rvo))->g31ai[].rns27.[(long long) .ibeg->ibeg + $$CIV7]) * ((double *)((char *)d-dg31ad1%addr  + d-dg31ad1%rvo))->dg31ad1[].rns29.[(long long) .ibeg->ibeg + $$CIV7]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at grdv.f90 <line 171> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dv21%addr  + -8ll))->dv21[].rns24.[(long long) .ibeg->ibeg + $$CIV7] = ((double *)((char *)d-dv21%addr  + -8ll))->dv21[].rns24.[(long long) .ibeg->ibeg + $$CIV7] - (( 2.5000000000000000E-001 * (((((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV7] + ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll]) + ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long long) .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV7]) + ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long long) .jbeg->jbeg)][($$CIV7 + (long long) .ibeg->ibeg) - 1ll])) * ((double *)((char *)d-g2ai%addr  + d-g2ai%rvo))->g2ai[].rns25.[(long long) .ibeg->ibeg + $$CIV7]) * ((double *)((char *)d-dg2ad1%addr  + d-dg2ad1%rvo))->dg2ad1[].rns28.[(long long) .ibeg->ibeg + $$CIV7]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 10) at grdv.f90 <line 176> was not SIMD vectorized because it contains memory references ((char *)d-dv31%addr  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV7)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 10) at grdv.f90 <line 176> was not SIMD vectorized because it contains operation in ((double *)((char *)d-dv31%addr  + -8ll))->dv31[].rns26.[(long long) .ibeg->ibeg + $$CIV7] - (( 2.5000000000000000E-001 * (((((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV7] + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll]) + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV7]) + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll])) * ((double *)((char *)d-g31ai%addr  + d-g31ai%rvo))->g31ai[].rns27.[(long long) .ibeg->ibeg + $$CIV7]) * ((double *)((char *)d-dg31ad1%addr  + d-dg31ad1%rvo))->dg31ad1[].rns29.[(long long) .ibeg->ibeg + $$CIV7] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 10) at grdv.f90 <line 176> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg + $$CIVA) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIV9) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIV7)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at grdv.f90 <line 176> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 10) at grdv.f90 <line 172> was not SIMD vectorized because it contains memory references ((char *)d-dv21%addr  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV7)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 10) at grdv.f90 <line 172> was not SIMD vectorized because it contains operation in ((double *)((char *)d-dv21%addr  + -8ll))->dv21[].rns24.[(long long) .ibeg->ibeg + $$CIV7] - (( 2.5000000000000000E-001 * (((((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) .ibeg->ibeg + $$CIV7] + ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll]) + ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long long) .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV7]) + ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long long) .jbeg->jbeg)][($$CIV7 + (long long) .ibeg->ibeg) - 1ll])) * ((double *)((char *)d-g2ai%addr  + d-g2ai%rvo))->g2ai[].rns25.[(long long) .ibeg->ibeg + $$CIV7]) * ((double *)((char *)d-dg2ad1%addr  + d-dg2ad1%rvo))->dg2ad1[].rns28.[(long long) .ibeg->ibeg + $$CIV7] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 10) at grdv.f90 <line 172> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg + $$CIVA) + (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg + $$CIV9) + (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg + $$CIV7)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at grdv.f90 <line 172> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-538 (I) Loop (loop index 11) at grdv.f90 <line 185> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 11) at grdv.f90 <line 185> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 15) at grdv.f90 <line 76> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 16) at grdv.f90 <line 77> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 17) at grdv.f90 <line 78> was not SIMD vectorized because it is not profitable to vectorize.
1586-554 (I) Loop (loop index 17) at grdv.f90 <line 79> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 17) at grdv.f90 <line 80> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"8">. Total number of the innermost loops SIMD vectorized <"0">.


    10|         SUBROUTINE grdv (ibeg, iend, jbeg, jend, kbeg, kend, erold, gvcf, deldotv)
    10|           d-dv11%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv12%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv13%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv21%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv22%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv23%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv31%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv32%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv33%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  _alloca(8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0))))
    75|           IF ((0 <> ((xhydro  .XOR.  1)  .AND.  1))) THEN
    76|             IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &     int(kend) - int(kbeg)) > 0)) THEN
                      $$CIV2 = 0
       Id=15          DO $$CIV2 = $$CIV2, MOD((1 + (int(kend) - int(kbeg))), &
                &         int(4))-1
    77|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV1 = 0
       Id=16              DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    78|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV0 = 0
       Id=17                  DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(&
                &                 kbeg) + $$CIV2) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,&
                &                 int(kbeg) + $$CIV2) =  0.0000000000000000E+000
    81|                       ENDDO
                            ENDIF
    82|                   ENDDO
                        ENDIF
    83|               ENDDO
                    ENDIF
    76|             IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) &
                &     - int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                      $$CIVB = int(0)
       Id=1           DO $$CIVB = $$CIVB, int(((int(kend) - (MOD((1 + (int(&
                &         kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    77|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV1 = 0
       Id=2               DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    78|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV0 = 0
       Id=3                   DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,(&
                &                 $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &                 4)) + int(kbeg)) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,(&
                &                 $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &                 4)) + int(kbeg)) =  0.0000000000000000E+000
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + (&
                &                 ($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 &
                &                 + (($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg)&
                &                 )), 4)) + int(kbeg))) =  &
                &                 0.0000000000000000E+000
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + (&
                &                 ($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 &
                &                 + (($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg)&
                &                 )), 4)) + int(kbeg))) =  &
                &                 0.0000000000000000E+000
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + (&
                &                 ($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 &
                &                 + (($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg)&
                &                 )), 4)) + int(kbeg))) =  &
                &                 0.0000000000000000E+000
    81|                       ENDDO
                            ENDIF
    82|                   ENDDO
                        ENDIF
    83|               ENDDO
                    ENDIF
    84|           ELSE
    85|             lab_1
    88|             IF (.NOT.(1 + (int(kend) - int(kbeg)) > 0)) GOTO lab_64
                    $$CIVA = 0
       Id=4         DO $$CIVA = $$CIVA, int((1 + (int(kend) - int(kbeg))))-1
    89|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV9 = 0
       Id=5             DO $$CIV9 = $$CIV9, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    96|                   IF (.NOT.(1 + (int(iend) - int(ibeg)) > 0)) GOTO &
                &           lab_68
                          $$CIV3 = 0
                          $$PRC8 = d-v1%addr%v1(int(ibeg),$$CIV9 + int(jbeg),&
                &           $$CIVA + int(kbeg))
       Id=6               DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(ibeg))&
                &             ))-1
                            $$PRC9 = d-v1%addr%v1(1 + (int(ibeg) + $$CIV3),&
                &             $$CIV9 + int(jbeg),$$CIVA + int(kbeg))
    97|                     d-dv11%addr%dv11[].rns0.(int(ibeg) + $$CIV3) = (&
                &             $$PRC9 - $$PRC8) * d-dx1ai%addr%dx1ai(int(ibeg) + &
                &             $$CIV3)
    98|                     d-dv22%addr%dv22[].rns3.(int(ibeg) + $$CIV3) = (( &
                &             5.0000000000000000E-001 * ($$PRC9 + $$PRC8)) * &
                &             d-g2bi%addr%g2bi(int(ibeg) + $$CIV3)) * &
                &             d-dg2bd1%addr%dg2bd1(int(ibeg) + $$CIV3)
   101|                     d-dv33%addr%dv33[].rns6.(int(ibeg) + $$CIV3) = (( &
                &             5.0000000000000000E-001 * ($$PRC9 + $$PRC8)) * &
                &             d-g31bi%addr%g31bi(int(ibeg) + $$CIV3)) * &
                &             d-dg31bd1%addr%dg31bd1(int(ibeg) + $$CIV3)
                            $$PRC8 = $$PRC9
   104|                   ENDDO
                        ENDIF
   105|                 IF (.NOT.(ldimen > 1)) GOTO lab_20
   106|                 IF (.NOT.(1 + (int(iend) - int(ibeg)) > 0)) GOTO lab_70
                        $$CIV4 = 0
       Id=7             DO $$CIV4 = $$CIV4, int((1 + (int(iend) - int(ibeg))))&
                &           -1
   107|                   d-dv22%addr%dv22[].rns3.(int(ibeg) + $$CIV4) = &
                &           d-dv22%addr%dv22[].rns3.(int(ibeg) + $$CIV4) + ((&
                &           d-v2%addr%v2(int(ibeg) + $$CIV4,1 + ($$CIV9 + int(&
                &           jbeg)),int(kbeg) + $$CIVA) - d-v2%addr%v2(int(ibeg) + &
                &           $$CIV4,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)) * &
                &           d-dx2ai%addr%dx2ai(int(jbeg) + $$CIV9)) * &
                &           d-g2bi%addr%g2bi(int(ibeg) + $$CIV4)
   110|                   d-dv33%addr%dv33[].rns6.(int(ibeg) + $$CIV4) = (&
                &           d-dv33%addr%dv33[].rns6.(int(ibeg) + $$CIV4) + ((( &
                &           5.0000000000000000E-001 * (d-v2%addr%v2(int(ibeg) + &
                &           $$CIV4,1 + ($$CIV9 + int(jbeg)),int(kbeg) + $$CIVA) + &
                &           d-v2%addr%v2(int(ibeg) + $$CIV4,int(jbeg) + $$CIV9,&
                &           int(kbeg) + $$CIVA))) * d-g32bi%addr%g32bi(int(jbeg) &
                &           + $$CIV9)) * d-g2bi%addr%g2bi(int(ibeg) + $$CIV4)) * &
                &           d-dg32bd2%addr%dg32bd2(int(jbeg) + $$CIV9)) + (((&
                &           d-v3%addr%v3(int(ibeg) + $$CIV4,int(jbeg) + $$CIV9,1 &
                &           + ($$CIVA + int(kbeg))) - d-v3%addr%v3(int(ibeg) + &
                &           $$CIV4,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)) * &
                &           d-dx3ai%addr%dx3ai(int(kbeg) + $$CIVA)) * &
                &           d-g31bi%addr%g31bi(int(ibeg) + $$CIV4)) * &
                &           d-g32bi%addr%g32bi(int(jbeg) + $$CIV9)
   115|                 ENDDO
                        lab_70
   116|                 lab_20
   117|                 IF (.NOT.(1 + (int(iend) - int(ibeg)) > 0)) GOTO lab_72
                        $$CIV5 = 0
       Id=8             DO $$CIV5 = $$CIV5, int((1 + (int(iend) - int(ibeg))))&
                &           -1
   118|                   IF (.NOT.(ldimen > 1)) GOTO lab_26
   119|                   d-dv23%addr%dv23[].rns15.(int(ibeg) + $$CIV5) = ((((&
                &           d-dx2bi%addr%dx2bi(int(jbeg) + $$CIV9) * (&
                &           d-v3%addr%v3(int(ibeg) + $$CIV5,int(jbeg) + $$CIV9,&
                &           int(kbeg) + $$CIVA) - d-v3%addr%v3(int(ibeg) + $$CIV5,&
                &           ($$CIV9 + int(jbeg)) - 1,int(kbeg) + $$CIVA)) + &
                &           d-dx2bi%addr%dx2bi(1 + ($$CIV9 + int(jbeg))) * (&
                &           d-v3%addr%v3(int(ibeg) + $$CIV5,1 + ($$CIV9 + int(&
                &           jbeg)),int(kbeg) + $$CIVA) - d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA))) + &
                &           d-dx2bi%addr%dx2bi(int(jbeg) + $$CIV9) * (&
                &           d-v3%addr%v3(int(ibeg) + $$CIV5,int(jbeg) + $$CIV9,1 &
                &           + ($$CIVA + int(kbeg))) - d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,($$CIV9 + int(jbeg)) - 1,1 + ($$CIVA + int(&
                &           kbeg))))) + d-dx2bi%addr%dx2bi(1 + ($$CIV9 + int(jbeg)&
                &           )) * (d-v3%addr%v3(int(ibeg) + $$CIV5,1 + ($$CIV9 + &
                &           int(jbeg)),1 + ($$CIVA + int(kbeg))) - d-v3%addr%v3(&
                &           int(ibeg) + $$CIV5,int(jbeg) + $$CIV9,1 + ($$CIVA + &
                &           int(kbeg))))) * d-g2bi%addr%g2bi(int(ibeg) + $$CIV5)) &
                &           *  2.5000000000000000E-001
   124|                   GOTO lab_27
   126|                   lab_27
   128|                   d-dv32%addr%dv32[].rns17.(int(ibeg) + $$CIV5) = (((&
                &           d-dx3bi%addr%dx3bi(int(kbeg) + $$CIVA) * (&
                &           d-v2%addr%v2(int(ibeg) + $$CIV5,int(jbeg) + $$CIV9,&
                &           int(kbeg) + $$CIVA) - d-v2%addr%v2(int(ibeg) + $$CIV5,&
                &           int(jbeg) + $$CIV9,($$CIVA + int(kbeg)) - 1)) + &
                &           d-dx3bi%addr%dx3bi(1 + ($$CIVA + int(kbeg))) * (&
                &           d-v2%addr%v2(int(ibeg) + $$CIV5,int(jbeg) + $$CIV9,1 &
                &           + ($$CIVA + int(kbeg))) - d-v2%addr%v2(int(ibeg) + &
                &           $$CIV5,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA))) * &
                &           d-g32ai%addr%g32ai(int(jbeg) + $$CIV9) + (&
                &           d-dx3bi%addr%dx3bi(int(kbeg) + $$CIVA) * (&
                &           d-v2%addr%v2(int(ibeg) + $$CIV5,1 + ($$CIV9 + int(&
                &           jbeg)),int(kbeg) + $$CIVA) - d-v2%addr%v2(int(ibeg) + &
                &           $$CIV5,1 + ($$CIV9 + int(jbeg)),($$CIVA + int(kbeg)) &
                &           - 1)) + d-dx3bi%addr%dx3bi(1 + ($$CIVA + int(kbeg))) &
                &           * (d-v2%addr%v2(int(ibeg) + $$CIV5,1 + ($$CIV9 + int(&
                &           jbeg)),1 + ($$CIVA + int(kbeg))) - d-v2%addr%v2(int(&
                &           ibeg) + $$CIV5,1 + ($$CIV9 + int(jbeg)),int(kbeg) + &
                &           $$CIVA))) * d-g32ai%addr%g32ai(1 + ($$CIV9 + int(jbeg)&
                &           ))) * d-g31bi%addr%g31bi(int(ibeg) + $$CIV5)) *  &
                &           2.5000000000000000E-001 - (((((( &
                &           5.0000000000000000E-001 * (d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &           d-v3%addr%v3(int(ibeg) + $$CIV5,($$CIV9 + int(jbeg)) &
                &           - 1,int(kbeg) + $$CIVA))) * d-g32ai%addr%g32ai(int(&
                &           jbeg) + $$CIV9)) * d-dg32ad2%addr%dg32ad2(int(jbeg) + &
                &           $$CIV9) + (( 5.0000000000000000E-001 * (d-v3%addr%v3(&
                &           int(ibeg) + $$CIV5,1 + ($$CIV9 + int(jbeg)),int(kbeg) &
                &           + $$CIVA) + d-v3%addr%v3(int(ibeg) + $$CIV5,int(jbeg) &
                &           + $$CIV9,int(kbeg) + $$CIVA))) * d-g32ai%addr%g32ai(1 &
                &           + ($$CIV9 + int(jbeg)))) * d-dg32ad2%addr%dg32ad2(1 + &
                &           ($$CIV9 + int(jbeg)))) + (( 5.0000000000000000E-001 * &
                &           (d-v3%addr%v3(int(ibeg) + $$CIV5,int(jbeg) + $$CIV9,1 &
                &           + ($$CIVA + int(kbeg))) + d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,($$CIV9 + int(jbeg)) - 1,1 + ($$CIVA + int(&
                &           kbeg))))) * d-g32ai%addr%g32ai(int(jbeg) + $$CIV9)) * &
                &           d-dg32ad2%addr%dg32ad2(int(jbeg) + $$CIV9)) + (( &
                &           5.0000000000000000E-001 * (d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,1 + ($$CIV9 + int(jbeg)),1 + ($$CIVA + int(&
                &           kbeg))) + d-v3%addr%v3(int(ibeg) + $$CIV5,int(jbeg) + &
                &           $$CIV9,1 + ($$CIVA + int(kbeg))))) * &
                &           d-g32ai%addr%g32ai(1 + ($$CIV9 + int(jbeg)))) * &
                &           d-dg32ad2%addr%dg32ad2(1 + ($$CIV9 + int(jbeg)))) * &
                &           d-g2bi%addr%g2bi(int(ibeg) + $$CIV5)) *  &
                &           2.5000000000000000E-001
   144|                   GOTO lab_29
   124|                   lab_26
   125|                   d-dv23%addr%dv23[].rns15.(int(ibeg) + $$CIV5) =  &
                &           0.0000000000000000E+000
                          GOTO lab_28
   144|                   lab_28
   145|                   d-dv32%addr%dv32[].rns17.(int(ibeg) + $$CIV5) =  &
                &           0.0000000000000000E+000
   146|                   lab_29
   147|                 ENDDO
                      ENDIF
   153|               IF (.NOT.(1 + (int((iend + 1)) - int(ibeg)) > 0)) GOTO &
                &       lab_74
                      $$CIV6 = 0
       Id=9           DO $$CIV6 = $$CIV6, int((1 + (int((iend + 1)) - int(&
                &         ibeg))))-1
   154|                 IF (.NOT.(ldimen > 1)) GOTO lab_34
   155|                 d-dv12%addr%dv12[].rns21.(int(ibeg) + $$CIV6) = ( &
                &         5.0000000000000000E-001 * d-dx1bi%addr%dx1bi(int(ibeg) &
                &         + $$CIV6)) * (((d-v2%addr%v2(int(ibeg) + $$CIV6,int(&
                &         jbeg) + $$CIV9,int(kbeg) + $$CIVA) - d-v2%addr%v2((&
                &         $$CIV6 + int(ibeg)) - 1,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA)) + d-v2%addr%v2(int(ibeg) + $$CIV6,1 + ($$CIV9 &
                &         + int(jbeg)),int(kbeg) + $$CIVA)) - d-v2%addr%v2((&
                &         $$CIV6 + int(ibeg)) - 1,1 + ($$CIV9 + int(jbeg)),int(&
                &         kbeg) + $$CIVA))
   157|                 d-dv13%addr%dv13[].rns23.(int(ibeg) + $$CIV6) = ( &
                &         5.0000000000000000E-001 * d-dx1bi%addr%dx1bi(int(ibeg) &
                &         + $$CIV6)) * (((d-v3%addr%v3(int(ibeg) + $$CIV6,int(&
                &         jbeg) + $$CIV9,int(kbeg) + $$CIVA) - d-v3%addr%v3((&
                &         $$CIV6 + int(ibeg)) - 1,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA)) + d-v3%addr%v3(int(ibeg) + $$CIV6,int(jbeg) + &
                &         $$CIV9,1 + ($$CIVA + int(kbeg)))) - d-v3%addr%v3((&
                &         $$CIV6 + int(ibeg)) - 1,int(jbeg) + $$CIV9,1 + ($$CIVA &
                &         + int(kbeg))))
   159|                 GOTO lab_35
   160|                 d-dv12%addr%dv12[].rns21.(int(ibeg) + $$CIV6) =  &
                &         0.0000000000000000E+000
   161|                 d-dv13%addr%dv13[].rns23.(int(ibeg) + $$CIV6) =  &
                &         0.0000000000000000E+000
   162|               ENDIF
   163|               d-dv21%addr%dv21[].rns24.(int(ibeg) + $$CIV6) = ( &
                &       5.0000000000000000E-001 * (d-dx2bi%addr%dx2bi(int(jbeg) + &
                &       $$CIV9) * (d-v1%addr%v1(int(ibeg) + $$CIV6,int(jbeg) + &
                &       $$CIV9,int(kbeg) + $$CIVA) - d-v1%addr%v1(int(ibeg) + &
                &       $$CIV6,($$CIV9 + int(jbeg)) - 1,int(kbeg) + $$CIVA)) + &
                &       d-dx2bi%addr%dx2bi(1 + ($$CIV9 + int(jbeg))) * (&
                &       d-v1%addr%v1(int(ibeg) + $$CIV6,1 + ($$CIV9 + int(jbeg)),&
                &       int(kbeg) + $$CIVA) - d-v1%addr%v1(int(ibeg) + $$CIV6,int(&
                &       jbeg) + $$CIV9,int(kbeg) + $$CIVA)))) * d-g2ai%addr%g2ai(&
                &       int(ibeg) + $$CIV6)
   166|               d-dv31%addr%dv31[].rns26.(int(ibeg) + $$CIV6) = (( &
                &       5.0000000000000000E-001 * (d-dx3bi%addr%dx3bi(int(kbeg) + &
                &       $$CIVA) * (d-v1%addr%v1(int(ibeg) + $$CIV6,int(jbeg) + &
                &       $$CIV9,int(kbeg) + $$CIVA) - d-v1%addr%v1(int(ibeg) + &
                &       $$CIV6,int(jbeg) + $$CIV9,($$CIVA + int(kbeg)) - 1)) + &
                &       d-dx3bi%addr%dx3bi(1 + ($$CIVA + int(kbeg))) * (&
                &       d-v1%addr%v1(int(ibeg) + $$CIV6,int(jbeg) + $$CIV9,1 + (&
                &       $$CIVA + int(kbeg))) - d-v1%addr%v1(int(ibeg) + $$CIV6,&
                &       int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)))) * &
                &       d-g31ai%addr%g31ai(int(ibeg) + $$CIV6)) * &
                &       d-g32bi%addr%g32bi(int(jbeg) + $$CIV9)
   169|             ENDDO
                  ENDIF
   170|           IF (.NOT.(ldimen > 1)) GOTO lab_39
   171|           IF (.NOT.(1 + (int((iend + 1)) - int(ibeg)) > 0)) GOTO lab_76
                  $$CIV7 = 0
                  $$PRC0 = d-v3%addr%v3(int(ibeg) - 1,$$CIV9 + int(jbeg),1 + (&
                &   $$CIVA + int(kbeg)))
                  $$PRC2 = d-v3%addr%v3(int(ibeg) - 1,$$CIV9 + int(jbeg),$$CIVA &
                &   + int(kbeg))
                  $$PRC4 = d-v2%addr%v2(int(ibeg) - 1,1 + ($$CIV9 + int(jbeg)),&
                &   $$CIVA + int(kbeg))
                  $$PRC6 = d-v2%addr%v2(int(ibeg) - 1,$$CIV9 + int(jbeg),$$CIVA &
                &   + int(kbeg))
       Id=10      DO $$CIV7 = $$CIV7, int((1 + (int((iend + 1)) - int(ibeg))))&
                &     -1
                    $$PRC1 = d-v3%addr%v3(int(ibeg) + $$CIV7,$$CIV9 + int(jbeg),&
                &     1 + ($$CIVA + int(kbeg)))
                    $$PRC3 = d-v3%addr%v3(int(ibeg) + $$CIV7,$$CIV9 + int(jbeg),&
                &     $$CIVA + int(kbeg))
                    $$PRC5 = d-v2%addr%v2(int(ibeg) + $$CIV7,1 + ($$CIV9 + int(&
                &     jbeg)),$$CIVA + int(kbeg))
                    $$PRC7 = d-v2%addr%v2(int(ibeg) + $$CIV7,$$CIV9 + int(jbeg),&
                &     $$CIVA + int(kbeg))
   172|             d-dv21%addr%dv21[].rns24.(int(ibeg) + $$CIV7) = &
                &     d-dv21%addr%dv21[].rns24.(int(ibeg) + $$CIV7) - (( &
                &     2.5000000000000000E-001 * ((($$PRC7 + $$PRC6) + $$PRC5) + &
                &     $$PRC4)) * d-g2ai%addr%g2ai(int(ibeg) + $$CIV7)) * &
                &     d-dg2ad1%addr%dg2ad1(int(ibeg) + $$CIV7)
   176|             d-dv31%addr%dv31[].rns26.(int(ibeg) + $$CIV7) = &
                &     d-dv31%addr%dv31[].rns26.(int(ibeg) + $$CIV7) - (( &
                &     2.5000000000000000E-001 * ((($$PRC3 + $$PRC2) + $$PRC1) + &
                &     $$PRC0)) * d-g31ai%addr%g31ai(int(ibeg) + $$CIV7)) * &
                &     d-dg31ad1%addr%dg31ad1(int(ibeg) + $$CIV7)
                    $$PRC6 = $$PRC7
                    $$PRC4 = $$PRC5
                    $$PRC2 = $$PRC3
                    $$PRC0 = $$PRC1
   180|           ENDDO
                  lab_76
   181|           lab_39
   185|           IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                    $$CIV8 = 0
       Id=11        DO $$CIV8 = $$CIV8, int((1 + (int(iend) - int(ibeg))))-1
   189|               derdx1.rnn0 = (erold(1 + ($$CIV8 + int(ibeg)),int(jbeg) + &
                &       $$CIV9,int(kbeg) + $$CIVA) - erold(($$CIV8 + int(ibeg)) - &
                &       1,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)) / (&
                &       d-dx1b%addr%dx1b(int(ibeg) + $$CIV8) + d-dx1b%addr%dx1b(1 &
                &       + ($$CIV8 + int(ibeg))))
   191|               IF ((ldimen == 1)) THEN
   192|                 derdx2 =  0.0000000000000000E+000
   193|               ELSE
   194|                 derdx2 = ((erold(int(ibeg) + $$CIV8,1 + ($$CIV9 + int(&
                &         jbeg)),int(kbeg) + $$CIVA) - erold(int(ibeg) + $$CIV8,(&
                &         $$CIV9 + int(jbeg)) - 1,int(kbeg) + $$CIVA)) * &
                &         d-g2bi%addr%g2bi(int(ibeg) + $$CIV8)) / (&
                &         d-dx2b%addr%dx2b(int(jbeg) + $$CIV9) + d-dx2b%addr%dx2b(&
                &         1 + ($$CIV9 + int(jbeg))))
   196|               ENDIF
   197|               IF ((ldimen <> 3)) THEN
   212|                 big_r = (_sqrt(%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + &
                &         %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)
   247|                 gvcf(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA) = ((d-dv11%addr%dv11[].rns0.(int(ibeg) + $$CIV8)&
                &          * ( 5.0000000000000000E-001 * ( &
                &         1.0000000000000000E+000 - (( 2.0000000000000000E+000 + (&
                &         _sqrt(%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(&
                &         derdx2) * %VAL(derdx2)) * ( 1.0000000000000000E+000 / (&
                &         d-kapr%addr%kapr(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA) + d-sig%addr%sig(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)))) / max(erold(&
                &         int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA), 1.0000000000000000E-099)) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * ((&
                &         _sqrt(%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(&
                &         derdx2) * %VAL(derdx2)) * ( 1.0000000000000000E+000 / (&
                &         d-kapr%addr%kapr(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA) + d-sig%addr%sig(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)))) / max(erold(&
                &         int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA), 1.0000000000000000E-099))) + ((_sqrt(%VAL(&
                &         derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(&
                &         derdx2)) * ( 1.0000000000000000E+000 / (&
                &         d-kapr%addr%kapr(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA) + d-sig%addr%sig(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)))) / max(erold(&
                &         int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA), 1.0000000000000000E-099)) * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r))) + ( 1.5000000000000000E+000 * ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * ((derdx1.rnn0 / max(_sqrt(&
                &         %VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * &
                &         %VAL(derdx2)), 1.0000000000000000E-099)) * (derdx1.rnn0 &
                &         / max(_sqrt(%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + &
                &         %VAL(derdx2) * %VAL(derdx2)), 1.0000000000000000E-099)))&
                &         ) + d-dv22%addr%dv22[].rns3.(int(ibeg) + $$CIV8) * ( &
                &         5.0000000000000000E-001 * ( 1.0000000000000000E+000 - ((&
                &          2.0000000000000000E+000 + (_sqrt(%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)) / (( 6.0000000000000000E+000 &
                &         +  3.0000000000000000E+000 * ((_sqrt(%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099))) + ((_sqrt(%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)) * ((_sqrt(%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099))) + ((( &
                &         2.0000000000000000E+000 + (_sqrt(%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)) / (( 6.0000000000000000E+000 &
                &         +  3.0000000000000000E+000 * ((_sqrt(%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099))) + ((_sqrt(%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)) * ((_sqrt(%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)))) * (( &
                &         2.0000000000000000E+000 + (_sqrt(%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)) / (( 6.0000000000000000E+000 &
                &         +  3.0000000000000000E+000 * big_r) + big_r * big_r))) &
                &         * (big_r * big_r))) + ( 1.5000000000000000E+000 * ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * ((derdx2 / max(_sqrt(%VAL(&
                &         derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(&
                &         derdx2)), 1.0000000000000000E-099)) * (derdx2 / max(&
                &         _sqrt(%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(&
                &         derdx2) * %VAL(derdx2)), 1.0000000000000000E-099))))) + &
                &         d-dv33%addr%dv33[].rns6.(int(ibeg) + $$CIV8) * ( &
                &         5.0000000000000000E-001 * ( 1.0000000000000000E+000 - ((&
                &          2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r))))) + ((((&
                &         d-dv12%addr%dv12[].rns21.(int(ibeg) + $$CIV8) + &
                &         d-dv12%addr%dv12[].rns21.(1 + ($$CIV8 + int(ibeg)))) + &
                &         d-dv21%addr%dv21[].rns24.(int(ibeg) + $$CIV8)) + &
                &         d-dv21%addr%dv21[].rns24.(1 + ($$CIV8 + int(ibeg)))) *  &
                &         5.0000000000000000E-001) * ((( 1.5000000000000000E+000 &
                &         * ((( 2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * (derdx1.rnn0 / max(_sqrt(&
                &         %VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * &
                &         %VAL(derdx2)), 1.0000000000000000E-099))) * (derdx2 / &
                &         max(_sqrt(%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(&
                &         derdx2) * %VAL(derdx2)), 1.0000000000000000E-099)))
   257|                 deldotv(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) &
                &         + $$CIVA) = (d-dvl1ai%addr%dvl1ai(int(ibeg) + $$CIV8) * &
                &         ((d-g2a%addr%g2a(1 + ($$CIV8 + int(ibeg))) * &
                &         d-g31a%addr%g31a(1 + ($$CIV8 + int(ibeg)))) * &
                &         d-v1%addr%v1(1 + ($$CIV8 + int(ibeg)),int(jbeg) + &
                &         $$CIV9,int(kbeg) + $$CIVA) - (d-g2a%addr%g2a(int(ibeg) &
                &         + $$CIV8) * d-g31a%addr%g31a(int(ibeg) + $$CIV8)) * &
                &         d-v1%addr%v1(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(&
                &         kbeg) + $$CIVA)) + (d-g2bi%addr%g2bi(int(ibeg) + $$CIV8)&
                &          * d-dvl2ai%addr%dvl2ai(int(jbeg) + $$CIV9)) * (&
                &         d-g32a%addr%g32a(1 + ($$CIV9 + int(jbeg))) * &
                &         d-v2%addr%v2(int(ibeg) + $$CIV8,1 + ($$CIV9 + int(jbeg))&
                &         ,int(kbeg) + $$CIVA) - d-g32a%addr%g32a(int(jbeg) + &
                &         $$CIV9) * d-v2%addr%v2(int(ibeg) + $$CIV8,int(jbeg) + &
                &         $$CIV9,int(kbeg) + $$CIVA))) + ((d-g31bi%addr%g31bi(int(&
                &         ibeg) + $$CIV8) * d-g32bi%addr%g32bi(int(jbeg) + $$CIV9)&
                &         ) * d-dvl3ai%addr%dvl3ai(int(kbeg) + $$CIVA)) * (&
                &         d-v3%addr%v3(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,1 + (&
                &         $$CIVA + int(kbeg))) - d-v3%addr%v3(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA))
                      ELSE
   200|                 derdx3 = (((erold(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         1 + ($$CIVA + int(kbeg))) - erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,($$CIVA + int(kbeg)) - 1)) * &
                &         d-g31bi%addr%g31bi(int(ibeg) + $$CIV8)) * &
                &         d-g32bi%addr%g32bi(int(ibeg) + $$CIV8)) / (&
                &         d-dx3b%addr%dx3b(int(kbeg) + $$CIVA) + d-dx3b%addr%dx3b(&
                &         1 + ($$CIVA + int(kbeg))))
   212|                 big_r = (_sqrt((%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + &
                &         %VAL(derdx2) * %VAL(derdx2)) + %VAL(derdx3) * %VAL(&
                &         derdx3)) * ( 1.0000000000000000E+000 / (&
                &         d-kapr%addr%kapr(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA) + d-sig%addr%sig(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)))) / max(erold(&
                &         int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA), 1.0000000000000000E-099)
   247|                 gvcf(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA) = ((((d-dv11%addr%dv11[].rns0.(int(ibeg) + &
                &         $$CIV8) * ( 5.0000000000000000E-001 * ( &
                &         1.0000000000000000E+000 - (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r))) + ( 1.5000000000000000E+000 * ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * ((derdx1.rnn0 / max(_sqrt((&
                &         %VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * &
                &         %VAL(derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099)) * (derdx1.rnn0 / max(_sqrt((&
                &         %VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * &
                &         %VAL(derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099)))) + d-dv22%addr%dv22[].rns3.(&
                &         int(ibeg) + $$CIV8) * ( 5.0000000000000000E-001 * ( &
                &         1.0000000000000000E+000 - (( 2.0000000000000000E+000 + (&
                &         _sqrt((%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(&
                &         derdx2) * %VAL(derdx2)) + %VAL(derdx3) * %VAL(derdx3)) &
                &         * ( 1.0000000000000000E+000 / (d-kapr%addr%kapr(int(&
                &         ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)) / (( 6.0000000000000000E+000 &
                &         +  3.0000000000000000E+000 * ((_sqrt((%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + &
                &         %VAL(derdx3) * %VAL(derdx3)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099))) + ((_sqrt((%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + &
                &         %VAL(derdx3) * %VAL(derdx3)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)) * ((_sqrt((%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + &
                &         %VAL(derdx3) * %VAL(derdx3)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099))) + ((( &
                &         2.0000000000000000E+000 + (_sqrt((%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + %VAL(&
                &         derdx3) * %VAL(derdx3)) * ( 1.0000000000000000E+000 / (&
                &         d-kapr%addr%kapr(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA) + d-sig%addr%sig(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)))) / max(erold(&
                &         int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA), 1.0000000000000000E-099)) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * ((&
                &         _sqrt((%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(&
                &         derdx2) * %VAL(derdx2)) + %VAL(derdx3) * %VAL(derdx3)) &
                &         * ( 1.0000000000000000E+000 / (d-kapr%addr%kapr(int(&
                &         ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099))) + ((_sqrt((%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + &
                &         %VAL(derdx3) * %VAL(derdx3)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)) * ((_sqrt((%VAL(derdx1.rnn0) &
                &         * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + &
                &         %VAL(derdx3) * %VAL(derdx3)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr(int(ibeg) + &
                &         $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + $$CIVA) + &
                &         d-sig%addr%sig(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA)))) / max(erold(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA), &
                &         1.0000000000000000E-099)))) * (( &
                &         2.0000000000000000E+000 + (_sqrt((%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + %VAL(&
                &         derdx3) * %VAL(derdx3)) * ( 1.0000000000000000E+000 / (&
                &         d-kapr%addr%kapr(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,&
                &         int(kbeg) + $$CIVA) + d-sig%addr%sig(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA)))) / max(erold(&
                &         int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) + &
                &         $$CIVA), 1.0000000000000000E-099)) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r))) + ( &
                &         1.5000000000000000E+000 * ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r)) -  3.3333333333333331E-001)) * ((derdx2 &
                &         / max(_sqrt((%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + &
                &         %VAL(derdx2) * %VAL(derdx2)) + %VAL(derdx3) * %VAL(&
                &         derdx3)), 1.0000000000000000E-099)) * (derdx2 / max(&
                &         _sqrt((%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(&
                &         derdx2) * %VAL(derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099))))) + d-dv33%addr%dv33[].rns6.(&
                &         int(ibeg) + $$CIV8) * ( 5.0000000000000000E-001 * ( &
                &         1.0000000000000000E+000 - (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r))) + ( 1.5000000000000000E+000 * ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * ((derdx3 / max(_sqrt((%VAL(&
                &         derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(&
                &         derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099)) * (derdx3 / max(_sqrt((%VAL(&
                &         derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(&
                &         derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099))))) + ((((&
                &         d-dv12%addr%dv12[].rns21.(int(ibeg) + $$CIV8) + &
                &         d-dv12%addr%dv12[].rns21.(1 + ($$CIV8 + int(ibeg)))) + &
                &         d-dv21%addr%dv21[].rns24.(int(ibeg) + $$CIV8)) + &
                &         d-dv21%addr%dv21[].rns24.(1 + ($$CIV8 + int(ibeg)))) *  &
                &         5.0000000000000000E-001) * ((( 1.5000000000000000E+000 &
                &         * ((( 2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * (derdx1.rnn0 / max(_sqrt((&
                &         %VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * &
                &         %VAL(derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099))) * (derdx2 / max(_sqrt((%VAL(&
                &         derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(&
                &         derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099)))) + ((((&
                &         d-dv13%addr%dv13[].rns23.(int(ibeg) + $$CIV8) + &
                &         d-dv13%addr%dv13[].rns23.(1 + ($$CIV8 + int(ibeg)))) + &
                &         d-dv31%addr%dv31[].rns26.(int(ibeg) + $$CIV8)) + &
                &         d-dv31%addr%dv31[].rns26.(1 + ($$CIV8 + int(ibeg)))) *  &
                &         5.0000000000000000E-001) * ((( 1.5000000000000000E+000 &
                &         * ((( 2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * (derdx1.rnn0 / max(_sqrt((&
                &         %VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * &
                &         %VAL(derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099))) * (derdx3 / max(_sqrt((%VAL(&
                &         derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(&
                &         derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099)))) + (&
                &         d-dv23%addr%dv23[].rns15.(int(ibeg) + $$CIV8) + &
                &         d-dv32%addr%dv32[].rns17.(int(ibeg) + $$CIV8)) * ((( &
                &         1.5000000000000000E+000 * ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r)) -  3.3333333333333331E-001)) * (derdx2 &
                &         / max(_sqrt((%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + &
                &         %VAL(derdx2) * %VAL(derdx2)) + %VAL(derdx3) * %VAL(&
                &         derdx3)), 1.0000000000000000E-099))) * (derdx3 / max(&
                &         _sqrt((%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + %VAL(&
                &         derdx2) * %VAL(derdx2)) + %VAL(derdx3) * %VAL(derdx3)), &
                &         1.0000000000000000E-099)))
   257|                 deldotv(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(kbeg) &
                &         + $$CIVA) = (d-dvl1ai%addr%dvl1ai(int(ibeg) + $$CIV8) * &
                &         ((d-g2a%addr%g2a(1 + ($$CIV8 + int(ibeg))) * &
                &         d-g31a%addr%g31a(1 + ($$CIV8 + int(ibeg)))) * &
                &         d-v1%addr%v1(1 + ($$CIV8 + int(ibeg)),int(jbeg) + &
                &         $$CIV9,int(kbeg) + $$CIVA) - (d-g2a%addr%g2a(int(ibeg) &
                &         + $$CIV8) * d-g31a%addr%g31a(int(ibeg) + $$CIV8)) * &
                &         d-v1%addr%v1(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,int(&
                &         kbeg) + $$CIVA)) + (d-g2bi%addr%g2bi(int(ibeg) + $$CIV8)&
                &          * d-dvl2ai%addr%dvl2ai(int(jbeg) + $$CIV9)) * (&
                &         d-g32a%addr%g32a(1 + ($$CIV9 + int(jbeg))) * &
                &         d-v2%addr%v2(int(ibeg) + $$CIV8,1 + ($$CIV9 + int(jbeg))&
                &         ,int(kbeg) + $$CIVA) - d-g32a%addr%g32a(int(jbeg) + &
                &         $$CIV9) * d-v2%addr%v2(int(ibeg) + $$CIV8,int(jbeg) + &
                &         $$CIV9,int(kbeg) + $$CIVA))) + ((d-g31bi%addr%g31bi(int(&
                &         ibeg) + $$CIV8) * d-g32bi%addr%g32bi(int(jbeg) + $$CIV9)&
                &         ) * d-dvl3ai%addr%dvl3ai(int(kbeg) + $$CIVA)) * (&
                &         d-v3%addr%v3(int(ibeg) + $$CIV8,int(jbeg) + $$CIV9,1 + (&
                &         $$CIVA + int(kbeg))) - d-v3%addr%v3(int(ibeg) + $$CIV8,&
                &         int(jbeg) + $$CIV9,int(kbeg) + $$CIVA))
                      ENDIF
   266|             ENDDO
                  ENDIF
   267|         ENDDO
              ENDIF
   268|       ENDDO
                lab_64
   271|         lab_80
                RETURN
              END SUBROUTINE grdv


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0            76            15    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            77            16    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            78            17    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            80                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            76             1    Outer loop has been unrolled 4 time(s).
         0            76             1    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            77             2    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            78             3    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            80                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            80                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            80                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            79                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            80                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            88             4    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            89             5    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            96             6    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0            97                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dv11%addr  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV3))  with 
                                          non-vectorizable alignment.
         0            97                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-v1%addr  + 
                                          d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + 
                                          $$CIVA][(long long) .jbeg->jbeg + $$CIV9][1ll + 
                                          ($$CIV3 + (long long) .ibeg->ibeg)] - ((double 
                                          *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long 
                                          long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + 
                                          $$CIV9][(long long) .ibeg->ibeg + $$CIV3]) * ((double 
                                          *)((char *)d-dx1ai%addr  + 
                                          d-dx1ai%rvo))->dx1ai[].rns1.[(long long) .ibeg->ibeg 
                                          + $$CIV3] which is not  suitable for SIMD 
                                          vectorization.
         0            97                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg 
                                          + $$CIVA) + (d-v1%bounds%mult[].off488)*((long long) 
                                          .jbeg->jbeg + $$CIV9) + 
                                          (d-v1%bounds%mult[].off512)*(1ll + ($$CIV3 + (long 
                                          long) .ibeg->ibeg))) with  non-vectorizable strides.
         0            97                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            98                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dv22%addr  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV3))  with 
                                          non-vectorizable alignment.
         0            98                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 5.0000000000000000E-001 * (((double 
                                          *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long 
                                          long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + 
                                          $$CIV9][1ll + ($$CIV3 + (long long) .ibeg->ibeg)] + 
                                          ((double *)((char *)d-v1%addr  + 
                                          d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + 
                                          $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) 
                                          .ibeg->ibeg + $$CIV3])) * ((double *)((char 
                                          *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long 
                                          long) .ibeg->ibeg + $$CIV3]) * ((double *)((char 
                                          *)d-dg2bd1%addr  + 
                                          d-dg2bd1%rvo))->dg2bd1[].rns4.[(long long) 
                                          .ibeg->ibeg + $$CIV3] which is not  suitable for SIMD 
                                          vectorization.
         0            98                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg 
                                          + $$CIVA) + (d-v1%bounds%mult[].off488)*((long long) 
                                          .jbeg->jbeg + $$CIV9) + 
                                          (d-v1%bounds%mult[].off512)*(1ll + ($$CIV3 + (long 
                                          long) .ibeg->ibeg))) with  non-vectorizable strides.
         0            98                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           101                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dv33%addr  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV3))  with 
                                          non-vectorizable alignment.
         0           101                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 5.0000000000000000E-001 * (((double 
                                          *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long 
                                          long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + 
                                          $$CIV9][1ll + ($$CIV3 + (long long) .ibeg->ibeg)] + 
                                          ((double *)((char *)d-v1%addr  + 
                                          d-v1%rvo))->v1[].rns2.[(long long) .kbeg->kbeg + 
                                          $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) 
                                          .ibeg->ibeg + $$CIV3])) * ((double *)((char 
                                          *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns8.[(long 
                                          long) .ibeg->ibeg + $$CIV3]) * ((double *)((char 
                                          *)d-dg31bd1%addr  + 
                                          d-dg31bd1%rvo))->dg31bd1[].rns7.[(long long) 
                                          .ibeg->ibeg + $$CIV3] which is not  suitable for SIMD 
                                          vectorization.
         0           101                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg 
                                          + $$CIVA) + (d-v1%bounds%mult[].off488)*((long long) 
                                          .jbeg->jbeg + $$CIV9) + 
                                          (d-v1%bounds%mult[].off512)*(1ll + ($$CIV3 + (long 
                                          long) .ibeg->ibeg))) with  non-vectorizable strides.
         0           101                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           106             7    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0           107                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dv22%addr  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV4))  with 
                                          non-vectorizable alignment.
         0           107                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *)d-dv22%addr  + 
                                          -8ll))->dv22[].rns3.[(long long) .ibeg->ibeg + 
                                          $$CIV4] + ((((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + 
                                          $$CIVA][1ll + ($$CIV9 + (long long) 
                                          .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV4] - 
                                          ((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + 
                                          $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) 
                                          .ibeg->ibeg + $$CIV4]) * ((double *)((char 
                                          *)d-dx2ai%addr  + d-dx2ai%rvo))->dx2ai[].rns9.[(long 
                                          long) .jbeg->jbeg + $$CIV9]) * ((double *)((char 
                                          *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long 
                                          long) .ibeg->ibeg + $$CIV4] which is not  suitable 
                                          for SIMD vectorization.
         0           107                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg 
                                          + $$CIVA) + (d-v2%bounds%mult[].off592)*(1ll + 
                                          ($$CIV9 + (long long) .jbeg->jbeg)) + 
                                          (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg 
                                          + $$CIV4)) with  non-vectorizable strides.
         0           107                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           110                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dv33%addr  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV4))  with 
                                          non-vectorizable alignment.
         0           110                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-dv33%addr  + 
                                          -8ll))->dv33[].rns6.[(long long) .ibeg->ibeg + 
                                          $$CIV4] + ((( 5.0000000000000000E-001 * (((double 
                                          *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long 
                                          long) .kbeg->kbeg + $$CIVA][1ll + ($$CIV9 + (long 
                                          long) .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV4] 
                                          + ((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + 
                                          $$CIVA][(long long) .jbeg->jbeg + $$CIV9][(long long) 
                                          .ibeg->ibeg + $$CIV4])) * ((double *)((char 
                                          *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns11.[(long 
                                          long) .jbeg->jbeg + $$CIV9]) * ((double *)((char 
                                          *)d-g2bi%addr  + d-g2bi%rvo))->g2bi[].rns5.[(long 
                                          long) .ibeg->ibeg + $$CIV4]) * ((double *)((char 
                                          *)d-dg32bd2%addr  + 
                                          d-dg32bd2%rvo))->dg32bd2[].rns14.[(long long) 
                                          .jbeg->jbeg + $$CIV9]) + (((((double *)((char 
                                          *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA 
                                          + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + 
                                          $$CIV9][(long long) .ibeg->ibeg + $$CIV4] - ((double 
                                          *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long 
                                          long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + 
                                          $$CIV9][(long long) .ibeg->ibeg + $$CIV4]) * ((double 
                                          *)((char *)d-dx3ai%addr  + 
                                          d-dx3ai%rvo))->dx3ai[].rns12.[(long long) .kbeg->kbeg 
                                          + $$CIVA]) * ((double *)((char *)d-g31bi%addr  + 
                                          d-g31bi%rvo))->g31bi[].rns8.[(long long) .ibeg->ibeg 
                                          + $$CIV4]) * ((double *)((char *)d-g32bi%addr  + 
                                          d-g32bi%rvo))->g32bi[].rns11.[(long long) .jbeg->jbeg 
                                          + $$CIV9] which is not  suitable for SIMD 
                                          vectorization.
         0           110                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg 
                                          + $$CIVA) + (d-v2%bounds%mult[].off592)*(1ll + 
                                          ($$CIV9 + (long long) .jbeg->jbeg)) + 
                                          (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg 
                                          + $$CIV4)) with  non-vectorizable strides.
         0           110                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           117             8    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           117             8    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           153             9    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           153             9    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           171            10    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0           172                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dv21%addr  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV7))  with 
                                          non-vectorizable alignment.
         0           172                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *)d-dv21%addr  + 
                                          -8ll))->dv21[].rns24.[(long long) .ibeg->ibeg + 
                                          $$CIV7] - (( 2.5000000000000000E-001 * (((((double 
                                          *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long 
                                          long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + 
                                          $$CIV9][(long long) .ibeg->ibeg + $$CIV7] + ((double 
                                          *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns10.[(long 
                                          long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + 
                                          $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll]) + 
                                          ((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + 
                                          $$CIVA][1ll + ($$CIV9 + (long long) 
                                          .jbeg->jbeg)][(long long) .ibeg->ibeg + $$CIV7]) + 
                                          ((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns10.[(long long) .kbeg->kbeg + 
                                          $$CIVA][1ll + ($$CIV9 + (long long) 
                                          .jbeg->jbeg)][($$CIV7 + (long long) .ibeg->ibeg) - 
                                          1ll])) * ((double *)((char *)d-g2ai%addr  + 
                                          d-g2ai%rvo))->g2ai[].rns25.[(long long) .ibeg->ibeg + 
                                          $$CIV7]) * ((double *)((char *)d-dg2ad1%addr  + 
                                          d-dg2ad1%rvo))->dg2ad1[].rns28.[(long long) 
                                          .ibeg->ibeg + $$CIV7] which is not  suitable for SIMD 
                                          vectorization.
         0           172                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg 
                                          + $$CIVA) + (d-v2%bounds%mult[].off592)*((long long) 
                                          .jbeg->jbeg + $$CIV9) + 
                                          (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg 
                                          + $$CIV7)) with  non-vectorizable strides.
         0           172                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           176                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dv31%addr  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV7))  with 
                                          non-vectorizable alignment.
         0           176                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *)d-dv31%addr  + 
                                          -8ll))->dv31[].rns26.[(long long) .ibeg->ibeg + 
                                          $$CIV7] - (( 2.5000000000000000E-001 * (((((double 
                                          *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long 
                                          long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + 
                                          $$CIV9][(long long) .ibeg->ibeg + $$CIV7] + ((double 
                                          *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[(long 
                                          long) .kbeg->kbeg + $$CIVA][(long long) .jbeg->jbeg + 
                                          $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll]) + 
                                          ((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV9][(long 
                                          long) .ibeg->ibeg + $$CIV7]) + ((double *)((char 
                                          *)d-v3%addr  + d-v3%rvo))->v3[].rns13.[1ll + ($$CIVA 
                                          + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + 
                                          $$CIV9][($$CIV7 + (long long) .ibeg->ibeg) - 1ll])) * 
                                          ((double *)((char *)d-g31ai%addr  + 
                                          d-g31ai%rvo))->g31ai[].rns27.[(long long) .ibeg->ibeg 
                                          + $$CIV7]) * ((double *)((char *)d-dg31ad1%addr  + 
                                          d-dg31ad1%rvo))->dg31ad1[].rns29.[(long long) 
                                          .ibeg->ibeg + $$CIV7] which is not  suitable for SIMD 
                                          vectorization.
         0           176                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg 
                                          + $$CIVA) + (d-v3%bounds%mult[].off696)*((long long) 
                                          .jbeg->jbeg + $$CIV9) + 
                                          (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg 
                                          + $$CIV7)) with  non-vectorizable strides.
         0           176                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           185            11    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           185            11    Loop was not SIMD vectorized because it contains 
                                          control flow.


    10|         SUBROUTINE grdv (ibeg, iend, jbeg, jend, kbeg, kend, erold, gvcf, deldotv)
    10|           d-dv11%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv12%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv13%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv21%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv22%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv23%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv31%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv32%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  d-dv33%addr = _alloca(max(int(%VAL(in)),0) * 8)
                  _alloca(8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0))))
    75|           IF ((0 <> ((xhydro  .XOR.  1)  .AND.  1))) THEN
    76|             IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &     int(kend) - int(kbeg)) > 0)) THEN
                      $$CIV2 = 0
       Id=15          DO $$CIV2 = $$CIV2, MOD((1 + (int(kend) - int(kbeg))), &
                &         int(4))-1
    77|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV1 = 0
       Id=16              DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    78|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV0 = 0
       Id=17                  DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(&
                &                 kbeg) + $$CIV2) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,&
                &                 int(kbeg) + $$CIV2) =  0.0000000000000000E+000
    81|                       ENDDO
                            ENDIF
    82|                   ENDDO
                        ENDIF
    83|               ENDDO
                    ENDIF
    76|             IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) &
                &     - int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                      $$CIVB = int(0)
       Id=1           DO $$CIVB = $$CIVB, int(((int(kend) - (MOD((1 + (int(&
                &         kend) - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    77|                 IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                          $$CIV1 = 0
       Id=2               DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))&
                &             ))-1
    78|                     IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                              $$CIV0 = 0
       Id=3                   DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &                 ibeg))))-1
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,(&
                &                 $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &                 4)) + int(kbeg)) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,(&
                &                 $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), &
                &                 4)) + int(kbeg)) =  0.0000000000000000E+000
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + (&
                &                 ($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 &
                &                 + (($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg)&
                &                 )), 4)) + int(kbeg))) =  &
                &                 0.0000000000000000E+000
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + (&
                &                 ($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 &
                &                 + (($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg)&
                &                 )), 4)) + int(kbeg))) =  &
                &                 0.0000000000000000E+000
    79|                         gvcf(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + (&
                &                 ($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))),&
                &                  4)) + int(kbeg))) =  0.0000000000000000E+000
    80|                         deldotv(int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 &
                &                 + (($$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg)&
                &                 )), 4)) + int(kbeg))) =  &
                &                 0.0000000000000000E+000
    81|                       ENDDO
                            ENDIF
    82|                   ENDDO
                        ENDIF
    83|               ENDDO
                    ENDIF
    84|           ELSE
    85|             lab_1
    88|             IF (.NOT.(1 + (int(kend) - int(kbeg)) > 0)) GOTO lab_64
                    $$CIVA = 0
       Id=4         DO $$CIVA = $$CIVA, int((1 + (int(kend) - int(kbeg))))-1
    89|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV9 = 0
       Id=5             DO $$CIV9 = $$CIV9, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    96|                   IF (.NOT.(1 + (int(iend) - int(ibeg)) > 0)) GOTO &
                &           lab_68
                          $$CIV3 = 0
                          $$PRC8 = d-v1%addr%v1(int(ibeg),$$CIV9 + int(jbeg),&
                &           $$CIVA + int(kbeg))
       Id=6               DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(ibeg))&
                &             ))-1
                            $$PRC9 = d-v1%addr%v1(1 + (int(ibeg) + $$CIV3),&
                &             $$CIV9 + int(jbeg),$$CIVA + int(kbeg))
    97|                     d-dv11%addr%dv11[].rns0.(int(ibeg) + $$CIV3) = (&
                &             $$PRC9 - $$PRC8) * d-dx1ai%addr%dx1ai(int(ibeg) + &
                &             $$CIV3)
    98|                     d-dv22%addr%dv22[].rns3.(int(ibeg) + $$CIV3) = (( &
                &             5.0000000000000000E-001 * ($$PRC9 + $$PRC8)) * &
                &             d-g2bi%addr%g2bi(int(ibeg) + $$CIV3)) * &
                &             d-dg2bd1%addr%dg2bd1(int(ibeg) + $$CIV3)
   101|                     d-dv33%addr%dv33[].rns6.(int(ibeg) + $$CIV3) = (( &
                &             5.0000000000000000E-001 * ($$PRC9 + $$PRC8)) * &
                &             d-g31bi%addr%g31bi(int(ibeg) + $$CIV3)) * &
                &             d-dg31bd1%addr%dg31bd1(int(ibeg) + $$CIV3)
                            $$PRC8 = $$PRC9
   104|                   ENDDO
                        ENDIF
   105|                 IF (.NOT.(ldimen > 1)) GOTO lab_20
   106|                 IF (.NOT.(1 + (int(iend) - int(ibeg)) > 0)) GOTO lab_70
                        $$CIV4 = 0
   107|                 $$ICM0 = $$CIV9 + int(jbeg)
                        $$csx0 = int(jbeg) + $$CIV9
                        $$ICM1 = d-dx2ai%addr%dx2ai($$csx0)
                        $$csx1 = int(kbeg) + $$CIVA
   110|                 $$ICM2 = d-g32bi%addr%g32bi($$csx0)
                        $$ICM3 = d-dg32bd2%addr%dg32bd2($$csx0)
   106|Id=7             DO $$CIV4 = $$CIV4, int((1 + (int(iend) - int(ibeg))))&
                &           -1
   107|                   d-dv22%addr%dv22[].rns3.(int(ibeg) + $$CIV4) = &
                &           d-dv22%addr%dv22[].rns3.(int(ibeg) + $$CIV4) + ((&
                &           d-v2%addr%v2(int(ibeg) + $$CIV4,1 + $$csx0,$$csx1) - &
                &           d-v2%addr%v2(int(ibeg) + $$CIV4,$$ICM0,$$csx1)) * &
                &           $$ICM1) * d-g2bi%addr%g2bi(int(ibeg) + $$CIV4)
   110|                   d-dv33%addr%dv33[].rns6.(int(ibeg) + $$CIV4) = (&
                &           d-dv33%addr%dv33[].rns6.(int(ibeg) + $$CIV4) + ((( &
                &           5.0000000000000000E-001 * (d-v2%addr%v2(int(ibeg) + &
                &           $$CIV4,1 + $$csx0,$$csx1) + d-v2%addr%v2(int(ibeg) + &
                &           $$CIV4,$$ICM0,$$csx1))) * $$ICM2) * d-g2bi%addr%g2bi(&
                &           int(ibeg) + $$CIV4)) * $$ICM3) + (((d-v3%addr%v3(int(&
                &           ibeg) + $$CIV4,$$ICM0,1 + $$csx1) - d-v3%addr%v3(int(&
                &           ibeg) + $$CIV4,$$ICM0,$$csx1)) * d-dx3ai%addr%dx3ai(&
                &           $$csx1)) * d-g31bi%addr%g31bi(int(ibeg) + $$CIV4)) * &
                &           $$ICM2
   115|                 ENDDO
                        lab_70
   116|                 lab_20
   117|                 IF (.NOT.(1 + (int(iend) - int(ibeg)) > 0)) GOTO lab_72
                        $$CIV5 = 0
       Id=8             DO $$CIV5 = $$CIV5, int((1 + (int(iend) - int(ibeg))))&
                &           -1
   118|                   IF (.NOT.(ldimen > 1)) GOTO lab_26
   119|                   $$csx2 = int(jbeg) + $$CIV9
                          $$csx3 = $$CIVA + int(kbeg)
                          d-dv23%addr%dv23[].rns15.(int(ibeg) + $$CIV5) = ((((&
                &           d-dx2bi%addr%dx2bi($$csx2) * (d-v3%addr%v3(int(ibeg) &
                &           + $$CIV5,$$csx2,$$csx3) - d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,$$csx2 - 1,$$csx3)) + d-dx2bi%addr%dx2bi(1 + &
                &           $$csx2) * (d-v3%addr%v3(int(ibeg) + $$CIV5,1 + $$csx2,&
                &           $$csx3) - d-v3%addr%v3(int(ibeg) + $$CIV5,$$csx2,&
                &           $$csx3))) + d-dx2bi%addr%dx2bi($$csx2) * (&
                &           d-v3%addr%v3(int(ibeg) + $$CIV5,$$csx2,1 + $$csx3) - &
                &           d-v3%addr%v3(int(ibeg) + $$CIV5,$$csx2 - 1,1 + $$csx3)&
                &           )) + d-dx2bi%addr%dx2bi(1 + $$csx2) * (d-v3%addr%v3(&
                &           int(ibeg) + $$CIV5,1 + $$csx2,1 + $$csx3) - &
                &           d-v3%addr%v3(int(ibeg) + $$CIV5,$$csx2,1 + $$csx3))) &
                &           * d-g2bi%addr%g2bi(int(ibeg) + $$CIV5)) *  &
                &           2.5000000000000000E-001
   124|                   GOTO lab_27
   126|                   lab_27
   128|                   d-dv32%addr%dv32[].rns17.(int(ibeg) + $$CIV5) = (((&
                &           d-dx3bi%addr%dx3bi($$csx3) * (d-v2%addr%v2(int(ibeg) &
                &           + $$CIV5,$$csx2,$$csx3) - d-v2%addr%v2(int(ibeg) + &
                &           $$CIV5,$$csx2,$$csx3 - 1)) + d-dx3bi%addr%dx3bi(1 + &
                &           $$csx3) * (d-v2%addr%v2(int(ibeg) + $$CIV5,$$csx2,1 + &
                &           $$csx3) - d-v2%addr%v2(int(ibeg) + $$CIV5,$$csx2,&
                &           $$csx3))) * d-g32ai%addr%g32ai($$csx2) + (&
                &           d-dx3bi%addr%dx3bi($$csx3) * (d-v2%addr%v2(int(ibeg) &
                &           + $$CIV5,1 + $$csx2,$$csx3) - d-v2%addr%v2(int(ibeg) &
                &           + $$CIV5,1 + $$csx2,$$csx3 - 1)) + d-dx3bi%addr%dx3bi(&
                &           1 + $$csx3) * (d-v2%addr%v2(int(ibeg) + $$CIV5,1 + &
                &           $$csx2,1 + $$csx3) - d-v2%addr%v2(int(ibeg) + $$CIV5,&
                &           1 + $$csx2,$$csx3))) * d-g32ai%addr%g32ai(1 + $$csx2))&
                &            * d-g31bi%addr%g31bi(int(ibeg) + $$CIV5)) *  &
                &           2.5000000000000000E-001 - (((((( &
                &           5.0000000000000000E-001 * (d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,$$csx2,$$csx3) + d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,$$csx2 - 1,$$csx3))) * d-g32ai%addr%g32ai(&
                &           $$csx2)) * d-dg32ad2%addr%dg32ad2($$csx2) + (( &
                &           5.0000000000000000E-001 * (d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,1 + $$csx2,$$csx3) + d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,$$csx2,$$csx3))) * d-g32ai%addr%g32ai(1 + &
                &           $$csx2)) * d-dg32ad2%addr%dg32ad2(1 + $$csx2)) + (( &
                &           5.0000000000000000E-001 * (d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,$$csx2,1 + $$csx3) + d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,$$csx2 - 1,1 + $$csx3))) * d-g32ai%addr%g32ai(&
                &           $$csx2)) * d-dg32ad2%addr%dg32ad2($$csx2)) + (( &
                &           5.0000000000000000E-001 * (d-v3%addr%v3(int(ibeg) + &
                &           $$CIV5,1 + $$csx2,1 + $$csx3) + d-v3%addr%v3(int(ibeg)&
                &            + $$CIV5,$$csx2,1 + $$csx3))) * d-g32ai%addr%g32ai(1 &
                &           + $$csx2)) * d-dg32ad2%addr%dg32ad2(1 + $$csx2)) * &
                &           d-g2bi%addr%g2bi(int(ibeg) + $$CIV5)) *  &
                &           2.5000000000000000E-001
   144|                   GOTO lab_29
   124|                   lab_26
   125|                   d-dv23%addr%dv23[].rns15.(int(ibeg) + $$CIV5) =  &
                &           0.0000000000000000E+000
                          GOTO lab_28
   144|                   lab_28
   145|                   d-dv32%addr%dv32[].rns17.(int(ibeg) + $$CIV5) =  &
                &           0.0000000000000000E+000
   146|                   lab_29
   147|                 ENDDO
                      ENDIF
   153|               IF (.NOT.(1 + (int((iend + 1)) - int(ibeg)) > 0)) GOTO &
                &       lab_74
                      $$CIV6 = 0
   155|               $$ICM0 = int(jbeg) + $$CIV9
                      $$ICM4 = 1 + ($$CIV9 + int(jbeg))
                      $$ICM5 = int(kbeg) + $$CIVA
   157|               $$ICM6 = 1 + ($$CIVA + int(kbeg))
   163|               $$ICM7 = d-dx2bi%addr%dx2bi(1 + ($$CIV9 + int(jbeg)))
                      $$ICM8 = d-dx2bi%addr%dx2bi(int(jbeg) + $$CIV9)
   166|               $$ICM2 = d-g32bi%addr%g32bi(int(jbeg) + $$CIV9)
                      $$ICM9 = d-dx3bi%addr%dx3bi(1 + ($$CIVA + int(kbeg)))
                      $$ICMA = d-dx3bi%addr%dx3bi(int(kbeg) + $$CIVA)
   153|Id=9           DO $$CIV6 = $$CIV6, int((1 + (int((iend + 1)) - int(&
                &         ibeg))))-1
   154|                 IF (.NOT.(ldimen > 1)) GOTO lab_34
   155|                 d-dv12%addr%dv12[].rns21.(int(ibeg) + $$CIV6) = ( &
                &         5.0000000000000000E-001 * d-dx1bi%addr%dx1bi(int(ibeg) &
                &         + $$CIV6)) * (((d-v2%addr%v2(int(ibeg) + $$CIV6,$$ICM0,&
                &         $$ICM5) - d-v2%addr%v2(($$CIV6 + int(ibeg)) - 1,$$ICM0,&
                &         $$ICM5)) + d-v2%addr%v2(int(ibeg) + $$CIV6,$$ICM4,&
                &         $$ICM5)) - d-v2%addr%v2(($$CIV6 + int(ibeg)) - 1,$$ICM4,&
                &         $$ICM5))
   157|                 d-dv13%addr%dv13[].rns23.(int(ibeg) + $$CIV6) = ( &
                &         5.0000000000000000E-001 * d-dx1bi%addr%dx1bi(int(ibeg) &
                &         + $$CIV6)) * (((d-v3%addr%v3(int(ibeg) + $$CIV6,$$ICM0,&
                &         $$ICM5) - d-v3%addr%v3(($$CIV6 + int(ibeg)) - 1,$$ICM0,&
                &         $$ICM5)) + d-v3%addr%v3(int(ibeg) + $$CIV6,$$ICM0,&
                &         $$ICM6)) - d-v3%addr%v3(($$CIV6 + int(ibeg)) - 1,$$ICM0,&
                &         $$ICM6))
   159|                 GOTO lab_35
   160|                 d-dv12%addr%dv12[].rns21.(int(ibeg) + $$CIV6) =  &
                &         0.0000000000000000E+000
   161|                 d-dv13%addr%dv13[].rns23.(int(ibeg) + $$CIV6) =  &
                &         0.0000000000000000E+000
   162|               ENDIF
   163|               d-dv21%addr%dv21[].rns24.(int(ibeg) + $$CIV6) = ( &
                &       5.0000000000000000E-001 * ($$ICM8 * (d-v1%addr%v1(int(&
                &       ibeg) + $$CIV6,$$ICM0,$$ICM5) - d-v1%addr%v1(int(ibeg) + &
                &       $$CIV6,($$CIV9 + int(jbeg)) - 1,$$ICM5)) + $$ICM7 * (&
                &       d-v1%addr%v1(int(ibeg) + $$CIV6,$$ICM4,$$ICM5) - &
                &       d-v1%addr%v1(int(ibeg) + $$CIV6,$$ICM0,$$ICM5)))) * &
                &       d-g2ai%addr%g2ai(int(ibeg) + $$CIV6)
   166|               d-dv31%addr%dv31[].rns26.(int(ibeg) + $$CIV6) = (( &
                &       5.0000000000000000E-001 * ($$ICMA * (d-v1%addr%v1(int(&
                &       ibeg) + $$CIV6,$$ICM0,$$ICM5) - d-v1%addr%v1(int(ibeg) + &
                &       $$CIV6,$$ICM0,($$CIVA + int(kbeg)) - 1)) + $$ICM9 * (&
                &       d-v1%addr%v1(int(ibeg) + $$CIV6,$$ICM0,$$ICM6) - &
                &       d-v1%addr%v1(int(ibeg) + $$CIV6,$$ICM0,$$ICM5)))) * &
                &       d-g31ai%addr%g31ai(int(ibeg) + $$CIV6)) * $$ICM2
   169|             ENDDO
                  ENDIF
   170|           IF (.NOT.(ldimen > 1)) GOTO lab_39
   171|           IF (.NOT.(1 + (int((iend + 1)) - int(ibeg)) > 0)) GOTO lab_76
                  $$CIV7 = 0
                  $$PRC0 = d-v3%addr%v3(int(ibeg) - 1,$$CIV9 + int(jbeg),1 + (&
                &   $$CIVA + int(kbeg)))
                  $$PRC2 = d-v3%addr%v3(int(ibeg) - 1,$$CIV9 + int(jbeg),$$CIVA &
                &   + int(kbeg))
                  $$PRC4 = d-v2%addr%v2(int(ibeg) - 1,1 + ($$CIV9 + int(jbeg)),&
                &   $$CIVA + int(kbeg))
                  $$PRC6 = d-v2%addr%v2(int(ibeg) - 1,$$CIV9 + int(jbeg),$$CIVA &
                &   + int(kbeg))
       Id=10      DO $$CIV7 = $$CIV7, int((1 + (int((iend + 1)) - int(ibeg))))&
                &     -1
                    $$PRC1 = d-v3%addr%v3(int(ibeg) + $$CIV7,$$CIV9 + int(jbeg),&
                &     1 + ($$CIVA + int(kbeg)))
                    $$PRC3 = d-v3%addr%v3(int(ibeg) + $$CIV7,$$CIV9 + int(jbeg),&
                &     $$CIVA + int(kbeg))
                    $$PRC5 = d-v2%addr%v2(int(ibeg) + $$CIV7,1 + ($$CIV9 + int(&
                &     jbeg)),$$CIVA + int(kbeg))
                    $$PRC7 = d-v2%addr%v2(int(ibeg) + $$CIV7,$$CIV9 + int(jbeg),&
                &     $$CIVA + int(kbeg))
   172|             d-dv21%addr%dv21[].rns24.(int(ibeg) + $$CIV7) = &
                &     d-dv21%addr%dv21[].rns24.(int(ibeg) + $$CIV7) - (( &
                &     2.5000000000000000E-001 * ((($$PRC7 + $$PRC6) + $$PRC5) + &
                &     $$PRC4)) * d-g2ai%addr%g2ai(int(ibeg) + $$CIV7)) * &
                &     d-dg2ad1%addr%dg2ad1(int(ibeg) + $$CIV7)
   176|             d-dv31%addr%dv31[].rns26.(int(ibeg) + $$CIV7) = &
                &     d-dv31%addr%dv31[].rns26.(int(ibeg) + $$CIV7) - (( &
                &     2.5000000000000000E-001 * ((($$PRC3 + $$PRC2) + $$PRC1) + &
                &     $$PRC0)) * d-g31ai%addr%g31ai(int(ibeg) + $$CIV7)) * &
                &     d-dg31ad1%addr%dg31ad1(int(ibeg) + $$CIV7)
                    $$PRC6 = $$PRC7
                    $$PRC4 = $$PRC5
                    $$PRC2 = $$PRC3
                    $$PRC0 = $$PRC1
   180|           ENDDO
                  lab_76
   181|           lab_39
   185|           IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                    $$CIV8 = 0
   189|             $$ICM0 = int(jbeg) + $$CIV9
                    $$ICM5 = int(kbeg) + $$CIVA
   185|Id=11        DO $$CIV8 = $$CIV8, int((1 + (int(iend) - int(ibeg))))-1
   189|               $$csx4 = $$CIV8 + int(ibeg)
                      derdx1.rnn0 = (erold(1 + $$csx4,$$ICM0,$$ICM5) - erold(&
                &       $$csx4 - 1,$$ICM0,$$ICM5)) / (d-dx1b%addr%dx1b($$csx4) + &
                &       d-dx1b%addr%dx1b(1 + $$csx4))
   191|               IF ((ldimen == 1)) THEN
   192|                 derdx2 =  0.0000000000000000E+000
   193|               ELSE
   194|                 derdx2 = ((erold($$csx4,1 + $$ICM0,$$ICM5) - erold(&
                &         $$csx4,$$ICM0 - 1,$$ICM5)) * d-g2bi%addr%g2bi($$csx4)) &
                &         / (d-dx2b%addr%dx2b($$ICM0) + d-dx2b%addr%dx2b(1 + &
                &         $$ICM0))
   196|               ENDIF
   197|               IF ((ldimen <> 3)) THEN
   212|                 $$csx5 = (_sqrt(%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) + &
                &         %VAL(derdx2) * %VAL(derdx2)) * ( &
                &         1.0000000000000000E+000 / (d-kapr%addr%kapr($$csx4,&
                &         $$ICM0,$$ICM5) + d-sig%addr%sig($$csx4,$$ICM0,$$ICM5))))&
                &          / max(erold($$csx4,$$ICM0,$$ICM5), &
                &         1.0000000000000000E-099)
                        big_r = $$csx5
   221|                 $$csx6 = derdx1.rnn0 / max(_sqrt(%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)), &
                &         1.0000000000000000E-099)
   225|                 $$csx7 = derdx2 / max(_sqrt(%VAL(derdx1.rnn0) * %VAL(&
                &         derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)), &
                &         1.0000000000000000E-099)
   247|                 gvcf($$csx4,$$ICM0,$$ICM5) = ((d-dv11%addr%dv11[].rns0.(&
                &         $$csx4) * ( 5.0000000000000000E-001 * ( &
                &         1.0000000000000000E+000 - (( 2.0000000000000000E+000 + &
                &         $$csx5) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * $$csx5) + $$csx5 * big_r) + ((&
                &         ( 2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r))) + ( 1.5000000000000000E+000 * ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * ($$csx6 * $$csx6)) + &
                &         d-dv22%addr%dv22[].rns3.($$csx4) * ( &
                &         5.0000000000000000E-001 * ( 1.0000000000000000E+000 - ((&
                &          2.0000000000000000E+000 + $$csx5) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         $$csx5) + $$csx5 * $$csx5) + ((( &
                &         2.0000000000000000E+000 + $$csx5) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         $$csx5) + $$csx5 * $$csx5)) * (( &
                &         2.0000000000000000E+000 + $$csx5) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r))) + ( &
                &         1.5000000000000000E+000 * ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r)) -  3.3333333333333331E-001)) * ($$csx7 &
                &         * $$csx7))) + d-dv33%addr%dv33[].rns6.($$csx4) * ( &
                &         5.0000000000000000E-001 * ( 1.0000000000000000E+000 - ((&
                &          2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r))))) + ((((&
                &         d-dv12%addr%dv12[].rns21.($$csx4) + &
                &         d-dv12%addr%dv12[].rns21.(1 + $$csx4)) + &
                &         d-dv21%addr%dv21[].rns24.($$csx4)) + &
                &         d-dv21%addr%dv21[].rns24.(1 + $$csx4)) *  &
                &         5.0000000000000000E-001) * ((( 1.5000000000000000E+000 &
                &         * ((( 2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * $$csx6) * $$csx7)
   257|                 deldotv($$csx4,$$ICM0,$$ICM5) = (d-dvl1ai%addr%dvl1ai(&
                &         $$csx4) * ((d-g2a%addr%g2a(1 + $$csx4) * &
                &         d-g31a%addr%g31a(1 + $$csx4)) * d-v1%addr%v1(1 + $$csx4,&
                &         $$ICM0,$$ICM5) - (d-g2a%addr%g2a($$csx4) * &
                &         d-g31a%addr%g31a($$csx4)) * d-v1%addr%v1($$csx4,$$ICM0,&
                &         $$ICM5)) + (d-g2bi%addr%g2bi($$csx4) * &
                &         d-dvl2ai%addr%dvl2ai($$ICM0)) * (d-g32a%addr%g32a(1 + &
                &         $$ICM0) * d-v2%addr%v2($$csx4,1 + $$ICM0,$$ICM5) - &
                &         d-g32a%addr%g32a($$ICM0) * d-v2%addr%v2($$csx4,$$ICM0,&
                &         $$ICM5))) + ((d-g31bi%addr%g31bi($$csx4) * &
                &         d-g32bi%addr%g32bi($$ICM0)) * d-dvl3ai%addr%dvl3ai(&
                &         $$ICM5)) * (d-v3%addr%v3($$csx4,$$ICM0,1 + $$ICM5) - &
                &         d-v3%addr%v3($$csx4,$$ICM0,$$ICM5))
                      ELSE
   200|                 derdx3 = (((erold($$csx4,$$ICM0,1 + $$ICM5) - erold(&
                &         $$csx4,$$ICM0,$$ICM5 - 1)) * d-g31bi%addr%g31bi($$csx4))&
                &          * d-g32bi%addr%g32bi($$csx4)) / (d-dx3b%addr%dx3b(&
                &         $$ICM5) + d-dx3b%addr%dx3b(1 + $$ICM5))
   212|                 $$csx8 = (_sqrt((%VAL(derdx1.rnn0) * %VAL(derdx1.rnn0) &
                &         + %VAL(derdx2) * %VAL(derdx2)) + %VAL(derdx3) * %VAL(&
                &         derdx3)) * ( 1.0000000000000000E+000 / (&
                &         d-kapr%addr%kapr($$csx4,$$ICM0,$$ICM5) + d-sig%addr%sig(&
                &         $$csx4,$$ICM0,$$ICM5)))) / max(erold($$csx4,$$ICM0,&
                &         $$ICM5), 1.0000000000000000E-099)
                        big_r = $$csx8
   221|                 $$csx9 = derdx1.rnn0 / max(_sqrt((%VAL(derdx1.rnn0) * &
                &         %VAL(derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + %VAL(&
                &         derdx3) * %VAL(derdx3)), 1.0000000000000000E-099)
   225|                 $$csxA = derdx2 / max(_sqrt((%VAL(derdx1.rnn0) * %VAL(&
                &         derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + %VAL(&
                &         derdx3) * %VAL(derdx3)), 1.0000000000000000E-099)
   226|                 $$csxB = derdx3 / max(_sqrt((%VAL(derdx1.rnn0) * %VAL(&
                &         derdx1.rnn0) + %VAL(derdx2) * %VAL(derdx2)) + %VAL(&
                &         derdx3) * %VAL(derdx3)), 1.0000000000000000E-099)
   247|                 gvcf($$csx4,$$ICM0,$$ICM5) = ((((&
                &         d-dv11%addr%dv11[].rns0.($$csx4) * ( &
                &         5.0000000000000000E-001 * ( 1.0000000000000000E+000 - ((&
                &          2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r))) + ( &
                &         1.5000000000000000E+000 * ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r)) -  3.3333333333333331E-001)) * ($$csx9 &
                &         * $$csx9)) + d-dv22%addr%dv22[].rns3.($$csx4) * ( &
                &         5.0000000000000000E-001 * ( 1.0000000000000000E+000 - ((&
                &          2.0000000000000000E+000 + $$csx8) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         $$csx8) + $$csx8 * $$csx8) + ((( &
                &         2.0000000000000000E+000 + $$csx8) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         $$csx8) + $$csx8 * $$csx8)) * (( &
                &         2.0000000000000000E+000 + $$csx8) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r))) + ( &
                &         1.5000000000000000E+000 * ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r)) -  3.3333333333333331E-001)) * ($$csxA &
                &         * $$csxA))) + d-dv33%addr%dv33[].rns6.($$csx4) * ( &
                &         5.0000000000000000E-001 * ( 1.0000000000000000E+000 - ((&
                &          2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r))) + ( &
                &         1.5000000000000000E+000 * ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r)) -  3.3333333333333331E-001)) * ($$csxB &
                &         * $$csxB))) + ((((d-dv12%addr%dv12[].rns21.($$csx4) + &
                &         d-dv12%addr%dv12[].rns21.(1 + $$csx4)) + &
                &         d-dv21%addr%dv21[].rns24.($$csx4)) + &
                &         d-dv21%addr%dv21[].rns24.(1 + $$csx4)) *  &
                &         5.0000000000000000E-001) * ((( 1.5000000000000000E+000 &
                &         * ((( 2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * $$csx9) * $$csxA)) + ((((&
                &         d-dv13%addr%dv13[].rns23.($$csx4) + &
                &         d-dv13%addr%dv13[].rns23.(1 + $$csx4)) + &
                &         d-dv31%addr%dv31[].rns26.($$csx4)) + &
                &         d-dv31%addr%dv31[].rns26.(1 + $$csx4)) *  &
                &         5.0000000000000000E-001) * ((( 1.5000000000000000E+000 &
                &         * ((( 2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r) + ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r)) * (( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r))) * (big_r * big_r)) -  &
                &         3.3333333333333331E-001)) * $$csx9) * $$csxB)) + (&
                &         d-dv23%addr%dv23[].rns15.($$csx4) + &
                &         d-dv32%addr%dv32[].rns17.($$csx4)) * ((( &
                &         1.5000000000000000E+000 * ((( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r) + ((( &
                &         2.0000000000000000E+000 + big_r) / (( &
                &         6.0000000000000000E+000 +  3.0000000000000000E+000 * &
                &         big_r) + big_r * big_r)) * (( 2.0000000000000000E+000 + &
                &         big_r) / (( 6.0000000000000000E+000 +  &
                &         3.0000000000000000E+000 * big_r) + big_r * big_r))) * (&
                &         big_r * big_r)) -  3.3333333333333331E-001)) * $$csxA) &
                &         * $$csxB)
   257|                 deldotv($$csx4,$$ICM0,$$ICM5) = (d-dvl1ai%addr%dvl1ai(&
                &         $$csx4) * ((d-g2a%addr%g2a(1 + $$csx4) * &
                &         d-g31a%addr%g31a(1 + $$csx4)) * d-v1%addr%v1(1 + $$csx4,&
                &         $$ICM0,$$ICM5) - (d-g2a%addr%g2a($$csx4) * &
                &         d-g31a%addr%g31a($$csx4)) * d-v1%addr%v1($$csx4,$$ICM0,&
                &         $$ICM5)) + (d-g2bi%addr%g2bi($$csx4) * &
                &         d-dvl2ai%addr%dvl2ai($$ICM0)) * (d-g32a%addr%g32a(1 + &
                &         $$ICM0) * d-v2%addr%v2($$csx4,1 + $$ICM0,$$ICM5) - &
                &         d-g32a%addr%g32a($$ICM0) * d-v2%addr%v2($$csx4,$$ICM0,&
                &         $$ICM5))) + ((d-g31bi%addr%g31bi($$csx4) * &
                &         d-g32bi%addr%g32bi($$ICM0)) * d-dvl3ai%addr%dvl3ai(&
                &         $$ICM5)) * (d-v3%addr%v3($$csx4,$$ICM0,1 + $$ICM5) - &
                &         d-v3%addr%v3($$csx4,$$ICM0,$$ICM5))
                      ENDIF
   266|             ENDDO
                  ENDIF
   267|         ENDDO
              ENDIF
   268|       ENDDO
                lab_64
   271|         lab_80
                RETURN
              END SUBROUTINE grdv

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   ssus ssss ssss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ssss  ssss ssss ssss ssss
 CCR's set/used:   ssss ssss
     | 000000                           PDEF     grdv
   10|                                  PROC      .ibeg,.iend,.jbeg,.jend,.kbeg,.kend,.erold,.gvcf,.deldotv,gr3-gr10
    0| 000000 stfd     DBE1FFF8   1     STFL      #stack(gr1,-8)=fp31
    0| 000004 stfd     DBC1FFF0   1     STFL      #stack(gr1,-16)=fp30
    0| 000008 stfd     DBA1FFE8   1     STFL      #stack(gr1,-24)=fp29
    0| 00000C stfd     DB81FFE0   1     STFL      #stack(gr1,-32)=fp28
    0| 000010 stfd     DB61FFD8   1     STFL      #stack(gr1,-40)=fp27
    0| 000014 stfd     DB41FFD0   1     STFL      #stack(gr1,-48)=fp26
    0| 000018 stfd     DB21FFC8   1     STFL      #stack(gr1,-56)=fp25
    0| 00001C stfd     DB01FFC0   1     STFL      #stack(gr1,-64)=fp24
    0| 000020 stfd     DAE1FFB8   1     STFL      #stack(gr1,-72)=fp23
    0| 000024 stfd     DAC1FFB0   1     STFL      #stack(gr1,-80)=fp22
    0| 000028 stfd     DAA1FFA8   1     STFL      #stack(gr1,-88)=fp21
    0| 00002C stfd     DA81FFA0   1     STFL      #stack(gr1,-96)=fp20
    0| 000030 stfd     DA61FF98   1     STFL      #stack(gr1,-104)=fp19
    0| 000034 stfd     DA41FF90   1     STFL      #stack(gr1,-112)=fp18
    0| 000038 stfd     DA21FF88   1     STFL      #stack(gr1,-120)=fp17
    0| 00003C stfd     DA01FF80   1     STFL      #stack(gr1,-128)=fp16
    0| 000040 stfd     D9E1FF78   1     STFL      #stack(gr1,-136)=fp15
    0| 000044 stfd     D9C1FF70   1     STFL      #stack(gr1,-144)=fp14
    0| 000048 std      FBE1FF68   1     ST8       #stack(gr1,-152)=gr31
    0| 00004C std      FBC1FF60   1     ST8       #stack(gr1,-160)=gr30
    0| 000050 std      FBA1FF58   1     ST8       #stack(gr1,-168)=gr29
    0| 000054 std      FB81FF50   1     ST8       #stack(gr1,-176)=gr28
    0| 000058 std      FB61FF48   1     ST8       #stack(gr1,-184)=gr27
    0| 00005C std      FB41FF40   1     ST8       #stack(gr1,-192)=gr26
    0| 000060 std      FB21FF38   1     ST8       #stack(gr1,-200)=gr25
    0| 000064 std      FB01FF30   1     ST8       #stack(gr1,-208)=gr24
    0| 000068 std      FAE1FF28   1     ST8       #stack(gr1,-216)=gr23
    0| 00006C std      FAC1FF20   1     ST8       #stack(gr1,-224)=gr22
    0| 000070 std      FAA1FF18   1     ST8       #stack(gr1,-232)=gr21
    0| 000074 std      FA81FF10   1     ST8       #stack(gr1,-240)=gr20
    0| 000078 std      FA61FF08   1     ST8       #stack(gr1,-248)=gr19
    0| 00007C std      FA41FF00   1     ST8       #stack(gr1,-256)=gr18
    0| 000080 std      FA21FEF8   1     ST8       #stack(gr1,-264)=gr17
    0| 000084 std      FA01FEF0   1     ST8       #stack(gr1,-272)=gr16
    0| 000088 std      F9E1FEE8   1     ST8       #stack(gr1,-280)=gr15
    0| 00008C std      F9C1FEE0   1     ST8       #stack(gr1,-288)=gr14
    0| 000090 mfcr     7D800026   1     LFCR      gr12=cr[234],2
    0| 000094 stw      91810008   1     ST4A      #stack(gr1,8)=gr12
    0| 000098 stdu     F821F7C1   1     ST8U      gr1,#stack(gr1,-2112)=gr1
    0| 00009C or       7C3F0B78   1     LR        gr31=gr1
    0| 0000A0 ld       E9620000   1     L8        gr11=.&&N&&param(gr2,0)
    0| 0000A4 lwa      EBA70002   1     L4A       gr29=kbeg(gr7,0)
    0| 0000A8 lwa      E8E80002   1     L4A       gr7=kend(gr8,0)
    0| 0000AC ld       E8010000   1     L8        gr0=#stack(gr1,0)
   75| 0000B0 ld       EB820000   1     L8        gr28=.&&N&&config(gr2,0)
    0| 0000B4 lwa      EBCB0002   1     L4A       gr30=<s18:d0:l4>(gr11,0)
    0| 0000B8 std      FBBF0348   1     ST8       #SPILL0(gr31,840)=gr29
    0| 0000BC subf     7CFD3850   1     S         gr7=gr7,gr29
    0| 0000C0 lwa      E96B0006   1     L4A       gr11=<s18:d4:l4>(gr11,4)
    0| 0000C4 addic.   37670001   1     AI_R      gr27,cr0=gr7,1,ca"
   75| 0000C8 lwz      819C0028   1     L4Z       gr12=<s423:d40:l4>(gr28,40)
    0| 0000CC std      FB7F0508   1     ST8       #SPILL1(gr31,1288)=gr27
    0| 0000D0 sradi    7FC8FE76   1     SRA8      gr8=gr30,63,ca"
    0| 0000D4 mcrf     4C800000   1     LRCR      cr1=cr0
    0| 0000D8 andc     7FC84078   1     ANDC      gr8=gr30,gr8
    0| 0000DC rldicr   791A1F24   1     SLL8      gr26=gr8,3
    0| 0000E0 sradi    7D7EFE76   1     SRA8      gr30=gr11,63,ca"
    0| 0000E4 std      FB5F0200   1     ST8       #SPILL2(gr31,512)=gr26
    0| 0000E8 neg      7CFA00D0   1     COMP      gr7=gr26
   75| 0000EC andi.    718C0001   1     RN4_R     gr12,cr0=gr12,0,0x1
    0| 0000F0 rldicr   78E706A4   1     RN8       gr7=gr7,0,0xFFFFFFFFFFFFFFE0
    0| 0000F4 andc     7D7EF078   1     ANDC      gr30=gr11,gr30
    0| 0000F8 stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 0000FC std      F83F06F8   1     ST8       #SPILL59(gr31,1784)=gr1
    0| 000100 ld       E8010000   1     L8        gr0=#stack(gr1,0)
    0| 000104 addi     3B210080   1     AI        gr25=gr1,128
    0| 000108 std      FB3F0638   1     ST8       #SPILL3(gr31,1592)=gr25
    0| 00010C stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 000110 std      F83F06E0   1     ST8       #SPILL61(gr31,1760)=gr1
    0| 000114 ld       E8010000   1     L8        gr0=#stack(gr1,0)
    0| 000118 addi     3B010080   1     AI        gr24=gr1,128
    0| 00011C std      FB1F0660   1     ST8       #SPILL4(gr31,1632)=gr24
    0| 000120 stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 000124 std      F83F06A0   1     ST8       #SPILL65(gr31,1696)=gr1
    0| 000128 ld       E8010000   1     L8        gr0=#stack(gr1,0)
    0| 00012C addi     3AE10080   1     AI        gr23=gr1,128
    0| 000130 std      FAFF0668   1     ST8       #SPILL5(gr31,1640)=gr23
    0| 000134 stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 000138 ld       E8010000   1     L8        gr0=#stack(gr1,0)
    0| 00013C std      F83F0628   1     ST8       #SPILL67(gr31,1576)=gr1
    0| 000140 addi     3AC10080   1     AI        gr22=gr1,128
    0| 000144 std      FADF0670   1     ST8       #SPILL6(gr31,1648)=gr22
    0| 000148 stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 00014C ld       E8010000   1     L8        gr0=#stack(gr1,0)
    0| 000150 std      F83F06D8   1     ST8       #SPILL62(gr31,1752)=gr1
    0| 000154 addi     3AA10080   1     AI        gr21=gr1,128
    0| 000158 std      FABF0640   1     ST8       #SPILL7(gr31,1600)=gr21
    0| 00015C stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 000160 ld       E8010000   1     L8        gr0=#stack(gr1,0)
    0| 000164 std      F83F06C8   1     ST8       #SPILL63(gr31,1736)=gr1
    0| 000168 addi     3A810080   1     AI        gr20=gr1,128
    0| 00016C std      FA9F0650   1     ST8       #SPILL8(gr31,1616)=gr20
    0| 000170 stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 000174 ld       E8010000   1     L8        gr0=#stack(gr1,0)
    0| 000178 std      F83F0620   1     ST8       #SPILL66(gr31,1568)=gr1
    0| 00017C addi     3A610080   1     AI        gr19=gr1,128
    0| 000180 std      FA7F0678   1     ST8       #SPILL9(gr31,1656)=gr19
    0| 000184 stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 000188 ld       E8010000   1     L8        gr0=#stack(gr1,0)
    0| 00018C std      F83F06B8   1     ST8       #SPILL64(gr31,1720)=gr1
    0| 000190 addi     3A410080   1     AI        gr18=gr1,128
    0| 000194 std      FA5F0658   1     ST8       #SPILL10(gr31,1624)=gr18
    0| 000198 stdux    7C01396A   1     ST8U      gr1,#stack(gr1,gr7,0)=gr0
    0| 00019C addi     3A210080   1     AI        gr17=gr1,128
    0| 0001A0 std      FA3F0648   1     ST8       #SPILL11(gr31,1608)=gr17
   75| 0001A4 bc       40820388   1     BF        CL.1,cr0,0x4/eq,taken=50%(0,0)
   75| 0001A8 sradi    7F601674   1     SRA8CA    gr0,ca=gr27,2
   75| 0001AC addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
   76| 0001B0 rldicr   78071764   1     SLL8      gr7=gr0,2
   76| 0001B4 subf     7D27D851   1     S_R       gr9,cr0=gr27,gr7
   76| 0001B8 crand    4C250A02   1     CR_N      cr0=cr[10],0x2/gt,0x2/gt,0x2/gt,cr0
   76| 0001BC bc       408100D8   1     BF        CL.93,cr0,0x2/gt,taken=50%(0,0)
   76| 0001C0 lwa      EBA50002   1     L4A       gr29=jbeg(gr5,0)
   76| 0001C4 lwa      E8060002   1     L4A       gr0=jend(gr6,0)
   76| 0001C8 addi     39600000   1     LI        gr11=0
   76| 0001CC subf     7D9D0050   1     S         gr12=gr0,gr29
   76| 0001D0 addic.   340C0001   1     AI_R      gr0,cr0=gr12,1,ca"
    0| 0001D4 bc       40810344   1     BF        CL.231,cr0,0x2/gt,taken=50%(0,0)
    0| 0001D8 rldicr   7BCC1F24   1     SLL8      gr12=gr30,3
    0| 0001DC mulld    7FBAE9D2   1     M         gr29=gr26,gr29
    0| 0001E0 mulld    7F4861D2   1     M         gr26=gr8,gr12
    0| 0001E4 ld       EADF0348   1     L8        gr22=#SPILL0(gr31,840)
    0| 0001E8 neg      7F8C00D0   1     COMP      gr28=gr12
    0| 0001EC ld       EABF0200   1     L8        gr21=#SPILL2(gr31,512)
    0| 0001F0 addi     3BBDFFF0   1     AI        gr29=gr29,-16
    0| 0001F4 mulld    7F68E1D2   1     M         gr27=gr8,gr28
    0| 0001F8 mulld    7D96D1D2   1     M         gr12=gr22,gr26
    0| 0001FC lwa      EB230002   1     L4A       gr25=ibeg(gr3,0)
    0| 000200 subf     7D956050   1     S         gr12=gr12,gr21
    0| 000204 ld       EB820000   1     L8        gr28=.+CONSTANT_AREA(gr2,0)
    0| 000208 add      7FACEA14   1     A         gr29=gr12,gr29
    0| 00020C lwa      E9840002   1     L4A       gr12=iend(gr4,0)
    0| 000210 add      7F1BEA14   1     A         gr24=gr27,gr29
    0| 000214 add      7EEAC214   1     A         gr23=gr10,gr24
    0| 000218 lfs      C01C0000   1     LFS       fp0=+CONSTANT_AREA(gr28,0)
    0| 00021C subf     7FB96050   1     S         gr29=gr12,gr25
    0| 000220 addic.   37BD0001   1     AI_R      gr29,cr0=gr29,1,ca"
    0| 000224 mcrf     4F800000   1     LRCR      cr7=cr0
   76|                              CL.88:
    0| 000228 addi     3B6C0001   1     AI        gr27=gr12,1
    0| 00022C rldicr   7B3C1F24   1     SLL8      gr28=gr25,3
   77| 000230 addi     3BA00000   1     LI        gr29=0
    0| 000234 bc       409D004C   1     BF        CL.92,cr7,0x2/gt,taken=20%(20,80)
    0| 000238 subf     7ED9D851   1     S_R       gr22,cr0=gr27,gr25
    0| 00023C add      7E78E214   1     A         gr19=gr24,gr28
    0| 000240 add      7EB7E214   1     A         gr21=gr23,gr28
    0| 000244 ld       EA9F08B0   1     L8        gr20=.deldotv(gr31,2224)
    0| 000248 ori      60210000   1     XNOP      
    0| 00024C ori      60210000   1     XNOP      
   77|                              CL.89:
   80| 000250 add      7F93A214   1     A         gr28=gr19,gr20
   79| 000254 or       7EBBAB78   1     LR        gr27=gr21
    0| 000258 mtspr    7EC903A6   1     LCTR      ctr=gr22
    0|                              CL.511:
   79| 00025C stfdu    DC1B0008   1     STFDU     gr27,gvcf[](gr27,8)=fp0
   80| 000260 stfdu    DC1C0008   1     STFDU     gr28,deldotv[](gr28,8)=fp0
    0| 000264 bc       4200FFF8   1     BCT       ctr=CL.511,taken=100%(100,0)
    0| 000268 ld       EB9F0200   1     L8        gr28=#SPILL2(gr31,512)
   82| 00026C addi     3BBD0001   1     AI        gr29=gr29,1
   82| 000270 cmpld    7F3D0040   1     CL8       cr6=gr29,gr0
    0| 000274 add      7E73E214   1     A         gr19=gr19,gr28
    0| 000278 add      7EB5E214   1     A         gr21=gr21,gr28
   82| 00027C bc       4198FFD4   1     BT        CL.89,cr6,0x8/llt,taken=80%(80,20)
   82|                              CL.92:
   83| 000280 addi     396B0001   1     AI        gr11=gr11,1
    0| 000284 add      7F18D214   1     A         gr24=gr24,gr26
   83| 000288 cmpd     7F295800   1     C8        cr6=gr9,gr11
    0| 00028C add      7EF7D214   1     A         gr23=gr23,gr26
   83| 000290 bc       4199FF98   1     BT        CL.88,cr6,0x2/gt,taken=80%(80,20)
   83|                              CL.93:
   76| 000294 ld       E81F0508   1     L8        gr0=#SPILL1(gr31,1288)
   76| 000298 cmpd     7F204800   1     C8        cr6=gr0,gr9
   76| 00029C crand    4C25CA02   1     CR_N      cr0=cr[16],0x2/gt,0x2/gt,0x2/gt,cr0
   76| 0002A0 bc       40810234   1     BF        CL.720,cr0,0x2/gt,taken=30%(30,70)
    0| 0002A4 rldicr   7BC01F24   1     SLL8      gr0=gr30,3
   76| 0002A8 lwa      E8A50002   1     L4A       gr5=jbeg(gr5,0)
    0| 0002AC mulld    7D6041D2   1     M         gr11=gr0,gr8
    0| 0002B0 ld       EB7F0200   1     L8        gr27=#SPILL2(gr31,512)
    0| 0002B4 ld       EB5F0348   1     L8        gr26=#SPILL0(gr31,840)
   76| 0002B8 lwa      E8C60002   1     L4A       gr6=jend(gr6,0)
   83| 0002BC addi     38E7FFFF   1     AI        gr7=gr7,-1
    0| 0002C0 mulld    7D2959D2   1     M         gr9=gr9,gr11
    0| 0002C4 mulld    7D85D9D2   1     M         gr12=gr5,gr27
    0| 0002C8 mulld    7F8BD1D2   1     M         gr28=gr11,gr26
   83| 0002CC sradi    7CE71674   1     SRA8CA    gr7,ca=gr7,2
   76| 0002D0 subf     7FA53050   1     S         gr29=gr6,gr5
   83| 0002D4 addze    7CA70194   1     ADDE      gr5,ca=gr7,0,ca
    0| 0002D8 rldicr   7BC626E4   1     SLL8      gr6=gr30,4
    0| 0002DC neg      7CE000D0   1     COMP      gr7=gr0
   76| 0002E0 addic.   341D0001   1     AI_R      gr0,cr0=gr29,1,ca"
   76| 0002E4 addi     3B200000   1     LI        gr25=0
    0| 0002E8 addi     3BACFFF0   1     AI        gr29=gr12,-16
   76| 0002EC std      FB3F0348   1     ST8       #SPILL0(gr31,840)=gr25
    0| 0002F0 subf     7D9BE050   1     S         gr12=gr28,gr27
    0| 0002F4 bc       408101E0   1     BF        CL.720,cr0,0x2/gt,taken=20%(20,80)
    0| 0002F8 lwa      EB030002   1     L4A       gr24=ibeg(gr3,0)
    0| 0002FC lwa      EAE40002   1     L4A       gr23=iend(gr4,0)
    0| 000300 rldicr   7BDE2EA4   1     SLL8      gr30=gr30,5
    0| 000304 add      7C8CEA14   1     A         gr4=gr12,gr29
    0| 000308 mulld    7CC641D2   1     M         gr6=gr6,gr8
    0| 00030C std      FB1F0508   1     ST8       #SPILL1(gr31,1288)=gr24
    0| 000310 std      FAFF0638   1     ST8       #SPILL3(gr31,1592)=gr23
    0| 000314 mulld    7CE741D2   1     M         gr7=gr7,gr8
    0| 000318 ld       E8620000   1     L8        gr3=.+CONSTANT_AREA(gr2,0)
    0| 00031C add      7EC44A14   1     A         gr22=gr4,gr9
    0| 000320 subf     7C98B850   1     S         gr4=gr23,gr24
    0| 000324 add      7D8AB214   1     A         gr12=gr10,gr22
    0| 000328 mulld    7FC8F1D2   1     M         gr30=gr8,gr30
    0| 00032C addi     39050001   1     AI        gr8=gr5,1
    0| 000330 std      FADF0660   1     ST8       #SPILL4(gr31,1632)=gr22
    0| 000334 std      F91F0668   1     ST8       #SPILL5(gr31,1640)=gr8
    0| 000338 add      7DC66214   1     A         gr14=gr6,gr12
    0| 00033C add      7FA76214   1     A         gr29=gr7,gr12
    0| 000340 add      7F8B6214   1     A         gr28=gr11,gr12
    0| 000344 add      7F6BB214   1     A         gr27=gr11,gr22
    0| 000348 add      7F46B214   1     A         gr26=gr6,gr22
    0| 00034C add      7F27B214   1     A         gr25=gr7,gr22
    0| 000350 addic.   34840001   1     AI_R      gr4,cr0=gr4,1,ca"
    0| 000354 lfs      C0030000   1     LFS       fp0=+CONSTANT_AREA(gr3,0)
   76|                              CL.59:
    0| 000358 ld       E8DF0638   1     L8        gr6=#SPILL3(gr31,1592)
    0| 00035C ld       E8FF0508   1     L8        gr7=#SPILL1(gr31,1288)
   77| 000360 addi     38600000   1     LI        gr3=0
    0| 000364 addi     38A60001   1     AI        gr5=gr6,1
    0| 000368 rldicr   78E41F24   1     SLL8      gr4=gr7,3
    0| 00036C bc       408100D8   1     BF        CL.60,cr0,0x2/gt,taken=20%(20,80)
    0| 000370 subf     7F072850   1     S         gr24=gr5,gr7
    0| 000374 ld       E8BF0660   1     L8        gr5=#SPILL4(gr31,1632)
    0| 000378 add      7EE4D214   1     A         gr23=gr4,gr26
    0| 00037C add      7EC4CA14   1     A         gr22=gr4,gr25
    0| 000380 add      7EA4DA14   1     A         gr21=gr4,gr27
    0| 000384 add      7E64EA14   1     A         gr19=gr4,gr29
    0| 000388 add      7E447214   1     A         gr18=gr4,gr14
    0| 00038C add      7E842A14   1     A         gr20=gr4,gr5
    0| 000390 add      7E24E214   1     A         gr17=gr4,gr28
    0| 000394 add      7E046214   1     A         gr16=gr4,gr12
    0| 000398 ld       E9FF08B0   1     L8        gr15=.deldotv(gr31,2224)
   77|                              CL.61:
   80| 00039C add      7C8FB214   1     A         gr4=gr15,gr22
   80| 0003A0 add      7CAFA214   1     A         gr5=gr15,gr20
   80| 0003A4 stfdu    DC040008   1     STFDU     gr4,deldotv[](gr4,8)=fp0
   80| 0003A8 add      7CEFAA14   1     A         gr7=gr15,gr21
   80| 0003AC stfdu    DC050008   1     STFDU     gr5,deldotv[](gr5,8)=fp0
   79| 0003B0 or       7E098378   1     LR        gr9=gr16
   80| 0003B4 stfdu    DC070008   1     STFDU     gr7,deldotv[](gr7,8)=fp0
   79| 0003B8 or       7E268B78   1     LR        gr6=gr17
   79| 0003BC or       7E689B78   1     LR        gr8=gr19
   79| 0003C0 or       7E4A9378   1     LR        gr10=gr18
   79| 0003C4 stfdu    DC080008   1     STFDU     gr8,gvcf[](gr8,8)=fp0
   79| 0003C8 stfdu    DC090008   1     STFDU     gr9,gvcf[](gr9,8)=fp0
    0| 0003CC mtspr    7F0903A6   1     LCTR      ctr=gr24
   79| 0003D0 stfdu    DC060008   1     STFDU     gr6,gvcf[](gr6,8)=fp0
   79| 0003D4 stfdu    DC0A0008   1     STFDU     gr10,gvcf[](gr10,8)=fp0
   80| 0003D8 add      7D6FBA14   1     A         gr11=gr15,gr23
    0| 0003DC bc       42400034   1     BCF       ctr=CL.512,taken=0%(0,100)
    0| 0003E0 ori      60210000   1     XNOP      
    0| 0003E4 ori      60210000   1     XNOP      
    0| 0003E8 ori      60210000   1     XNOP      
    0|                              CL.513:
   79| 0003EC stfdu    DC080008   1     STFDU     gr8,gvcf[](gr8,8)=fp0
   79| 0003F0 stfdu    DC090008   1     STFDU     gr9,gvcf[](gr9,8)=fp0
   79| 0003F4 stfdu    DC060008   1     STFDU     gr6,gvcf[](gr6,8)=fp0
   80| 0003F8 stfdu    DC0B0008   1     STFDU     gr11,deldotv[](gr11,8)=fp0
   79| 0003FC stfdu    DC0A0008   1     STFDU     gr10,gvcf[](gr10,8)=fp0
   80| 000400 stfdu    DC040008   1     STFDU     gr4,deldotv[](gr4,8)=fp0
   80| 000404 stfdu    DC050008   1     STFDU     gr5,deldotv[](gr5,8)=fp0
   80| 000408 stfdu    DC070008   1     STFDU     gr7,deldotv[](gr7,8)=fp0
    0| 00040C bc       4200FFE0   1     BCT       ctr=CL.513,taken=100%(100,0)
    0|                              CL.512:
    0| 000410 ld       E89F0200   1     L8        gr4=#SPILL2(gr31,512)
   82| 000414 addi     38630001   1     AI        gr3=gr3,1
   80| 000418 stfdu    DC0B0008   1     STFDU     gr11,deldotv[](gr11,8)=fp0
   82| 00041C cmpld    7CA30040   1     CL8       cr1=gr3,gr0
    0| 000420 add      7EE4BA14   1     A         gr23=gr4,gr23
    0| 000424 add      7EC4B214   1     A         gr22=gr4,gr22
    0| 000428 add      7EA4AA14   1     A         gr21=gr4,gr21
    0| 00042C add      7E84A214   1     A         gr20=gr4,gr20
    0| 000430 add      7E649A14   1     A         gr19=gr4,gr19
    0| 000434 add      7E449214   1     A         gr18=gr4,gr18
    0| 000438 add      7E248A14   1     A         gr17=gr4,gr17
    0| 00043C add      7E048214   1     A         gr16=gr4,gr16
   82| 000440 bc       4184FF5C   1     BT        CL.61,cr1,0x8/llt,taken=80%(80,20)
   82|                              CL.60:
   83| 000444 ld       E87F0348   1     L8        gr3=#SPILL0(gr31,840)
   83| 000448 ld       E89F0668   1     L8        gr4=#SPILL5(gr31,1640)
    0| 00044C ld       E8BF0660   1     L8        gr5=#SPILL4(gr31,1632)
    0| 000450 add      7DCEF214   1     A         gr14=gr14,gr30
    0| 000454 add      7FBDF214   1     A         gr29=gr29,gr30
    0| 000458 add      7F9CF214   1     A         gr28=gr28,gr30
   83| 00045C addi     38630001   1     AI        gr3=gr3,1
    0| 000460 add      7D8CF214   1     A         gr12=gr12,gr30
   83| 000464 std      F87F0348   1     ST8       #SPILL0(gr31,840)=gr3
   83| 000468 cmpld    7CA32040   1     CL8       cr1=gr3,gr4
    0| 00046C add      7CA5F214   1     A         gr5=gr5,gr30
    0| 000470 add      7F7BF214   1     A         gr27=gr27,gr30
    0| 000474 std      F8BF0660   1     ST8       #SPILL4(gr31,1632)=gr5
    0| 000478 add      7F5AF214   1     A         gr26=gr26,gr30
    0| 00047C add      7F39F214   1     A         gr25=gr25,gr30
   83| 000480 bc       4184FED8   1     BT        CL.59,cr1,0x8/llt,taken=80%(80,20)
  271| 000484 ld       E8210000   1     L8        gr1=#stack(gr1,0),gr31"
  271| 000488 ld       E9C1FEE0   1     L8        gr14=#stack(gr1,-288)
  271| 00048C ld       E9E1FEE8   1     L8        gr15=#stack(gr1,-280)
  271| 000490 ld       EA01FEF0   1     L8        gr16=#stack(gr1,-272)
  271| 000494 ld       EA21FEF8   1     L8        gr17=#stack(gr1,-264)
  271| 000498 ld       EA41FF00   1     L8        gr18=#stack(gr1,-256)
  271| 00049C ld       EA61FF08   1     L8        gr19=#stack(gr1,-248)
  271| 0004A0 ld       EA81FF10   1     L8        gr20=#stack(gr1,-240)
  271| 0004A4 ld       EAA1FF18   1     L8        gr21=#stack(gr1,-232)
  271| 0004A8 ld       EAC1FF20   1     L8        gr22=#stack(gr1,-224)
  271| 0004AC ld       EAE1FF28   1     L8        gr23=#stack(gr1,-216)
  271| 0004B0 ld       EB01FF30   1     L8        gr24=#stack(gr1,-208)
  271| 0004B4 ld       EB21FF38   1     L8        gr25=#stack(gr1,-200)
  271| 0004B8 ld       EB41FF40   1     L8        gr26=#stack(gr1,-192)
  271| 0004BC ld       EB61FF48   1     L8        gr27=#stack(gr1,-184)
  271| 0004C0 ld       EB81FF50   1     L8        gr28=#stack(gr1,-176)
  271| 0004C4 ld       EBA1FF58   1     L8        gr29=#stack(gr1,-168)
  271| 0004C8 ld       EBC1FF60   1     L8        gr30=#stack(gr1,-160)
  271| 0004CC ld       EBE1FF68   1     L8        gr31=#stack(gr1,-152)
  271| 0004D0 bclr     4E800020   1     BA        lr
   76|                              CL.720:
  271| 0004D4 ld       E8210000   1     L8        gr1=#stack(gr1,0),gr31"
  271| 0004D8 ld       EA21FEF8   1     L8        gr17=#stack(gr1,-264)
  271| 0004DC ld       EA41FF00   1     L8        gr18=#stack(gr1,-256)
  271| 0004E0 ld       EA61FF08   1     L8        gr19=#stack(gr1,-248)
  271| 0004E4 ld       EA81FF10   1     L8        gr20=#stack(gr1,-240)
  271| 0004E8 ld       EAA1FF18   1     L8        gr21=#stack(gr1,-232)
  271| 0004EC ld       EAC1FF20   1     L8        gr22=#stack(gr1,-224)
  271| 0004F0 ld       EAE1FF28   1     L8        gr23=#stack(gr1,-216)
  271| 0004F4 ld       EB01FF30   1     L8        gr24=#stack(gr1,-208)
  271| 0004F8 ld       EB21FF38   1     L8        gr25=#stack(gr1,-200)
  271| 0004FC ld       EB41FF40   1     L8        gr26=#stack(gr1,-192)
  271| 000500 ld       EB61FF48   1     L8        gr27=#stack(gr1,-184)
  271| 000504 ld       EB81FF50   1     L8        gr28=#stack(gr1,-176)
  271| 000508 ld       EBA1FF58   1     L8        gr29=#stack(gr1,-168)
  271| 00050C ld       EBC1FF60   1     L8        gr30=#stack(gr1,-160)
  271| 000510 ld       EBE1FF68   1     L8        gr31=#stack(gr1,-152)
  271| 000514 bclr     4E800020   1     BA        lr
   82|                              CL.231:
    0| 000518 mtspr    7D2903A6   1     LCTR      ctr=gr9
   82|                              CL.220:
   83| 00051C addi     396B0001   1     AI        gr11=gr11,1
   83| 000520 cmpd     7F2B4800   1     C8        cr6=gr11,gr9
   83| 000524 bc       4118FFF8   1     BCTT      ctr=CL.220,cr6,0x1/lt,taken=80%(80,20)
    0| 000528 b        4BFFFD6C   1     B         CL.93,-1
   85|                              CL.1:
   88| 00052C bc       4085FFA8   1     BF        CL.720,cr1,0x2/gt,taken=20%(20,80)
    0| 000530 rldicr   7BDB1F24   1     SLL8      gr27=gr30,3
   96| 000534 ld       E9820000   1     L8        gr12=.&&N&field(gr2,0)
  194| 000538 neg      7F5B00D0   1     COMP      gr26=gr27
   88| 00053C lwa      E9E50002   1     L4A       gr15=jbeg(gr5,0)
  194| 000540 mulld    7DC8D1D2   1     M         gr14=gr8,gr26
   88| 000544 std      F9FF0340   1     ST8       #SPILL12(gr31,832)=gr15
  194| 000548 std      F9DF0600   1     ST8       #SPILL55(gr31,1536)=gr14
   88| 00054C lwa      E8C60002   1     L4A       gr6=jend(gr6,0)
  105| 000550 lwa      EB9C0006   1     L4A       gr28=<s423:d4:l4>(gr28,4)
  257| 000554 ld       E9620000   1     L8        gr11=.&&N&grid(gr2,0)
    0| 000558 mulld    7F28D9D2   1     M         gr25=gr8,gr27
  105| 00055C std      FB9F0618   1     ST8       #SPILL56(gr31,1560)=gr28
    0| 000560 std      FB3F01F8   1     ST8       #SPILL13(gr31,504)=gr25
  194| 000564 addi     3B4EFFF0   1     AI        gr26=gr14,-16
  107| 000568 ld       EBAC0208   1     L8        gr29=<s120:d520:l8>(gr12,520)
  107| 00056C ld       E8AC0268   1     L8        gr5=<s120:d616:l8>(gr12,616)
   88| 000570 subf     7CCF3050   1     S         gr6=gr6,gr15
  194| 000574 add      7F09D214   1     A         gr24=gr9,gr26
  107| 000578 ld       EB8C0220   1     L8        gr28=<s120:d544:l8>(gr12,544)
  194| 00057C std      FB1F06C0   1     ST8       #SPILL14(gr31,1728)=gr24
  212| 000580 ld       EA020000   1     L8        gr16=.&&N&opac(gr2,0)
  110| 000584 ld       E80C0270   1     L8        gr0=<s120:d624:l8>(gr12,624)
  110| 000588 ld       E8EC02D0   1     L8        gr7=<s120:d720:l8>(gr12,720)
   88| 00058C addic.   36E60001   1     AI_R      gr23,cr0=gr6,1,ca"
   96| 000590 ld       EB2C01A0   1     L8        gr25=<s120:d416:l8>(gr12,416)
   88| 000594 std      FAFF0138   1     ST8       #SPILL15(gr31,312)=gr23
  110| 000598 ld       EB6B0CE8   1     L8        gr27=<s149:d3304:l8>(gr11,3304)
   96| 00059C ld       EB0C01B8   1     L8        gr24=<s120:d440:l8>(gr12,440)
  110| 0005A0 ld       EB4B0D00   1     L8        gr26=<s149:d3328:l8>(gr11,3328)
  110| 0005A4 ld       E8CC0288   1     L8        gr6=<s120:d648:l8>(gr12,648)
  212| 0005A8 ld       E9E20000   1     L8        gr15=.&&N&opac(gr2,0)
  155| 0005AC add      7EFCEA14   1     A         gr23=gr28,gr29
  107| 0005B0 subf     7FA5E850   1     S         gr29=gr29,gr5
  155| 0005B4 std      FAFF0590   1     ST8       #SPILL18(gr31,1424)=gr23
    0| 0005B8 add      7E38CA14   1     A         gr17=gr24,gr25
    0| 0005BC add      7F3ADA14   1     A         gr25=gr26,gr27
    0| 0005C0 std      FA3F05E0   1     ST8       #SPILL17(gr31,1504)=gr17
    0| 0005C4 std      FB3F0370   1     ST8       #SPILL19(gr31,880)=gr25
  157| 0005C8 add      7F603214   1     A         gr27=gr0,gr6
  107| 0005CC add      7F1CEA14   1     A         gr24=gr28,gr29
  157| 0005D0 std      FB7F0598   1     ST8       #SPILL20(gr31,1432)=gr27
  107| 0005D4 std      FB1F05A0   1     ST8       #SPILL21(gr31,1440)=gr24
  110| 0005D8 subf     7C070050   1     S         gr0=gr0,gr7
  212| 0005DC ld       EBB003A8   1     L8        gr29=<s394:d936:l8>(gr16,936)
  212| 0005E0 ld       EB8F03C0   1     L8        gr28=<s394:d960:l8>(gr15,960)
  110| 0005E4 add      7E403214   1     A         gr18=gr0,gr6
  212| 0005E8 ld       E81000D0   1     L8        gr0=<s394:d208:l8>(gr16,208)
  110| 0005EC std      FA5F05A8   1     ST8       #SPILL22(gr31,1448)=gr18
  212| 0005F0 ld       E8CF00E8   1     L8        gr6=<s394:d232:l8>(gr15,232)
  101| 0005F4 ld       EA2B0C40   1     L8        gr17=<s149:d3136:l8>(gr11,3136)
  101| 0005F8 ld       EA0B0C58   1     L8        gr16=<s149:d3160:l8>(gr11,3160)
    0| 0005FC mfcr     7EC00026   1     LFCR      gr22=cr0,0
    0| 000600 add      7FBDE214   1     A         gr29=gr29,gr28
    0| 000604 std      FADF0710   1     ST8       #SPILL16(gr31,1808)=gr22
    0| 000608 std      FBBF0240   1     ST8       #SPILL27(gr31,576)=gr29
  194| 00060C ld       EB2B0850   1     L8        gr25=<s149:d2128:l8>(gr11,2128)
  200| 000610 ld       EB6B0888   1     L8        gr27=<s149:d2184:l8>(gr11,2184)
  194| 000614 ld       EB0B0868   1     L8        gr24=<s149:d2152:l8>(gr11,2152)
  200| 000618 ld       EB4B08A0   1     L8        gr26=<s149:d2208:l8>(gr11,2208)
  257| 00061C ld       EACB05E8   1     L8        gr22=<s149:d1512:l8>(gr11,1512)
  257| 000620 ld       EA8B0460   1     L8        gr20=<s149:d1120:l8>(gr11,1120)
    0| 000624 add      7C003214   1     A         gr0=gr0,gr6
  257| 000628 ld       EBAB0478   1     L8        gr29=<s149:d1144:l8>(gr11,1144)
    0| 00062C std      F81F02B0   1     ST8       #SPILL28(gr31,688)=gr0
  119| 000630 ld       EA6B08F8   1     L8        gr19=<s149:d2296:l8>(gr11,2296)
  257| 000634 ld       EAAB0428   1     L8        gr21=<s149:d1064:l8>(gr11,1064)
  119| 000638 ld       EAEB0910   1     L8        gr23=<s149:d2320:l8>(gr11,2320)
    0| 00063C add      7DD08A14   1     A         gr14=gr16,gr17
  257| 000640 ld       EB8B0440   1     L8        gr28=<s149:d1088:l8>(gr11,1088)
    0| 000644 std      F9DF06B0   1     ST8       #SPILL23(gr31,1712)=gr14
  257| 000648 ld       E80B0600   1     L8        gr0=<s149:d1536:l8>(gr11,1536)
  194| 00064C add      7F39C214   1     A         gr25=gr25,gr24
  200| 000650 add      7F7BD214   1     A         gr27=gr27,gr26
  194| 000654 std      FB3F01D8   1     ST8       #SPILL25(gr31,472)=gr25
  200| 000658 std      FB7F01E8   1     ST8       #SPILL26(gr31,488)=gr27
  107| 00065C ld       EB0C0250   1     L8        gr24=<s120:d592:l8>(gr12,592)
  110| 000660 ld       EB4C02A0   1     L8        gr26=<s120:d672:l8>(gr12,672)
  163| 000664 ld       E9CB0540   1     L8        gr14=<s149:d1344:l8>(gr11,1344)
    0| 000668 add      7E94EA14   1     A         gr20=gr20,gr29
    0| 00066C addi     3BB60008   1     AI        gr29=gr22,8
    0| 000670 std      FA9F0378   1     ST8       #SPILL33(gr31,888)=gr20
  107| 000674 std      FB1F0140   1     ST8       #SPILL29(gr31,320)=gr24
  110| 000678 std      FB5F0208   1     ST8       #SPILL30(gr31,520)=gr26
  163| 00067C std      F9DF0610   1     ST8       #SPILL57(gr31,1552)=gr14
  119| 000680 add      7E53BA14   1     A         gr18=gr19,gr23
    0| 000684 add      7EB5E214   1     A         gr21=gr21,gr28
    0| 000688 add      7DE0B214   1     A         gr15=gr0,gr22
    0| 00068C add      7EC0EA14   1     A         gr22=gr0,gr29
  119| 000690 std      FA5F0470   1     ST8       #SPILL24(gr31,1136)=gr18
    0| 000694 std      FABF0358   1     ST8       #SPILL31(gr31,856)=gr21
   96| 000698 ld       E8CC0200   1     L8        gr6=<s120:d512:l8>(gr12,512)
    0| 00069C std      F9FF0368   1     ST8       #SPILL32(gr31,872)=gr15
  257| 0006A0 ld       EA4B03F0   1     L8        gr18=<s149:d1008:l8>(gr11,1008)
    0| 0006A4 std      FADF0360   1     ST8       #SPILL34(gr31,864)=gr22
  257| 0006A8 ld       EAAB0498   1     L8        gr21=<s149:d1176:l8>(gr11,1176)
  257| 0006AC ld       EB0B04D0   1     L8        gr24=<s149:d1232:l8>(gr11,1232)
  166| 0006B0 ld       E9EB0578   1     L8        gr15=<s149:d1400:l8>(gr11,1400)
  189| 0006B4 ld       EB4B0818   1     L8        gr26=<s149:d2072:l8>(gr11,2072)
  128| 0006B8 ld       EB6B0930   1     L8        gr27=<s149:d2352:l8>(gr11,2352)
   98| 0006BC ld       EB2B0C08   1     L8        gr25=<s149:d3080:l8>(gr11,3080)
  163| 0006C0 ld       E80B0558   1     L8        gr0=<s149:d1368:l8>(gr11,1368)
   98| 0006C4 ld       EB8B0C20   1     L8        gr28=<s149:d3104:l8>(gr11,3104)
   98| 0006C8 std      FB3F0700   1     ST8       #SPILL68(gr31,1792)=gr25
  189| 0006CC ld       EBAB0830   1     L8        gr29=<s149:d2096:l8>(gr11,2096)
  257| 0006D0 ld       EA8B0408   1     L8        gr20=<s149:d1032:l8>(gr11,1032)
  257| 0006D4 ld       EACB04B0   1     L8        gr22=<s149:d1200:l8>(gr11,1200)
  163| 0006D8 std      F81F0608   1     ST8       #SPILL58(gr31,1544)=gr0
   96| 0006DC ld       E80C01D0   1     L8        gr0=<s120:d464:l8>(gr12,464)
   98| 0006E0 std      FB9F05F8   1     ST8       #SPILL60(gr31,1528)=gr28
  128| 0006E4 ld       EB8B0948   1     L8        gr28=<s149:d2376:l8>(gr11,2376)
  257| 0006E8 ld       EB2B04E8   1     L8        gr25=<s149:d1256:l8>(gr11,1256)
  166| 0006EC ld       E9CB0590   1     L8        gr14=<s149:d1424:l8>(gr11,1424)
   96| 0006F0 std      F81F0218   1     ST8       #SPILL35(gr31,536)=gr0
   96| 0006F4 ld       E80C01E8   1     L8        gr0=<s120:d488:l8>(gr12,488)
    0| 0006F8 add      7F9BE214   1     A         gr28=gr27,gr28
  189| 0006FC add      7F7AEA14   1     A         gr27=gr26,gr29
    0| 000700 add      7F58CA14   1     A         gr26=gr24,gr25
  189| 000704 std      FB7F06A8   1     ST8       #SPILL51(gr31,1704)=gr27
    0| 000708 std      FB5F0698   1     ST8       #SPILL52(gr31,1688)=gr26
   96| 00070C std      F81F0128   1     ST8       #SPILL36(gr31,296)=gr0
  107| 000710 ld       E80C0238   1     L8        gr0=<s120:d568:l8>(gr12,568)
  110| 000714 ld       E98C02B8   1     L8        gr12=<s120:d696:l8>(gr12,696)
    0| 000718 add      7F15B214   1     A         gr24=gr21,gr22
    0| 00071C add      7EB2A214   1     A         gr21=gr18,gr20
    0| 000720 std      FB1F0690   1     ST8       #SPILL53(gr31,1680)=gr24
    0| 000724 ld       EBBF0600   1     L8        gr29=#SPILL55(gr31,1536)
  107| 000728 std      F81F0210   1     ST8       #SPILL37(gr31,528)=gr0
  110| 00072C std      F99F0158   1     ST8       #SPILL38(gr31,344)=gr12
  212| 000730 ld       E9820000   1     L8        gr12=.&&N&opac(gr2,0)
    0| 000734 ld       EA9F0200   1     L8        gr20=#SPILL2(gr31,512)
    0| 000738 ld       EA5F0618   1     L8        gr18=#SPILL56(gr31,1560)
    0| 00073C std      FABF0688   1     ST8       #SPILL54(gr31,1672)=gr21
  212| 000740 ld       E80C0100   1     L8        gr0=<s394:d256:l8>(gr12,256)
    0| 000744 subf     7ED4E850   1     S         gr22=gr29,gr20
   97| 000748 ld       EBBF06F8   1     L8        gr29=#SPILL59(gr31,1784)
    0| 00074C std      FADF0600   1     ST8       #SPILL55(gr31,1536)=gr22
    0| 000750 cmpwi    2C920001   1     C4        cr1=gr18,1
    0| 000754 cmpwi    2F120003   1     C4        cr6=gr18,3
  212| 000758 std      F81F0230   1     ST8       #SPILL39(gr31,560)=gr0
    0| 00075C ld       E81F0340   1     L8        gr0=#SPILL12(gr31,832)
   98| 000760 ld       EA5F0700   1     L8        gr18=#SPILL68(gr31,1792)
    0| 000764 rldicr   780C1F24   1     SLL8      gr12=gr0,3
    0| 000768 std      F99F0588   1     ST8       #SPILL40(gr31,1416)=gr12
  155| 00076C rldicr   78AC0FA4   1     SLL8      gr12=gr5,1
    0| 000770 ld       E81F0588   1     L8        gr0=#SPILL40(gr31,1416)
    0| 000774 add      7C009A14   1     A         gr0=gr0,gr19
  155| 000778 ld       EA7F0590   1     L8        gr19=#SPILL18(gr31,1424)
    0| 00077C add      7EF70214   1     A         gr23=gr23,gr0
  157| 000780 rldicr   78E00FA4   1     SLL8      gr0=gr7,1
    0| 000784 std      FAFF0578   1     ST8       #SPILL42(gr31,1400)=gr23
  155| 000788 subf     7D8C9850   1     S         gr12=gr19,gr12
  155| 00078C std      F99F05B0   1     ST8       #SPILL41(gr31,1456)=gr12
   88| 000790 addi     39800000   1     LI        gr12=0
   88| 000794 std      F99F0350   1     ST8       #SPILL43(gr31,848)=gr12
  157| 000798 ld       E99F0598   1     L8        gr12=#SPILL20(gr31,1432)
  157| 00079C subf     7C006050   1     S         gr0=gr12,gr0
  157| 0007A0 std      F81F05C0   1     ST8       #SPILL44(gr31,1472)=gr0
    0| 0007A4 ld       E81F0140   1     L8        gr0=#SPILL29(gr31,320)
    0| 0007A8 add      7EE09A14   1     A         gr23=gr0,gr19
  107| 0007AC ld       EA7F05A0   1     L8        gr19=#SPILL21(gr31,1440)
    0| 0007B0 std      FAFF05B8   1     ST8       #SPILL45(gr31,1464)=gr23
  107| 0007B4 add      7EE09A14   1     A         gr23=gr0,gr19
    0| 0007B8 ld       E81F0208   1     L8        gr0=#SPILL30(gr31,520)
  107| 0007BC std      FAFF05D0   1     ST8       #SPILL46(gr31,1488)=gr23
    0| 0007C0 add      7E606214   1     A         gr19=gr0,gr12
  110| 0007C4 ld       E99F05A8   1     L8        gr12=#SPILL22(gr31,1448)
    0| 0007C8 std      FA7F05C8   1     ST8       #SPILL47(gr31,1480)=gr19
  110| 0007CC add      7EE06214   1     A         gr23=gr0,gr12
    0| 0007D0 ld       E81F0588   1     L8        gr0=#SPILL40(gr31,1416)
  110| 0007D4 std      FAFF05D8   1     ST8       #SPILL48(gr31,1496)=gr23
    0| 0007D8 ld       E99F0370   1     L8        gr12=#SPILL19(gr31,880)
    0| 0007DC add      7E606214   1     A         gr19=gr0,gr12
    0| 0007E0 ld       E81F05E0   1     L8        gr0=#SPILL17(gr31,1504)
    0| 0007E4 std      FA7F0580   1     ST8       #SPILL49(gr31,1408)=gr19
    0| 0007E8 add      7D803214   1     A         gr12=gr0,gr6
    0| 0007EC rldicr   7BC026E4   1     SLL8      gr0=gr30,4
    0| 0007F0 std      F99F0630   1     ST8       #SPILL50(gr31,1584)=gr12
    0| 0007F4 neg      7D8000D0   1     COMP      gr12=gr0
  101| 0007F8 addi     3811FFF8   1     AI        gr0=gr17,-8
    0| 0007FC mulld    7FC861D2   1     M         gr30=gr8,gr12
  101| 000800 add      7E208214   1     A         gr17=gr0,gr16
  166| 000804 addi     380FFFF8   1     AI        gr0=gr15,-8
  101| 000808 std      FA3F0618   1     ST8       #SPILL56(gr31,1560)=gr17
  163| 00080C ld       EA1F0610   1     L8        gr16=#SPILL57(gr31,1552)
  166| 000810 add      7DE07214   1     A         gr15=gr0,gr14
  163| 000814 ld       E9DF0608   1     L8        gr14=#SPILL58(gr31,1544)
  166| 000818 std      F9FF0610   1     ST8       #SPILL57(gr31,1552)=gr15
  194| 00081C rldicr   790C26E4   1     SLL8      gr12=gr8,4
   98| 000820 addi     3812FFF8   1     AI        gr0=gr18,-8
  163| 000824 addi     3910FFF8   1     AI        gr8=gr16,-8
   97| 000828 addi     3A1D0070   1     AI        gr16=gr29,112
  163| 00082C add      7F287214   1     A         gr25=gr8,gr14
   97| 000830 std      FA1F06F8   1     ST8       #SPILL59(gr31,1784)=gr16
  163| 000834 std      FB3F0608   1     ST8       #SPILL58(gr31,1544)=gr25
   98| 000838 ld       E9DF05F8   1     L8        gr14=#SPILL60(gr31,1528)
  155| 00083C ld       EBBF06E0   1     L8        gr29=#SPILL61(gr31,1760)
   98| 000840 add      7E407214   1     A         gr18=gr0,gr14
  155| 000844 addi     39DD0070   1     AI        gr14=gr29,112
   98| 000848 std      FA5F05F8   1     ST8       #SPILL60(gr31,1528)=gr18
  155| 00084C std      F9DF06E0   1     ST8       #SPILL61(gr31,1760)=gr14
   98| 000850 ld       EBBF06D8   1     L8        gr29=#SPILL62(gr31,1752)
  119| 000854 ld       E91F06C8   1     L8        gr8=#SPILL63(gr31,1736)
    0| 000858 add      7D4AB214   1     A         gr10=gr10,gr22
    0| 00085C ld       EAEB0BD0   1     L8        gr23=<s149:d3024:l8>(gr11,3024)
    0| 000860 std      F95F06E8   1     ST8       #SPILL70(gr31,1768)=gr10
    0| 000864 ld       E94B0280   1     L8        gr10=<s149:d640:l8>(gr11,640)
    0| 000868 ld       EA6B0C78   1     L8        gr19=<s149:d3192:l8>(gr11,3192)
  119| 00086C addi     38080070   1     AI        gr0=gr8,112
  128| 000870 ld       E91F06B8   1     L8        gr8=#SPILL64(gr31,1720)
  119| 000874 std      F81F06C8   1     ST8       #SPILL63(gr31,1736)=gr0
    0| 000878 std      FAFF04C8   1     ST8       #SPILL73(gr31,1224)=gr23
    0| 00087C ld       EB6B0210   1     L8        gr27=<s149:d528:l8>(gr11,528)
    0| 000880 std      FA7F04C0   1     ST8       #SPILL74(gr31,1216)=gr19
   98| 000884 addi     3BBD0070   1     AI        gr29=gr29,112
  128| 000888 addi     38080070   1     AI        gr0=gr8,112
  157| 00088C ld       E91F06A0   1     L8        gr8=#SPILL65(gr31,1696)
  128| 000890 std      F81F06B8   1     ST8       #SPILL64(gr31,1720)=gr0
   98| 000894 std      FBBF06D8   1     ST8       #SPILL62(gr31,1752)=gr29
    0| 000898 std      FB7F04F0   1     ST8       #SPILL75(gr31,1264)=gr27
  157| 00089C addi     38080070   1     AI        gr0=gr8,112
  166| 0008A0 ld       E91F0620   1     L8        gr8=#SPILL66(gr31,1568)
  157| 0008A4 std      F81F06A0   1     ST8       #SPILL65(gr31,1696)=gr0
  166| 0008A8 addi     38080070   1     AI        gr0=gr8,112
  163| 0008AC ld       E91F0628   1     L8        gr8=#SPILL67(gr31,1576)
  166| 0008B0 std      F81F0620   1     ST8       #SPILL66(gr31,1568)=gr0
  163| 0008B4 addi     38080070   1     AI        gr0=gr8,112
    0| 0008B8 ld       E90B0D20   1     L8        gr8=<s149:d3360:l8>(gr11,3360)
  163| 0008BC std      F81F0628   1     ST8       #SPILL67(gr31,1576)=gr0
  194| 0008C0 ld       E81F06C0   1     L8        gr0=#SPILL14(gr31,1728)
  194| 0008C4 subf     7D8C0050   1     S         gr12=gr0,gr12
    0| 0008C8 subf     7C144850   1     S         gr0=gr9,gr20
  194| 0008CC std      F99F0700   1     ST8       #SPILL68(gr31,1792)=gr12
    0| 0008D0 std      F81F05F0   1     ST8       #SPILL69(gr31,1520)=gr0
    0| 0008D4 add      7FC0F214   1     A         gr30=gr0,gr30
    0| 0008D8 ld       E80B0D38   1     L8        gr0=<s149:d3384:l8>(gr11,3384)
    0| 0008DC ld       E98B0268   1     L8        gr12=<s149:d616:l8>(gr11,616)
    0| 0008E0 std      FBDF0680   1     ST8       #SPILL71(gr31,1664)=gr30
    0| 0008E4 ld       EA8B01F8   1     L8        gr20=<s149:d504:l8>(gr11,504)
    0| 0008E8 add      7FC04214   1     A         gr30=gr0,gr8
    0| 0008EC add      7D8C5214   1     A         gr12=gr12,gr10
    0| 0008F0 std      FBDF04A8   1     ST8       #SPILL76(gr31,1192)=gr30
    0| 0008F4 ld       E94B0230   1     L8        gr10=<s149:d560:l8>(gr11,560)
    0| 0008F8 ld       EBCB0248   1     L8        gr30=<s149:d584:l8>(gr11,584)
    0| 0008FC ld       E90B0BE8   1     L8        gr8=<s149:d3048:l8>(gr11,3048)
    0| 000900 std      F99F04A0   1     ST8       #SPILL77(gr31,1184)=gr12
    0| 000904 ld       E98B0620   1     L8        gr12=<s149:d1568:l8>(gr11,1568)
    0| 000908 ld       E80B0C90   1     L8        gr0=<s149:d3216:l8>(gr11,3216)
    0| 00090C std      F95F0488   1     ST8       #SPILL80(gr31,1160)=gr10
    0| 000910 std      FBDF0498   1     ST8       #SPILL81(gr31,1176)=gr30
    0| 000914 ld       E94B0670   1     L8        gr10=<s149:d1648:l8>(gr11,1648)
    0| 000918 ld       EBCB08C0   1     L8        gr30=<s149:d2240:l8>(gr11,2240)
    0| 00091C std      F91F04E8   1     ST8       #SPILL78(gr31,1256)=gr8
    0| 000920 ld       E90B0658   1     L8        gr8=<s149:d1624:l8>(gr11,1624)
    0| 000924 std      F99F0450   1     ST8       #SPILL82(gr31,1104)=gr12
    0| 000928 ld       E98B08D8   1     L8        gr12=<s149:d2264:l8>(gr11,2264)
    0| 00092C std      F95F0468   1     ST8       #SPILL85(gr31,1128)=gr10
    0| 000930 std      FBDF0428   1     ST8       #SPILL86(gr31,1064)=gr30
    0| 000934 ld       E95F0140   1     L8        gr10=#SPILL29(gr31,320)
    0| 000938 ld       EBDF0340   1     L8        gr30=#SPILL12(gr31,832)
    0| 00093C std      F91F0460   1     ST8       #SPILL83(gr31,1120)=gr8
    0| 000940 ld       E90B0508   1     L8        gr8=<s149:d1288:l8>(gr11,1288)
    0| 000944 std      F81F04E0   1     ST8       #SPILL79(gr31,1248)=gr0
    0| 000948 ld       E80B0638   1     L8        gr0=<s149:d1592:l8>(gr11,1592)
    0| 00094C std      F99F0410   1     ST8       #SPILL87(gr31,1040)=gr12
    0| 000950 ld       E99F0348   1     L8        gr12=#SPILL0(gr31,840)
    0| 000954 std      FA9F04D0   1     ST8       #SPILL72(gr31,1232)=gr20
    0| 000958 std      F91F0390   1     ST8       #SPILL88(gr31,912)=gr8
    0| 00095C mulld    7D0AF1D2   1     M         gr8=gr10,gr30
    0| 000960 ld       E95F0210   1     L8        gr10=#SPILL37(gr31,528)
    0| 000964 std      F81F0458   1     ST8       #SPILL84(gr31,1112)=gr0
    0| 000968 ld       E80B05B0   1     L8        gr0=<s149:d1456:l8>(gr11,1456)
    0| 00096C std      F81F03A8   1     ST8       #SPILL89(gr31,936)=gr0
    0| 000970 mulld    7C0A61D2   1     M         gr0=gr10,gr12
    0| 000974 ld       E95F0158   1     L8        gr10=#SPILL38(gr31,344)
    0| 000978 add      7C004214   1     A         gr0=gr0,gr8
    0| 00097C ld       E91F0208   1     L8        gr8=#SPILL30(gr31,520)
    0| 000980 mulld    7D4AF1D2   1     M         gr10=gr10,gr30
    0| 000984 mulld    7D0861D2   1     M         gr8=gr8,gr12
    0| 000988 ld       E99F05A0   1     L8        gr12=#SPILL21(gr31,1440)
    0| 00098C add      7D085214   1     A         gr8=gr8,gr10
    0| 000990 ld       E95F0128   1     L8        gr10=#SPILL36(gr31,296)
    0| 000994 add      7C006214   1     A         gr0=gr0,gr12
    0| 000998 std      F81F0528   1     ST8       #SPILL90(gr31,1320)=gr0
    0| 00099C mulld    7C0AF1D2   1     M         gr0=gr10,gr30
    0| 0009A0 ld       EBDF05A8   1     L8        gr30=#SPILL22(gr31,1448)
    0| 0009A4 ld       E95F0218   1     L8        gr10=#SPILL35(gr31,536)
    0| 0009A8 add      7D88F214   1     A         gr12=gr8,gr30
    0| 0009AC ld       E91F0348   1     L8        gr8=#SPILL0(gr31,840)
    0| 0009B0 ld       EBDF05E0   1     L8        gr30=#SPILL17(gr31,1504)
    0| 0009B4 std      F99F0540   1     ST8       #SPILL91(gr31,1344)=gr12
    0| 0009B8 mulld    7D4851D2   1     M         gr10=gr8,gr10
    0| 0009BC add      7D80F214   1     A         gr12=gr0,gr30
    0| 0009C0 ld       E9020000   1     L8        gr8=.+CONSTANT_AREA(gr2,0)
    0| 0009C4 add      7D8A6214   1     A         gr12=gr10,gr12
    0| 0009C8 std      F99F0568   1     ST8       #SPILL92(gr31,1384)=gr12
    0| 0009CC subf     7D86F050   1     S         gr12=gr30,gr6
    0| 0009D0 std      F99F05E8   1     ST8       #SPILL93(gr31,1512)=gr12
  189| 0009D4 addi     3996FFE8   1     AI        gr12=gr22,-24
  189| 0009D8 add      7D296214   1     A         gr9=gr9,gr12
  189| 0009DC std      F93F06F0   1     ST8       #SPILL94(gr31,1776)=gr9
    0| 0009E0 ld       EBDF05E8   1     L8        gr30=#SPILL93(gr31,1512)
    0| 0009E4 add      7FDE0214   1     A         gr30=gr30,gr0
    0| 0009E8 ld       E99F05E8   1     L8        gr12=#SPILL93(gr31,1512)
    0| 0009EC ld       EB5F0540   1     L8        gr26=#SPILL91(gr31,1344)
  101| 0009F0 addi     3AA10070   1     AI        gr21=gr1,112
    0| 0009F4 lfs      C0080000   1     LFS       fp0=+CONSTANT_AREA(gr8,0)
  101| 0009F8 std      FABF06D0   1     ST8       #SPILL99(gr31,1744)=gr21
    0| 0009FC lfs      C0280004   1     LFS       fp1=+CONSTANT_AREA(gr8,4)
    0| 000A00 add      7C0A6214   1     A         gr0=gr10,gr12
    0| 000A04 ld       E95F0128   1     L8        gr10=#SPILL36(gr31,296)
    0| 000A08 lfs      C0480008   1     LFS       fp2=+CONSTANT_AREA(gr8,8)
    0| 000A0C lfs      C068000C   1     LFS       fp3=+CONSTANT_AREA(gr8,12)
    0| 000A10 lfd      C8880010   1     LFL       fp4=+CONSTANT_AREA(gr8,16)
    0| 000A14 lfs      C0A80030   1     LFS       fp5=+CONSTANT_AREA(gr8,48)
    0| 000A18 subf     7FCAF050   1     S         gr30=gr30,gr10
    0| 000A1C ld       E95F0218   1     L8        gr10=#SPILL35(gr31,536)
    0| 000A20 std      FBDF0708   1     ST8       #SPILL95(gr31,1800)=gr30
    0| 000A24 subf     7C0A0050   1     S         gr0=gr0,gr10
    0| 000A28 ld       E95F0528   1     L8        gr10=#SPILL90(gr31,1320)
    0| 000A2C std      F81F0570   1     ST8       #SPILL96(gr31,1392)=gr0
    0| 000A30 ld       E81F0140   1     L8        gr0=#SPILL29(gr31,320)
    0| 000A34 add      7D805214   1     A         gr12=gr0,gr10
    0| 000A38 ld       E81F0208   1     L8        gr0=#SPILL30(gr31,520)
    0| 000A3C std      F99F0530   1     ST8       #SPILL97(gr31,1328)=gr12
    0| 000A40 add      7F00D214   1     A         gr24=gr0,gr26
    0| 000A44 ld       E81F0348   1     L8        gr0=#SPILL0(gr31,840)
    0| 000A48 std      FB1F0560   1     ST8       #SPILL98(gr31,1376)=gr24
    0| 000A4C rldicr   78001F24   1     SLL8      gr0=gr0,3
    0| 000A50 add      7F80E214   1     A         gr28=gr0,gr28
    0| 000A54 ld       E81F0210   1     L8        gr0=#SPILL37(gr31,528)
    0| 000A58 std      FB9F0430   1     ST8       #SPILL100(gr31,1072)=gr28
    0| 000A5C subf     7EC06050   1     S         gr22=gr12,gr0
    0| 000A60 subf     7E205050   1     S         gr17=gr10,gr0
    0| 000A64 std      FADF0500   1     ST8       #SPILL101(gr31,1280)=gr22
    0| 000A68 std      FA3F0510   1     ST8       #SPILL102(gr31,1296)=gr17
    0| 000A6C add      7DE05214   1     A         gr15=gr0,gr10
    0| 000A70 add      7D406214   1     A         gr10=gr0,gr12
    0| 000A74 std      F9FF0518   1     ST8       #SPILL103(gr31,1304)=gr15
    0| 000A78 std      F95F0520   1     ST8       #SPILL104(gr31,1312)=gr10
    0| 000A7C ld       E81F0158   1     L8        gr0=#SPILL38(gr31,344)
    0| 000A80 add      7F20C214   1     A         gr25=gr0,gr24
    0| 000A84 add      7E00D214   1     A         gr16=gr0,gr26
    0| 000A88 std      FB3F0538   1     ST8       #SPILL105(gr31,1336)=gr25
    0| 000A8C std      FA1F0548   1     ST8       #SPILL106(gr31,1352)=gr16
    0| 000A90 subf     7E40C050   1     S         gr18=gr24,gr0
    0| 000A94 subf     7DC0D050   1     S         gr14=gr26,gr0
    0| 000A98 std      FA5F0550   1     ST8       #SPILL107(gr31,1360)=gr18
    0| 000A9C std      F9DF0558   1     ST8       #SPILL108(gr31,1368)=gr14
    0| 000AA0 ld       E80B0520   1     L8        gr0=<s149:d1312:l8>(gr11,1312)
    0| 000AA4 ld       EB420000   1     L8        gr26=.&&N&opac(gr2,0)
    0| 000AA8 ld       E96B05C8   1     L8        gr11=<s149:d1480:l8>(gr11,1480)
    0| 000AAC std      F81F03B8   1     ST8       #SPILL109(gr31,952)=gr0
    0| 000AB0 ld       E81A0118   1     L8        gr0=<s394:d280:l8>(gr26,280)
    0| 000AB4 std      F97F0380   1     ST8       #SPILL110(gr31,896)=gr11
    0| 000AB8 std      F81F0228   1     ST8       #SPILL111(gr31,552)=gr0
    0| 000ABC ld       E81A0130   1     L8        gr0=<s394:d304:l8>(gr26,304)
    0| 000AC0 std      F81F0098   1     ST8       #SPILL112(gr31,152)=gr0
    0| 000AC4 ld       E81A03D8   1     L8        gr0=<s394:d984:l8>(gr26,984)
    0| 000AC8 std      F81F0238   1     ST8       #SPILL113(gr31,568)=gr0
    0| 000ACC ld       E81A03F0   1     L8        gr0=<s394:d1008:l8>(gr26,1008)
    0| 000AD0 std      F81F0220   1     ST8       #SPILL114(gr31,544)=gr0
    0| 000AD4 ld       E81A0408   1     L8        gr0=<s394:d1032:l8>(gr26,1032)
   88|                              CL.65:
   89| 000AD8 ld       E93F0710   1     L8        gr9=#SPILL16(gr31,1808)
   89| 000ADC mtcrf    7D280120   1     MTCRF     cr0=gr9,0
   89| 000AE0 bc       408116A0   1     BF        CL.66,cr0,0x2/gt,taken=20%(20,80)
   89| 000AE4 lwz      81440000   1     L4Z       gr10=iend(gr4,0)
   89| 000AE8 lwa      EBA30002   1     L4A       gr29=ibeg(gr3,0)
  110| 000AEC ld       E9DF05A8   1     L8        gr14=#SPILL22(gr31,1448)
  107| 000AF0 ld       EA1F05A0   1     L8        gr16=#SPILL21(gr31,1440)
  110| 000AF4 ld       EA5F0598   1     L8        gr18=#SPILL20(gr31,1432)
  107| 000AF8 ld       EA9F0590   1     L8        gr20=#SPILL18(gr31,1424)
   89| 000AFC addi     392A0001   1     AI        gr9=gr10,1
   89| 000B00 std      FBBF02A8   1     ST8       #SPILL115(gr31,680)=gr29
  147| 000B04 extsw    7D2C07B4   1     EXTS4     gr12=gr9
   89| 000B08 extsw    7D4B07B4   1     EXTS4     gr11=gr10
  147| 000B0C subf     7D3D6050   1     S         gr9=gr12,gr29
   89| 000B10 subf     7FDD5850   1     S         gr30=gr11,gr29
  147| 000B14 addi     39290001   1     AI        gr9=gr9,1
   89| 000B18 addic.   37DE0001   1     AI_R      gr30,cr0=gr30,1,ca"
    0| 000B1C cmpdi    2FA90000   1     C8        cr7=gr9,0
    0| 000B20 subfic   213D0001   1     SFI       gr9=1,gr29,ca"
    0| 000B24 addi     3BCA0002   1     AI        gr30=gr10,2
    0| 000B28 add      7EE95A14   1     A         gr23=gr9,gr11
    0| 000B2C add      7EC96214   1     A         gr22=gr9,gr12
    0| 000B30 std      FAFF01F0   1     ST8       #SPILL120(gr31,496)=gr23
    0| 000B34 std      FADF03E8   1     ST8       #SPILL121(gr31,1000)=gr22
    0| 000B38 add      7D295214   1     A         gr9=gr9,gr10
  107| 000B3C mulld    7D45E9D2   1     M         gr10=gr5,gr29
  155| 000B40 ld       E99F05B0   1     L8        gr12=#SPILL41(gr31,1456)
    0| 000B44 rlwinm   552907FE   1     RN4       gr9=gr9,0,0x1
    0| 000B48 subf     7FDDF050   1     S         gr30=gr30,gr29
    0| 000B4C cmpdi    2EA90000   1     C8        cr5=gr9,0
    0| 000B50 rlwinm   57D507FE   1     RN4       gr21=gr30,0,0x1
  110| 000B54 mulld    7D27E9D2   1     M         gr9=gr7,gr29
    0| 000B58 std      FABF03D0   1     ST8       #SPILL122(gr31,976)=gr21
  155| 000B5C add      7FCA6214   1     A         gr30=gr10,gr12
    0| 000B60 ld       E99F05B8   1     L8        gr12=#SPILL45(gr31,1464)
  155| 000B64 std      FBDF0418   1     ST8       #SPILL127(gr31,1048)=gr30
  110| 000B68 add      7D697214   1     A         gr11=gr9,gr14
  107| 000B6C add      7DEA8214   1     A         gr15=gr10,gr16
  110| 000B70 std      F97F0408   1     ST8       #SPILL126(gr31,1032)=gr11
  107| 000B74 std      F9FF0420   1     ST8       #SPILL125(gr31,1056)=gr15
    0| 000B78 add      7DCA6214   1     A         gr14=gr10,gr12
  157| 000B7C ld       E99F05C0   1     L8        gr12=#SPILL44(gr31,1472)
    0| 000B80 std      F9DF0280   1     ST8       #SPILL128(gr31,640)=gr14
  110| 000B84 add      7E299214   1     A         gr17=gr9,gr18
    0| 000B88 ld       EB3F0588   1     L8        gr25=#SPILL40(gr31,1416)
  110| 000B8C std      FA3F0268   1     ST8       #SPILL124(gr31,616)=gr17
  107| 000B90 add      7E6AA214   1     A         gr19=gr10,gr20
  157| 000B94 add      7E096214   1     A         gr16=gr9,gr12
  107| 000B98 std      FA7F0278   1     ST8       #SPILL123(gr31,632)=gr19
  157| 000B9C std      FA1F0400   1     ST8       #SPILL129(gr31,1024)=gr16
    0| 000BA0 ld       E99F05C8   1     L8        gr12=#SPILL47(gr31,1480)
    0| 000BA4 ld       EB5F0580   1     L8        gr26=#SPILL49(gr31,1408)
    0| 000BA8 addi     3B190008   1     AI        gr24=gr25,8
    0| 000BAC ld       EB7F0578   1     L8        gr27=#SPILL42(gr31,1400)
    0| 000BB0 std      FB1F01C8   1     ST8       #SPILL119(gr31,456)=gr24
   89| 000BB4 addi     3B800000   1     LI        gr28=0
    0| 000BB8 add      7E496214   1     A         gr18=gr9,gr12
    0| 000BBC std      FB5F0180   1     ST8       #SPILL118(gr31,384)=gr26
   89| 000BC0 std      FB9F0120   1     ST8       #SPILL116(gr31,288)=gr28
    0| 000BC4 std      FB7F0178   1     ST8       #SPILL117(gr31,376)=gr27
    0| 000BC8 std      FA5F0270   1     ST8       #SPILL130(gr31,624)=gr18
  107| 000BCC ld       E99F05D0   1     L8        gr12=#SPILL46(gr31,1488)
  107| 000BD0 add      7E8A6214   1     A         gr20=gr10,gr12
  110| 000BD4 ld       E99F05D8   1     L8        gr12=#SPILL48(gr31,1496)
  107| 000BD8 std      FA9F0480   1     ST8       #SPILL131(gr31,1152)=gr20
  110| 000BDC add      7F296214   1     A         gr25=gr9,gr12
    0| 000BE0 ld       E99F0530   1     L8        gr12=#SPILL97(gr31,1328)
  110| 000BE4 std      FB3F0490   1     ST8       #SPILL132(gr31,1168)=gr25
    0| 000BE8 add      7F4A6214   1     A         gr26=gr10,gr12
    0| 000BEC ld       E99F0528   1     L8        gr12=#SPILL90(gr31,1320)
    0| 000BF0 std      FB5F0148   1     ST8       #SPILL133(gr31,328)=gr26
    0| 000BF4 add      7F6A6214   1     A         gr27=gr10,gr12
    0| 000BF8 ld       E99F0560   1     L8        gr12=#SPILL98(gr31,1376)
    0| 000BFC std      FB7F0150   1     ST8       #SPILL134(gr31,336)=gr27
    0| 000C00 add      7F896214   1     A         gr28=gr9,gr12
    0| 000C04 ld       E99F0540   1     L8        gr12=#SPILL91(gr31,1344)
    0| 000C08 std      FB9F0160   1     ST8       #SPILL135(gr31,352)=gr28
    0| 000C0C add      7F096214   1     A         gr24=gr9,gr12
    0| 000C10 ld       E99F0500   1     L8        gr12=#SPILL101(gr31,1280)
    0| 000C14 std      FB1F0168   1     ST8       #SPILL136(gr31,360)=gr24
    0| 000C18 add      7EEA6214   1     A         gr23=gr10,gr12
    0| 000C1C ld       E99F0550   1     L8        gr12=#SPILL107(gr31,1360)
    0| 000C20 std      FAFF0188   1     ST8       #SPILL137(gr31,392)=gr23
    0| 000C24 add      7EC96214   1     A         gr22=gr9,gr12
    0| 000C28 ld       E99F0558   1     L8        gr12=#SPILL108(gr31,1368)
    0| 000C2C std      FADF0190   1     ST8       #SPILL138(gr31,400)=gr22
    0| 000C30 add      7EA96214   1     A         gr21=gr9,gr12
    0| 000C34 ld       E99F0538   1     L8        gr12=#SPILL105(gr31,1336)
    0| 000C38 std      FABF0198   1     ST8       #SPILL139(gr31,408)=gr21
    0| 000C3C add      7E696214   1     A         gr19=gr9,gr12
    0| 000C40 ld       E99F0548   1     L8        gr12=#SPILL106(gr31,1352)
    0| 000C44 std      FA7F01A0   1     ST8       #SPILL140(gr31,416)=gr19
    0| 000C48 add      7D296214   1     A         gr9=gr9,gr12
    0| 000C4C std      F93F01A8   1     ST8       #SPILL141(gr31,424)=gr9
    0| 000C50 ld       E93F0510   1     L8        gr9=#SPILL102(gr31,1296)
    0| 000C54 add      7D895214   1     A         gr12=gr9,gr10
    0| 000C58 ld       E93F0520   1     L8        gr9=#SPILL104(gr31,1312)
    0| 000C5C std      F99F01B0   1     ST8       #SPILL142(gr31,432)=gr12
    0| 000C60 add      7E295214   1     A         gr17=gr9,gr10
    0| 000C64 ld       E93F0518   1     L8        gr9=#SPILL103(gr31,1304)
    0| 000C68 std      FA3F01B8   1     ST8       #SPILL143(gr31,440)=gr17
    0| 000C6C add      7D4A4A14   1     A         gr10=gr10,gr9
  163| 000C70 ld       E97F05E8   1     L8        gr11=#SPILL93(gr31,1512)
    0| 000C74 std      F95F01C0   1     ST8       #SPILL144(gr31,448)=gr10
   96| 000C78 mulld    7D46E9D2   1     M         gr10=gr6,gr29
   97| 000C7C rldicr   7BA91F24   1     SLL8      gr9=gr29,3
  163| 000C80 add      7FCA5A14   1     A         gr30=gr10,gr11
    0| 000C84 ld       E97F05F0   1     L8        gr11=#SPILL69(gr31,1520)
  163| 000C88 std      FBDF03D8   1     ST8       #SPILL147(gr31,984)=gr30
   96| 000C8C ld       EBBF05E0   1     L8        gr29=#SPILL17(gr31,1504)
    0| 000C90 add      7DC95A14   1     A         gr14=gr9,gr11
   98| 000C94 ld       E97F05F8   1     L8        gr11=#SPILL60(gr31,1528)
    0| 000C98 std      F9DF02A0   1     ST8       #SPILL148(gr31,672)=gr14
   96| 000C9C add      7DEAEA14   1     A         gr15=gr10,gr29
   97| 000CA0 addi     3BA9FFF8   1     AI        gr29=gr9,-8
   96| 000CA4 std      F9FF0288   1     ST8       #SPILL145(gr31,648)=gr15
   97| 000CA8 std      FBBF0388   1     ST8       #SPILL146(gr31,904)=gr29
   98| 000CAC add      7E095A14   1     A         gr16=gr9,gr11
    0| 000CB0 ld       E97F0600   1     L8        gr11=#SPILL55(gr31,1536)
   98| 000CB4 std      FA1F02C0   1     ST8       #SPILL149(gr31,704)=gr16
    0| 000CB8 add      7E495A14   1     A         gr18=gr9,gr11
  163| 000CBC ld       E97F0608   1     L8        gr11=#SPILL58(gr31,1544)
    0| 000CC0 std      FA5F01E0   1     ST8       #SPILL150(gr31,480)=gr18
  163| 000CC4 add      7E895A14   1     A         gr20=gr9,gr11
  166| 000CC8 ld       E97F0610   1     L8        gr11=#SPILL57(gr31,1552)
  163| 000CCC std      FA9F03C0   1     ST8       #SPILL151(gr31,960)=gr20
  166| 000CD0 add      7F295A14   1     A         gr25=gr9,gr11
  101| 000CD4 ld       E97F0618   1     L8        gr11=#SPILL56(gr31,1560)
  166| 000CD8 std      FB3F03B0   1     ST8       #SPILL152(gr31,944)=gr25
  101| 000CDC add      7F495A14   1     A         gr26=gr9,gr11
  166| 000CE0 ld       E97F0620   1     L8        gr11=#SPILL66(gr31,1568)
  101| 000CE4 std      FB5F0478   1     ST8       #SPILL153(gr31,1144)=gr26
  166| 000CE8 add      7F695A14   1     A         gr27=gr9,gr11
  163| 000CEC ld       E97F0628   1     L8        gr11=#SPILL67(gr31,1576)
  166| 000CF0 std      FB7F0398   1     ST8       #SPILL154(gr31,920)=gr27
  163| 000CF4 add      7F895A14   1     A         gr28=gr9,gr11
    0| 000CF8 ld       E97F0630   1     L8        gr11=#SPILL50(gr31,1584)
  163| 000CFC std      FB9F03A0   1     ST8       #SPILL155(gr31,928)=gr28
    0| 000D00 add      7F0A5A14   1     A         gr24=gr10,gr11
    0| 000D04 ld       E97F0638   1     L8        gr11=#SPILL3(gr31,1592)
    0| 000D08 std      FB1F0290   1     ST8       #SPILL156(gr31,656)=gr24
    0| 000D0C add      7EE95A14   1     A         gr23=gr9,gr11
    0| 000D10 ld       E97F0640   1     L8        gr11=#SPILL7(gr31,1600)
    0| 000D14 std      FAFF02F8   1     ST8       #SPILL157(gr31,760)=gr23
    0| 000D18 add      7EC95A14   1     A         gr22=gr9,gr11
    0| 000D1C ld       E97F0648   1     L8        gr11=#SPILL11(gr31,1608)
    0| 000D20 std      FADF02F0   1     ST8       #SPILL158(gr31,752)=gr22
    0| 000D24 add      7EA95A14   1     A         gr21=gr9,gr11
    0| 000D28 ld       E97F0370   1     L8        gr11=#SPILL19(gr31,880)
    0| 000D2C std      FABF02E8   1     ST8       #SPILL159(gr31,744)=gr21
    0| 000D30 add      7E695A14   1     A         gr19=gr9,gr11
    0| 000D34 ld       E97F0650   1     L8        gr11=#SPILL8(gr31,1616)
    0| 000D38 std      FA7F0338   1     ST8       #SPILL160(gr31,824)=gr19
    0| 000D3C add      7D895A14   1     A         gr12=gr9,gr11
    0| 000D40 ld       E97F0658   1     L8        gr11=#SPILL10(gr31,1624)
    0| 000D44 std      F99F0330   1     ST8       #SPILL161(gr31,816)=gr12
    0| 000D48 add      7E295A14   1     A         gr17=gr9,gr11
    0| 000D4C ld       E97F0660   1     L8        gr11=#SPILL4(gr31,1632)
    0| 000D50 std      FA3F0320   1     ST8       #SPILL162(gr31,800)=gr17
    0| 000D54 add      7DE95A14   1     A         gr15=gr9,gr11
    0| 000D58 ld       E97F0668   1     L8        gr11=#SPILL5(gr31,1640)
    0| 000D5C std      F9FF02D0   1     ST8       #SPILL163(gr31,720)=gr15
    0| 000D60 add      7FA95A14   1     A         gr29=gr9,gr11
    0| 000D64 ld       E97F0670   1     L8        gr11=#SPILL6(gr31,1648)
    0| 000D68 std      FBBF0308   1     ST8       #SPILL164(gr31,776)=gr29
    0| 000D6C add      7FC95A14   1     A         gr30=gr9,gr11
    0| 000D70 ld       E97F0678   1     L8        gr11=#SPILL9(gr31,1656)
    0| 000D74 std      FBDF02C8   1     ST8       #SPILL165(gr31,712)=gr30
    0| 000D78 add      7DC95A14   1     A         gr14=gr9,gr11
    0| 000D7C ld       E97F0680   1     L8        gr11=#SPILL71(gr31,1664)
    0| 000D80 std      F9DF0300   1     ST8       #SPILL166(gr31,768)=gr14
    0| 000D84 add      7E095A14   1     A         gr16=gr9,gr11
    0| 000D88 ld       E97F0688   1     L8        gr11=#SPILL54(gr31,1672)
    0| 000D8C std      FA1F0298   1     ST8       #SPILL167(gr31,664)=gr16
    0| 000D90 add      7E495A14   1     A         gr18=gr9,gr11
    0| 000D94 ld       E97F0690   1     L8        gr11=#SPILL53(gr31,1680)
    0| 000D98 std      FA5F0318   1     ST8       #SPILL168(gr31,792)=gr18
    0| 000D9C add      7E895A14   1     A         gr20=gr9,gr11
    0| 000DA0 ld       E97F0698   1     L8        gr11=#SPILL52(gr31,1688)
    0| 000DA4 std      FA9F02E0   1     ST8       #SPILL169(gr31,736)=gr20
    0| 000DA8 add      7F295A14   1     A         gr25=gr9,gr11
  157| 000DAC ld       E97F06A0   1     L8        gr11=#SPILL65(gr31,1696)
    0| 000DB0 std      FB3F02D8   1     ST8       #SPILL170(gr31,728)=gr25
  157| 000DB4 add      7F495A14   1     A         gr26=gr9,gr11
  189| 000DB8 ld       E97F06A8   1     L8        gr11=#SPILL51(gr31,1704)
  157| 000DBC std      FB5F03F8   1     ST8       #SPILL171(gr31,1016)=gr26
  189| 000DC0 add      7F695A14   1     A         gr27=gr9,gr11
    0| 000DC4 ld       E97F06B0   1     L8        gr11=#SPILL23(gr31,1712)
  189| 000DC8 std      FB7F02B8   1     ST8       #SPILL172(gr31,696)=gr27
    0| 000DCC add      7F895A14   1     A         gr28=gr9,gr11
  128| 000DD0 ld       E97F06B8   1     L8        gr11=#SPILL64(gr31,1720)
    0| 000DD4 std      FB9F0310   1     ST8       #SPILL173(gr31,784)=gr28
  128| 000DD8 add      7F095A14   1     A         gr24=gr9,gr11
  194| 000DDC ld       E97F06C0   1     L8        gr11=#SPILL14(gr31,1728)
  128| 000DE0 std      FB1F0438   1     ST8       #SPILL174(gr31,1080)=gr24
  194| 000DE4 add      7EE95A14   1     A         gr23=gr9,gr11
  119| 000DE8 ld       E97F06C8   1     L8        gr11=#SPILL63(gr31,1736)
  194| 000DEC std      FAFF0250   1     ST8       #SPILL175(gr31,592)=gr23
  119| 000DF0 add      7EC95A14   1     A         gr22=gr9,gr11
  101| 000DF4 ld       E97F06D0   1     L8        gr11=#SPILL99(gr31,1744)
  119| 000DF8 std      FADF0440   1     ST8       #SPILL176(gr31,1088)=gr22
  101| 000DFC add      7EA95A14   1     A         gr21=gr9,gr11
    0| 000E00 std      F87F04F8   1     ST8       #SPILL190(gr31,1272)=gr3
   98| 000E04 ld       E97F06D8   1     L8        gr11=#SPILL62(gr31,1752)
  101| 000E08 std      FABF04B0   1     ST8       #SPILL177(gr31,1200)=gr21
   98| 000E0C add      7E695A14   1     A         gr19=gr9,gr11
  155| 000E10 ld       E97F06E0   1     L8        gr11=#SPILL61(gr31,1760)
   98| 000E14 std      FA7F04B8   1     ST8       #SPILL178(gr31,1208)=gr19
  155| 000E18 add      7D895A14   1     A         gr12=gr9,gr11
  166| 000E1C ld       E97F0570   1     L8        gr11=#SPILL96(gr31,1392)
  155| 000E20 std      F99F03F0   1     ST8       #SPILL179(gr31,1008)=gr12
  166| 000E24 add      7E2A5A14   1     A         gr17=gr10,gr11
    0| 000E28 ld       E97F06E8   1     L8        gr11=#SPILL70(gr31,1768)
  166| 000E2C std      FA3F03E0   1     ST8       #SPILL180(gr31,992)=gr17
    0| 000E30 add      7DE95A14   1     A         gr15=gr9,gr11
  189| 000E34 ld       E97F06F0   1     L8        gr11=#SPILL94(gr31,1776)
    0| 000E38 std      F9FF0260   1     ST8       #SPILL181(gr31,608)=gr15
  189| 000E3C add      7FA95A14   1     A         gr29=gr9,gr11
   97| 000E40 ld       E97F06F8   1     L8        gr11=#SPILL59(gr31,1784)
  189| 000E44 std      FBBF0248   1     ST8       #SPILL182(gr31,584)=gr29
   97| 000E48 add      7FC95A14   1     A         gr30=gr9,gr11
  194| 000E4C ld       E97F0700   1     L8        gr11=#SPILL68(gr31,1792)
   97| 000E50 std      FBDF04D8   1     ST8       #SPILL183(gr31,1240)=gr30
  194| 000E54 add      7D295A14   1     A         gr9=gr9,gr11
    0| 000E58 ld       E97F0708   1     L8        gr11=#SPILL95(gr31,1800)
  194| 000E5C std      F93F0258   1     ST8       #SPILL184(gr31,600)=gr9
    0| 000E60 add      7DCA5A14   1     A         gr14=gr10,gr11
    0| 000E64 ld       E97F0568   1     L8        gr11=#SPILL92(gr31,1384)
    0| 000E68 std      F9DF0130   1     ST8       #SPILL185(gr31,304)=gr14
    0| 000E6C add      7D4A5A14   1     A         gr10=gr10,gr11
    0| 000E70 ld       E97F03E8   1     L8        gr11=#SPILL121(gr31,1000)
    0| 000E74 std      F95F0170   1     ST8       #SPILL186(gr31,368)=gr10
    0| 000E78 rldicl   7970F842   1     SRL8      gr16=gr11,1
    0| 000E7C ld       E97F01F0   1     L8        gr11=#SPILL120(gr31,496)
    0| 000E80 std      FA1F03C8   1     ST8       #SPILL187(gr31,968)=gr16
    0| 000E84 cmpdi    2E300000   1     C8        cr4=gr16,0
    0| 000E88 rldicl   7972F842   1     SRL8      gr18=gr11,1
    0| 000E8C ld       E97F0588   1     L8        gr11=#SPILL40(gr31,1416)
    0| 000E90 std      FA5F0448   1     ST8       #SPILL188(gr31,1096)=gr18
    0| 000E94 cmpdi    2DB20000   1     C8        cr3=gr18,0
    0| 000E98 std      F97F01D0   1     ST8       #SPILL189(gr31,464)=gr11
   89|                              CL.67:
   96| 000E9C bc       408120A0   1     BF        CL.291,cr0,0x2/gt,taken=50%(0,0)
  101| 000EA0 ld       EB3F04C0   1     L8        gr25=#SPILL74(gr31,1216)
  101| 000EA4 ld       EB1F0388   1     L8        gr24=#SPILL146(gr31,904)
   98| 000EA8 ld       EAFF04C8   1     L8        gr23=#SPILL73(gr31,1224)
   97| 000EAC ld       EADF04D0   1     L8        gr22=#SPILL72(gr31,1232)
   96| 000EB0 ld       E93F0170   1     L8        gr9=#SPILL186(gr31,368)
  101| 000EB4 ld       EABF04E0   1     L8        gr21=#SPILL79(gr31,1248)
   98| 000EB8 ld       EA9F04E8   1     L8        gr20=#SPILL78(gr31,1256)
   97| 000EBC ld       EA7F04F0   1     L8        gr19=#SPILL75(gr31,1264)
    0| 000EC0 ld       EA5F0448   1     L8        gr18=#SPILL188(gr31,1096)
  101| 000EC4 add      7FD8CA14   1     A         gr30=gr24,gr25
   98| 000EC8 add      7F97C214   1     A         gr28=gr23,gr24
   97| 000ECC add      7F56C214   1     A         gr26=gr22,gr24
   96| 000ED0 lfd      C9090000   1     LFL       fp8=v1(gr9,0)
  101| 000ED4 ld       E95F04B0   1     L8        gr10=#SPILL177(gr31,1200)
   98| 000ED8 ld       E97F04B8   1     L8        gr11=#SPILL178(gr31,1208)
   97| 000EDC ld       E99F04D8   1     L8        gr12=#SPILL183(gr31,1240)
  101| 000EE0 add      7FD5F214   1     A         gr30=gr21,gr30
  101| 000EE4 ld       EBBF0478   1     L8        gr29=#SPILL153(gr31,1144)
   98| 000EE8 add      7F94E214   1     A         gr28=gr20,gr28
   98| 000EEC ld       EB7F02C0   1     L8        gr27=#SPILL149(gr31,704)
   97| 000EF0 add      7F53D214   1     A         gr26=gr19,gr26
    0| 000EF4 mtspr    7E4903A6   1     LCTR      ctr=gr18
    0| 000EF8 bc       41960050   1     BT        CL.500,cr5,0x4/eq,taken=50%(0,0)
   96| 000EFC lfdux    7CC934EE   1     LFDU      fp6,gr9=v1(gr9,gr6,0)
  101| 000F00 lfdu     CD3D0008   1     LFDU      fp9,gr29=g31bi(gr29,8)
   98| 000F04 lfdu     CCFB0008   1     LFDU      fp7,gr27=g2bi(gr27,8)
   97| 000F08 lfdu     CD5A0008   1     LFDU      fp10,gr26=dx1ai(gr26,8)
   98| 000F0C lfdu     CD7C0008   1     LFDU      fp11,gr28=dg2bd1(gr28,8)
  101| 000F10 lfdu     CD9E0008   1     LFDU      fp12,gr30=dg31bd1(gr30,8)
   98| 000F14 fadd     FDA6402A   1     AFL       fp13=fp6,fp8,fcr
   97| 000F18 fsub     FFE64028   2     SFL       fp31=fp6,fp8,fcr
  101| 000F1C fmr      FD003090   2     LRFL      fp8=fp6
   98| 000F20 fmul     FCCD0072   2     MFL       fp6=fp13,fp1,fcr
   97| 000F24 fmul     FD5F02B2   2     MFL       fp10=fp31,fp10,fcr
   98| 000F28 fmul     FCE601F2   2     MFL       fp7=fp6,fp7,fcr
  101| 000F2C fmul     FCC60272   2     MFL       fp6=fp6,fp9,fcr
   97| 000F30 stfdu    DD4C0008   2     STFDU     gr12,dv11[].rns0.(gr12,8)=fp10
   98| 000F34 fmul     FCE702F2   1     MFL       fp7=fp7,fp11,fcr
  101| 000F38 fmul     FCC60332   2     MFL       fp6=fp6,fp12,fcr
   98| 000F3C stfdu    DCEB0008   2     STFDU     gr11,dv22[].rns3.(gr11,8)=fp7
  101| 000F40 stfdu    DCCA0008   1     STFDU     gr10,dv33[].rns6.(gr10,8)=fp6
    0| 000F44 bc       418E011C   1     BT        CL.415,cr3,0x4/eq,taken=20%(20,80)
   96|                              CL.500:
   96| 000F48 lfdux    7CC934EE   1     LFDU      fp6,gr9=v1(gr9,gr6,0)
   97| 000F4C lfd      C93A0008   1     LFL       fp9=dx1ai(gr26,8)
   97| 000F50 fsub     FD464028   1     SFL       fp10=fp6,fp8,fcr
   96| 000F54 lfdux    7CE934EE   1     LFDU      fp7,gr9=v1(gr9,gr6,0)
   98| 000F58 fadd     FD86402A   1     AFL       fp12=fp6,fp8,fcr
   97| 000F5C fmul     FD0A0272   2     MFL       fp8=fp10,fp9,fcr
   96| 000F60 bc       42400090   1     BCF       ctr=CL.519,taken=0%(0,100)
   96|                              CL.520:
   97| 000F64 lfd      C93A0018   1     LFL       fp9=dx1ai(gr26,24)
   97| 000F68 lfdu     CD5A0010   1     LFDU      fp10,gr26=dx1ai(gr26,16)
  101| 000F6C lfd      C97E0008   1     LFL       fp11=dg31bd1(gr30,8)
  101| 000F70 lfd      CB9D0008   1     LFL       fp28=g31bi(gr29,8)
   98| 000F74 lfd      CBBB0008   1     LFL       fp29=g2bi(gr27,8)
   98| 000F78 fadd     FFC7302A   1     AFL       fp30=fp7,fp6,fcr
   98| 000F7C fmul     FF6C0072   2     MFL       fp27=fp12,fp1,fcr
   98| 000F80 lfd      C99C0008   1     LFL       fp12=dg2bd1(gr28,8)
  101| 000F84 lfdu     CDBE0010   1     LFDU      fp13,gr30=dg31bd1(gr30,16)
  101| 000F88 lfdu     CFFD0010   1     LFDU      fp31,gr29=g31bi(gr29,16)
   98| 000F8C lfdu     CF5B0010   1     LFDU      fp26,gr27=g2bi(gr27,16)
   98| 000F90 fmul     FFDE0072   1     MFL       fp30=fp30,fp1,fcr
   98| 000F94 fmul     FFBB0772   2     MFL       fp29=fp27,fp29,fcr
  101| 000F98 fmul     FF9B0732   2     MFL       fp28=fp27,fp28,fcr
   97| 000F9C fsub     FF673028   2     SFL       fp27=fp7,fp6,fcr
   98| 000FA0 lfdu     CF3C0010   1     LFDU      fp25,gr28=dg2bd1(gr28,16)
   96| 000FA4 lfdux    7CC934EE   1     LFDU      fp6,gr9=v1(gr9,gr6,0)
   98| 000FA8 fmul     FF5E06B2   1     MFL       fp26=fp30,fp26,fcr
  101| 000FAC fmul     FFFE07F2   2     MFL       fp31=fp30,fp31,fcr
   98| 000FB0 fmul     FD9D0332   2     MFL       fp12=fp29,fp12,fcr
  101| 000FB4 fmul     FD7C02F2   2     MFL       fp11=fp28,fp11,fcr
   97| 000FB8 fmul     FD5B02B2   2     MFL       fp10=fp27,fp10,fcr
   97| 000FBC stfd     D90C0008   1     STFL      dv11[].rns0.(gr12,8)=fp8
   97| 000FC0 fsub     FD063828   1     SFL       fp8=fp6,fp7,fcr
   98| 000FC4 fmul     FFDA0672   2     MFL       fp30=fp26,fp25,fcr
  101| 000FC8 fmul     FDBF0372   2     MFL       fp13=fp31,fp13,fcr
   98| 000FCC stfd     D98B0008   1     STFL      dv22[].rns3.(gr11,8)=fp12
   98| 000FD0 fadd     FD86382A   1     AFL       fp12=fp6,fp7,fcr
  101| 000FD4 stfd     D96A0008   1     STFL      dv33[].rns6.(gr10,8)=fp11
   97| 000FD8 fmul     FD080272   1     MFL       fp8=fp8,fp9,fcr
   96| 000FDC lfdux    7CE934EE   1     LFDU      fp7,gr9=v1(gr9,gr6,0)
   98| 000FE0 stfdu    DFCB0010   1     STFDU     gr11,dv22[].rns3.(gr11,16)=fp30
  101| 000FE4 stfdu    DDAA0010   1     STFDU     gr10,dv33[].rns6.(gr10,16)=fp13
   97| 000FE8 stfdu    DD4C0010   1     STFDU     gr12,dv11[].rns0.(gr12,16)=fp10
    0| 000FEC bc       4200FF78   1     BCT       ctr=CL.520,taken=100%(100,0)
   96|                              CL.519:
   97| 000FF0 stfd     D90C0008   1     STFL      dv11[].rns0.(gr12,8)=fp8
   98| 000FF4 fadd     FD07302A   1     AFL       fp8=fp7,fp6,fcr
  101| 000FF8 lfd      C93D0008   1     LFL       fp9=g31bi(gr29,8)
   98| 000FFC fmul     FD4C0072   1     MFL       fp10=fp12,fp1,fcr
   98| 001000 lfd      C97B0008   1     LFL       fp11=g2bi(gr27,8)
   97| 001004 fsub     FCC73028   1     SFL       fp6=fp7,fp6,fcr
  101| 001008 lfdu     CCFD0010   1     LFDU      fp7,gr29=g31bi(gr29,16)
   98| 00100C fmul     FD080072   1     MFL       fp8=fp8,fp1,fcr
   98| 001010 lfdu     CD9B0010   1     LFDU      fp12,gr27=g2bi(gr27,16)
  101| 001014 fmul     FD2A0272   1     MFL       fp9=fp10,fp9,fcr
   97| 001018 lfdu     CDBA0010   1     LFDU      fp13,gr26=dx1ai(gr26,16)
   98| 00101C fmul     FD4A02F2   1     MFL       fp10=fp10,fp11,fcr
  101| 001020 lfd      C97E0008   1     LFL       fp11=dg31bd1(gr30,8)
  101| 001024 fmul     FCE801F2   1     MFL       fp7=fp8,fp7,fcr
   98| 001028 lfd      CBFC0008   1     LFL       fp31=dg2bd1(gr28,8)
   98| 00102C fmul     FD080332   1     MFL       fp8=fp8,fp12,fcr
  101| 001030 lfdu     CD9E0010   1     LFDU      fp12,gr30=dg31bd1(gr30,16)
   97| 001034 fmul     FCC60372   1     MFL       fp6=fp6,fp13,fcr
   98| 001038 lfdu     CDBC0010   1     LFDU      fp13,gr28=dg2bd1(gr28,16)
  101| 00103C fmul     FD2902F2   1     MFL       fp9=fp9,fp11,fcr
   98| 001040 fmul     FD4A07F2   2     MFL       fp10=fp10,fp31,fcr
  101| 001044 fmul     FCE70332   2     MFL       fp7=fp7,fp12,fcr
   97| 001048 stfdu    DCCC0010   2     STFDU     gr12,dv11[].rns0.(gr12,16)=fp6
   98| 00104C fmul     FCC80372   1     MFL       fp6=fp8,fp13,fcr
  101| 001050 stfd     D92A0008   1     STFL      dv33[].rns6.(gr10,8)=fp9
   98| 001054 stfd     D94B0008   1     STFL      dv22[].rns3.(gr11,8)=fp10
  101| 001058 stfdu    DCEA0010   1     STFDU     gr10,dv33[].rns6.(gr10,16)=fp7
   98| 00105C stfdu    DCCB0010   1     STFDU     gr11,dv22[].rns3.(gr11,16)=fp6
    0|                              CL.415:
  105| 001060 bc       40851C74   1     BF        CL.240,cr1,0x2/gt,taken=50%(0,0)
  106| 001064 bc       40811CAC   1     BF        CL.72,cr0,0x2/gt,taken=50%(0,0)
  107| 001068 ld       EADF0120   1     L8        gr22=#SPILL116(gr31,288)
  107| 00106C ld       EABF0340   1     L8        gr21=#SPILL12(gr31,832)
  107| 001070 ld       EA9F0348   1     L8        gr20=#SPILL0(gr31,840)
  107| 001074 ld       EA7F0350   1     L8        gr19=#SPILL43(gr31,848)
  107| 001078 ld       EA5F0140   1     L8        gr18=#SPILL29(gr31,320)
  107| 00107C ld       E9FF0210   1     L8        gr15=#SPILL37(gr31,528)
  110| 001080 ld       EA1F0158   1     L8        gr16=#SPILL38(gr31,344)
  107| 001084 add      7FB5B214   1     A         gr29=gr21,gr22
  107| 001088 ld       E9DF0420   1     L8        gr14=#SPILL125(gr31,1056)
  107| 00108C add      7F93A214   1     A         gr28=gr19,gr20
  107| 001090 mulld    7D52E9D2   1     M         gr10=gr18,gr29
  107| 001094 ld       E97F0480   1     L8        gr11=#SPILL131(gr31,1152)
  107| 001098 mulld    7F4FE1D2   1     M         gr26=gr15,gr28
  110| 00109C ld       EA3F0208   1     L8        gr17=#SPILL30(gr31,520)
  107| 0010A0 add      7D8A7214   1     A         gr12=gr10,gr14
  107| 0010A4 add      7F2A5A14   1     A         gr25=gr10,gr11
  107| 0010A8 ld       EB1F0488   1     L8        gr24=#SPILL80(gr31,1160)
  110| 0010AC mulld    7F70E9D2   1     M         gr27=gr16,gr29
  110| 0010B0 ld       EAFF0408   1     L8        gr23=#SPILL126(gr31,1032)
  107| 0010B4 add      7D8CD214   1     A         gr12=gr12,gr26
  107| 0010B8 add      7F5ACA14   1     A         gr26=gr26,gr25
  107| 0010BC ld       EB3F0498   1     L8        gr25=#SPILL81(gr31,1176)
  107| 0010C0 rldicr   7BA91F24   1     SLL8      gr9=gr29,3
  110| 0010C4 mulld    7FD1E1D2   1     M         gr30=gr17,gr28
  107| 0010C8 add      7D49C214   1     A         gr10=gr9,gr24
  110| 0010CC add      7F17DA14   1     A         gr24=gr23,gr27
  110| 0010D0 ld       EAFF0490   1     L8        gr23=#SPILL132(gr31,1168)
  107| 0010D4 lfdx     7CCACCAE   1     LFL       fp6=dx2ai(gr10,gr25,0)
  110| 0010D8 ld       EB3F04A0   1     L8        gr25=#SPILL77(gr31,1184)
  110| 0010DC rldicr   7B8B1F24   1     SLL8      gr11=gr28,3
  110| 0010E0 ld       E95F0370   1     L8        gr10=#SPILL19(gr31,880)
  110| 0010E4 add      7EF7F214   1     A         gr23=gr23,gr30
  110| 0010E8 add      7FDEC214   1     A         gr30=gr30,gr24
  110| 0010EC lfdx     7D195CAE   1     LFL       fp8=dx3ai(gr25,gr11,0)
  110| 0010F0 ld       E97F04A8   1     L8        gr11=#SPILL76(gr31,1192)
    0| 0010F4 ld       EB1F0448   1     L8        gr24=#SPILL188(gr31,1096)
  110| 0010F8 lfdx     7CEA4CAE   1     LFL       fp7=g32bi(gr10,gr9,0)
  107| 0010FC ld       E95F04B8   1     L8        gr10=#SPILL178(gr31,1208)
  110| 001100 add      7F7BBA14   1     A         gr27=gr27,gr23
  107| 001104 ld       EB3F02C0   1     L8        gr25=#SPILL149(gr31,704)
  110| 001108 lfdx     7D2B4CAE   1     LFL       fp9=dg32bd2(gr11,gr9,0)
  110| 00110C ld       E93F04B0   1     L8        gr9=#SPILL177(gr31,1200)
  110| 001110 ld       E97F0478   1     L8        gr11=#SPILL153(gr31,1144)
    0| 001114 mtspr    7F0903A6   1     LCTR      ctr=gr24
    0| 001118 bc       41960060   1     BT        CL.496,cr5,0x4/eq,taken=50%(0,0)
  107| 00111C lfdux    7D5A2CEE   1     LFDU      fp10,gr26=v2(gr26,gr5,0)
  107| 001120 lfdux    7D6C2CEE   1     LFDU      fp11,gr12=v2(gr12,gr5,0)
  110| 001124 lfdux    7D9B3CEE   1     LFDU      fp12,gr27=v3(gr27,gr7,0)
  110| 001128 lfdux    7DBE3CEE   1     LFDU      fp13,gr30=v3(gr30,gr7,0)
  107| 00112C lfdu     CFF90008   1     LFDU      fp31,gr25=g2bi(gr25,8)
  107| 001130 lfd      CB8A0008   1     LFL       fp28=dv22[].rns3.(gr10,8)
  110| 001134 lfd      CBC90008   1     LFL       fp30=dv33[].rns6.(gr9,8)
  110| 001138 lfdu     CFAB0008   1     LFDU      fp29,gr11=g31bi(gr11,8)
  110| 00113C fadd     FF6A582A   1     AFL       fp27=fp10,fp11,fcr
  107| 001140 fsub     FD4A5828   2     SFL       fp10=fp10,fp11,fcr
  110| 001144 fsub     FD6C6828   2     SFL       fp11=fp12,fp13,fcr
  110| 001148 fmul     FD9B0072   2     MFL       fp12=fp27,fp1,fcr
  107| 00114C fmul     FD4A01B2   2     MFL       fp10=fp10,fp6,fcr
  110| 001150 fmul     FD6802F2   2     MFL       fp11=fp8,fp11,fcr
  110| 001154 fmul     FD8C01F2   2     MFL       fp12=fp12,fp7,fcr
  107| 001158 fmadd    FD4AE7FA   2     FMA       fp10=fp28,fp10,fp31,fcr
  110| 00115C fmul     FD6B0772   2     MFL       fp11=fp11,fp29,fcr
  110| 001160 fmul     FD9F0332   2     MFL       fp12=fp31,fp12,fcr
  107| 001164 stfdu    DD4A0008   2     STFDU     gr10,dv22[].rns3.(gr10,8)=fp10
  110| 001168 fmadd    FD4CF27A   1     FMA       fp10=fp30,fp12,fp9,fcr
  110| 00116C fmadd    FD4752FA   2     FMA       fp10=fp10,fp7,fp11,fcr
  110| 001170 stfdu    DD490008   2     STFDU     gr9,dv33[].rns6.(gr9,8)=fp10
    0| 001174 bc       418E016C   1     BT        CL.408,cr3,0x4/eq,taken=20%(20,80)
    0|                              CL.496:
  107| 001178 lfdux    7FFA2CEE   1     LFDU      fp31,gr26=v2(gr26,gr5,0)
  107| 00117C lfdux    7FCC2CEE   1     LFDU      fp30,gr12=v2(gr12,gr5,0)
  110| 001180 lfdux    7D9B3CEE   1     LFDU      fp12,gr27=v3(gr27,gr7,0)
  110| 001184 lfdux    7DBE3CEE   1     LFDU      fp13,gr30=v3(gr30,gr7,0)
  107| 001188 lfd      C9590008   1     LFL       fp10=g2bi(gr25,8)
  107| 00118C lfd      CAAA0008   1     LFL       fp21=dv22[].rns3.(gr10,8)
  110| 001190 lfd      C9690008   1     LFL       fp11=dv33[].rns6.(gr9,8)
  107| 001194 lfdux    7F7A2CEE   1     LFDU      fp27,gr26=v2(gr26,gr5,0)
  110| 001198 fadd     FFBFF02A   1     AFL       fp29=fp31,fp30,fcr
  107| 00119C lfdux    7F4C2CEE   1     LFDU      fp26,gr12=v2(gr12,gr5,0)
  110| 0011A0 fsub     FD8C6828   1     SFL       fp12=fp12,fp13,fcr
  110| 0011A4 lfdux    7DBB3CEE   1     LFDU      fp13,gr27=v3(gr27,gr7,0)
  107| 0011A8 fsub     FFFFF028   1     SFL       fp31=fp31,fp30,fcr
  110| 0011AC lfdux    7FDE3CEE   1     LFDU      fp30,gr30=v3(gr30,gr7,0)
  110| 0011B0 fmul     FF3D0072   1     MFL       fp25=fp29,fp1,fcr
  107| 0011B4 lfd      CBAA0010   1     LFL       fp29=dv22[].rns3.(gr10,16)
  110| 0011B8 fadd     FEFBD02A   1     AFL       fp23=fp27,fp26,fcr
  110| 0011BC lfd      CB8B0008   1     LFL       fp28=g31bi(gr11,8)
  107| 0011C0 fsub     FF7BD028   1     SFL       fp27=fp27,fp26,fcr
  107| 0011C4 lfdu     CF590010   1     LFDU      fp26,gr25=g2bi(gr25,16)
  110| 0011C8 fmul     FF3901F2   1     MFL       fp25=fp25,fp7,fcr
  110| 0011CC lfd      CB090010   1     LFL       fp24=dv33[].rns6.(gr9,16)
  110| 0011D0 fmul     FEF70072   1     MFL       fp23=fp23,fp1,fcr
  110| 0011D4 lfdu     CECB0010   1     LFDU      fp22,gr11=g31bi(gr11,16)
  110| 0011D8 fmul     FD880332   1     MFL       fp12=fp8,fp12,fcr
  110| 0011DC fsub     FDADF028   2     SFL       fp13=fp13,fp30,fcr
  107| 0011E0 fmul     FFDB01B2   2     MFL       fp30=fp27,fp6,fcr
  110| 0011E4 fmul     FF6A0672   2     MFL       fp27=fp10,fp25,fcr
  110| 0011E8 fmul     FF3701F2   2     MFL       fp25=fp23,fp7,fcr
  107| 0011EC fmul     FFFF01B2   2     MFL       fp31=fp31,fp6,fcr
  110| 0011F0 fmul     FD8C0732   2     MFL       fp12=fp12,fp28,fcr
  110| 0011F4 fmul     FDA80372   2     MFL       fp13=fp8,fp13,fcr
  107| 0011F8 fmadd    FFDEEEBA   2     FMA       fp30=fp29,fp30,fp26,fcr
  110| 0011FC fmadd    FD7B5A7A   2     FMA       fp11=fp11,fp27,fp9,fcr
  110| 001200 fmul     FFBA0672   2     MFL       fp29=fp26,fp25,fcr
  107| 001204 fmadd    FFFFAABA   2     FMA       fp31=fp21,fp31,fp10,fcr
    0| 001208 bc       424000B8   1     BCF       ctr=CL.516,taken=0%(0,100)
    0|                              CL.517:
  107| 00120C lfd      C94A0018   1     LFL       fp10=dv22[].rns3.(gr10,24)
  110| 001210 fmadd    FFBDC27A   1     FMA       fp29=fp24,fp29,fp9,fcr
  110| 001214 fmadd    FF475B3A   2     FMA       fp26=fp11,fp7,fp12,fcr
  110| 001218 fmul     FD8D05B2   2     MFL       fp12=fp13,fp22,fcr
  107| 00121C stfdu    DFCA0010   2     STFDU     gr10,dv22[].rns3.(gr10,16)=fp30
  110| 001220 lfd      C9690018   1     LFL       fp11=dv33[].rns6.(gr9,24)
  107| 001224 lfdux    7F9A2CEE   1     LFDU      fp28,gr26=v2(gr26,gr5,0)
  107| 001228 lfdux    7F6C2CEE   1     LFDU      fp27,gr12=v2(gr12,gr5,0)
  110| 00122C fmadd    FD87EB3A   1     FMA       fp12=fp29,fp7,fp12,fcr
  110| 001230 stfd     DB490008   1     STFL      dv33[].rns6.(gr9,8)=fp26
  107| 001234 stfd     DBEAFFF8   1     STFL      dv22[].rns3.(gr10,-8)=fp31
  110| 001238 lfdux    7FFB3CEE   1     LFDU      fp31,gr27=v3(gr27,gr7,0)
  110| 00123C lfdux    7FBE3CEE   1     LFDU      fp29,gr30=v3(gr30,gr7,0)
  107| 001240 lfdux    7F5A2CEE   1     LFDU      fp26,gr26=v2(gr26,gr5,0)
  107| 001244 lfdux    7ECC2CEE   1     LFDU      fp22,gr12=v2(gr12,gr5,0)
  110| 001248 fadd     FDBCD82A   1     AFL       fp13=fp28,fp27,fcr
  110| 00124C stfdu    DD890010   2     STFDU     gr9,dv33[].rns6.(gr9,16)=fp12
  107| 001250 lfd      CBCA0010   1     LFL       fp30=dv22[].rns3.(gr10,16)
  110| 001254 lfd      C98B0008   1     LFL       fp12=g31bi(gr11,8)
  110| 001258 fsub     FEFFE828   1     SFL       fp23=fp31,fp29,fcr
  107| 00125C lfd      CBF90008   1     LFL       fp31=g2bi(gr25,8)
  110| 001260 fadd     FFBAB02A   1     AFL       fp29=fp26,fp22,fcr
  110| 001264 fmul     FF2D0072   2     MFL       fp25=fp13,fp1,fcr
  110| 001268 lfdux    7DBB3CEE   1     LFDU      fp13,gr27=v3(gr27,gr7,0)
  110| 00126C lfdux    7F1E3CEE   1     LFDU      fp24,gr30=v3(gr30,gr7,0)
  110| 001270 fmul     FEE805F2   1     MFL       fp23=fp8,fp23,fcr
  107| 001274 fsub     FF5AB028   2     SFL       fp26=fp26,fp22,fcr
  110| 001278 fmul     FFBD0072   2     MFL       fp29=fp29,fp1,fcr
  110| 00127C fmul     FF3901F2   2     MFL       fp25=fp25,fp7,fcr
  107| 001280 fsub     FF9CD828   2     SFL       fp28=fp28,fp27,fcr
  107| 001284 lfdu     CF790010   1     LFDU      fp27,gr25=g2bi(gr25,16)
  110| 001288 fsub     FDADC028   1     SFL       fp13=fp13,fp24,fcr
  107| 00128C fmul     FF5A01B2   2     MFL       fp26=fp26,fp6,fcr
  110| 001290 fmul     FFBD01F2   2     MFL       fp29=fp29,fp7,fcr
  110| 001294 fmul     FF3F0672   2     MFL       fp25=fp31,fp25,fcr
  107| 001298 fmul     FF9C01B2   2     MFL       fp28=fp28,fp6,fcr
  110| 00129C lfd      CB090010   1     LFL       fp24=dv33[].rns6.(gr9,16)
  110| 0012A0 lfdu     CECB0010   1     LFDU      fp22,gr11=g31bi(gr11,16)
  110| 0012A4 fmul     FD970332   1     MFL       fp12=fp23,fp12,fcr
  110| 0012A8 fmul     FFBB0772   2     MFL       fp29=fp27,fp29,fcr
  110| 0012AC fmadd    FD795A7A   2     FMA       fp11=fp11,fp25,fp9,fcr
  110| 0012B0 fmul     FDA80372   2     MFL       fp13=fp8,fp13,fcr
  107| 0012B4 fmadd    FFDAF6FA   2     FMA       fp30=fp30,fp26,fp27,fcr
  107| 0012B8 fmadd    FFFC57FA   2     FMA       fp31=fp10,fp28,fp31,fcr
    0| 0012BC bc       4200FF50   1     BCT       ctr=CL.517,taken=100%(100,0)
    0|                              CL.516:
  110| 0012C0 fmul     FD0D05B2   1     MFL       fp8=fp13,fp22,fcr
  107| 0012C4 stfdu    DFCA0010   2     STFDU     gr10,dv22[].rns3.(gr10,16)=fp30
  110| 0012C8 fmadd    FCDDC27A   1     FMA       fp6=fp24,fp29,fp9,fcr
  107| 0012CC stfd     DBEAFFF8   1     STFL      dv22[].rns3.(gr10,-8)=fp31
  110| 0012D0 fmadd    FD275B3A   1     FMA       fp9=fp11,fp7,fp12,fcr
  110| 0012D4 fmadd    FCC7323A   2     FMA       fp6=fp6-fp8,fcr
  110| 0012D8 stfd     D9290008   1     STFL      dv33[].rns6.(gr9,8)=fp9
  110| 0012DC stfdu    DCC90010   1     STFDU     gr9,dv33[].rns6.(gr9,16)=fp6
    0|                              CL.408:
  117| 0012E0 bc       40811A30   1     BF        CL.72,cr0,0x2/gt,taken=50%(0,0)
    0| 0012E4 bc       408519F0   1     BF        CL.240,cr1,0x2/gt,taken=50%(0,0)
  119| 0012E8 ld       E93F0168   1     L8        gr9=#SPILL136(gr31,360)
  119| 0012EC ld       E95F01A8   1     L8        gr10=#SPILL141(gr31,424)
  119| 0012F0 ld       E97F0198   1     L8        gr11=#SPILL139(gr31,408)
  128| 0012F4 ld       EAFF0450   1     L8        gr23=#SPILL82(gr31,1104)
  128| 0012F8 ld       EADF0458   1     L8        gr22=#SPILL84(gr31,1112)
    0| 0012FC ld       EA9F01C8   1     L8        gr20=#SPILL119(gr31,456)
  119| 001300 lfdux    7D093CEE   1     LFDU      fp8,gr9=v3(gr9,gr7,0)
  119| 001304 lfdux    7D2A3CEE   1     LFDU      fp9,gr10=v3(gr10,gr7,0)
  119| 001308 lfdux    7D4B3CEE   1     LFDU      fp10,gr11=v3(gr11,gr7,0)
  119| 00130C ld       E99F0160   1     L8        gr12=#SPILL135(gr31,352)
  119| 001310 ld       EBDF0190   1     L8        gr30=#SPILL138(gr31,400)
  128| 001314 add      7F16BA14   1     A         gr24=gr22,gr23
  128| 001318 ld       EA7F0460   1     L8        gr19=#SPILL83(gr31,1120)
  128| 00131C ld       EA5F0468   1     L8        gr18=#SPILL85(gr31,1128)
  128| 001320 fadd     FCE8482A   1     AFL       fp7=fp8,fp9,fcr
    0| 001324 lfdx     7CD8A4AE   1     LFL       fp6=g32ai(gr24,gr20,0)
  128| 001328 fadd     FD68502A   1     AFL       fp11=fp8,fp10,fcr
    0| 00132C ld       EA3F01D0   1     L8        gr17=#SPILL189(gr31,464)
  119| 001330 fsub     FD294028   1     SFL       fp9=fp9,fp8,fcr
  119| 001334 lfdux    7DAC3CEE   1     LFDU      fp13,gr12=v3(gr12,gr7,0)
  128| 001338 fmul     FCE70072   1     MFL       fp7=fp7,fp1,fcr
  119| 00133C lfdux    7FBE3CEE   1     LFDU      fp29,gr30=v3(gr30,gr7,0)
  119| 001340 fsub     FD485028   1     SFL       fp10=fp8,fp10,fcr
  128| 001344 add      7EB29A14   1     A         gr21=gr18,gr19
  128| 001348 fmul     FD8B0072   1     MFL       fp12=fp11,fp1,fcr
    0| 00134C lfdx     7D188CAE   1     LFL       fp8=g32ai(gr24,gr17,0)
  128| 001350 fmul     FFE601F2   1     MFL       fp31=fp6,fp7,fcr
    0| 001354 lfdx     7CF5A4AE   1     LFL       fp7=dg32ad2(gr21,gr20,0)
  128| 001358 fadd     FD6DE82A   1     AFL       fp11=fp13,fp29,fcr
  128| 00135C ld       EB5F0148   1     L8        gr26=#SPILL133(gr31,328)
  119| 001360 fsub     FEADE828   1     SFL       fp21=fp13,fp29,fcr
  128| 001364 ld       EB3F01B8   1     L8        gr25=#SPILL143(gr31,440)
  128| 001368 fmul     FF480332   1     MFL       fp26=fp8,fp12,fcr
  119| 00136C ld       EB7F01A0   1     L8        gr27=#SPILL140(gr31,416)
  128| 001370 fmul     FF7F01F2   1     MFL       fp27=fp31,fp7,fcr
    0| 001374 ld       EA1F0470   1     L8        gr16=#SPILL24(gr31,1136)
  128| 001378 fmul     FFCB0072   1     MFL       fp30=fp11,fp1,fcr
  128| 00137C lfdux    7FFA2CEE   1     LFDU      fp31,gr26=v2(gr26,gr5,0)
  128| 001380 lfdux    7D992CEE   1     LFDU      fp12,gr25=v2(gr25,gr5,0)
  119| 001384 lfdux    7F9B3CEE   1     LFDU      fp28,gr27=v3(gr27,gr7,0)
  128| 001388 ld       EB1F0150   1     L8        gr24=#SPILL134(gr31,336)
    0| 00138C lfdx     7D70A4AE   1     LFL       fp11=dx2bi(gr16,gr20,0)
  128| 001390 fmul     FFC807B2   1     MFL       fp30=fp8,fp30,fcr
  128| 001394 ld       EAFF01C0   1     L8        gr23=#SPILL144(gr31,448)
  128| 001398 ld       EADF0188   1     L8        gr22=#SPILL137(gr31,392)
  128| 00139C fsub     FF2CF828   1     SFL       fp25=fp12,fp31,fcr
    0| 0013A0 lfdx     7D958CAE   1     LFL       fp12=dg32ad2(gr21,gr17,0)
  119| 0013A4 fsub     FE7C6828   1     SFL       fp19=fp28,fp13,fcr
    0| 0013A8 ld       E9FF0430   1     L8        gr15=#SPILL100(gr31,1072)
  119| 0013AC fmul     FF0B0272   1     MFL       fp24=fp11,fp9,fcr
  128| 0013B0 lfdux    7EF72CEE   1     LFDU      fp23,gr23=v2(gr23,gr5,0)
  128| 0013B4 fadd     FD2DE02A   1     AFL       fp9=fp13,fp28,fcr
    0| 0013B8 lfdx     7DB08CAE   2     LFL       fp13=dx2bi(gr16,gr17,0)
  128| 0013BC fmadd    FF7ADB3A   1     FMA       fp27=fp27,fp26,fp12,fcr
  128| 0013C0 lfdux    7F982CEE   1     LFDU      fp28,gr24=v2(gr24,gr5,0)
  128| 0013C4 lfdux    7F562CEE   1     LFDU      fp26,gr22=v2(gr22,gr5,0)
  128| 0013C8 ld       EABF01B0   1     L8        gr21=#SPILL142(gr31,432)
  128| 0013CC fmul     FFA90072   1     MFL       fp29=fp9,fp1,fcr
    0| 0013D0 lfd      C92F0008   1     LFL       fp9=dx3bi(gr15,8)
  119| 0013D4 fmadd    FF0DC2BA   1     FMA       fp24=fp24,fp13,fp10,fcr
    0| 0013D8 lfd      C94F0000   1     LFL       fp10=dx3bi(gr15,0)
  128| 0013DC fsub     FEF7E028   1     SFL       fp23=fp23,fp28,fcr
  128| 0013E0 lfdux    7ED52CEE   1     LFDU      fp22,gr21=v2(gr21,gr5,0)
  128| 0013E4 fsub     FFFFD028   1     SFL       fp31=fp31,fp26,fcr
    0| 0013E8 ld       E9DF01F0   1     L8        gr14=#SPILL120(gr31,496)
  128| 0013EC fmul     FF290672   1     MFL       fp25=fp9,fp25,fcr
  119| 0013F0 ld       EA9F02C0   1     L8        gr20=#SPILL149(gr31,704)
  128| 0013F4 fmul     FE860772   1     MFL       fp20=fp6,fp29,fcr
  128| 0013F8 ld       EA7F0478   1     L8        gr19=#SPILL153(gr31,1144)
  128| 0013FC fmul     FFA905F2   1     MFL       fp29=fp9,fp23,fcr
    0| 001400 mtspr    7DC903A6   1     LCTR      ctr=gr14
  128| 001404 fsub     FF9CB028   1     SFL       fp28=fp28,fp22,fcr
  128| 001408 ld       EA5F0438   1     L8        gr18=#SPILL174(gr31,1080)
  128| 00140C fmadd    FFEACFFA   1     FMA       fp31=fp25,fp10,fp31,fcr
  119| 001410 ld       EA3F0440   1     L8        gr17=#SPILL176(gr31,1088)
  128| 001414 fmadd    FFCCDFBA   1     FMA       fp30=fp27,fp12,fp30,fcr
  119| 001418 lfdu     CF740008   1     LFDU      fp27,gr20=g2bi(gr20,8)
  119| 00141C fmadd    FF0DC57A   1     FMA       fp24=fp24,fp13,fp21,fcr
  128| 001420 lfdu     CF530008   2     LFDU      fp26,gr19=g31bi(gr19,8)
  128| 001424 fmadd    FF2AEF3A   1     FMA       fp25=fp29,fp10,fp28,fcr
  128| 001428 fmul     FFBF01B2   2     MFL       fp29=fp31,fp6,fcr
  128| 00142C fmadd    FF87F53A   2     FMA       fp28=fp30,fp7,fp20,fcr
  119| 001430 fmadd    FECBC4FA   2     FMA       fp22=fp24,fp11,fp19,fcr
    0| 001434 bc       424000EC   1     BCF       ctr=CL.514,taken=0%(0,100)
    0| 001438 ori      60210000   1     XNOP      
    0|                              CL.515:
  128| 00143C lfdux    7FF52CEE   1     LFDU      fp31,gr21=v2(gr21,gr5,0)
  128| 001440 lfdux    7FD82CEE   1     LFDU      fp30,gr24=v2(gr24,gr5,0)
  128| 001444 fmadd    FEF9EA3A   1     FMA       fp23=fp29,fp25,fp8,fcr
  128| 001448 fmul     FF1B0732   2     MFL       fp24=fp27,fp28,fcr
  119| 00144C fmul     FF3606F2   2     MFL       fp25=fp22,fp27,fcr
  128| 001450 lfdux    7FB72CEE   1     LFDU      fp29,gr23=v2(gr23,gr5,0)
  128| 001454 lfdux    7F962CEE   1     LFDU      fp28,gr22=v2(gr22,gr5,0)
  119| 001458 lfdux    7F693CEE   1     LFDU      fp27,gr9=v3(gr9,gr7,0)
  128| 00145C fmul     FEB706B2   1     MFL       fp21=fp23,fp26,fcr
  128| 001460 fmul     FE9800B2   2     MFL       fp20=fp24,fp2,fcr
  119| 001464 lfdux    7F4A3CEE   1     LFDU      fp26,gr10=v3(gr10,gr7,0)
  119| 001468 fmul     FF3900B2   1     MFL       fp25=fp25,fp2,fcr
  119| 00146C lfdux    7F1B3CEE   1     LFDU      fp24,gr27=v3(gr27,gr7,0)
  119| 001470 lfdux    7EEC3CEE   1     LFDU      fp23,gr12=v3(gr12,gr7,0)
  119| 001474 lfdux    7ECB3CEE   1     LFDU      fp22,gr11=v3(gr11,gr7,0)
  128| 001478 fmsub    FEB5A0B8   1     FMS       fp21=fp20,fp21,fp2,fcr
  128| 00147C lfdux    7E9A2CEE   1     LFDU      fp20,gr26=v2(gr26,gr5,0)
  128| 001480 fadd     FE7BD02A   1     AFL       fp19=fp27,fp26,fcr
  119| 001484 lfdux    7E5E3CEE   1     LFDU      fp18,gr30=v3(gr30,gr7,0)
  128| 001488 lfdux    7E392CEE   1     LFDU      fp17,gr25=v2(gr25,gr5,0)
  119| 00148C fsub     FE18B828   1     SFL       fp16=fp24,fp23,fcr
  128| 001490 fadd     FDFBB02A   2     AFL       fp15=fp27,fp22,fcr
  128| 001494 stfdu    DEB20008   2     STFDU     gr18,dv32[].rns17.(gr18,8)=fp21
  128| 001498 fmul     FEB30072   1     MFL       fp21=fp19,fp1,fcr
  119| 00149C fsub     FF5AD828   2     SFL       fp26=fp26,fp27,fcr
  119| 0014A0 fsub     FE779028   2     SFL       fp19=fp23,fp18,fcr
  119| 0014A4 fsub     FF7BB028   2     SFL       fp27=fp27,fp22,fcr
  128| 0014A8 fadd     FED7902A   2     AFL       fp22=fp23,fp18,fcr
  128| 0014AC fmul     FE4F0072   2     MFL       fp18=fp15,fp1,fcr
  128| 0014B0 fmul     FEA60572   2     MFL       fp21=fp6,fp21,fcr
  119| 0014B4 fmul     FF4B06B2   2     MFL       fp26=fp11,fp26,fcr
  128| 0014B8 fsub     FE31A028   2     SFL       fp17=fp17,fp20,fcr
  128| 0014BC fadd     FF17C02A   2     AFL       fp24=fp23,fp24,fcr
  128| 0014C0 fmul     FEF60072   2     MFL       fp23=fp22,fp1,fcr
  128| 0014C4 fmul     FEC804B2   2     MFL       fp22=fp8,fp18,fcr
  128| 0014C8 fmul     FEB501F2   2     MFL       fp21=fp21,fp7,fcr
  128| 0014CC fsub     FFBDF028   2     SFL       fp29=fp29,fp30,fcr
  128| 0014D0 fsub     FF94E028   2     SFL       fp28=fp20,fp28,fcr
  128| 0014D4 fmul     FE890472   2     MFL       fp20=fp9,fp17,fcr
  128| 0014D8 fmul     FF180072   2     MFL       fp24=fp24,fp1,fcr
  128| 0014DC fmul     FEE805F2   2     MFL       fp23=fp8,fp23,fcr
  128| 0014E0 fmadd    FED6AB3A   2     FMA       fp22=fp21,fp22,fp12,fcr
  119| 0014E4 fmadd    FF6DD6FA   2     FMA       fp27=fp26,fp13,fp27,fcr
  128| 0014E8 fsub     FFFEF828   2     SFL       fp31=fp30,fp31,fcr
  128| 0014EC fmul     FFC90772   2     MFL       fp30=fp9,fp29,fcr
  128| 0014F0 fmadd    FFAAA73A   2     FMA       fp29=fp20,fp10,fp28,fcr
  128| 0014F4 fmul     FF860632   2     MFL       fp28=fp6,fp24,fcr
  128| 0014F8 fmadd    FF4CB5FA   2     FMA       fp26=fp22,fp12,fp23,fcr
  119| 0014FC fmadd    FF0DDCFA   2     FMA       fp24=fp27,fp13,fp19,fcr
  119| 001500 stfdu    DF310008   2     STFDU     gr17,dv23[].rns15.(gr17,8)=fp25
  119| 001504 lfdu     CF740008   1     LFDU      fp27,gr20=g2bi(gr20,8)
  128| 001508 fmadd    FF2AF7FA   1     FMA       fp25=fp30,fp10,fp31,fcr
  128| 00150C fmul     FFBD01B2   2     MFL       fp29=fp29,fp6,fcr
  128| 001510 fmadd    FF87D73A   2     FMA       fp28=fp26,fp7,fp28,fcr
  119| 001514 fmadd    FECBC43A   2     FMA       fp22=fp24,fp11,fp16,fcr
  128| 001518 lfdu     CF530008   2     LFDU      fp26,gr19=g31bi(gr19,8)
    0| 00151C bc       4200FF20   1     BCT       ctr=CL.515,taken=100%(100,0)
    0|                              CL.514:
  128| 001520 fmadd    FCD9EA3A   1     FMA       fp6=fp29,fp25,fp8,fcr
  128| 001524 fmul     FCFB0732   2     MFL       fp7=fp27,fp28,fcr
  119| 001528 fmul     FD1606F2   2     MFL       fp8=fp22,fp27,fcr
  128| 00152C fmul     FCC606B2   2     MFL       fp6=fp6,fp26,fcr
  128| 001530 fmul     FCE700B2   2     MFL       fp7=fp7,fp2,fcr
  119| 001534 fmul     FD0800B2   2     MFL       fp8=fp8,fp2,fcr
  128| 001538 fmsub    FCC638B8   2     FMS       fp6=fp7,fp6,fp2,fcr
  119| 00153C stfdu    DD110008   2     STFDU     gr17,dv23[].rns15.(gr17,8)=fp8
  128| 001540 stfdu    DCD20008   1     STFDU     gr18,dv32[].rns17.(gr18,8)=fp6
  153| 001544 bc       409D07B4   1     BF        CL.39,cr7,0x2/gt,taken=50%(0,0)
  163| 001548 ld       E97F0178   1     L8        gr11=#SPILL117(gr31,376)
  166| 00154C ld       E99F0180   1     L8        gr12=#SPILL118(gr31,384)
  155| 001550 addi     395D0001   1     AI        gr10=gr29,1
  157| 001554 addi     393C0001   1     AI        gr9=gr28,1
  163| 001558 lfd      C8CB0008   1     LFL       fp6=dx2bi(gr11,8)
  163| 00155C lfd      C8EB0000   1     LFL       fp7=dx2bi(gr11,0)
  166| 001560 lfd      C90C0000   1     LFL       fp8=g32bi(gr12,0)
   79|                              CL.298:
  166| 001564 ld       EAFF0218   1     L8        gr23=#SPILL35(gr31,536)
  157| 001568 ld       EA5F0208   1     L8        gr18=#SPILL30(gr31,520)
  166| 00156C ld       EB1F0128   1     L8        gr24=#SPILL36(gr31,296)
  157| 001570 ld       EA9F0158   1     L8        gr20=#SPILL38(gr31,344)
  155| 001574 ld       EA7F0210   1     L8        gr19=#SPILL37(gr31,528)
  166| 001578 ld       EB3F03E0   1     L8        gr25=#SPILL180(gr31,992)
  166| 00157C mulld    7D69B9D2   1     M         gr11=gr9,gr23
  157| 001580 mulld    7EA991D2   1     M         gr21=gr9,gr18
  166| 001584 mulld    7D98E9D2   1     M         gr12=gr24,gr29
  163| 001588 mulld    7D2AC1D2   1     M         gr9=gr10,gr24
  163| 00158C ld       EB1F03D8   1     L8        gr24=#SPILL147(gr31,984)
  163| 001590 mulld    7FD7E1D2   1     M         gr30=gr23,gr28
  155| 001594 ld       EAFF0140   1     L8        gr23=#SPILL29(gr31,320)
  166| 001598 add      7F4CC214   1     A         gr26=gr12,gr24
  157| 00159C ld       EA3F0408   1     L8        gr17=#SPILL126(gr31,1032)
  166| 0015A0 add      7D6BD214   1     A         gr11=gr11,gr26
  157| 0015A4 mulld    7F54E9D2   1     M         gr26=gr20,gr29
  155| 0015A8 mulld    7F6AB9D2   1     M         gr27=gr10,gr23
  163| 0015AC add      7D4CF214   1     A         gr10=gr12,gr30
  166| 0015B0 add      7D8CCA14   1     A         gr12=gr12,gr25
  157| 0015B4 mulld    7F32E1D2   1     M         gr25=gr18,gr28
  155| 0015B8 mulld    7F93E1D2   1     M         gr28=gr19,gr28
  163| 0015BC ld       EADF0130   1     L8        gr22=#SPILL185(gr31,304)
  155| 0015C0 mulld    7FB7E9D2   1     M         gr29=gr23,gr29
  157| 0015C4 ld       EA5F0400   1     L8        gr18=#SPILL129(gr31,1024)
  157| 0015C8 add      7E71D214   1     A         gr19=gr17,gr26
  155| 0015CC add      7E3BE214   1     A         gr17=gr27,gr28
  155| 0015D0 ld       EB7F0410   1     L8        gr27=#SPILL87(gr31,1040)
  155| 0015D4 ld       EAFF0388   1     L8        gr23=#SPILL146(gr31,904)
  163| 0015D8 add      7D29C214   1     A         gr9=gr9,gr24
  157| 0015DC add      7E99D214   1     A         gr20=gr25,gr26
    0| 0015E0 ld       E9DF03C8   1     L8        gr14=#SPILL187(gr31,968)
  163| 0015E4 add      7D29F214   1     A         gr9=gr9,gr30
  163| 0015E8 add      7FDEB214   1     A         gr30=gr30,gr22
  157| 0015EC add      7ED2D214   1     A         gr22=gr18,gr26
  155| 0015F0 add      7DF7DA14   1     A         gr15=gr23,gr27
  157| 0015F4 add      7EF2A214   1     A         gr23=gr18,gr20
  157| 0015F8 ld       EA5F0408   1     L8        gr18=#SPILL126(gr31,1032)
    0| 0015FC mtspr    7DC903A6   1     LCTR      ctr=gr14
  155| 001600 ld       E9DF0420   1     L8        gr14=#SPILL125(gr31,1056)
  155| 001604 add      7E1CEA14   1     A         gr16=gr28,gr29
  157| 001608 add      7ED5B214   1     A         gr22=gr21,gr22
  157| 00160C add      7EB59A14   1     A         gr21=gr21,gr19
  157| 001610 add      7E949214   1     A         gr20=gr20,gr18
  155| 001614 ld       EA5F0418   1     L8        gr18=#SPILL127(gr31,1048)
  163| 001618 add      7D4AC214   1     A         gr10=gr10,gr24
  166| 00161C ld       EBBF0398   1     L8        gr29=#SPILL154(gr31,920)
  163| 001620 ld       EB9F03A0   1     L8        gr28=#SPILL155(gr31,928)
  157| 001624 ld       EB7F03F8   1     L8        gr27=#SPILL171(gr31,1016)
  155| 001628 ld       EB5F03F0   1     L8        gr26=#SPILL179(gr31,1008)
  155| 00162C add      7E709214   1     A         gr19=gr16,gr18
  155| 001630 add      7E528A14   1     A         gr18=gr18,gr17
  155| 001634 add      7E2E8A14   1     A         gr17=gr14,gr17
  155| 001638 add      7E0E8214   1     A         gr16=gr14,gr16
  155| 00163C ld       E9DF0428   1     L8        gr14=#SPILL86(gr31,1064)
  166| 001640 ld       EB3F03B0   1     L8        gr25=#SPILL152(gr31,944)
  163| 001644 ld       EB1F03C0   1     L8        gr24=#SPILL151(gr31,960)
  155| 001648 add      7DEE7A14   1     A         gr15=gr14,gr15
    0| 00164C ld       E9DF03D0   1     L8        gr14=#SPILL122(gr31,976)
    0| 001650 cmpdi    2D2E0000   1     C8        cr2=gr14,0
    0| 001654 bc       418A00B0   1     BT        CL.502,cr2,0x4/eq,taken=50%(0,0)
  163| 001658 lfdux    7F2A34EE   1     LFDU      fp25,gr10=v1(gr10,gr6,0)
  166| 00165C lfdux    7DAB34EE   1     LFDU      fp13,gr11=v1(gr11,gr6,0)
  163| 001660 lfdux    7D6934EE   1     LFDU      fp11,gr9=v1(gr9,gr6,0)
  166| 001664 lfdux    7D8C34EE   1     LFDU      fp12,gr12=v1(gr12,gr6,0)
  155| 001668 lfdux    7FB02CEE   1     LFDU      fp29,gr16=v2(gr16,gr5,0)
  155| 00166C lfdux    7F932CEE   1     LFDU      fp28,gr19=v2(gr19,gr5,0)
  157| 001670 lfdux    7F743CEE   1     LFDU      fp27,gr20=v3(gr20,gr7,0)
  157| 001674 lfdux    7F573CEE   1     LFDU      fp26,gr23=v3(gr23,gr7,0)
  166| 001678 fsub     FFEDC828   1     SFL       fp31=fp13,fp25,fcr
  163| 00167C lfdux    7EFE34EE   1     LFDU      fp23,gr30=v1(gr30,gr6,0)
  163| 001680 fsub     FF0BC828   1     SFL       fp24=fp11,fp25,fcr
  155| 001684 lfdux    7D712CEE   2     LFDU      fp11,gr17=v2(gr17,gr5,0)
  166| 001688 fsub     FD996028   1     SFL       fp12=fp25,fp12,fcr
  157| 00168C lfdux    7DB53CEE   1     LFDU      fp13,gr21=v3(gr21,gr7,0)
  166| 001690 fmul     FFE907F2   1     MFL       fp31=fp9,fp31,fcr
  155| 001694 lfdu     CFCF0008   1     LFDU      fp30,gr15=dx1bi(gr15,8)
  155| 001698 fsub     FFBDE028   1     SFL       fp29=fp29,fp28,fcr
  155| 00169C lfdux    7F922CEE   2     LFDU      fp28,gr18=v2(gr18,gr5,0)
  157| 0016A0 fsub     FF7BD028   1     SFL       fp27=fp27,fp26,fcr
  157| 0016A4 lfdux    7F563CEE   1     LFDU      fp26,gr22=v3(gr22,gr7,0)
  163| 0016A8 fsub     FF39B828   1     SFL       fp25=fp25,fp23,fcr
  166| 0016AC lfdu     CED90008   1     LFDU      fp22,gr25=g31ai(gr25,8)
  163| 0016B0 fmul     FF060632   1     MFL       fp24=fp6,fp24,fcr
  163| 0016B4 lfdu     CEF80008   1     LFDU      fp23,gr24=g2ai(gr24,8)
  166| 0016B8 fmadd    FD8AFB3A   1     FMA       fp12=fp31,fp10,fp12,fcr
  155| 0016BC fadd     FD6BE82A   2     AFL       fp11=fp11,fp29,fcr
  157| 0016C0 fadd     FDADD82A   2     AFL       fp13=fp13,fp27,fcr
  155| 0016C4 fmul     FFFE0072   2     MFL       fp31=fp30,fp1,fcr
  163| 0016C8 fmadd    FFC7C67A   2     FMA       fp30=fp24,fp7,fp25,fcr
  166| 0016CC fmul     FD8C0072   2     MFL       fp12=fp12,fp1,fcr
  155| 0016D0 fsub     FD6BE028   2     SFL       fp11=fp11,fp28,fcr
  157| 0016D4 fsub     FDADD028   2     SFL       fp13=fp13,fp26,fcr
  163| 0016D8 fmul     FFDE0072   2     MFL       fp30=fp30,fp1,fcr
  166| 0016DC fmul     FD8C05B2   2     MFL       fp12=fp12,fp22,fcr
  155| 0016E0 fmul     FD7F02F2   2     MFL       fp11=fp31,fp11,fcr
  157| 0016E4 fmul     FDBF0372   2     MFL       fp13=fp31,fp13,fcr
  163| 0016E8 fmul     FFFE05F2   2     MFL       fp31=fp30,fp23,fcr
  155| 0016EC stfdu    DD7A0008   2     STFDU     gr26,dv12[].rns21.(gr26,8)=fp11
  166| 0016F0 fmul     FD880332   1     MFL       fp12=fp8,fp12,fcr
  157| 0016F4 stfdu    DDBB0008   2     STFDU     gr27,dv13[].rns23.(gr27,8)=fp13
  163| 0016F8 stfdu    DFFC0008   1     STFDU     gr28,dv21[].rns24.(gr28,8)=fp31
  166| 0016FC stfdu    DD9D0008   1     STFDU     gr29,dv31[].rns26.(gr29,8)=fp12
    0| 001700 bc       419202B8   1     BT        CL.74,cr4,0x4/eq,taken=20%(20,80)
    0|                              CL.502:
  163| 001704 lfdux    7D8A34EE   1     LFDU      fp12,gr10=v1(gr10,gr6,0)
  166| 001708 lfdux    7FEB34EE   1     LFDU      fp31,gr11=v1(gr11,gr6,0)
  163| 00170C lfdux    7D6934EE   1     LFDU      fp11,gr9=v1(gr9,gr6,0)
  166| 001710 lfdux    7DAC34EE   1     LFDU      fp13,gr12=v1(gr12,gr6,0)
  163| 001714 lfdux    7F5E34EE   1     LFDU      fp26,gr30=v1(gr30,gr6,0)
  155| 001718 lfdux    7E512CEE   1     LFDU      fp18,gr17=v2(gr17,gr5,0)
  157| 00171C lfdux    7E763CEE   1     LFDU      fp19,gr22=v3(gr22,gr7,0)
  163| 001720 lfdux    7FAA34EE   1     LFDU      fp29,gr10=v1(gr10,gr6,0)
  166| 001724 fsub     FF9F6028   1     SFL       fp28=fp31,fp12,fcr
  166| 001728 lfdux    7F6B34EE   1     LFDU      fp27,gr11=v1(gr11,gr6,0)
  163| 00172C fsub     FFCB6028   1     SFL       fp30=fp11,fp12,fcr
  163| 001730 lfdux    7D6934EE   1     LFDU      fp11,gr9=v1(gr9,gr6,0)
  166| 001734 fsub     FDAC6828   1     SFL       fp13=fp12,fp13,fcr
  166| 001738 lfdux    7FEC34EE   1     LFDU      fp31,gr12=v1(gr12,gr6,0)
  166| 00173C fmul     FF290732   1     MFL       fp25=fp9,fp28,fcr
  163| 001740 lfdux    7F9E34EE   1     LFDU      fp28,gr30=v1(gr30,gr6,0)
  166| 001744 fsub     FF1BE828   1     SFL       fp24=fp27,fp29,fcr
  155| 001748 lfdux    7F702CEE   2     LFDU      fp27,gr16=v2(gr16,gr5,0)
  163| 00174C fsub     FD6BE828   1     SFL       fp11=fp11,fp29,fcr
  155| 001750 lfdux    7DF22CEE   2     LFDU      fp15,gr18=v2(gr18,gr5,0)
  163| 001754 fsub     FD8CD028   1     SFL       fp12=fp12,fp26,fcr
  155| 001758 lfdux    7F532CEE   2     LFDU      fp26,gr19=v2(gr19,gr5,0)
  166| 00175C fsub     FFFDF828   1     SFL       fp31=fp29,fp31,fcr
  163| 001760 lfd      C9D80008   1     LFL       fp14=g2ai(gr24,8)
  166| 001764 fmul     FF090632   1     MFL       fp24=fp9,fp24,fcr
  166| 001768 lfd      CA990008   1     LFL       fp20=g31ai(gr25,8)
  163| 00176C fsub     FF9DE028   1     SFL       fp28=fp29,fp28,fcr
  155| 001770 lfdux    7FB02CEE   2     LFDU      fp29,gr16=v2(gr16,gr5,0)
  163| 001774 fmul     FEE602F2   1     MFL       fp23=fp6,fp11,fcr
  166| 001778 lfdu     CE390010   1     LFDU      fp17,gr25=g31ai(gr25,16)
  166| 00177C fmadd    FDAACB7A   1     FMA       fp13=fp25,fp10,fp13,fcr
  157| 001780 lfdux    7F343CEE   1     LFDU      fp25,gr20=v3(gr20,gr7,0)
  166| 001784 fmadd    FFEAC7FA   1     FMA       fp31=fp24,fp10,fp31,fcr
  157| 001788 lfdux    7F173CEE   1     LFDU      fp24,gr23=v3(gr23,gr7,0)
  163| 00178C fmadd    FEE7BF3A   1     FMA       fp23=fp23,fp7,fp28,fcr
  155| 001790 lfdux    7F932CEE   2     LFDU      fp28,gr19=v2(gr19,gr5,0)
  163| 001794 fmul     FFC607B2   1     MFL       fp30=fp6,fp30,fcr
  155| 001798 lfd      CA0F0008   1     LFL       fp16=dx1bi(gr15,8)
  166| 00179C fmul     FEAD0072   1     MFL       fp21=fp13,fp1,fcr
  157| 0017A0 lfdux    7DB53CEE   1     LFDU      fp13,gr21=v3(gr21,gr7,0)
  155| 0017A4 fsub     FF7BD028   1     SFL       fp27=fp27,fp26,fcr
  155| 0017A8 lfdux    7F512CEE   2     LFDU      fp26,gr17=v2(gr17,gr5,0)
  163| 0017AC fmadd    FD87F33A   1     FMA       fp12=fp30,fp7,fp12,fcr
  157| 0017B0 lfdux    7FD43CEE   1     LFDU      fp30,gr20=v3(gr20,gr7,0)
  155| 0017B4 fsub     FFBDE028   1     SFL       fp29=fp29,fp28,fcr
  157| 0017B8 lfdux    7F973CEE   1     LFDU      fp28,gr23=v3(gr23,gr7,0)
  157| 0017BC fsub     FF39C028   1     SFL       fp25=fp25,fp24,fcr
  157| 0017C0 lfdux    7F153CEE   1     LFDU      fp24,gr21=v3(gr21,gr7,0)
  163| 0017C4 fmul     FEF70072   1     MFL       fp23=fp23,fp1,fcr
  155| 0017C8 lfdu     CD6F0010   1     LFDU      fp11,gr15=dx1bi(gr15,16)
  155| 0017CC fadd     FFBAE82A   1     AFL       fp29=fp26,fp29,fcr
  163| 0017D0 lfdu     CF580010   1     LFDU      fp26,gr24=g2ai(gr24,16)
  157| 0017D4 fsub     FFDEE028   1     SFL       fp30=fp30,fp28,fcr
  157| 0017D8 lfdux    7F963CEE   1     LFDU      fp28,gr22=v3(gr22,gr7,0)
  166| 0017DC fmul     FFFF0072   1     MFL       fp31=fp31,fp1,fcr
  155| 0017E0 lfdux    7ED22CEE   2     LFDU      fp22,gr18=v2(gr18,gr5,0)
  163| 0017E4 fmul     FD8C0072   1     MFL       fp12=fp12,fp1,fcr
  155| 0017E8 fmul     FD6B0072   2     MFL       fp11=fp11,fp1,fcr
  157| 0017EC fadd     FFD8F02A   2     AFL       fp30=fp24,fp30,fcr
  166| 0017F0 fmul     FF150532   2     MFL       fp24=fp21,fp20,fcr
  166| 0017F4 fmul     FFFF0472   2     MFL       fp31=fp31,fp17,fcr
  155| 0017F8 fadd     FF72D82A   2     AFL       fp27=fp18,fp27,fcr
  155| 0017FC fsub     FFBDB028   2     SFL       fp29=fp29,fp22,fcr
  163| 001800 fmul     FD8C03B2   2     MFL       fp12=fp12,fp14,fcr
  157| 001804 fsub     FFDEE028   2     SFL       fp30=fp30,fp28,fcr
  163| 001808 fmul     FF9706B2   2     MFL       fp28=fp23,fp26,fcr
  157| 00180C fadd     FDADC82A   2     AFL       fp13=fp13,fp25,fcr
  166| 001810 fmul     FF480632   2     MFL       fp26=fp8,fp24,fcr
  155| 001814 fmul     FFAB0772   2     MFL       fp29=fp11,fp29,fcr
  166| 001818 fmul     FFE807F2   2     MFL       fp31=fp8,fp31,fcr
  163| 00181C stfd     D99C0008   1     STFL      dv21[].rns24.(gr28,8)=fp12
  157| 001820 fmul     FD6B07B2   1     MFL       fp11=fp11,fp30,fcr
  163| 001824 stfdu    DF9C0010   2     STFDU     gr28,dv21[].rns24.(gr28,16)=fp28
  155| 001828 fsub     FFDB7828   1     SFL       fp30=fp27,fp15,fcr
  166| 00182C stfd     DB5D0008   1     STFL      dv31[].rns26.(gr29,8)=fp26
  155| 001830 fmul     FF900072   1     MFL       fp28=fp16,fp1,fcr
  155| 001834 stfdu    DFBA0010   2     STFDU     gr26,dv12[].rns21.(gr26,16)=fp29
  157| 001838 fsub     FD8D9828   1     SFL       fp12=fp13,fp19,fcr
  157| 00183C stfdu    DD7B0010   2     STFDU     gr27,dv13[].rns23.(gr27,16)=fp11
  166| 001840 stfdu    DFFD0010   1     STFDU     gr29,dv31[].rns26.(gr29,16)=fp31
  155| 001844 fmul     FDBC07B2   1     MFL       fp13=fp28,fp30,fcr
  157| 001848 fmul     FFFC0332   2     MFL       fp31=fp28,fp12,fcr
    0| 00184C bc       42400164   1     BCF       ctr=CL.521,taken=0%(0,100)
    0| 001850 ori      60210000   1     XNOP      
    0| 001854 ori      60210000   1     XNOP      
    0| 001858 ori      60210000   1     XNOP      
    0|                              CL.522:
  155| 00185C lfd      C96F0008   1     LFL       fp11=dx1bi(gr15,8)
  155| 001860 lfdu     CF4F0010   1     LFDU      fp26,gr15=dx1bi(gr15,16)
  155| 001864 lfdux    7D922CEE   1     LFDU      fp12,gr18=v2(gr18,gr5,0)
  155| 001868 stfd     D9BAFFF8   1     STFL      dv12[].rns21.(gr26,-8)=fp13
  155| 00186C lfdux    7F702CEE   1     LFDU      fp27,gr16=v2(gr16,gr5,0)
  155| 001870 lfdux    7F132CEE   1     LFDU      fp24,gr19=v2(gr19,gr5,0)
  157| 001874 stfd     DBFBFFF8   1     STFL      dv13[].rns23.(gr27,-8)=fp31
  155| 001878 lfdux    7DB12CEE   1     LFDU      fp13,gr17=v2(gr17,gr5,0)
  157| 00187C lfdux    7FF43CEE   1     LFDU      fp31,gr20=v3(gr20,gr7,0)
  157| 001880 lfdux    7FD73CEE   1     LFDU      fp30,gr23=v3(gr23,gr7,0)
  155| 001884 lfdux    7F302CEE   1     LFDU      fp25,gr16=v2(gr16,gr5,0)
  155| 001888 lfdux    7EF32CEE   1     LFDU      fp23,gr19=v2(gr19,gr5,0)
  157| 00188C lfdux    7FB63CEE   1     LFDU      fp29,gr22=v3(gr22,gr7,0)
  157| 001890 lfdux    7F953CEE   1     LFDU      fp28,gr21=v3(gr21,gr7,0)
  155| 001894 fsub     FF7BC028   1     SFL       fp27=fp27,fp24,fcr
  157| 001898 lfdux    7ED43CEE   1     LFDU      fp22,gr20=v3(gr20,gr7,0)
  157| 00189C lfdux    7EB73CEE   1     LFDU      fp21,gr23=v3(gr23,gr7,0)
  155| 0018A0 lfdux    7F112CEE   1     LFDU      fp24,gr17=v2(gr17,gr5,0)
  155| 0018A4 fsub     FEF9B828   1     SFL       fp23=fp25,fp23,fcr
  155| 0018A8 fmul     FF5A0072   2     MFL       fp26=fp26,fp1,fcr
  155| 0018AC lfdux    7E722CEE   2     LFDU      fp19,gr18=v2(gr18,gr5,0)
  157| 0018B0 lfdux    7F363CEE   1     LFDU      fp25,gr22=v3(gr22,gr7,0)
  157| 0018B4 lfdux    7E953CEE   1     LFDU      fp20,gr21=v3(gr21,gr7,0)
  157| 0018B8 fsub     FE36A828   1     SFL       fp17=fp22,fp21,fcr
  155| 0018BC fadd     FE58B82A   2     AFL       fp18=fp24,fp23,fcr
  163| 0018C0 lfdux    7F0934EE   1     LFDU      fp24,gr9=v1(gr9,gr6,0)
  166| 0018C4 lfdux    7EEC34EE   1     LFDU      fp23,gr12=v1(gr12,gr6,0)
  163| 0018C8 lfdux    7ECA34EE   1     LFDU      fp22,gr10=v1(gr10,gr6,0)
  166| 0018CC lfdux    7EAB34EE   1     LFDU      fp21,gr11=v1(gr11,gr6,0)
  157| 0018D0 fadd     FE94882A   1     AFL       fp20=fp20,fp17,fcr
  155| 0018D4 fsub     FE729828   2     SFL       fp19=fp18,fp19,fcr
  163| 0018D8 lfdux    7E5E34EE   1     LFDU      fp18,gr30=v1(gr30,gr6,0)
  163| 0018DC lfdux    7E2934EE   1     LFDU      fp17,gr9=v1(gr9,gr6,0)
  166| 0018E0 lfdux    7E0C34EE   1     LFDU      fp16,gr12=v1(gr12,gr6,0)
  163| 0018E4 lfdux    7DEA34EE   1     LFDU      fp15,gr10=v1(gr10,gr6,0)
  166| 0018E8 lfdux    7DCB34EE   1     LFDU      fp14,gr11=v1(gr11,gr6,0)
  166| 0018EC fsub     FEB5B028   1     SFL       fp21=fp21,fp22,fcr
  157| 0018F0 fsub     FF34C828   2     SFL       fp25=fp20,fp25,fcr
  163| 0018F4 lfdux    7E9E34EE   1     LFDU      fp20,gr30=v1(gr30,gr6,0)
  163| 0018F8 fsub     FE569028   1     SFL       fp18=fp22,fp18,fcr
  163| 0018FC fsub     FF18B028   2     SFL       fp24=fp24,fp22,fcr
  163| 001900 fsub     FE317828   2     SFL       fp17=fp17,fp15,fcr
  166| 001904 fsub     FDCE7828   2     SFL       fp14=fp14,fp15,fcr
  166| 001908 fsub     FE0F8028   2     SFL       fp16=fp15,fp16,fcr
  166| 00190C fmul     FEA90572   2     MFL       fp21=fp9,fp21,fcr
  166| 001910 fsub     FEF6B828   2     SFL       fp23=fp22,fp23,fcr
  163| 001914 fsub     FECFA028   2     SFL       fp22=fp15,fp20,fcr
  163| 001918 fmul     FE860472   2     MFL       fp20=fp6,fp17,fcr
  166| 00191C fmul     FE2903B2   2     MFL       fp17=fp9,fp14,fcr
  163| 001920 fmul     FF060632   2     MFL       fp24=fp6,fp24,fcr
  163| 001924 lfd      C9F80008   1     LFL       fp15=g2ai(gr24,8)
  166| 001928 fmadd    FEEAADFA   1     FMA       fp23=fp21,fp10,fp23,fcr
  163| 00192C lfdu     CEB80010   1     LFDU      fp21,gr24=g2ai(gr24,16)
  163| 001930 fmadd    FEC7A5BA   1     FMA       fp22=fp20,fp7,fp22,fcr
  166| 001934 fmadd    FE8A8C3A   2     FMA       fp20=fp17,fp10,fp16,fcr
  163| 001938 fmadd    FF07C4BA   2     FMA       fp24=fp24,fp7,fp18,fcr
  166| 00193C lfd      CA590008   1     LFL       fp18=g31ai(gr25,8)
  166| 001940 fmul     FEF70072   1     MFL       fp23=fp23,fp1,fcr
  166| 001944 lfdu     CE390010   1     LFDU      fp17,gr25=g31ai(gr25,16)
  163| 001948 fmul     FED60072   1     MFL       fp22=fp22,fp1,fcr
  166| 00194C fmul     FE940072   2     MFL       fp20=fp20,fp1,fcr
  163| 001950 fmul     FF180072   2     MFL       fp24=fp24,fp1,fcr
  155| 001954 fmul     FE7A04F2   2     MFL       fp19=fp26,fp19,fcr
  166| 001958 fmul     FEF704B2   2     MFL       fp23=fp23,fp18,fcr
  157| 00195C fmul     FF5A0672   2     MFL       fp26=fp26,fp25,fcr
  163| 001960 fmul     FF360572   2     MFL       fp25=fp22,fp21,fcr
  166| 001964 fmul     FED40472   2     MFL       fp22=fp20,fp17,fcr
  163| 001968 fmul     FF1803F2   2     MFL       fp24=fp24,fp15,fcr
  157| 00196C fsub     FFFFF028   2     SFL       fp31=fp31,fp30,fcr
  166| 001970 fmul     FFC805F2   2     MFL       fp30=fp8,fp23,fcr
  155| 001974 fadd     FDADD82A   2     AFL       fp13=fp13,fp27,fcr
  155| 001978 stfdu    DE7A0010   2     STFDU     gr26,dv12[].rns21.(gr26,16)=fp19
  166| 00197C fmul     FF6805B2   1     MFL       fp27=fp8,fp22,fcr
  163| 001980 stfdu    DF3C0010   2     STFDU     gr28,dv21[].rns24.(gr28,16)=fp25
  157| 001984 stfdu    DF5B0010   1     STFDU     gr27,dv13[].rns23.(gr27,16)=fp26
  163| 001988 stfd     DB1CFFF8   1     STFL      dv21[].rns24.(gr28,-8)=fp24
  166| 00198C stfd     DBDD0008   1     STFL      dv31[].rns26.(gr29,8)=fp30
  157| 001990 fadd     FFFCF82A   1     AFL       fp31=fp28,fp31,fcr
  166| 001994 stfdu    DF7D0010   2     STFDU     gr29,dv31[].rns26.(gr29,16)=fp27
  155| 001998 fsub     FD8D6028   1     SFL       fp12=fp13,fp12,fcr
  155| 00199C fmul     FD6B0072   2     MFL       fp11=fp11,fp1,fcr
  157| 0019A0 fsub     FFFFE828   2     SFL       fp31=fp31,fp29,fcr
  155| 0019A4 fmul     FDAB0332   2     MFL       fp13=fp11,fp12,fcr
  157| 0019A8 fmul     FFEB07F2   2     MFL       fp31=fp11,fp31,fcr
    0| 0019AC bc       4200FEB0   1     BCT       ctr=CL.522,taken=100%(100,0)
    0|                              CL.521:
  155| 0019B0 stfd     D9BAFFF8   1     STFL      dv12[].rns21.(gr26,-8)=fp13
  157| 0019B4 stfd     DBFBFFF8   1     STFL      dv13[].rns23.(gr27,-8)=fp31
  169|                              CL.74:
  170| 0019B8 bc       40850340   1     BF        CL.39,cr1,0x2/gt,taken=50%(0,0)
  171| 0019BC bc       409D033C   1     BF        CL.39,cr7,0x2/gt,taken=50%(0,0)
  176| 0019C0 ld       EB1F0380   1     L8        gr24=#SPILL110(gr31,896)
  176| 0019C4 ld       EAFF0388   1     L8        gr23=#SPILL146(gr31,904)
  172| 0019C8 ld       EADF0390   1     L8        gr22=#SPILL88(gr31,912)
    0| 0019CC ld       EA5F03D0   1     L8        gr18=#SPILL122(gr31,976)
  171| 0019D0 ld       E93F0150   1     L8        gr9=#SPILL134(gr31,336)
  171| 0019D4 ld       E95F0168   1     L8        gr10=#SPILL136(gr31,360)
  171| 0019D8 ld       EB3F0160   1     L8        gr25=#SPILL135(gr31,352)
  171| 0019DC ld       EB5F0148   1     L8        gr26=#SPILL133(gr31,328)
  176| 0019E0 ld       EABF03A8   1     L8        gr21=#SPILL89(gr31,936)
  172| 0019E4 ld       EA9F03B8   1     L8        gr20=#SPILL109(gr31,952)
    0| 0019E8 ld       EA7F03C8   1     L8        gr19=#SPILL187(gr31,968)
  176| 0019EC add      7FD7C214   1     A         gr30=gr23,gr24
  172| 0019F0 add      7F96BA14   1     A         gr28=gr22,gr23
    0| 0019F4 cmpdi    2D320000   1     C8        cr2=gr18,0
  171| 0019F8 lfd      C9B90000   1     LFL       fp13=v3(gr25,0)
  171| 0019FC lfd      C98A0000   1     LFL       fp12=v3(gr10,0)
  171| 001A00 lfd      C8DA0000   1     LFL       fp6=v2(gr26,0)
  171| 001A04 lfd      C9690000   1     LFL       fp11=v2(gr9,0)
  176| 001A08 ld       E97F0398   1     L8        gr11=#SPILL154(gr31,920)
  172| 001A0C ld       E99F03A0   1     L8        gr12=#SPILL155(gr31,928)
  176| 001A10 add      7FD5F214   1     A         gr30=gr21,gr30
  176| 001A14 ld       EBBF03B0   1     L8        gr29=#SPILL152(gr31,944)
  172| 001A18 add      7F94E214   1     A         gr28=gr20,gr28
  172| 001A1C ld       EB7F03C0   1     L8        gr27=#SPILL151(gr31,960)
    0| 001A20 mtspr    7E6903A6   1     LCTR      ctr=gr19
    0| 001A24 bc       418A0078   1     BT        CL.504,cr2,0x4/eq,taken=50%(0,0)
  171| 001A28 lfdux    7CEA3CEE   1     LFDU      fp7,gr10=v3(gr10,gr7,0)
  171| 001A2C lfdux    7D092CEE   1     LFDU      fp8,gr9=v2(gr9,gr5,0)
  171| 001A30 lfdux    7D393CEE   1     LFDU      fp9,gr25=v3(gr25,gr7,0)
  171| 001A34 lfdux    7D5A2CEE   1     LFDU      fp10,gr26=v2(gr26,gr5,0)
  172| 001A38 lfdu     CFFB0008   1     LFDU      fp31,gr27=g2ai(gr27,8)
  176| 001A3C lfdu     CFDD0008   1     LFDU      fp30,gr29=g31ai(gr29,8)
  172| 001A40 lfd      CBAC0008   1     LFL       fp29=dv21[].rns24.(gr12,8)
  176| 001A44 fadd     FD87602A   1     AFL       fp12=fp7,fp12,fcr
  172| 001A48 lfdu     CF9C0008   1     LFDU      fp28,gr28=dg2ad1(gr28,8)
  172| 001A4C fadd     FF68582A   1     AFL       fp27=fp8,fp11,fcr
  176| 001A50 lfd      CB4B0008   1     LFL       fp26=dv31[].rns26.(gr11,8)
  176| 001A54 fmr      FD604090   1     LRFL      fp11=fp8
  176| 001A58 lfdu     CD1E0008   1     LFDU      fp8,gr30=dg31ad1(gr30,8)
  176| 001A5C fadd     FF2C482A   1     AFL       fp25=fp12,fp9,fcr
  176| 001A60 fmr      FD803890   2     LRFL      fp12=fp7
  172| 001A64 fadd     FCFB502A   2     AFL       fp7=fp27,fp10,fcr
  176| 001A68 fadd     FF79682A   2     AFL       fp27=fp25,fp13,fcr
  176| 001A6C fmr      FDA04890   2     LRFL      fp13=fp9
  172| 001A70 fadd     FCE7302A   2     AFL       fp7=fp7,fp6,fcr
  176| 001A74 fmr      FCC05090   2     LRFL      fp6=fp10
  176| 001A78 fmul     FD3B00B2   2     MFL       fp9=fp27,fp2,fcr
  172| 001A7C fmul     FCE700B2   2     MFL       fp7=fp7,fp2,fcr
  176| 001A80 fmul     FD2907B2   2     MFL       fp9=fp9,fp30,fcr
  172| 001A84 fmul     FCE707F2   2     MFL       fp7=fp7,fp31,fcr
  176| 001A88 fnmsub   FD09D23C   2     FNMS      fp8=fp26,fp9,fp8,fcr
  172| 001A8C fnmsub   FCE7EF3C   2     FNMS      fp7=fp29,fp7,fp28,fcr
  176| 001A90 stfdu    DD0B0008   2     STFDU     gr11,dv31[].rns26.(gr11,8)=fp8
  172| 001A94 stfdu    DCEC0008   1     STFDU     gr12,dv21[].rns24.(gr12,8)=fp7
    0| 001A98 bc       41920260   1     BT        CL.39,cr4,0x4/eq,taken=20%(20,80)
    0|                              CL.504:
  171| 001A9C lfdux    7F6A3CEE   1     LFDU      fp27,gr10=v3(gr10,gr7,0)
  171| 001AA0 lfdux    7FF93CEE   1     LFDU      fp31,gr25=v3(gr25,gr7,0)
  171| 001AA4 lfdux    7CE92CEE   1     LFDU      fp7,gr9=v2(gr9,gr5,0)
  171| 001AA8 lfdux    7D1A2CEE   1     LFDU      fp8,gr26=v2(gr26,gr5,0)
  176| 001AAC lfd      CBBD0008   1     LFL       fp29=g31ai(gr29,8)
  176| 001AB0 lfd      C92B0008   1     LFL       fp9=dv31[].rns26.(gr11,8)
  176| 001AB4 lfd      C95E0008   1     LFL       fp10=dg31ad1(gr30,8)
  176| 001AB8 fadd     FF3B602A   1     AFL       fp25=fp27,fp12,fcr
  171| 001ABC lfdux    7FCA3CEE   1     LFDU      fp30,gr10=v3(gr10,gr7,0)
  172| 001AC0 fadd     FF47582A   1     AFL       fp26=fp7,fp11,fcr
  171| 001AC4 lfdux    7D793CEE   1     LFDU      fp11,gr25=v3(gr25,gr7,0)
  171| 001AC8 lfdux    7D892CEE   1     LFDU      fp12,gr9=v2(gr9,gr5,0)
  176| 001ACC lfd      CB8B0010   1     LFL       fp28=dv31[].rns26.(gr11,16)
  176| 001AD0 fadd     FF19F82A   1     AFL       fp24=fp25,fp31,fcr
  176| 001AD4 lfdu     CF3D0010   1     LFDU      fp25,gr29=g31ai(gr29,16)
  176| 001AD8 fadd     FEFED82A   1     AFL       fp23=fp30,fp27,fcr
  176| 001ADC lfdu     CF7E0010   1     LFDU      fp27,gr30=dg31ad1(gr30,16)
  172| 001AE0 fadd     FF5A402A   1     AFL       fp26=fp26,fp8,fcr
  176| 001AE4 fadd     FDB8682A   2     AFL       fp13=fp24,fp13,fcr
  176| 001AE8 fadd     FF17582A   2     AFL       fp24=fp23,fp11,fcr
  176| 001AEC fmul     FDAD00B2   2     MFL       fp13=fp13,fp2,fcr
  176| 001AF0 fadd     FFF8F82A   2     AFL       fp31=fp24,fp31,fcr
  176| 001AF4 fmul     FDAD0772   2     MFL       fp13=fp13,fp29,fcr
  176| 001AF8 fmul     FFFF00B2   2     MFL       fp31=fp31,fp2,fcr
    0| 001AFC bc       42400198   1     BCF       ctr=CL.523,taken=0%(0,100)
  172| 001B00 fadd     FF1A302A   1     AFL       fp24=fp26,fp6,fcr
  171| 001B04 lfdux    7F4A3CEE   1     LFDU      fp26,gr10=v3(gr10,gr7,0)
  172| 001B08 fadd     FCEC382A   1     AFL       fp7=fp12,fp7,fcr
  171| 001B0C lfdux    7CDA2CEE   1     LFDU      fp6,gr26=v2(gr26,gr5,0)
  176| 001B10 fmul     FFBF0672   1     MFL       fp29=fp31,fp25,fcr
  171| 001B14 lfdux    7FF93CEE   1     LFDU      fp31,gr25=v3(gr25,gr7,0)
  172| 001B18 fmul     FF3800B2   1     MFL       fp25=fp24,fp2,fcr
  172| 001B1C lfd      CB1B0008   1     LFL       fp24=g2ai(gr27,8)
  176| 001B20 fadd     FEFAF02A   1     AFL       fp23=fp26,fp30,fcr
  171| 001B24 lfdux    7FCA3CEE   1     LFDU      fp30,gr10=v3(gr10,gr7,0)
  172| 001B28 fadd     FCE7302A   1     AFL       fp7=fp7,fp6,fcr
  172| 001B2C lfd      CA6C0008   1     LFL       fp19=dv21[].rns24.(gr12,8)
  176| 001B30 fnmsub   FE9DE6FC   1     FNMS      fp20=fp28,fp29,fp27,fcr
  171| 001B34 lfdux    7FB93CEE   1     LFDU      fp29,gr25=v3(gr25,gr7,0)
  176| 001B38 fadd     FEB7F82A   1     AFL       fp21=fp23,fp31,fcr
  172| 001B3C lfd      CB9C0008   1     LFL       fp28=dg2ad1(gr28,8)
  172| 001B40 fadd     FD07402A   1     AFL       fp8=fp7,fp8,fcr
  172| 001B44 lfdu     CF7B0010   1     LFDU      fp27,gr27=g2ai(gr27,16)
  176| 001B48 fadd     FF5ED02A   1     AFL       fp26=fp30,fp26,fcr
  171| 001B4C lfdux    7CE92CEE   1     LFDU      fp7,gr9=v2(gr9,gr5,0)
  172| 001B50 fmul     FF390632   1     MFL       fp25=fp25,fp24,fcr
  172| 001B54 lfd      CB0C0010   1     LFL       fp24=dv21[].rns24.(gr12,16)
  176| 001B58 fnmsub   FDAD4ABC   1     FNMS      fp13=fp9,fp13,fp10,fcr
  176| 001B5C lfd      C92B0018   1     LFL       fp9=dv31[].rns26.(gr11,24)
  172| 001B60 fmul     FEE800B2   1     MFL       fp23=fp8,fp2,fcr
  176| 001B64 stfdu    DE8B0010   2     STFDU     gr11,dv31[].rns26.(gr11,16)=fp20
  176| 001B68 fadd     FD75582A   1     AFL       fp11=fp21,fp11,fcr
  172| 001B6C lfdu     CEDC0010   1     LFDU      fp22,gr28=dg2ad1(gr28,16)
  176| 001B70 fadd     FF5AE82A   1     AFL       fp26=fp26,fp29,fcr
  176| 001B74 stfd     D9ABFFF8   1     STFL      dv31[].rns26.(gr11,-8)=fp13
  172| 001B78 fnmsub   FF999F3C   1     FNMS      fp28=fp19,fp25,fp28,fcr
  171| 001B7C lfdux    7D1A2CEE   1     LFDU      fp8,gr26=v2(gr26,gr5,0)
  172| 001B80 fmul     FF3706F2   1     MFL       fp25=fp23,fp27,fcr
  176| 001B84 lfd      CABD0008   1     LFL       fp21=g31ai(gr29,8)
  172| 001B88 fadd     FF67602A   1     AFL       fp27=fp7,fp12,fcr
  176| 001B8C lfd      C95E0008   1     LFL       fp10=dg31ad1(gr30,8)
  176| 001B90 fadd     FDBAF82A   1     AFL       fp13=fp26,fp31,fcr
  172| 001B94 stfd     DB8C0008   1     STFL      dv21[].rns24.(gr12,8)=fp28
  176| 001B98 fmul     FD6B00B2   1     MFL       fp11=fp11,fp2,fcr
  171| 001B9C lfdux    7D892CEE   1     LFDU      fp12,gr9=v2(gr9,gr5,0)
  172| 001BA0 fnmsub   FF19C5BC   1     FNMS      fp24=fp24,fp25,fp22,fcr
  176| 001BA4 lfd      CB8B0010   1     LFL       fp28=dv31[].rns26.(gr11,16)
  172| 001BA8 fadd     FF5B402A   1     AFL       fp26=fp27,fp8,fcr
  176| 001BAC lfdu     CF3D0010   1     LFDU      fp25,gr29=g31ai(gr29,16)
  176| 001BB0 fmul     FFED00B2   1     MFL       fp31=fp13,fp2,fcr
  176| 001BB4 lfdu     CF7E0010   1     LFDU      fp27,gr30=dg31ad1(gr30,16)
  176| 001BB8 fmul     FDAB0572   1     MFL       fp13=fp11,fp21,fcr
    0| 001BBC bc       424000D4   1     BCF       ctr=CL.524,taken=0%(0,100)
    0| 001BC0 ori      60210000   1     XNOP      
    0| 001BC4 ori      60210000   1     XNOP      
    0| 001BC8 ori      60210000   1     XNOP      
    0|                              CL.525:
  171| 001BCC lfdux    7D6A3CEE   1     LFDU      fp11,gr10=v3(gr10,gr7,0)
  172| 001BD0 fadd     FF5A302A   1     AFL       fp26=fp26,fp6,fcr
  171| 001BD4 lfdux    7CDA2CEE   1     LFDU      fp6,gr26=v2(gr26,gr5,0)
  172| 001BD8 fadd     FCEC382A   1     AFL       fp7=fp12,fp7,fcr
  176| 001BDC fmul     FFFF0672   2     MFL       fp31=fp31,fp25,fcr
  176| 001BE0 fnmsub   FDAD4ABC   2     FNMS      fp13=fp9,fp13,fp10,fcr
  172| 001BE4 stfdu    DF0C0010   2     STFDU     gr12,dv21[].rns24.(gr12,16)=fp24
  176| 001BE8 fadd     FF2BF02A   1     AFL       fp25=fp11,fp30,fcr
  171| 001BEC lfdux    7FCA3CEE   1     LFDU      fp30,gr10=v3(gr10,gr7,0)
  172| 001BF0 fadd     FCE7302A   1     AFL       fp7=fp7,fp6,fcr
  176| 001BF4 fnmsub   FF1FE6FC   2     FNMS      fp24=fp28,fp31,fp27,fcr
  176| 001BF8 lfd      C92B0018   1     LFL       fp9=dv31[].rns26.(gr11,24)
  171| 001BFC lfdux    7FF93CEE   1     LFDU      fp31,gr25=v3(gr25,gr7,0)
  176| 001C00 lfd      C95E0008   1     LFL       fp10=dg31ad1(gr30,8)
  172| 001C04 lfd      CB9B0008   1     LFL       fp28=g2ai(gr27,8)
  172| 001C08 fadd     FF67402A   1     AFL       fp27=fp7,fp8,fcr
  172| 001C0C fmul     FF5A00B2   2     MFL       fp26=fp26,fp2,fcr
  176| 001C10 stfdu    DF0B0010   2     STFDU     gr11,dv31[].rns26.(gr11,16)=fp24
  172| 001C14 lfd      C90C0008   1     LFL       fp8=dv21[].rns24.(gr12,8)
  176| 001C18 fadd     FCF9F82A   1     AFL       fp7=fp25,fp31,fcr
  172| 001C1C lfdu     CF3B0010   1     LFDU      fp25,gr27=g2ai(gr27,16)
  172| 001C20 fmul     FF1B00B2   1     MFL       fp24=fp27,fp2,fcr
  172| 001C24 fmul     FF9A0732   2     MFL       fp28=fp26,fp28,fcr
  172| 001C28 lfd      CB7C0008   1     LFL       fp27=dg2ad1(gr28,8)
  176| 001C2C fadd     FEFE582A   1     AFL       fp23=fp30,fp11,fcr
  176| 001C30 fadd     FF47E82A   2     AFL       fp26=fp7,fp29,fcr
  171| 001C34 lfdux    7FB93CEE   1     LFDU      fp29,gr25=v3(gr25,gr7,0)
  171| 001C38 lfdux    7CE92CEE   1     LFDU      fp7,gr9=v2(gr9,gr5,0)
  172| 001C3C fmul     FD780672   1     MFL       fp11=fp24,fp25,fcr
  172| 001C40 lfd      CB2C0010   1     LFL       fp25=dv21[].rns24.(gr12,16)
  172| 001C44 lfdu     CF1C0010   1     LFDU      fp24,gr28=dg2ad1(gr28,16)
  172| 001C48 fnmsub   FF9C46FC   1     FNMS      fp28=fp8,fp28,fp27,fcr
  176| 001C4C stfd     D9ABFFF8   1     STFL      dv31[].rns26.(gr11,-8)=fp13
  176| 001C50 fadd     FDB7E82A   1     AFL       fp13=fp23,fp29,fcr
  172| 001C54 fadd     FF67602A   2     AFL       fp27=fp7,fp12,fcr
  171| 001C58 lfdux    7D892CEE   1     LFDU      fp12,gr9=v2(gr9,gr5,0)
  171| 001C5C lfdux    7D1A2CEE   1     LFDU      fp8,gr26=v2(gr26,gr5,0)
  172| 001C60 fnmsub   FF0BCE3C   1     FNMS      fp24=fp25,fp11,fp24,fcr
  176| 001C64 lfd      C97D0008   1     LFL       fp11=g31ai(gr29,8)
  176| 001C68 fadd     FFEDF82A   1     AFL       fp31=fp13,fp31,fcr
  176| 001C6C fmul     FDBA00B2   2     MFL       fp13=fp26,fp2,fcr
  172| 001C70 stfd     DB8C0008   1     STFL      dv21[].rns24.(gr12,8)=fp28
  176| 001C74 lfd      CB8B0010   1     LFL       fp28=dv31[].rns26.(gr11,16)
  172| 001C78 fadd     FF5B402A   1     AFL       fp26=fp27,fp8,fcr
  176| 001C7C lfdu     CF3D0010   1     LFDU      fp25,gr29=g31ai(gr29,16)
  176| 001C80 fmul     FFFF00B2   1     MFL       fp31=fp31,fp2,fcr
  176| 001C84 fmul     FDAD02F2   2     MFL       fp13=fp13,fp11,fcr
  176| 001C88 lfdu     CF7E0010   1     LFDU      fp27,gr30=dg31ad1(gr30,16)
    0| 001C8C bc       4200FF40   1     BCT       ctr=CL.525,taken=100%(100,0)
    0|                              CL.524:
  172| 001C90 stfdu    DF0C0010   1     STFDU     gr12,dv21[].rns24.(gr12,16)=fp24
    0|                              CL.523:
  171| 001C94 lfdux    7D7A2CEE   1     LFDU      fp11,gr26=v2(gr26,gr5,0)
  172| 001C98 fadd     FCEC382A   1     AFL       fp7=fp12,fp7,fcr
  172| 001C9C lfd      C99B0008   1     LFL       fp12=g2ai(gr27,8)
  172| 001CA0 fadd     FCDA302A   1     AFL       fp6=fp26,fp6,fcr
  172| 001CA4 lfd      CBAC0008   1     LFL       fp29=dv21[].rns24.(gr12,8)
  176| 001CA8 fmul     FFFF0672   1     MFL       fp31=fp31,fp25,fcr
  172| 001CAC lfdu     CFDB0010   1     LFDU      fp30,gr27=g2ai(gr27,16)
  172| 001CB0 fadd     FCE7582A   1     AFL       fp7=fp7,fp11,fcr
  172| 001CB4 lfd      C97C0008   1     LFL       fp11=dg2ad1(gr28,8)
  172| 001CB8 fmul     FCC600B2   1     MFL       fp6=fp6,fp2,fcr
  172| 001CBC lfd      CB4C0010   1     LFL       fp26=dv21[].rns24.(gr12,16)
  176| 001CC0 fnmsub   FFFFE6FC   1     FNMS      fp31=fp28,fp31,fp27,fcr
  172| 001CC4 lfdu     CF9C0010   1     LFDU      fp28,gr28=dg2ad1(gr28,16)
  172| 001CC8 fadd     FCE7402A   1     AFL       fp7=fp7,fp8,fcr
  176| 001CCC fnmsub   FD0D4ABC   2     FNMS      fp8=fp9,fp13,fp10,fcr
  172| 001CD0 fmul     FCC60332   2     MFL       fp6=fp6,fp12,fcr
  176| 001CD4 stfdu    DFEB0010   2     STFDU     gr11,dv31[].rns26.(gr11,16)=fp31
  172| 001CD8 fmul     FCE700B2   1     MFL       fp7=fp7,fp2,fcr
  176| 001CDC stfd     D90BFFF8   1     STFL      dv31[].rns26.(gr11,-8)=fp8
  172| 001CE0 fnmsub   FCC6EAFC   1     FNMS      fp6=fp29,fp6,fp11,fcr
  172| 001CE4 fmul     FCE707B2   2     MFL       fp7=fp7,fp30,fcr
  172| 001CE8 stfd     D8CC0008   1     STFL      dv21[].rns24.(gr12,8)=fp6
  172| 001CEC fnmsub   FCC7D73C   1     FNMS      fp6=fp26,fp7,fp28,fcr
  172| 001CF0 stfdu    DCCC0010   2     STFDU     gr12,dv21[].rns24.(gr12,16)=fp6
    0| 001CF4 ori      60210000   1     XNOP      
  181|                              CL.39:
  185| 001CF8 bc       40810388   1     BF        CL.78,cr0,0x2/gt,taken=50%(0,0)
  189| 001CFC ld       EBBF0340   1     L8        gr29=#SPILL12(gr31,832)
  189| 001D00 ld       EB9F0120   1     L8        gr28=#SPILL116(gr31,288)
  189| 001D04 ld       EB7F0348   1     L8        gr27=#SPILL0(gr31,840)
  189| 001D08 ld       EB5F0350   1     L8        gr26=#SPILL43(gr31,848)
    0| 001D0C ld       EB3F0358   1     L8        gr25=#SPILL31(gr31,856)
    0| 001D10 ld       EB1F0360   1     L8        gr24=#SPILL34(gr31,864)
    0| 001D14 ld       EAFF0368   1     L8        gr23=#SPILL32(gr31,872)
    0| 001D18 ld       EADF0370   1     L8        gr22=#SPILL19(gr31,880)
    0| 001D1C ld       EABF0378   1     L8        gr21=#SPILL33(gr31,888)
  189| 001D20 add      7D7CEA14   1     A         gr11=gr28,gr29
  189| 001D24 add      7D5ADA14   1     A         gr10=gr26,gr27
    0| 001D28 rldicr   797E1F24   1     SLL8      gr30=gr11,3
    0| 001D2C rldicr   794C1F24   1     SLL8      gr12=gr10,3
    0| 001D30 lfdx     7CD9F4AE   1     LFL       fp6=dvl2ai(gr25,gr30,0)
    0| 001D34 lfdx     7CF8F4AE   1     LFL       fp7=g32a(gr24,gr30,0)
    0| 001D38 lfdx     7D17F4AE   1     LFL       fp8=g32a(gr23,gr30,0)
    0| 001D3C lfdx     7D36F4AE   1     LFL       fp9=g32bi(gr22,gr30,0)
    0| 001D40 lfdx     7D5564AE   1     LFL       fp10=dvl3ai(gr21,gr12,0)
    0| 001D44 ld       E93F08B0   1     L8        gr9=.deldotv(gr31,2224)
    0| 001D48 bc       40860854   1     BF        CL.245,cr1,0x4/eq,taken=50%(0,0)
  189| 001D4C ld       EA3F01F8   1     L8        gr17=#SPILL13(gr31,504)
  189| 001D50 ld       E9FF0200   1     L8        gr15=#SPILL2(gr31,512)
    0| 001D54 ld       EB9F0158   1     L8        gr28=#SPILL38(gr31,344)
    0| 001D58 ld       EB7F0208   1     L8        gr27=#SPILL30(gr31,520)
  200| 001D5C ld       EA9F01E8   1     L8        gr20=#SPILL26(gr31,488)
    0| 001D60 ld       EB5F0140   1     L8        gr26=#SPILL29(gr31,320)
  189| 001D64 mulld    7FAA89D2   1     M         gr29=gr10,gr17
  189| 001D68 mulld    7FCB79D2   1     M         gr30=gr11,gr15
    0| 001D6C ld       EB3F0210   1     L8        gr25=#SPILL37(gr31,528)
  200| 001D70 add      7E6CA214   1     A         gr19=gr12,gr20
    0| 001D74 mulld    7D8BE1D2   1     M         gr12=gr11,gr28
  200| 001D78 std      FA7F00C8   1     ST8       #SPILL193(gr31,200)=gr19
  189| 001D7C add      7F1DF214   1     A         gr24=gr29,gr30
    0| 001D80 mulld    7FCAD9D2   1     M         gr30=gr10,gr27
    0| 001D84 ld       EADF0128   1     L8        gr22=#SPILL36(gr31,296)
    0| 001D88 ld       EABF0220   1     L8        gr21=#SPILL114(gr31,544)
    0| 001D8C ld       E9DF0228   1     L8        gr14=#SPILL111(gr31,552)
    0| 001D90 add      7FCCF214   1     A         gr30=gr12,gr30
    0| 001D94 mulld    7D8BD1D2   1     M         gr12=gr11,gr26
    0| 001D98 mulld    7F8AC9D2   1     M         gr28=gr10,gr25
    0| 001D9C ld       EAFF0218   1     L8        gr23=#SPILL35(gr31,536)
    0| 001DA0 ld       EA9F0230   1     L8        gr20=#SPILL39(gr31,560)
    0| 001DA4 ld       EA7F0238   1     L8        gr19=#SPILL113(gr31,568)
    0| 001DA8 ld       EA5F01F0   1     L8        gr18=#SPILL120(gr31,496)
    0| 001DAC ld       EA1F01E0   1     L8        gr16=#SPILL150(gr31,480)
    0| 001DB0 add      7F8CE214   1     A         gr28=gr12,gr28
    0| 001DB4 mulld    7F6BB1D2   1     M         gr27=gr11,gr22
    0| 001DB8 mulld    7D8BA9D2   1     M         gr12=gr11,gr21
    0| 001DBC mulld    7D6B71D2   1     M         gr11=gr11,gr14
    0| 001DC0 ld       EA3F0260   1     L8        gr17=#SPILL181(gr31,608)
    0| 001DC4 mtspr    7E4903A6   1     LCTR      ctr=gr18
    0| 001DC8 add      7D298214   1     A         gr9=gr9,gr16
    0| 001DCC mulld    7FAAB9D2   1     M         gr29=gr10,gr23
    0| 001DD0 or       7D635B78   1     LR        gr3=gr11
    0| 001DD4 mulld    7F2AA1D2   1     M         gr25=gr10,gr20
    0| 001DD8 mulld    7EEA99D2   1     M         gr23=gr10,gr19
    0| 001DDC ld       E95F0240   1     L8        gr10=#SPILL27(gr31,576)
  189| 001DE0 ld       EA5F0248   1     L8        gr18=#SPILL182(gr31,584)
    0| 001DE4 add      7D71C214   1     A         gr11=gr17,gr24
    0| 001DE8 ld       EA1F0268   1     L8        gr16=#SPILL124(gr31,616)
    0| 001DEC ld       EA7F0298   1     L8        gr19=#SPILL167(gr31,664)
    0| 001DF0 ld       EA3F02A0   1     L8        gr17=#SPILL148(gr31,672)
    0| 001DF4 add      7D29C214   1     A         gr9=gr9,gr24
    0| 001DF8 add      7DCA6214   1     A         gr14=gr10,gr12
  189| 001DFC add      7D52C214   1     A         gr10=gr18,gr24
    0| 001E00 add      7D90F214   1     A         gr12=gr16,gr30
    0| 001E04 add      7E53C214   1     A         gr18=gr19,gr24
    0| 001E08 add      7F11C214   1     A         gr24=gr17,gr24
    0| 001E0C std      FA5F0100   1     ST8       #SPILL194(gr31,256)=gr18
    0| 001E10 std      FB1F00F8   1     ST8       #SPILL195(gr31,248)=gr24
    0| 001E14 ld       EA3F02A8   1     L8        gr17=#SPILL115(gr31,680)
    0| 001E18 ld       EA1F0098   1     L8        gr16=#SPILL112(gr31,152)
    0| 001E1C ld       E9FF0270   1     L8        gr15=#SPILL130(gr31,624)
    0| 001E20 add      7F5BEA14   1     A         gr26=gr27,gr29
    0| 001E24 ld       EB7F0278   1     L8        gr27=#SPILL123(gr31,632)
    0| 001E28 ld       EADF0280   1     L8        gr22=#SPILL128(gr31,640)
    0| 001E2C ld       EABF0288   1     L8        gr21=#SPILL145(gr31,648)
    0| 001E30 mulld    7F1089D2   1     M         gr24=gr16,gr17
    0| 001E34 add      7FCFF214   1     A         gr30=gr15,gr30
    0| 001E38 ld       E9FF02B0   1     L8        gr15=#SPILL28(gr31,688)
    0| 001E3C add      7FBBE214   1     A         gr29=gr27,gr28
    0| 001E40 add      7F96E214   1     A         gr28=gr22,gr28
    0| 001E44 mulld    7EC089D2   1     M         gr22=gr0,gr17
    0| 001E48 add      7F187A14   1     A         gr24=gr24,gr15
    0| 001E4C ld       EA9F0290   1     L8        gr20=#SPILL156(gr31,656)
    0| 001E50 add      7DF6BA14   1     A         gr15=gr22,gr23
    0| 001E54 add      7E18CA14   1     A         gr16=gr24,gr25
  189| 001E58 ld       EB3F02B8   1     L8        gr25=#SPILL172(gr31,696)
    0| 001E5C ld       EAFF02C0   1     L8        gr23=#SPILL149(gr31,704)
    0| 001E60 add      7F75D214   1     A         gr27=gr21,gr26
    0| 001E64 add      7F54D214   1     A         gr26=gr20,gr26
    0| 001E68 ld       EB1F02E0   1     L8        gr24=#SPILL169(gr31,736)
    0| 001E6C ld       EADF02F0   1     L8        gr22=#SPILL158(gr31,752)
  189| 001E70 std      FB3F00E0   1     ST8       #SPILL196(gr31,224)=gr25
    0| 001E74 std      FAFF00E8   1     ST8       #SPILL197(gr31,232)=gr23
    0| 001E78 ld       EB3F02D8   1     L8        gr25=#SPILL170(gr31,728)
    0| 001E7C ld       EAFF02E8   1     L8        gr23=#SPILL159(gr31,744)
    0| 001E80 ld       EABF02F8   1     L8        gr21=#SPILL157(gr31,760)
    0| 001E84 ld       EA9F0300   1     L8        gr20=#SPILL166(gr31,768)
    0| 001E88 ld       EA7F0308   1     L8        gr19=#SPILL164(gr31,776)
    0| 001E8C stfd     D85F0118   1     STFL      #SPILL191(gr31,280)=fp2
    0| 001E90 ld       EA5F0310   1     L8        gr18=#SPILL173(gr31,784)
    0| 001E94 ld       EA3F0318   1     L8        gr17=#SPILL168(gr31,792)
    0| 001E98 stfd     D81F0110   1     STFL      #SPILL192(gr31,272)=fp0
    0| 001E9C add      7E038214   1     A         gr16=gr3,gr16
    0| 001EA0 add      7DEE7A14   1     A         gr15=gr14,gr15
    0| 001EA4 std      F8BF00A8   1     ST8       #SPILL198(gr31,168)=gr5
    0| 001EA8 ld       E9DF0338   1     L8        gr14=#SPILL160(gr31,824)
    0| 001EAC lfs      C1C80020   1     LFS       fp14=+CONSTANT_AREA(gr8,32)
    0| 001EB0 std      F81F00B0   1     ST8       #SPILL199(gr31,176)=gr0
    0| 001EB4 lfs      C0080018   1     LFS       fp0=+CONSTANT_AREA(gr8,24)
    0| 001EB8 lfd      C8480028   1     LFL       fp2=+CONSTANT_AREA(gr8,40)
    0| 001EBC std      F89F00D8   1     ST8       #SPILL200(gr31,216)=gr4
    0| 001EC0 ld       E87F00F8   1     L8        gr3=#SPILL195(gr31,248)
    0| 001EC4 ld       E89F0100   1     L8        gr4=#SPILL194(gr31,256)
  185|                              CL.79:
  189| 001EC8 ld       E8BF00E0   1     L8        gr5=#SPILL196(gr31,224)
  189| 001ECC lfd      C98A0018   1     LFL       fp12=erold[](gr10,24)
  189| 001ED0 lfdu     CFEA0008   1     LFDU      fp31,gr10=erold[](gr10,8)
  189| 001ED4 lfd      C9A50000   1     LFL       fp13=dx1b(gr5,0)
  189| 001ED8 lfdu     CFC50008   1     LFDU      fp30,gr5=dx1b(gr5,8)
  189| 001EDC fsub     FD8CF828   1     SFL       fp12=fp12,fp31,fcr
  189| 001EE0 std      F8BF00E0   1     ST8       #SPILL196(gr31,224)=gr5
  189| 001EE4 fadd     FDADF02A   1     AFL       fp13=fp13,fp30,fcr
    0| 001EE8 ld       E8BF00E8   1     L8        gr5=#SPILL197(gr31,232)
  189| 001EEC fdiv     FD8C6824   1     DFL       fp12=fp12,fp13,fcr
    0| 001EF0 lfdu     CD650008   1     LFDU      fp11,gr5=g2bi(gr5,8)
    0| 001EF4 std      F8BF00E8   1     ST8       #SPILL197(gr31,232)=gr5
  197| 001EF8 bc       419A0408   1     BT        CL.47,cr6,0x4/eq,taken=50%(0,0)
  212| 001EFC lfd      C9AF0000   1     LFL       fp13=kapr(gr15,0)
  212| 001F00 lfd      CBF00000   1     LFL       fp31=sig(gr16,0)
  257| 001F04 lfd      CBB80000   1     LFL       fp29=g2a(gr24,0)
  257| 001F08 lfd      CB990000   1     LFL       fp28=g31a(gr25,0)
  257| 001F0C lfd      CB580008   1     LFL       fp26=g2a(gr24,8)
  257| 001F10 lfd      CB390008   1     LFL       fp25=g31a(gr25,8)
  257| 001F14 lfd      CB7D0000   1     LFL       fp27=v2(gr29,0)
  257| 001F18 lfd      CB1B0000   1     LFL       fp24=v1(gr27,0)
  257| 001F1C lfd      CA920000   1     LFL       fp20=g31bi(gr18,0)
  257| 001F20 lfd      CAFC0000   1     LFL       fp23=v2(gr28,0)
  257| 001F24 lfd      CABA0000   1     LFL       fp21=v1(gr26,0)
  257| 001F28 lfd      CA510000   1     LFL       fp18=dvl1ai(gr17,0)
  257| 001F2C lfd      CA3E0000   1     LFL       fp17=v3(gr30,0)
  257| 001F30 lfd      CA0C0000   1     LFL       fp16=v3(gr12,0)
  212| 001F34 lfd      CBCA0008   1     LFL       fp30=erold[](gr10,8)
  247| 001F38 lfd      CAD6FFF8   1     LFL       fp22=dv22[].rns3.(gr22,-8)
  247| 001F3C lfd      CA75FFF8   1     LFL       fp19=dv11[].rns0.(gr21,-8)
  247| 001F40 lfd      C9F7FFF8   1     LFL       fp15=dv33[].rns6.(gr23,-8)
  212| 001F44 fadd     FDADF82A   1     AFL       fp13=fp13,fp31,fcr
  257| 001F48 fmul     FFFD0732   2     MFL       fp31=fp29,fp28,fcr
  257| 001F4C fmul     FFBA0672   2     MFL       fp29=fp26,fp25,fcr
  257| 001F50 fmul     FF6806F2   2     MFL       fp27=fp8,fp27,fcr
  257| 001F54 fmul     FD6B01B2   2     MFL       fp11=fp11,fp6,fcr
  212| 001F58 fmul     FF2C0332   2     MFL       fp25=fp12,fp12,fcr
  257| 001F5C fsub     FF918028   2     SFL       fp28=fp17,fp16,fcr
  257| 001F60 fmul     FFFF0632   2     MFL       fp31=fp31,fp24,fcr
  257| 001F64 fmul     FF140272   2     MFL       fp24=fp20,fp9,fcr
  212| 001F68 qvfre    12806830   1     QVFRE     fp20=fp13
  257| 001F6C fmsub    FF67DDF8   1     FMS       fp27=fp27,fp7,fp23,fcr
  212| 001F70 fsqrt    FF20C82C   2     SQRT      fp25=fp25,fcr
  212| 001F74 fmsub    FEED1D38   2     FMS       fp23=fp3,fp13,fp20,fcr
  257| 001F78 fmsub    FFFDFD78   2     FMS       fp31=fp31,fp29,fp21,fcr
  247| 001F7C lfs      C2A8001C   1     LFS       fp21=+CONSTANT_AREA(gr8,28)
  257| 001F80 fmul     FD6B06F2   1     MFL       fp11=fp11,fp27,fcr
  257| 001F84 fmul     FFB802B2   2     MFL       fp29=fp24,fp10,fcr
  212| 001F88 fsub     FF44F028   2     SFL       fp26=fp4,fp30,fcr
  212| 001F8C fnmsub   FF74A5FC   2     FNMS      fp27=fp20,fp20,fp23,fcr
  257| 001F90 fmadd    FD725FFA   2     FMA       fp11=fp11,fp18,fp31,fcr
  212| 001F94 fsel     FFDAF12E   2     FSEL      fp30=fp26,fp30,fp4
  212| 001F98 fmsub    FFED1EF8   2     FMS       fp31=fp3,fp13,fp27,fcr
  221| 001F9C fsub     FF44C828   2     SFL       fp26=fp4,fp25,fcr
  257| 001FA0 fmadd    FD7D5F3A   2     FMA       fp11=fp11,fp29,fp28,fcr
  212| 001FA4 fnmsub   FFFBDFFC   2     FNMS      fp31=fp27,fp27,fp31,fcr
  221| 001FA8 fsel     FF5AC92E   2     FSEL      fp26=fp26,fp25,fp4
  257| 001FAC stfd     D969FFF8   1     STFL      deldotv[](gr9,-8)=fp11
  212| 001FB0 fmsub    FDAD1FF8   1     FMS       fp13=fp3,fp13,fp31,fcr
  221| 001FB4 fdiv     FD8CD024   2     DFL       fp12=fp12,fp26,fcr
  212| 001FB8 fnmsub   FD7FFB7C   2     FNMS      fp11=fp31,fp31,fp13,fcr
  247| 001FBC fmul     FD8C0332   2     MFL       fp12=fp12,fp12,fcr
  212| 001FC0 fmul     FD7902F2   2     MFL       fp11=fp25,fp11,fcr
  212| 001FC4 fdiv     FD6BF024   2     DFL       fp11=fp11,fp30,fcr
  247| 001FC8 fmadd    FDABABBA   2     FMA       fp13=fp21,fp11,fp14,fcr
  247| 001FCC fadd     FFEB002A   2     AFL       fp31=fp11,fp0,fcr
  247| 001FD0 fmul     FFCB02F2   2     MFL       fp30=fp11,fp11,fcr
  247| 001FD4 fmadd    FD6B6AFA   2     FMA       fp11=fp13,fp11,fp11,fcr
  247| 001FD8 fdiv     FD7F5824   2     DFL       fp11=fp31,fp11,fcr
  247| 001FDC fmul     FDAB02F2   2     MFL       fp13=fp11,fp11,fcr
  247| 001FE0 fmadd    FDBE5B7A   2     FMA       fp13=fp11,fp30,fp13,fcr
  247| 001FE4 fadd     FD6D102A   2     AFL       fp11=fp13,fp2,fcr
  247| 001FE8 fsub     FFE36828   2     SFL       fp31=fp3,fp13,fcr
  247| 001FEC fmul     FD6B0172   2     MFL       fp11=fp11,fp5,fcr
  247| 001FF0 fmul     FDBF0072   2     MFL       fp13=fp31,fp1,fcr
  247| 001FF4 fmul     FD6B0332   2     MFL       fp11=fp11,fp12,fcr
  247| 001FF8 fmul     FD960372   2     MFL       fp12=fp22,fp13,fcr
  247| 001FFC fmadd    FD7F587A   2     FMA       fp11=fp11,fp31,fp1,fcr
  247| 002000 fmadd    FD7362FA   2     FMA       fp11=fp12,fp19,fp11,fcr
  247| 002004 fmadd    FD6F5B7A   2     FMA       fp11=fp11,fp15,fp13,fcr
  247| 002008 stfd     D96BFFF8   1     STFL      gvcf[](gr11,-8)=fp11
  257|                              CL.81:
    0| 00200C ld       E81F0098   1     L8        gr0=#SPILL112(gr31,152)
    0| 002010 ld       E8BF00A8   1     L8        gr5=#SPILL198(gr31,168)
    0| 002014 addi     3B390008   1     AI        gr25=gr25,8
    0| 002018 addi     3B180008   1     AI        gr24=gr24,8
    0| 00201C addi     3AF70008   1     AI        gr23=gr23,8
    0| 002020 addi     3AD60008   1     AI        gr22=gr22,8
    0| 002024 add      7E008214   1     A         gr16=gr0,gr16
    0| 002028 ld       E81F00B0   1     L8        gr0=#SPILL199(gr31,176)
    0| 00202C addi     3AB50008   1     AI        gr21=gr21,8
    0| 002030 addi     3A940008   1     AI        gr20=gr20,8
    0| 002034 addi     3A730008   1     AI        gr19=gr19,8
    0| 002038 addi     39290008   1     AI        gr9=gr9,8
    0| 00203C addi     396B0008   1     AI        gr11=gr11,8
    0| 002040 add      7D876214   1     A         gr12=gr7,gr12
    0| 002044 add      7FC7F214   1     A         gr30=gr7,gr30
    0| 002048 addi     3A520008   1     AI        gr18=gr18,8
    0| 00204C add      7FA5EA14   1     A         gr29=gr5,gr29
    0| 002050 add      7F85E214   1     A         gr28=gr5,gr28
    0| 002054 add      7F66DA14   1     A         gr27=gr6,gr27
    0| 002058 add      7F46D214   1     A         gr26=gr6,gr26
    0| 00205C addi     3A310008   1     AI        gr17=gr17,8
    0| 002060 add      7DE07A14   1     A         gr15=gr0,gr15
    0| 002064 addi     38840008   1     AI        gr4=gr4,8
    0| 002068 addi     38630008   1     AI        gr3=gr3,8
    0| 00206C addi     39CE0008   1     AI        gr14=gr14,8
  266| 002070 bc       4200FE58   1     BCT       ctr=CL.79,taken=100%(100,0)
  266| 002074 ld       E89F00D8   1     L8        gr4=#SPILL200(gr31,216)
  266| 002078 lfd      C81F0110   1     LFL       fp0=#SPILL192(gr31,272)
  266| 00207C lfd      C85F0118   1     LFL       fp2=#SPILL191(gr31,280)
  266|                              CL.78:
    0| 002080 ld       E93F0128   1     L8        gr9=#SPILL36(gr31,296)
    0| 002084 ld       E95F0130   1     L8        gr10=#SPILL185(gr31,304)
    0| 002088 ld       EB3F0170   1     L8        gr25=#SPILL186(gr31,368)
  267| 00208C ld       E87F0120   1     L8        gr3=#SPILL116(gr31,288)
  267| 002090 ld       E97F0138   1     L8        gr11=#SPILL15(gr31,312)
    0| 002094 ld       E99F0140   1     L8        gr12=#SPILL29(gr31,320)
    0| 002098 ld       EBDF0148   1     L8        gr30=#SPILL133(gr31,328)
    0| 00209C add      7D495214   1     A         gr10=gr9,gr10
    0| 0020A0 ld       EBBF0150   1     L8        gr29=#SPILL134(gr31,336)
    0| 0020A4 std      F95F0130   1     ST8       #SPILL185(gr31,304)=gr10
    0| 0020A8 ld       EB9F0158   1     L8        gr28=#SPILL38(gr31,344)
    0| 0020AC ld       EB7F0160   1     L8        gr27=#SPILL135(gr31,352)
    0| 0020B0 ld       EB5F0168   1     L8        gr26=#SPILL136(gr31,360)
    0| 0020B4 add      7F29CA14   1     A         gr25=gr9,gr25
    0| 0020B8 ld       EB1F0178   1     L8        gr24=#SPILL117(gr31,376)
    0| 0020BC std      FB3F0170   1     ST8       #SPILL186(gr31,368)=gr25
    0| 0020C0 ld       EAFF0180   1     L8        gr23=#SPILL118(gr31,384)
    0| 0020C4 ld       EADF0188   1     L8        gr22=#SPILL137(gr31,392)
    0| 0020C8 ld       EABF0190   1     L8        gr21=#SPILL138(gr31,400)
    0| 0020CC ld       EA9F0198   1     L8        gr20=#SPILL139(gr31,408)
    0| 0020D0 ld       EA7F01A0   1     L8        gr19=#SPILL140(gr31,416)
    0| 0020D4 ld       EA5F01A8   1     L8        gr18=#SPILL141(gr31,424)
    0| 0020D8 ld       EA3F01B0   1     L8        gr17=#SPILL142(gr31,432)
    0| 0020DC ld       EA1F01B8   1     L8        gr16=#SPILL143(gr31,440)
    0| 0020E0 ld       E9FF01C0   1     L8        gr15=#SPILL144(gr31,448)
    0| 0020E4 ld       E9DF01C8   1     L8        gr14=#SPILL119(gr31,456)
    0| 0020E8 ld       E93F01D0   1     L8        gr9=#SPILL189(gr31,464)
  267| 0020EC addi     38630001   1     AI        gr3=gr3,1
    0| 0020F0 add      7FCCF214   1     A         gr30=gr12,gr30
  267| 0020F4 std      F87F0120   1     ST8       #SPILL116(gr31,288)=gr3
    0| 0020F8 std      FBDF0148   1     ST8       #SPILL133(gr31,328)=gr30
  267| 0020FC cmpld    7D235840   1     CL8       cr2=gr3,gr11
    0| 002100 add      7FACEA14   1     A         gr29=gr12,gr29
    0| 002104 add      7F7BE214   1     A         gr27=gr27,gr28
    0| 002108 std      FBBF0150   1     ST8       #SPILL134(gr31,336)=gr29
    0| 00210C std      FB7F0160   1     ST8       #SPILL135(gr31,352)=gr27
    0| 002110 add      7F5AE214   1     A         gr26=gr26,gr28
    0| 002114 addi     3B180008   1     AI        gr24=gr24,8
    0| 002118 std      FB5F0168   1     ST8       #SPILL136(gr31,360)=gr26
    0| 00211C std      FB1F0178   1     ST8       #SPILL117(gr31,376)=gr24
    0| 002120 addi     3AF70008   1     AI        gr23=gr23,8
    0| 002124 add      7ECCB214   1     A         gr22=gr12,gr22
    0| 002128 std      FAFF0180   1     ST8       #SPILL118(gr31,384)=gr23
    0| 00212C std      FADF0188   1     ST8       #SPILL137(gr31,392)=gr22
    0| 002130 add      7EB5E214   1     A         gr21=gr21,gr28
    0| 002134 add      7E94E214   1     A         gr20=gr20,gr28
    0| 002138 std      FABF0190   1     ST8       #SPILL138(gr31,400)=gr21
    0| 00213C std      FA9F0198   1     ST8       #SPILL139(gr31,408)=gr20
    0| 002140 add      7E73E214   1     A         gr19=gr19,gr28
    0| 002144 add      7E52E214   1     A         gr18=gr18,gr28
    0| 002148 std      FA7F01A0   1     ST8       #SPILL140(gr31,416)=gr19
    0| 00214C std      FA5F01A8   1     ST8       #SPILL141(gr31,424)=gr18
    0| 002150 add      7E2C8A14   1     A         gr17=gr12,gr17
    0| 002154 add      7E0C8214   1     A         gr16=gr12,gr16
    0| 002158 std      FA3F01B0   1     ST8       #SPILL142(gr31,432)=gr17
    0| 00215C std      FA1F01B8   1     ST8       #SPILL143(gr31,440)=gr16
    0| 002160 add      7DEC7A14   1     A         gr15=gr12,gr15
    0| 002164 addi     39CE0008   1     AI        gr14=gr14,8
    0| 002168 std      F9FF01C0   1     ST8       #SPILL144(gr31,448)=gr15
    0| 00216C std      F9DF01C8   1     ST8       #SPILL119(gr31,456)=gr14
    0| 002170 addi     39290008   1     AI        gr9=gr9,8
    0| 002174 std      F93F01D0   1     ST8       #SPILL189(gr31,464)=gr9
  267| 002178 bc       4188ED24   1     BT        CL.67,cr2,0x8/llt,taken=80%(80,20)
  267| 00217C ld       E87F04F8   1     L8        gr3=#SPILL190(gr31,1272)
  267|                              CL.66:
  268| 002180 ld       E93F0350   1     L8        gr9=#SPILL43(gr31,848)
    0| 002184 ld       E95F0210   1     L8        gr10=#SPILL37(gr31,528)
    0| 002188 ld       E97F0500   1     L8        gr11=#SPILL101(gr31,1280)
  268| 00218C ld       E99F0508   1     L8        gr12=#SPILL1(gr31,1288)
    0| 002190 ld       EBDF0510   1     L8        gr30=#SPILL102(gr31,1296)
    0| 002194 ld       EBBF0518   1     L8        gr29=#SPILL103(gr31,1304)
    0| 002198 ld       EB9F0520   1     L8        gr28=#SPILL104(gr31,1312)
    0| 00219C ld       EB7F0528   1     L8        gr27=#SPILL90(gr31,1320)
    0| 0021A0 ld       EB5F0530   1     L8        gr26=#SPILL97(gr31,1328)
    0| 0021A4 ld       EB3F0208   1     L8        gr25=#SPILL30(gr31,520)
    0| 0021A8 ld       EB1F0538   1     L8        gr24=#SPILL105(gr31,1336)
    0| 0021AC ld       EAFF0540   1     L8        gr23=#SPILL91(gr31,1344)
    0| 0021B0 ld       EADF0548   1     L8        gr22=#SPILL106(gr31,1352)
    0| 0021B4 ld       EABF0550   1     L8        gr21=#SPILL107(gr31,1360)
    0| 0021B8 ld       EA9F0558   1     L8        gr20=#SPILL108(gr31,1368)
    0| 0021BC ld       EA7F0560   1     L8        gr19=#SPILL98(gr31,1376)
    0| 0021C0 ld       EA5F0218   1     L8        gr18=#SPILL35(gr31,536)
    0| 0021C4 ld       EA3F0568   1     L8        gr17=#SPILL92(gr31,1384)
    0| 0021C8 ld       EA1F0570   1     L8        gr16=#SPILL96(gr31,1392)
    0| 0021CC ld       E9FF0430   1     L8        gr15=#SPILL100(gr31,1072)
  268| 0021D0 addi     39290001   1     AI        gr9=gr9,1
    0| 0021D4 add      7D6A5A14   1     A         gr11=gr10,gr11
  268| 0021D8 std      F93F0350   1     ST8       #SPILL43(gr31,848)=gr9
    0| 0021DC std      F97F0500   1     ST8       #SPILL101(gr31,1280)=gr11
  268| 0021E0 cmpld    7C296040   1     CL8       cr0=gr9,gr12
    0| 0021E4 add      7FCAF214   1     A         gr30=gr10,gr30
    0| 0021E8 add      7FAAEA14   1     A         gr29=gr10,gr29
    0| 0021EC std      FBDF0510   1     ST8       #SPILL102(gr31,1296)=gr30
    0| 0021F0 std      FBBF0518   1     ST8       #SPILL103(gr31,1304)=gr29
    0| 0021F4 add      7F8AE214   1     A         gr28=gr10,gr28
    0| 0021F8 add      7F6ADA14   1     A         gr27=gr10,gr27
    0| 0021FC std      FB9F0520   1     ST8       #SPILL104(gr31,1312)=gr28
    0| 002200 std      FB7F0528   1     ST8       #SPILL90(gr31,1320)=gr27
    0| 002204 add      7F4AD214   1     A         gr26=gr10,gr26
    0| 002208 add      7F18CA14   1     A         gr24=gr24,gr25
    0| 00220C std      FB5F0530   1     ST8       #SPILL97(gr31,1328)=gr26
    0| 002210 std      FB1F0538   1     ST8       #SPILL105(gr31,1336)=gr24
    0| 002214 add      7EF7CA14   1     A         gr23=gr23,gr25
    0| 002218 add      7ED6CA14   1     A         gr22=gr22,gr25
    0| 00221C std      FAFF0540   1     ST8       #SPILL91(gr31,1344)=gr23
    0| 002220 std      FADF0548   1     ST8       #SPILL106(gr31,1352)=gr22
    0| 002224 add      7EB5CA14   1     A         gr21=gr21,gr25
    0| 002228 add      7E94CA14   1     A         gr20=gr20,gr25
    0| 00222C std      FABF0550   1     ST8       #SPILL107(gr31,1360)=gr21
    0| 002230 std      FA9F0558   1     ST8       #SPILL108(gr31,1368)=gr20
    0| 002234 add      7E73CA14   1     A         gr19=gr19,gr25
    0| 002238 add      7E319214   1     A         gr17=gr17,gr18
    0| 00223C std      FA7F0560   1     ST8       #SPILL98(gr31,1376)=gr19
    0| 002240 std      FA3F0568   1     ST8       #SPILL92(gr31,1384)=gr17
    0| 002244 add      7E109214   1     A         gr16=gr16,gr18
    0| 002248 addi     39EF0008   1     AI        gr15=gr15,8
    0| 00224C std      FA1F0570   1     ST8       #SPILL96(gr31,1392)=gr16
    0| 002250 std      F9FF0430   1     ST8       #SPILL100(gr31,1072)=gr15
  268| 002254 bc       4180E884   1     BT        CL.65,cr0,0x8/llt,taken=80%(80,20)
  271|                              CL.94:
  271| 002258 ld       E8210000   1     L8        gr1=#stack(gr1,0),gr31"
  271| 00225C lwa      E981000A   1     L4A       gr12=#stack(gr1,8)
  271| 002260 ld       E9C1FEE0   1     L8        gr14=#stack(gr1,-288)
  271| 002264 ld       E9E1FEE8   1     L8        gr15=#stack(gr1,-280)
  271| 002268 ld       EA01FEF0   1     L8        gr16=#stack(gr1,-272)
  271| 00226C ld       EA21FEF8   1     L8        gr17=#stack(gr1,-264)
  271| 002270 ld       EA41FF00   1     L8        gr18=#stack(gr1,-256)
  271| 002274 ld       EA61FF08   1     L8        gr19=#stack(gr1,-248)
  271| 002278 ld       EA81FF10   1     L8        gr20=#stack(gr1,-240)
  271| 00227C ld       EAA1FF18   1     L8        gr21=#stack(gr1,-232)
  271| 002280 ld       EAC1FF20   1     L8        gr22=#stack(gr1,-224)
  271| 002284 ld       EAE1FF28   1     L8        gr23=#stack(gr1,-216)
  271| 002288 ld       EB01FF30   1     L8        gr24=#stack(gr1,-208)
  271| 00228C ld       EB21FF38   1     L8        gr25=#stack(gr1,-200)
  271| 002290 ld       EB41FF40   1     L8        gr26=#stack(gr1,-192)
  271| 002294 ld       EB61FF48   1     L8        gr27=#stack(gr1,-184)
  271| 002298 ld       EB81FF50   1     L8        gr28=#stack(gr1,-176)
  271| 00229C ld       EBA1FF58   1     L8        gr29=#stack(gr1,-168)
  271| 0022A0 ld       EBC1FF60   1     L8        gr30=#stack(gr1,-160)
  271| 0022A4 ld       EBE1FF68   1     L8        gr31=#stack(gr1,-152)
  271| 0022A8 mtcrf    7D820120   1     MTCRF     cr2=gr12
  271| 0022AC mtcrf    7D810120   1     MTCRF     cr3=gr12
  271| 0022B0 mtcrf    7D808120   1     MTCRF     cr4=gr12
  271| 0022B4 lfd      CBE1FFF8   1     LFL       fp31=#stack(gr1,-8)
  271| 0022B8 lfd      CBC1FFF0   1     LFL       fp30=#stack(gr1,-16)
  271| 0022BC lfd      CBA1FFE8   1     LFL       fp29=#stack(gr1,-24)
  271| 0022C0 lfd      CB81FFE0   1     LFL       fp28=#stack(gr1,-32)
  271| 0022C4 lfd      CB61FFD8   1     LFL       fp27=#stack(gr1,-40)
  271| 0022C8 lfd      CB41FFD0   1     LFL       fp26=#stack(gr1,-48)
  271| 0022CC lfd      CB21FFC8   1     LFL       fp25=#stack(gr1,-56)
  271| 0022D0 lfd      CB01FFC0   1     LFL       fp24=#stack(gr1,-64)
  271| 0022D4 lfd      CAE1FFB8   1     LFL       fp23=#stack(gr1,-72)
  271| 0022D8 lfd      CAC1FFB0   1     LFL       fp22=#stack(gr1,-80)
  271| 0022DC lfd      CAA1FFA8   1     LFL       fp21=#stack(gr1,-88)
  271| 0022E0 lfd      CA81FFA0   1     LFL       fp20=#stack(gr1,-96)
  271| 0022E4 lfd      CA61FF98   1     LFL       fp19=#stack(gr1,-104)
  271| 0022E8 lfd      CA41FF90   1     LFL       fp18=#stack(gr1,-112)
  271| 0022EC lfd      CA21FF88   1     LFL       fp17=#stack(gr1,-120)
  271| 0022F0 lfd      CA01FF80   1     LFL       fp16=#stack(gr1,-128)
  271| 0022F4 lfd      C9E1FF78   1     LFL       fp15=#stack(gr1,-136)
  271| 0022F8 lfd      C9C1FF70   1     LFL       fp14=#stack(gr1,-144)
  271| 0022FC bclr     4E800020   1     BA        lr
  199|                              CL.47:
  200| 002300 lfd      CBE3FFF8   1     LFL       fp31=erold[](gr3,-8)
  257| 002304 fmul     FD6B01B2   1     MFL       fp11=fp11,fp6,fcr
  200| 002308 lfd      CB84FFF8   1     LFL       fp28=erold[](gr4,-8)
  212| 00230C fmul     FDAC0332   1     MFL       fp13=fp12,fp12,fcr
  200| 002310 lfd      CB120000   2     LFL       fp24=g31bi(gr18,0)
  212| 002314 lfd      CBCF0000   1     LFL       fp30=kapr(gr15,0)
  212| 002318 lfd      CB300000   1     LFL       fp25=sig(gr16,0)
  257| 00231C lfd      CBB80000   1     LFL       fp29=g2a(gr24,0)
  257| 002320 lfd      CADD0000   1     LFL       fp22=v2(gr29,0)
  200| 002324 fsub     FEFFE028   1     SFL       fp23=fp31,fp28,fcr
  257| 002328 lfd      CB990000   1     LFL       fp28=g31a(gr25,0)
  257| 00232C fmul     FFF80272   1     MFL       fp31=fp24,fp9,fcr
  200| 002330 ld       E8BF00C8   1     L8        gr5=#SPILL193(gr31,200)
  212| 002334 fadd     FFDEC82A   1     AFL       fp30=fp30,fp25,fcr
  257| 002338 lfd      CB580008   1     LFL       fp26=g2a(gr24,8)
  200| 00233C fmul     FEB805F2   1     MFL       fp21=fp24,fp23,fcr
  257| 002340 lfd      CB1B0000   1     LFL       fp24=v1(gr27,0)
  257| 002344 fmul     FEFD0732   1     MFL       fp23=fp29,fp28,fcr
  257| 002348 lfd      CB390008   1     LFL       fp25=g31a(gr25,8)
  257| 00234C fmul     FEC805B2   1     MFL       fp22=fp8,fp22,fcr
  200| 002350 lfd      CB6E0000   1     LFL       fp27=g32bi(gr14,0)
  257| 002354 fmul     FFFF02B2   1     MFL       fp31=fp31,fp10,fcr
  257| 002358 lfd      CBBC0000   1     LFL       fp29=v2(gr28,0)
  257| 00235C fmul     FF170632   1     MFL       fp24=fp23,fp24,fcr
  200| 002360 lfd      CA850000   1     LFL       fp20=dx3b(gr5,0)
  257| 002364 fmul     FF5A0672   1     MFL       fp26=fp26,fp25,fcr
  200| 002368 lfd      CA650008   1     LFL       fp19=dx3b(gr5,8)
  200| 00236C fmul     FF7506F2   1     MFL       fp27=fp21,fp27,fcr
  257| 002370 lfd      CAFA0000   1     LFL       fp23=v1(gr26,0)
  257| 002374 fmsub    FFA7B778   1     FMS       fp29=fp22,fp7,fp29,fcr
  212| 002378 lfd      CB2A0008   1     LFL       fp25=erold[](gr10,8)
  212| 00237C qvfre    1380F030   1     QVFRE     fp28=fp30
  247| 002380 lfd      CAB3FFF8   1     LFL       fp21=dv13[].rns23.(gr19,-8)
  200| 002384 fadd     FE94982A   1     AFL       fp20=fp20,fp19,fcr
  247| 002388 lfd      CA730000   2     LFL       fp19=dv13[].rns23.(gr19,0)
  257| 00238C fmsub    FF5AC5F8   1     FMS       fp26=fp24,fp26,fp23,fcr
  257| 002390 lfd      CA310000   2     LFL       fp17=dvl1ai(gr17,0)
  257| 002394 fmul     FD6B0772   1     MFL       fp11=fp11,fp29,fcr
  257| 002398 lfd      CB1E0000   1     LFL       fp24=v3(gr30,0)
  212| 00239C fsub     FE44C828   1     SFL       fp18=fp4,fp25,fcr
  257| 0023A0 lfd      CAEC0000   1     LFL       fp23=v3(gr12,0)
  247| 0023A4 fadd     FEB5982A   1     AFL       fp21=fp21,fp19,fcr
  247| 0023A8 lfd      CAD4FFF8   1     LFL       fp22=dv31[].rns26.(gr20,-8)
  257| 0023AC fmadd    FD715EBA   1     FMA       fp11=fp11,fp17,fp26,fcr
  247| 0023B0 lfd      CA740000   1     LFL       fp19=dv31[].rns26.(gr20,0)
  212| 0023B4 fsel     FF32C92E   1     FSEL      fp25=fp18,fp25,fp4
  212| 0023B8 lfs      C2080034   1     LFS       fp16=+CONSTANT_AREA(gr8,52)
  257| 0023BC fsub     FF18B828   1     SFL       fp24=fp24,fp23,fcr
  212| 0023C0 lfs      C1E8003C   1     LFS       fp15=+CONSTANT_AREA(gr8,60)
  247| 0023C4 fadd     FED5B02A   1     AFL       fp22=fp21,fp22,fcr
  212| 0023C8 lfs      C2280038   1     LFS       fp17=+CONSTANT_AREA(gr8,56)
  200| 0023CC qvfre    1340A030   1     QVFRE     fp26=fp20
  247| 0023D0 lfd      CBB6FFF8   1     LFL       fp29=dv22[].rns3.(gr22,-8)
  257| 0023D4 fmadd    FD7F5E3A   1     FMA       fp11=fp11,fp31,fp24,fcr
  247| 0023D8 lfd      CAF5FFF8   1     LFL       fp23=dv11[].rns0.(gr21,-8)
  212| 0023DC fmsub    FE5E1F38   1     FMS       fp18=fp3,fp30,fp28,fcr
  247| 0023E0 lfd      CAB7FFF8   1     LFL       fp21=dv33[].rns6.(gr23,-8)
  247| 0023E4 fadd     FED6982A   1     AFL       fp22=fp22,fp19,fcr
  212| 0023E8 qvfre    1260C830   1     QVFRE     fp19=fp25
  200| 0023EC fmsub    FFF41EB8   1     FMS       fp31=fp3,fp20,fp26,fcr
  257| 0023F0 stfd     D969FFF8   1     STFL      deldotv[](gr9,-8)=fp11
  212| 0023F4 fnmsub   FF1CE4BC   1     FNMS      fp24=fp28,fp28,fp18,fcr
  212| 0023F8 lfs      C2480040   1     LFS       fp18=+CONSTANT_AREA(gr8,64)
  247| 0023FC fmul     FF960072   1     MFL       fp28=fp22,fp1,fcr
  212| 002400 fmsub    FED91CF8   2     FMS       fp22=fp3,fp25,fp19,fcr
  200| 002404 fnmsub   FD7AD7FC   2     FNMS      fp11=fp26,fp26,fp31,fcr
  212| 002408 fmsub    FFFE1E38   2     FMS       fp31=fp3,fp30,fp24,fcr
  212| 00240C fnmsub   FF539DBC   2     FNMS      fp26=fp19,fp19,fp22,fcr
  200| 002410 fmsub    FED41AF8   2     FMS       fp22=fp3,fp20,fp11,fcr
  212| 002414 fnmsub   FFF8C7FC   2     FNMS      fp31=fp24,fp24,fp31,fcr
  212| 002418 fmsub    FF191EB8   2     FMS       fp24=fp3,fp25,fp26,fcr
  200| 00241C fnmsub   FD6B5DBC   2     FNMS      fp11=fp11,fp11,fp22,fcr
  212| 002420 fmsub    FFDE1FF8   2     FMS       fp30=fp3,fp30,fp31,fcr
  212| 002424 fnmsub   FF5AD63C   2     FNMS      fp26=fp26,fp26,fp24,fcr
  200| 002428 fmul     FF1B02F2   2     MFL       fp24=fp27,fp11,fcr
  212| 00242C fnmsub   FFFFFFBC   2     FNMS      fp31=fp31,fp31,fp30,fcr
  200| 002430 fmsub    FFD4DE38   2     FMS       fp30=fp27,fp20,fp24,fcr
  200| 002434 fnmsub   FD6BC7BC   2     FNMS      fp11=fp24,fp11,fp30,fcr
  212| 002438 fmadd    FDAB6AFA   2     FMA       fp13=fp13,fp11,fp11,fcr
  212| 00243C frsqrte  FFC06834   2     FRSQRE    fp30=fp13
  212| 002440 fnabs    FF606910   2     NABSFL    fp27=fp13
  212| 002444 fmul     FF0D07B2   2     MFL       fp24=fp13,fp30,fcr
  212| 002448 fmadd    FE9E863A   2     FMA       fp20=fp16,fp30,fp24,fcr
  212| 00244C fmadd    FED47C7A   2     FMA       fp22=fp15,fp20,fp17,fcr
  212| 002450 fmadd    FED495BA   2     FMA       fp22=fp18,fp20,fp22,fcr
  212| 002454 fmul     FED405B2   2     MFL       fp22=fp20,fp22,fcr
  212| 002458 fmul     FF1805B2   2     MFL       fp24=fp24,fp22,fcr
  212| 00245C fmadd    FEDEF5BA   2     FMA       fp22=fp30,fp30,fp22,fcr
  212| 002460 fmadd    FFCDC7BA   2     FMA       fp30=fp24,fp13,fp30,fcr
  212| 002464 fmul     FF160072   2     MFL       fp24=fp22,fp1,fcr
  212| 002468 fmsub    FEDE6FB8   2     FMS       fp22=fp13,fp30,fp30,fcr
  212| 00246C fnmsub   FFD6F63C   2     FNMS      fp30=fp30,fp22,fp24,fcr
  212| 002470 fsel     FDBBF36E   2     FSEL      fp13=fp27,fp30,fp13
  212| 002474 fmul     FFFF0372   2     MFL       fp31=fp31,fp13,fcr
  221| 002478 fsub     FF646828   2     SFL       fp27=fp4,fp13,fcr
  212| 00247C fmul     FFDF06B2   2     MFL       fp30=fp31,fp26,fcr
  221| 002480 fsel     FDBB692E   2     FSEL      fp13=fp27,fp13,fp4
  212| 002484 fmsub    FF79FFB8   2     FMS       fp27=fp31,fp25,fp30,fcr
  221| 002488 qvfre    13E06830   1     QVFRE     fp31=fp13
  212| 00248C fnmsub   FF7AF6FC   1     FNMS      fp27=fp30,fp26,fp27,fcr
  221| 002490 fmsub    FFCD1FF8   2     FMS       fp30=fp3,fp13,fp31,fcr
  247| 002494 lfs      C268001C   1     LFS       fp19=+CONSTANT_AREA(gr8,28)
  221| 002498 fnmsub   FF5FFFBC   1     FNMS      fp26=fp31,fp31,fp30,fcr
  247| 00249C fadd     FFFB002A   2     AFL       fp31=fp27,fp0,fcr
  247| 0024A0 fmul     FFDB06F2   2     MFL       fp30=fp27,fp27,fcr
  247| 0024A4 fmadd    FF3B9BBA   2     FMA       fp25=fp19,fp27,fp14,fcr
  221| 0024A8 fmsub    FE6D1EB8   2     FMS       fp19=fp3,fp13,fp26,fcr
  247| 0024AC fmadd    FF7BCEFA   2     FMA       fp27=fp25,fp27,fp27,fcr
  221| 0024B0 fnmsub   FF5AD4FC   2     FNMS      fp26=fp26,fp26,fp19,fcr
  247| 0024B4 fdiv     FF3FD824   2     DFL       fp25=fp31,fp27,fcr
  247| 0024B8 qvfre    1300D830   1     QVFRE     fp24=fp27
  247| 0024BC fmul     FE990672   1     MFL       fp20=fp25,fp25,fcr
  247| 0024C0 fmsub    FEDB1E38   2     FMS       fp22=fp3,fp27,fp24,fcr
  247| 0024C4 fmadd    FF3ECD3A   2     FMA       fp25=fp25,fp30,fp20,fcr
  247| 0024C8 fnmsub   FF18C5BC   2     FNMS      fp24=fp24,fp24,fp22,fcr
  221| 0024CC fmul     FECC06B2   2     MFL       fp22=fp12,fp26,fcr
  226| 0024D0 fmul     FE8B06B2   2     MFL       fp20=fp11,fp26,fcr
  247| 0024D4 fadd     FE79102A   2     AFL       fp19=fp25,fp2,fcr
  247| 0024D8 fmsub    FE5B1E38   2     FMS       fp18=fp3,fp27,fp24,fcr
  221| 0024DC fmsub    FD8D65B8   2     FMS       fp12=fp12,fp13,fp22,fcr
  226| 0024E0 fmsub    FD6D5D38   2     FMS       fp11=fp11,fp13,fp20,fcr
  247| 0024E4 fsub     FDA3C828   2     SFL       fp13=fp3,fp25,fcr
  247| 0024E8 fmul     FF330172   2     MFL       fp25=fp19,fp5,fcr
  247| 0024EC fnmsub   FF18C4BC   2     FNMS      fp24=fp24,fp24,fp18,fcr
  221| 0024F0 fnmsub   FD9AB33C   2     FNMS      fp12=fp22,fp26,fp12,fcr
  226| 0024F4 fnmsub   FD7AA2FC   2     FNMS      fp11=fp20,fp26,fp11,fcr
  247| 0024F8 fmul     FF5F0632   2     MFL       fp26=fp31,fp24,fcr
  247| 0024FC fmul     FECC0332   2     MFL       fp22=fp12,fp12,fcr
  247| 002500 fmul     FE8B02F2   2     MFL       fp20=fp11,fp11,fcr
  247| 002504 fmul     FD990332   2     MFL       fp12=fp25,fp12,fcr
  247| 002508 fmsub    FFFBFEB8   2     FMS       fp31=fp31,fp27,fp26,fcr
  247| 00250C fmul     FF7905B2   2     MFL       fp27=fp25,fp22,fcr
  247| 002510 fmul     FF390532   2     MFL       fp25=fp25,fp20,fcr
  247| 002514 fmul     FD6B0332   2     MFL       fp11=fp11,fp12,fcr
  247| 002518 fnmsub   FD98D7FC   2     FNMS      fp12=fp26,fp24,fp31,fcr
  247| 00251C fmadd    FFEDD87A   2     FMA       fp31=fp27,fp13,fp1,fcr
  247| 002520 fmadd    FF6DC87A   2     FMA       fp27=fp25,fp13,fp1,fcr
  247| 002524 fmul     FDAC0332   2     MFL       fp13=fp12,fp12,fcr
  247| 002528 fmadd    FD9E637A   2     FMA       fp12=fp12,fp30,fp13,fcr
  247| 00252C fsub     FD836028   2     SFL       fp12=fp3,fp12,fcr
  247| 002530 fmul     FD8C0072   2     MFL       fp12=fp12,fp1,fcr
  247| 002534 fmul     FD9D0332   2     MFL       fp12=fp29,fp12,fcr
  247| 002538 fmadd    FD9767FA   2     FMA       fp12=fp12,fp23,fp31,fcr
  247| 00253C fmadd    FD9566FA   2     FMA       fp12=fp12,fp21,fp27,fcr
  247| 002540 fmadd    FD7C62FA   2     FMA       fp11=fp12,fp28,fp11,fcr
  247| 002544 stfd     D96BFFF8   1     STFL      gvcf[](gr11,-8)=fp11
    0| 002548 b        4BFFFAC4   1     B         CL.81,-1
    0|                              CL.302:
  170| 00254C bc       4085F7AC   1     BF        CL.39,cr1,0x2/gt,taken=50%(0,0)
  189| 002550 ld       EBBF0340   1     L8        gr29=#SPILL12(gr31,832)
  189| 002554 ld       EB9F0120   1     L8        gr28=#SPILL116(gr31,288)
  189| 002558 ld       EB7F0348   1     L8        gr27=#SPILL0(gr31,840)
  189| 00255C ld       EB5F0350   1     L8        gr26=#SPILL43(gr31,848)
    0| 002560 ld       EB3F0358   1     L8        gr25=#SPILL31(gr31,856)
    0| 002564 ld       EB1F0360   1     L8        gr24=#SPILL34(gr31,864)
    0| 002568 ld       EAFF0368   1     L8        gr23=#SPILL32(gr31,872)
    0| 00256C ld       EADF0370   1     L8        gr22=#SPILL19(gr31,880)
    0| 002570 ld       EABF0378   1     L8        gr21=#SPILL33(gr31,888)
  189| 002574 add      7D7CEA14   1     A         gr11=gr28,gr29
  189| 002578 add      7D5ADA14   1     A         gr10=gr26,gr27
    0| 00257C rldicr   797E1F24   1     SLL8      gr30=gr11,3
    0| 002580 rldicr   794C1F24   1     SLL8      gr12=gr10,3
    0| 002584 ld       E93F08B0   1     L8        gr9=.deldotv(gr31,2224)
    0| 002588 lfdx     7CD9F4AE   1     LFL       fp6=dvl2ai(gr25,gr30,0)
    0| 00258C lfdx     7CF8F4AE   1     LFL       fp7=g32a(gr24,gr30,0)
    0| 002590 lfdx     7D17F4AE   1     LFL       fp8=g32a(gr23,gr30,0)
    0| 002594 lfdx     7D36F4AE   1     LFL       fp9=g32bi(gr22,gr30,0)
    0| 002598 lfdx     7D5564AE   1     LFL       fp10=dvl3ai(gr21,gr12,0)
    0|                              CL.245:
  194| 00259C ld       E87F01D8   1     L8        gr3=#SPILL25(gr31,472)
  189| 0025A0 ld       E9FF01F8   1     L8        gr15=#SPILL13(gr31,504)
  189| 0025A4 ld       E9DF0200   1     L8        gr14=#SPILL2(gr31,512)
  200| 0025A8 ld       EA5F01E8   1     L8        gr18=#SPILL26(gr31,488)
    0| 0025AC ld       EBBF0158   1     L8        gr29=#SPILL38(gr31,344)
    0| 0025B0 ld       EB9F0208   1     L8        gr28=#SPILL30(gr31,520)
  194| 0025B4 add      7FC3F214   1     A         gr30=gr3,gr30
    0| 0025B8 ld       EB7F0140   1     L8        gr27=#SPILL29(gr31,320)
    0| 0025BC ld       EB5F0210   1     L8        gr26=#SPILL37(gr31,528)
    0| 0025C0 lfd      C97E0008   1     LFL       fp11=dx2b(gr30,8)
    0| 0025C4 lfd      C99E0000   1     LFL       fp12=dx2b(gr30,0)
  200| 0025C8 add      7E2C9214   1     A         gr17=gr12,gr18
  189| 0025CC mulld    7D8A79D2   1     M         gr12=gr10,gr15
    0| 0025D0 fadd     FDAC582A   1     AFL       fp13=fp12,fp11,fcr
  200| 0025D4 std      FA3F00C8   1     ST8       #SPILL193(gr31,200)=gr17
  189| 0025D8 mulld    7FCB71D2   1     M         gr30=gr11,gr14
    0| 0025DC qvfre    11606830   1     QVFRE     fp11=fp13
    0| 0025E0 ld       EB1F0128   1     L8        gr24=#SPILL36(gr31,296)
    0| 0025E4 ld       EADF0220   1     L8        gr22=#SPILL114(gr31,544)
    0| 0025E8 ld       EABF0228   1     L8        gr21=#SPILL111(gr31,552)
    0| 0025EC stfd     D9BF0100   1     STFL      #SPILL194(gr31,256)=fp13
    0| 0025F0 ld       EA7F01E0   1     L8        gr19=#SPILL150(gr31,480)
    0| 0025F4 fmsub    FD8D1AF8   1     FMS       fp12=fp3,fp13,fp11,fcr
  189| 0025F8 add      7EECF214   1     A         gr23=gr12,gr30
    0| 0025FC mulld    7FCBE9D2   1     M         gr30=gr11,gr29
    0| 002600 fnmsub   FD6B5B3C   1     FNMS      fp11=fp11,fp11,fp12,fcr
    0| 002604 mulld    7FAAE1D2   1     M         gr29=gr10,gr28
    0| 002608 fmsub    FD8D1AF8   1     FMS       fp12=fp3,fp13,fp11,fcr
    0| 00260C mulld    7D8BD9D2   1     M         gr12=gr11,gr27
    0| 002610 fnmsub   FFEB5B3C   1     FNMS      fp31=fp11,fp11,fp12,fcr
    0| 002614 mulld    7F8AD1D2   1     M         gr28=gr10,gr26
    0| 002618 ld       EB3F0218   1     L8        gr25=#SPILL35(gr31,536)
    0| 00261C stfd     DBFF00F8   1     STFL      #SPILL195(gr31,248)=fp31
    0| 002620 add      7D299A14   1     A         gr9=gr9,gr19
    0| 002624 add      7F8CE214   1     A         gr28=gr12,gr28
    0| 002628 mulld    7F6BC1D2   1     M         gr27=gr11,gr24
    0| 00262C mulld    7D8BB1D2   1     M         gr12=gr11,gr22
    0| 002630 mulld    7E8BA9D2   1     M         gr20=gr11,gr21
    0| 002634 ld       E97F0230   1     L8        gr11=#SPILL39(gr31,560)
    0| 002638 ld       EA7F0238   1     L8        gr19=#SPILL113(gr31,568)
  194| 00263C ld       E9FF0258   1     L8        gr15=#SPILL184(gr31,600)
    0| 002640 add      7FDEEA14   1     A         gr30=gr30,gr29
    0| 002644 mulld    7FAAC9D2   1     M         gr29=gr10,gr25
  194| 002648 add      7DCFBA14   1     A         gr14=gr15,gr23
    0| 00264C ld       E9FF0298   1     L8        gr15=#SPILL167(gr31,664)
  194| 002650 std      F9DF00E8   1     ST8       #SPILL197(gr31,232)=gr14
    0| 002654 add      7F5BEA14   1     A         gr26=gr27,gr29
    0| 002658 mulld    7EAA59D2   1     M         gr21=gr10,gr11
    0| 00265C mulld    7F2A99D2   1     M         gr25=gr10,gr19
    0| 002660 ld       E95F0240   1     L8        gr10=#SPILL27(gr31,576)
    0| 002664 ld       EB7F0268   1     L8        gr27=#SPILL124(gr31,616)
    0| 002668 ld       EADF0270   1     L8        gr22=#SPILL130(gr31,624)
    0| 00266C ld       EBBF0260   1     L8        gr29=#SPILL181(gr31,608)
    0| 002670 ld       EA7F0278   1     L8        gr19=#SPILL123(gr31,632)
  189| 002674 ld       EA5F0248   1     L8        gr18=#SPILL182(gr31,584)
    0| 002678 add      7DCFBA14   1     A         gr14=gr15,gr23
    0| 00267C ld       EA1F01F0   1     L8        gr16=#SPILL120(gr31,496)
    0| 002680 std      F9DF00A8   1     ST8       #SPILL198(gr31,168)=gr14
    0| 002684 add      7F0A6214   1     A         gr24=gr10,gr12
  194| 002688 ld       EA3F0250   1     L8        gr17=#SPILL175(gr31,592)
    0| 00268C add      7D9BF214   1     A         gr12=gr27,gr30
    0| 002690 add      7FD6F214   1     A         gr30=gr22,gr30
    0| 002694 ld       EADF02A0   1     L8        gr22=#SPILL148(gr31,672)
    0| 002698 add      7D77EA14   1     A         gr11=gr23,gr29
    0| 00269C add      7FB3E214   1     A         gr29=gr19,gr28
    0| 0026A0 ld       EA7F0098   1     L8        gr19=#SPILL112(gr31,152)
    0| 0026A4 ld       E9DF02A8   1     L8        gr14=#SPILL115(gr31,680)
  189| 0026A8 add      7D52BA14   1     A         gr10=gr18,gr23
    0| 0026AC ld       EA5F0280   1     L8        gr18=#SPILL128(gr31,640)
    0| 0026B0 mtspr    7E0903A6   1     LCTR      ctr=gr16
    0| 0026B4 add      7D29BA14   1     A         gr9=gr9,gr23
  194| 0026B8 add      7E11BA14   1     A         gr16=gr17,gr23
    0| 0026BC add      7EF6BA14   1     A         gr23=gr22,gr23
  194| 0026C0 std      FA1F00E0   1     ST8       #SPILL196(gr31,224)=gr16
    0| 0026C4 std      FAFF00B0   1     ST8       #SPILL199(gr31,176)=gr23
    0| 0026C8 add      7F92E214   1     A         gr28=gr18,gr28
    0| 0026CC mulld    7EEE99D2   1     M         gr23=gr14,gr19
    0| 0026D0 ld       EA5F02B0   1     L8        gr18=#SPILL28(gr31,688)
    0| 0026D4 mulld    7EC071D2   1     M         gr22=gr0,gr14
    0| 0026D8 ld       EA3F0288   1     L8        gr17=#SPILL145(gr31,648)
    0| 0026DC ld       EA1F0290   1     L8        gr16=#SPILL156(gr31,656)
    0| 0026E0 add      7EF79214   1     A         gr23=gr23,gr18
    0| 0026E4 add      7F39B214   1     A         gr25=gr25,gr22
    0| 0026E8 add      7EF5BA14   1     A         gr23=gr21,gr23
    0| 0026EC add      7F38CA14   1     A         gr25=gr24,gr25
    0| 0026F0 add      7F71D214   1     A         gr27=gr17,gr26
    0| 0026F4 add      7F50D214   1     A         gr26=gr16,gr26
    0| 0026F8 add      7F14BA14   1     A         gr24=gr20,gr23
  189| 0026FC ld       EA9F02B8   1     L8        gr20=#SPILL172(gr31,696)
    0| 002700 ld       EABF02C0   1     L8        gr21=#SPILL149(gr31,704)
    0| 002704 ld       EA1F0300   1     L8        gr16=#SPILL166(gr31,768)
    0| 002708 ld       EAFF02C8   1     L8        gr23=#SPILL165(gr31,712)
    0| 00270C ld       EADF02D0   1     L8        gr22=#SPILL163(gr31,720)
    0| 002710 ld       EA7F02E8   1     L8        gr19=#SPILL159(gr31,744)
  189| 002714 std      FA9F00D8   1     ST8       #SPILL200(gr31,216)=gr20
    0| 002718 std      FABF00F0   1     ST8       #SPILL201(gr31,240)=gr21
    0| 00271C std      FA1F00D0   1     ST8       #SPILL202(gr31,208)=gr16
    0| 002720 ld       EABF02D8   1     L8        gr21=#SPILL170(gr31,728)
    0| 002724 ld       EA9F02E0   1     L8        gr20=#SPILL169(gr31,736)
    0| 002728 ld       EA5F02F0   1     L8        gr18=#SPILL158(gr31,752)
    0| 00272C ld       EA3F02F8   1     L8        gr17=#SPILL157(gr31,760)
    0| 002730 stfd     D85F0118   1     STFL      #SPILL191(gr31,280)=fp2
    0| 002734 stfd     D81F0110   1     STFL      #SPILL192(gr31,272)=fp0
    0| 002738 ld       E87F0320   1     L8        gr3=#SPILL162(gr31,800)
    0| 00273C std      F8BF0090   1     ST8       #SPILL206(gr31,144)=gr5
    0| 002740 ld       EA1F0308   1     L8        gr16=#SPILL164(gr31,776)
    0| 002744 std      F81F00A0   1     ST8       #SPILL207(gr31,160)=gr0
    0| 002748 ld       E9FF0310   1     L8        gr15=#SPILL173(gr31,784)
    0| 00274C std      F8DF0088   1     ST8       #SPILL208(gr31,136)=gr6
    0| 002750 std      F87F0328   1     ST8       #SPILL203(gr31,808)=gr3
    0| 002754 ld       E87F0330   1     L8        gr3=#SPILL161(gr31,816)
    0| 002758 ld       E9DF0318   1     L8        gr14=#SPILL168(gr31,792)
    0| 00275C std      F89F0108   1     ST8       #SPILL209(gr31,264)=gr4
    0| 002760 std      F87F00B8   1     ST8       #SPILL204(gr31,184)=gr3
    0| 002764 ld       E87F0338   1     L8        gr3=#SPILL160(gr31,824)
    0| 002768 ld       E89F0328   1     L8        gr4=#SPILL203(gr31,808)
    0| 00276C std      F87F00C0   1     ST8       #SPILL205(gr31,192)=gr3
    0| 002770 ld       E87F00D0   1     L8        gr3=#SPILL202(gr31,208)
    0| 002774 ori      60210000   1     XNOP      
    0| 002778 ori      60210000   1     XNOP      
  185|                              CL.182:
  189| 00277C ld       E8BF00D8   1     L8        gr5=#SPILL200(gr31,216)
  189| 002780 lfd      C96A0018   1     LFL       fp11=erold[](gr10,24)
  189| 002784 lfdu     CD8A0008   1     LFDU      fp12,gr10=erold[](gr10,8)
  194| 002788 lfd      C81F00F8   1     LFL       fp0=#SPILL195(gr31,248)
  194| 00278C lfd      C85F0100   1     LFL       fp2=#SPILL194(gr31,256)
  189| 002790 lfd      CBE50000   1     LFL       fp31=dx1b(gr5,0)
  189| 002794 lfdu     CFC50008   1     LFDU      fp30,gr5=dx1b(gr5,8)
  189| 002798 fsub     FD6B6028   1     SFL       fp11=fp11,fp12,fcr
  189| 00279C std      F8BF00D8   1     ST8       #SPILL200(gr31,216)=gr5
  189| 0027A0 fadd     FD9FF02A   1     AFL       fp12=fp31,fp30,fcr
  194| 0027A4 ld       E8BF00E0   1     L8        gr5=#SPILL196(gr31,224)
  189| 0027A8 fdiv     FD6B6024   1     DFL       fp11=fp11,fp12,fcr
  194| 0027AC lfdu     CFA50008   1     LFDU      fp29,gr5=erold[](gr5,8)
  194| 0027B0 std      F8BF00E0   1     ST8       #SPILL196(gr31,224)=gr5
  194| 0027B4 ld       E8BF00E8   1     L8        gr5=#SPILL197(gr31,232)
  194| 0027B8 lfdu     CF850008   1     LFDU      fp28,gr5=erold[](gr5,8)
  194| 0027BC std      F8BF00E8   1     ST8       #SPILL197(gr31,232)=gr5
    0| 0027C0 ld       E8BF00F0   1     L8        gr5=#SPILL201(gr31,240)
    0| 0027C4 lfdu     CDA50008   1     LFDU      fp13,gr5=g2bi(gr5,8)
    0| 0027C8 std      F8BF00F0   1     ST8       #SPILL201(gr31,240)=gr5
  194| 0027CC fsub     FFFDE028   1     SFL       fp31=fp29,fp28,fcr
  194| 0027D0 fmul     FD9F0372   2     MFL       fp12=fp31,fp13,fcr
  194| 0027D4 fmul     FFEC0032   2     MFL       fp31=fp12,fp0,fcr
  194| 0027D8 fmsub    FD8267F8   2     FMS       fp12=fp12,fp2,fp31,fcr
  194| 0027DC fnmsub   FD80FB3C   2     FNMS      fp12=fp31,fp0,fp12,fcr
  197| 0027E0 bc       419A0188   1     BT        CL.185,cr6,0x4/eq,taken=50%(0,0)
  257| 0027E4 fmul     FDAD01B2   1     MFL       fp13=fp13,fp6,fcr
  212| 0027E8 lfd      CBB90000   1     LFL       fp29=kapr(gr25,0)
  212| 0027EC lfd      CB980000   1     LFL       fp28=sig(gr24,0)
  247| 0027F0 lfd      C816FFF8   1     LFL       fp0=dv12[].rns21.(gr22,-8)
  203| 0027F4 fmul     FF6C0332   1     MFL       fp27=fp12,fp12,fcr
  247| 0027F8 lfd      C8560000   1     LFL       fp2=dv12[].rns21.(gr22,0)
  257| 0027FC lfd      CB340000   1     LFL       fp25=g2a(gr20,0)
  257| 002800 stfd     D9BF00D0   1     STFL      #SPILL202(gr31,208)=fp13
  212| 002804 lfd      C9AA0008   1     LFL       fp13=erold[](gr10,8)
  212| 002808 fadd     FFBDE02A   1     AFL       fp29=fp29,fp28,fcr
  257| 00280C lfd      CAF50000   1     LFL       fp23=g31a(gr21,0)
  212| 002810 fmadd    FECBDAFA   1     FMA       fp22=fp27,fp11,fp11,fcr
  257| 002814 lfd      CABD0000   1     LFL       fp21=v2(gr29,0)
  257| 002818 lfd      CA740008   1     LFL       fp19=g2a(gr20,8)
  257| 00281C lfd      CA550008   1     LFL       fp18=g31a(gr21,8)
  212| 002820 fsub     FF446828   1     SFL       fp26=fp4,fp13,fcr
  247| 002824 lfd      CBD7FFF8   1     LFL       fp30=dv21[].rns24.(gr23,-8)
  212| 002828 fsqrt    FEC0B02C   1     SQRT      fp22=fp22,fcr
  257| 00282C lfd      CA3B0000   1     LFL       fp17=v1(gr27,0)
  257| 002830 lfd      CA1C0000   1     LFL       fp16=v2(gr28,0)
  247| 002834 lfd      CB770000   1     LFL       fp27=dv21[].rns24.(gr23,0)
  257| 002838 lfd      C9FA0000   1     LFL       fp15=v1(gr26,0)
  257| 00283C lfd      C9CE0000   1     LFL       fp14=dvl1ai(gr14,0)
  247| 002840 lfd      CBF2FFF8   1     LFL       fp31=dv22[].rns3.(gr18,-8)
  247| 002844 lfd      CB91FFF8   1     LFL       fp28=dv11[].rns0.(gr17,-8)
  247| 002848 lfd      CA93FFF8   1     LFL       fp20=dv33[].rns6.(gr19,-8)
  212| 00284C qvfre    1300E830   1     QVFRE     fp24=fp29
  212| 002850 fsel     FDBA692E   1     FSEL      fp13=fp26,fp13,fp4
  247| 002854 fadd     FF40102A   2     AFL       fp26=fp0,fp2,fcr
  257| 002858 lfd      C81F00D0   1     LFL       fp0=#SPILL202(gr31,208)
  257| 00285C fmul     FF3905F2   1     MFL       fp25=fp25,fp23,fcr
  247| 002860 lfs      C048001C   1     LFS       fp2=+CONSTANT_AREA(gr8,28)
  257| 002864 fmul     FEF304B2   1     MFL       fp23=fp19,fp18,fcr
  257| 002868 fmul     FEA80572   2     MFL       fp21=fp8,fp21,fcr
  212| 00286C fmsub    FE7D1E38   2     FMS       fp19=fp3,fp29,fp24,fcr
  247| 002870 fadd     FFDAF02A   2     AFL       fp30=fp26,fp30,fcr
  257| 002874 fmul     FF590472   2     MFL       fp26=fp25,fp17,fcr
  247| 002878 lfs      C2280020   1     LFS       fp17=+CONSTANT_AREA(gr8,32)
  221| 00287C fsub     FE44B028   1     SFL       fp18=fp4,fp22,fcr
  257| 002880 fmsub    FF27AC38   2     FMS       fp25=fp21,fp7,fp16,fcr
  247| 002884 lfs      C2080018   1     LFS       fp16=+CONSTANT_AREA(gr8,24)
  212| 002888 fnmsub   FF18C4FC   1     FNMS      fp24=fp24,fp24,fp19,fcr
  247| 00288C fadd     FFDED82A   2     AFL       fp30=fp30,fp27,fcr
  257| 002890 fmsub    FF77D3F8   2     FMS       fp27=fp26,fp23,fp15,fcr
  221| 002894 fsel     FEB2B12E   2     FSEL      fp21=fp18,fp22,fp4
  257| 002898 fmul     FF400672   2     MFL       fp26=fp0,fp25,fcr
  212| 00289C fmsub    FF3D1E38   2     FMS       fp25=fp3,fp29,fp24,fcr
  247| 0028A0 fmul     FFDE0072   2     MFL       fp30=fp30,fp1,fcr
  221| 0028A4 fdiv     FD6BA824   2     DFL       fp11=fp11,fp21,fcr
  212| 0028A8 fnmsub   FF38C67C   2     FNMS      fp25=fp24,fp24,fp25,fcr
  225| 0028AC qvfre    1300A830   1     QVFRE     fp24=fp21
  257| 0028B0 fmadd    FF6ED6FA   1     FMA       fp27=fp26,fp14,fp27,fcr
  247| 0028B4 fmul     FF4B02F2   2     MFL       fp26=fp11,fp11,fcr
  212| 0028B8 fmsub    FFBD1E78   2     FMS       fp29=fp3,fp29,fp25,fcr
  225| 0028BC fmsub    FEF51E38   2     FMS       fp23=fp3,fp21,fp24,fcr
  212| 0028C0 fnmsub   FFB9CF7C   2     FNMS      fp29=fp25,fp25,fp29,fcr
  225| 0028C4 fnmsub   FF38C5FC   2     FNMS      fp25=fp24,fp24,fp23,fcr
  212| 0028C8 fmul     FF160772   2     MFL       fp24=fp22,fp29,fcr
  225| 0028CC fmsub    FFB51E78   2     FMS       fp29=fp3,fp21,fp25,fcr
  212| 0028D0 fdiv     FDB86824   2     DFL       fp13=fp24,fp13,fcr
  225| 0028D4 fnmsub   FFB9CF7C   2     FNMS      fp29=fp25,fp25,fp29,fcr
  247| 0028D8 fmadd    FF2D147A   2     FMA       fp25=fp2,fp13,fp17,fcr
  247| 0028DC fadd     FF0D802A   2     AFL       fp24=fp13,fp16,fcr
  247| 0028E0 fmul     FECD0372   2     MFL       fp22=fp13,fp13,fcr
  225| 0028E4 fmul     FEEC0772   2     MFL       fp23=fp12,fp29,fcr
  247| 0028E8 fmadd    FDADCB7A   2     FMA       fp13=fp25,fp13,fp13,fcr
  225| 0028EC fmsub    FD9565F8   2     FMS       fp12=fp12,fp21,fp23,fcr
  247| 0028F0 fdiv     FDB86824   2     DFL       fp13=fp24,fp13,fcr
  225| 0028F4 fnmsub   FD9DBB3C   2     FNMS      fp12=fp23,fp29,fp12,fcr
  247| 0028F8 fmul     FFAD0372   2     MFL       fp29=fp13,fp13,fcr
  247| 0028FC fmul     FF2C0332   2     MFL       fp25=fp12,fp12,fcr
  247| 002900 fmadd    FDB66F7A   2     FMA       fp13=fp13,fp22,fp29,fcr
  247| 002904 lfd      C9E80028   1     LFL       fp15=+CONSTANT_AREA(gr8,40)
  247| 002908 fadd     FFAD782A   1     AFL       fp29=fp13,fp15,fcr
  247| 00290C fsub     FDA36828   2     SFL       fp13=fp3,fp13,fcr
  247| 002910 fmul     FFBD0172   2     MFL       fp29=fp29,fp5,fcr
  247| 002914 fmul     FF0D0072   2     MFL       fp24=fp13,fp1,fcr
  247| 002918 fmul     FF3D0672   2     MFL       fp25=fp29,fp25,fcr
  247| 00291C fmul     FF5D06B2   2     MFL       fp26=fp29,fp26,fcr
  247| 002920 fmul     FD6B0772   2     MFL       fp11=fp11,fp29,fcr
  247| 002924 fmadd    FFADC87A   2     FMA       fp29=fp25,fp13,fp1,fcr
  247| 002928 fmadd    FDADD07A   2     FMA       fp13=fp26,fp13,fp1,fcr
  247| 00292C fmul     FD6C02F2   2     MFL       fp11=fp12,fp11,fcr
  247| 002930 fmul     FD9F0772   2     MFL       fp12=fp31,fp29,fcr
  247| 002934 fmadd    FD9C637A   2     FMA       fp12=fp12,fp28,fp13,fcr
  257| 002938 lfd      C9AC0000   1     LFL       fp13=v3(gr12,0)
  247| 00293C fmadd    FD94663A   1     FMA       fp12=fp12,fp20,fp24,fcr
  247| 002940 fmadd    FD7E62FA   2     FMA       fp11=fp12,fp30,fp11,fcr
  257| 002944 lfd      C99E0000   1     LFL       fp12=v3(gr30,0)
  247| 002948 stfd     D96BFFF8   1     STFL      gvcf[](gr11,-8)=fp11
  257| 00294C fsub     FD8C6828   1     SFL       fp12=fp12,fp13,fcr
  257| 002950 lfd      C96F0000   1     LFL       fp11=g31bi(gr15,0)
  257| 002954 fmul     FD6B0272   1     MFL       fp11=fp11,fp9,fcr
  257| 002958 fmul     FD6B02B2   2     MFL       fp11=fp11,fp10,fcr
  257| 00295C fmadd    FD6BDB3A   2     FMA       fp11=fp27,fp11,fp12,fcr
  257| 002960 stfd     D969FFF8   1     STFL      deldotv[](gr9,-8)=fp11
    0| 002964 b        480002C0   1     B         CL.186,-1
  199|                              CL.185:
  200| 002968 ld       E8BF00B0   1     L8        gr5=#SPILL199(gr31,176)
  203| 00296C fmul     FFCC0332   1     MFL       fp30=fp12,fp12,fcr
  212| 002970 lfd      CB990000   1     LFL       fp28=kapr(gr25,0)
  212| 002974 lfd      CB580000   1     LFL       fp26=sig(gr24,0)
  200| 002978 lfd      CBEF0000   1     LFL       fp31=g31bi(gr15,0)
  212| 00297C lfs      C2280034   1     LFS       fp17=+CONSTANT_AREA(gr8,52)
  200| 002980 lfd      CBA5FFF8   1     LFL       fp29=erold[](gr5,-8)
  212| 002984 fmadd    FF6BF2FA   1     FMA       fp27=fp30,fp11,fp11,fcr
  200| 002988 ld       E8BF00A8   1     L8        gr5=#SPILL198(gr31,168)
  212| 00298C lfs      C208003C   1     LFS       fp16=+CONSTANT_AREA(gr8,60)
  212| 002990 fadd     FF9CD02A   1     AFL       fp28=fp28,fp26,fcr
  212| 002994 lfd      CB4A0008   1     LFL       fp26=erold[](gr10,8)
  212| 002998 lfs      C1E80038   1     LFS       fp15=+CONSTANT_AREA(gr8,56)
  212| 00299C lfs      C1C80040   1     LFS       fp14=+CONSTANT_AREA(gr8,64)
  200| 0029A0 lfd      CB25FFF8   1     LFL       fp25=erold[](gr5,-8)
  200| 0029A4 ld       E8BF00C0   1     L8        gr5=#SPILL205(gr31,192)
  247| 0029A8 lfd      CBD1FFF8   1     LFL       fp30=dv11[].rns0.(gr17,-8)
  212| 0029AC fsub     FE84D028   1     SFL       fp20=fp4,fp26,fcr
  200| 0029B0 lfd      CB050000   1     LFL       fp24=g32bi(gr5,0)
  200| 0029B4 fsub     FEDDC828   1     SFL       fp22=fp29,fp25,fcr
  200| 0029B8 ld       E8BF00C8   1     L8        gr5=#SPILL193(gr31,200)
  212| 0029BC fsel     FF54D12E   1     FSEL      fp26=fp20,fp26,fp4
  247| 0029C0 lfd      CBB2FFF8   2     LFL       fp29=dv22[].rns3.(gr18,-8)
  200| 0029C4 fmul     FEDF05B2   1     MFL       fp22=fp31,fp22,fcr
  200| 0029C8 lfd      CB250000   1     LFL       fp25=dx3b(gr5,0)
  200| 0029CC lfd      CAE50008   1     LFL       fp23=dx3b(gr5,8)
  200| 0029D0 fmul     FF160632   1     MFL       fp24=fp22,fp24,fcr
  200| 0029D4 fadd     FF39B82A   2     AFL       fp25=fp25,fp23,fcr
  212| 0029D8 qvfre    12E0E030   1     QVFRE     fp23=fp28
  200| 0029DC qvfre    12A0C830   1     QVFRE     fp21=fp25
  212| 0029E0 fmsub    FEDC1DF8   1     FMS       fp22=fp3,fp28,fp23,fcr
  200| 0029E4 fmsub    FE991D78   2     FMS       fp20=fp3,fp25,fp21,fcr
  212| 0029E8 fnmsub   FEF7BDBC   2     FNMS      fp23=fp23,fp23,fp22,fcr
  212| 0029EC qvfre    12C0D030   1     QVFRE     fp22=fp26
  200| 0029F0 fnmsub   FEB5AD3C   1     FNMS      fp21=fp21,fp21,fp20,fcr
  212| 0029F4 fmsub    FE9C1DF8   2     FMS       fp20=fp3,fp28,fp23,fcr
  212| 0029F8 fmsub    FE7A1DB8   2     FMS       fp19=fp3,fp26,fp22,fcr
  200| 0029FC fmsub    FE591D78   2     FMS       fp18=fp3,fp25,fp21,fcr
  212| 002A00 fnmsub   FEF7BD3C   2     FNMS      fp23=fp23,fp23,fp20,fcr
  212| 002A04 fnmsub   FED6B4FC   2     FNMS      fp22=fp22,fp22,fp19,fcr
  200| 002A08 fnmsub   FEB5ACBC   2     FNMS      fp21=fp21,fp21,fp18,fcr
  247| 002A0C lfs      C248001C   1     LFS       fp18=+CONSTANT_AREA(gr8,28)
  212| 002A10 fmsub    FF9C1DF8   1     FMS       fp28=fp3,fp28,fp23,fcr
  212| 002A14 fmsub    FE9A1DB8   2     FMS       fp20=fp3,fp26,fp22,fcr
  200| 002A18 fmul     FE780572   2     MFL       fp19=fp24,fp21,fcr
  212| 002A1C fnmsub   FEF7BF3C   2     FNMS      fp23=fp23,fp23,fp28,fcr
  212| 002A20 fnmsub   FED6B53C   2     FNMS      fp22=fp22,fp22,fp20,fcr
  200| 002A24 fmsub    FF99C4F8   2     FMS       fp28=fp24,fp25,fp19,fcr
  200| 002A28 fnmsub   FF959F3C   2     FNMS      fp28=fp19,fp21,fp28,fcr
  212| 002A2C fmadd    FF7CDF3A   2     FMA       fp27=fp27,fp28,fp28,fcr
  212| 002A30 frsqrte  FF20D834   2     FRSQRE    fp25=fp27
  212| 002A34 fnabs    FF00D910   2     NABSFL    fp24=fp27
  212| 002A38 fmul     FEBB0672   2     MFL       fp21=fp27,fp25,fcr
  212| 002A3C fmadd    FE798D7A   2     FMA       fp19=fp17,fp25,fp21,fcr
  247| 002A40 lfs      C2280018   1     LFS       fp17=+CONSTANT_AREA(gr8,24)
  212| 002A44 fmadd    FE9383FA   1     FMA       fp20=fp16,fp19,fp15,fcr
  212| 002A48 fmadd    FE93753A   2     FMA       fp20=fp14,fp19,fp20,fcr
  212| 002A4C fmul     FE930532   2     MFL       fp20=fp19,fp20,fcr
  247| 002A50 lfs      C2680020   1     LFS       fp19=+CONSTANT_AREA(gr8,32)
  212| 002A54 fmul     FEB50532   1     MFL       fp21=fp21,fp20,fcr
  212| 002A58 fmadd    FE99CD3A   2     FMA       fp20=fp25,fp25,fp20,fcr
  212| 002A5C fmadd    FF3BAE7A   2     FMA       fp25=fp21,fp27,fp25,fcr
  212| 002A60 fmul     FEB40072   2     MFL       fp21=fp20,fp1,fcr
  212| 002A64 fmsub    FE99DE78   2     FMS       fp20=fp27,fp25,fp25,fcr
  212| 002A68 fnmsub   FF34CD7C   2     FNMS      fp25=fp25,fp20,fp21,fcr
  212| 002A6C fsel     FF78CEEE   2     FSEL      fp27=fp24,fp25,fp27
  212| 002A70 fmul     FF3706F2   2     MFL       fp25=fp23,fp27,fcr
  221| 002A74 fsub     FEE4D828   2     SFL       fp23=fp4,fp27,fcr
  212| 002A78 fmul     FF1905B2   2     MFL       fp24=fp25,fp22,fcr
  221| 002A7C fsel     FF77D92E   2     FSEL      fp27=fp23,fp27,fp4
  212| 002A80 fmsub    FF5ACE38   2     FMS       fp26=fp25,fp26,fp24,fcr
  221| 002A84 qvfre    1320D830   1     QVFRE     fp25=fp27
  212| 002A88 fnmsub   FF16C6BC   1     FNMS      fp24=fp24,fp22,fp26,fcr
  221| 002A8C fmsub    FEDB1E78   2     FMS       fp22=fp3,fp27,fp25,fcr
  247| 002A90 fmadd    FEF894FA   2     FMA       fp23=fp18,fp24,fp19,fcr
  247| 002A94 fadd     FF58882A   2     AFL       fp26=fp24,fp17,fcr
  221| 002A98 fnmsub   FEB9CDBC   2     FNMS      fp21=fp25,fp25,fp22,fcr
  247| 002A9C fmul     FF380632   2     MFL       fp25=fp24,fp24,fcr
  247| 002AA0 fmadd    FF18BE3A   2     FMA       fp24=fp23,fp24,fp24,fcr
  221| 002AA4 fmsub    FE9B1D78   2     FMS       fp20=fp3,fp27,fp21,fcr
  247| 002AA8 fdiv     FEFAC024   2     DFL       fp23=fp26,fp24,fcr
  221| 002AAC fnmsub   FEB5AD3C   2     FNMS      fp21=fp21,fp21,fp20,fcr
  247| 002AB0 qvfre    12C0C030   1     QVFRE     fp22=fp24
  247| 002AB4 fmul     FE9705F2   1     MFL       fp20=fp23,fp23,fcr
  221| 002AB8 fmul     FE4B0572   2     MFL       fp18=fp11,fp21,fcr
  247| 002ABC fmsub    FE781DB8   2     FMS       fp19=fp3,fp24,fp22,fcr
  225| 002AC0 fmul     FE2C0572   2     MFL       fp17=fp12,fp21,fcr
  226| 002AC4 fmul     FE1C0572   2     MFL       fp16=fp28,fp21,fcr
  247| 002AC8 fmadd    FEF9BD3A   2     FMA       fp23=fp23,fp25,fp20,fcr
  247| 002ACC lfd      CA880028   1     LFL       fp20=+CONSTANT_AREA(gr8,40)
  247| 002AD0 fnmsub   FED6B4FC   1     FNMS      fp22=fp22,fp22,fp19,fcr
  221| 002AD4 fmsub    FD7B5CB8   2     FMS       fp11=fp11,fp27,fp18,fcr
  225| 002AD8 fmsub    FD9B6478   2     FMS       fp12=fp12,fp27,fp17,fcr
  226| 002ADC fmsub    FF9BE438   2     FMS       fp28=fp28,fp27,fp16,fcr
  247| 002AE0 fadd     FF77A02A   2     AFL       fp27=fp23,fp20,fcr
  247| 002AE4 fmsub    FE981DB8   2     FMS       fp20=fp3,fp24,fp22,fcr
  221| 002AE8 fnmsub   FD7592FC   2     FNMS      fp11=fp18,fp21,fp11,fcr
  225| 002AEC fnmsub   FD958B3C   2     FNMS      fp12=fp17,fp21,fp12,fcr
  247| 002AF0 fsub     FEE3B828   2     SFL       fp23=fp3,fp23,fcr
  226| 002AF4 fnmsub   FF95873C   2     FNMS      fp28=fp16,fp21,fp28,fcr
  247| 002AF8 fmul     FF7B0172   2     MFL       fp27=fp27,fp5,fcr
  247| 002AFC fnmsub   FEB6B53C   2     FNMS      fp21=fp22,fp22,fp20,fcr
  247| 002B00 lfd      CA50FFF8   2     LFL       fp18=dv13[].rns23.(gr16,-8)
  247| 002B04 fmul     FECC0332   1     MFL       fp22=fp12,fp12,fcr
  257| 002B08 lfd      CA350008   1     LFL       fp17=g31a(gr21,8)
  247| 002B0C fmul     FE6B02F2   1     MFL       fp19=fp11,fp11,fcr
  247| 002B10 ld       E8BF00B8   1     L8        gr5=#SPILL204(gr31,184)
  247| 002B14 fmul     FE9A0572   1     MFL       fp20=fp26,fp21,fcr
  257| 002B18 lfd      CA1B0000   1     LFL       fp16=v1(gr27,0)
  247| 002B1C fmul     FEDB05B2   1     MFL       fp22=fp27,fp22,fcr
  247| 002B20 fmul     FD7B02F2   2     MFL       fp11=fp27,fp11,fcr
  247| 002B24 fmul     FE7B04F2   2     MFL       fp19=fp27,fp19,fcr
  257| 002B28 fmul     FDAD01B2   2     MFL       fp13=fp13,fp6,fcr
  247| 002B2C fmsub    FF18D538   2     FMS       fp24=fp26,fp24,fp20,fcr
  257| 002B30 fmul     FFFF0272   2     MFL       fp31=fp31,fp9,fcr
  247| 002B34 fmadd    FF57987A   2     FMA       fp26=fp19,fp23,fp1,fcr
  247| 002B38 fmul     FE7C0732   2     MFL       fp19=fp28,fp28,fcr
  247| 002B3C fnmsub   FF15A63C   2     FNMS      fp24=fp20,fp21,fp24,fcr
  257| 002B40 fmul     FFFF02B2   2     MFL       fp31=fp31,fp10,fcr
  247| 002B44 fmul     FE7B04F2   2     MFL       fp19=fp27,fp19,fcr
  247| 002B48 fmul     FEB80632   2     MFL       fp21=fp24,fp24,fcr
  247| 002B4C fmadd    FF39C57A   2     FMA       fp25=fp24,fp25,fp21,fcr
  247| 002B50 lfd      CAB7FFF8   1     LFL       fp21=dv21[].rns24.(gr23,-8)
  247| 002B54 fsub     FF03C828   1     SFL       fp24=fp3,fp25,fcr
  247| 002B58 lfd      CB33FFF8   2     LFL       fp25=dv33[].rns6.(gr19,-8)
  247| 002B5C fmadd    FE98B07A   1     FMA       fp20=fp22,fp24,fp1,fcr
  247| 002B60 lfd      CB16FFF8   1     LFL       fp24=dv12[].rns21.(gr22,-8)
  247| 002B64 lfd      CAD60000   1     LFL       fp22=dv12[].rns21.(gr22,0)
  247| 002B68 fmul     FFBD0532   1     MFL       fp29=fp29,fp20,fcr
  247| 002B6C lfd      CA970000   1     LFL       fp20=dv21[].rns24.(gr23,0)
  247| 002B70 fadd     FF18B02A   1     AFL       fp24=fp24,fp22,fcr
  247| 002B74 lfd      CAD00000   2     LFL       fp22=dv13[].rns23.(gr16,0)
  247| 002B78 fmadd    FFDEEEBA   1     FMA       fp30=fp29,fp30,fp26,fcr
  247| 002B7C lfd      CBA3FFF8   2     LFL       fp29=dv31[].rns26.(gr3,-8)
  247| 002B80 fmadd    FF57987A   1     FMA       fp26=fp19,fp23,fp1,fcr
  247| 002B84 lfd      CAE30000   2     LFL       fp23=dv31[].rns26.(gr3,0)
  247| 002B88 fadd     FF18A82A   1     AFL       fp24=fp24,fp21,fcr
  247| 002B8C lfd      CAA5FFF8   1     LFL       fp21=dv23[].rns15.(gr5,-8)
  247| 002B90 fadd     FED2B02A   1     AFL       fp22=fp18,fp22,fcr
  257| 002B94 lfd      CA550000   1     LFL       fp18=g31a(gr21,0)
  247| 002B98 fmadd    FFD9F6BA   1     FMA       fp30=fp30,fp25,fp26,fcr
  247| 002B9C lfd      CA64FFF8   1     LFL       fp19=dv32[].rns17.(gr4,-8)
  247| 002BA0 fadd     FF38A02A   1     AFL       fp25=fp24,fp20,fcr
  257| 002BA4 lfd      CB140000   1     LFL       fp24=g2a(gr20,0)
  247| 002BA8 fadd     FFB6E82A   1     AFL       fp29=fp22,fp29,fcr
  257| 002BAC lfd      CAD40008   1     LFL       fp22=g2a(gr20,8)
  247| 002BB0 fmul     FE8C02F2   1     MFL       fp20=fp12,fp11,fcr
  257| 002BB4 lfd      CB4E0000   1     LFL       fp26=dvl1ai(gr14,0)
  247| 002BB8 fmul     FF390072   1     MFL       fp25=fp25,fp1,fcr
  247| 002BBC fmul     FD7C02F2   2     MFL       fp11=fp28,fp11,fcr
  247| 002BC0 fadd     FFBDB82A   2     AFL       fp29=fp29,fp23,fcr
  257| 002BC4 lfd      CAFA0000   1     LFL       fp23=v1(gr26,0)
  257| 002BC8 fmul     FED60472   1     MFL       fp22=fp22,fp17,fcr
  257| 002BCC lfd      CA3D0000   1     LFL       fp17=v2(gr29,0)
  257| 002BD0 fmul     FF1804B2   1     MFL       fp24=fp24,fp18,fcr
  257| 002BD4 lfd      CA5C0000   1     LFL       fp18=v2(gr28,0)
  247| 002BD8 fmadd    FFD9F53A   1     FMA       fp30=fp30,fp25,fp20,fcr
  257| 002BDC lfd      CB3E0000   1     LFL       fp25=v3(gr30,0)
  247| 002BE0 fmul     FFBD0072   1     MFL       fp29=fp29,fp1,fcr
  257| 002BE4 lfd      CA8C0000   1     LFL       fp20=v3(gr12,0)
  257| 002BE8 fmul     FE280472   1     MFL       fp17=fp8,fp17,fcr
  257| 002BEC fmul     FF180432   2     MFL       fp24=fp24,fp16,fcr
  247| 002BF0 fmul     FD9B0332   2     MFL       fp12=fp27,fp12,fcr
  247| 002BF4 fmadd    FD7DF2FA   2     FMA       fp11=fp30,fp29,fp11,fcr
  257| 002BF8 fmsub    FFC78CB8   2     FMS       fp30=fp17,fp7,fp18,fcr
  257| 002BFC fmsub    FF76C5F8   2     FMS       fp27=fp24,fp22,fp23,fcr
  247| 002C00 fadd     FF15982A   2     AFL       fp24=fp21,fp19,fcr
  247| 002C04 fmul     FD9C0332   2     MFL       fp12=fp28,fp12,fcr
  257| 002C08 fsub     FFB9A028   2     SFL       fp29=fp25,fp20,fcr
  257| 002C0C fmul     FDAD07B2   2     MFL       fp13=fp13,fp30,fcr
  247| 002C10 fmadd    FD785B3A   2     FMA       fp11=fp11,fp24,fp12,fcr
  257| 002C14 fmadd    FD9A6EFA   2     FMA       fp12=fp13,fp26,fp27,fcr
  247| 002C18 stfd     D96BFFF8   1     STFL      gvcf[](gr11,-8)=fp11
  257| 002C1C fmadd    FD7F677A   1     FMA       fp11=fp12,fp31,fp29,fcr
  257| 002C20 stfd     D969FFF8   1     STFL      deldotv[](gr9,-8)=fp11
  257|                              CL.186:
    0| 002C24 ld       E8DF0088   1     L8        gr6=#SPILL208(gr31,136)
    0| 002C28 ld       E81F0098   1     L8        gr0=#SPILL112(gr31,152)
    0| 002C2C ld       E8BF0090   1     L8        gr5=#SPILL206(gr31,144)
    0| 002C30 addi     3AF70008   1     AI        gr23=gr23,8
    0| 002C34 addi     3AD60008   1     AI        gr22=gr22,8
    0| 002C38 addi     3AB50008   1     AI        gr21=gr21,8
    0| 002C3C add      7F66DA14   1     A         gr27=gr6,gr27
    0| 002C40 add      7F46D214   1     A         gr26=gr6,gr26
    0| 002C44 ld       E8DF00A8   1     L8        gr6=#SPILL198(gr31,168)
    0| 002C48 add      7F00C214   1     A         gr24=gr0,gr24
    0| 002C4C ld       E81F00A0   1     L8        gr0=#SPILL207(gr31,160)
    0| 002C50 addi     3A940008   1     AI        gr20=gr20,8
    0| 002C54 addi     39290008   1     AI        gr9=gr9,8
    0| 002C58 addi     3A730008   1     AI        gr19=gr19,8
    0| 002C5C addi     38C60008   1     AI        gr6=gr6,8
    0| 002C60 addi     3A520008   1     AI        gr18=gr18,8
    0| 002C64 std      F8DF00A8   1     ST8       #SPILL198(gr31,168)=gr6
    0| 002C68 ld       E8DF00B0   1     L8        gr6=#SPILL199(gr31,176)
    0| 002C6C addi     3A310008   1     AI        gr17=gr17,8
    0| 002C70 addi     38630008   1     AI        gr3=gr3,8
    0| 002C74 addi     3A100008   1     AI        gr16=gr16,8
    0| 002C78 addi     396B0008   1     AI        gr11=gr11,8
    0| 002C7C add      7D876214   1     A         gr12=gr7,gr12
    0| 002C80 addi     38C60008   1     AI        gr6=gr6,8
    0| 002C84 add      7FC7F214   1     A         gr30=gr7,gr30
    0| 002C88 std      F8DF00B0   1     ST8       #SPILL199(gr31,176)=gr6
    0| 002C8C ld       E8DF00B8   1     L8        gr6=#SPILL204(gr31,184)
    0| 002C90 addi     39EF0008   1     AI        gr15=gr15,8
    0| 002C94 add      7FA5EA14   1     A         gr29=gr5,gr29
    0| 002C98 add      7F85E214   1     A         gr28=gr5,gr28
    0| 002C9C addi     39CE0008   1     AI        gr14=gr14,8
    0| 002CA0 add      7F20CA14   1     A         gr25=gr0,gr25
    0| 002CA4 addi     38C60008   1     AI        gr6=gr6,8
    0| 002CA8 addi     38840008   1     AI        gr4=gr4,8
    0| 002CAC std      F8DF00B8   1     ST8       #SPILL204(gr31,184)=gr6
    0| 002CB0 ld       E8DF00C0   1     L8        gr6=#SPILL205(gr31,192)
    0| 002CB4 addi     38C60008   1     AI        gr6=gr6,8
    0| 002CB8 std      F8DF00C0   1     ST8       #SPILL205(gr31,192)=gr6
  266| 002CBC bc       4200FAC0   1     BCT       ctr=CL.182,taken=100%(100,0)
  266| 002CC0 ld       E89F0108   1     L8        gr4=#SPILL209(gr31,264)
  266| 002CC4 ld       E8DF0088   1     L8        gr6=#SPILL208(gr31,136)
  266| 002CC8 lfd      C81F0110   1     LFL       fp0=#SPILL192(gr31,272)
  266| 002CCC lfd      C85F0118   1     LFL       fp2=#SPILL191(gr31,280)
    0| 002CD0 b        4BFFF3B0   1     B         CL.78,-1
    0|                              CL.240:
  145| 002CD4 ld       E93F0438   1     L8        gr9=#SPILL174(gr31,1080)
  125| 002CD8 ld       E95F0440   1     L8        gr10=#SPILL176(gr31,1088)
    0| 002CDC ld       E97F0448   1     L8        gr11=#SPILL188(gr31,1096)
    0| 002CE0 mtspr    7D6903A6   1     LCTR      ctr=gr11
    0| 002CE4 bc       41960018   1     BT        CL.498,cr5,0x4/eq,taken=50%(0,0)
  125| 002CE8 stfdu    DC0A0008   1     STFDU     gr10,dv23[].rns15.(gr10,8)=fp0
  145| 002CEC stfdu    DC090008   1     STFDU     gr9,dv32[].rns17.(gr9,8)=fp0
    0| 002CF0 bc       418E0020   1     BT        CL.72,cr3,0x4/eq,taken=20%(20,80)
    0| 002CF4 ori      60210000   1     XNOP      
    0| 002CF8 ori      60210000   1     XNOP      
    0|                              CL.498:
  125| 002CFC stfd     D80A0008   1     STFL      dv23[].rns15.(gr10,8)=fp0
  145| 002D00 stfd     D8090008   1     STFL      dv32[].rns17.(gr9,8)=fp0
  125| 002D04 stfdu    DC0A0010   1     STFDU     gr10,dv23[].rns15.(gr10,16)=fp0
  145| 002D08 stfdu    DC090010   1     STFDU     gr9,dv32[].rns17.(gr9,16)=fp0
    0| 002D0C bc       4200FFF0   1     BCT       ctr=CL.498,taken=100%(100,0)
  147|                              CL.72:
  153| 002D10 bc       409DF83C   1     BF        CL.302,cr7,0x2/gt,taken=50%(0,0)
  155| 002D14 ld       E99F0340   1     L8        gr12=#SPILL12(gr31,832)
  155| 002D18 ld       EBDF0120   1     L8        gr30=#SPILL116(gr31,288)
  155| 002D1C ld       EB7F0348   1     L8        gr27=#SPILL0(gr31,840)
  155| 002D20 ld       EB5F0350   1     L8        gr26=#SPILL43(gr31,848)
  163| 002D24 ld       E97F0178   1     L8        gr11=#SPILL117(gr31,376)
  166| 002D28 ld       EB3F0180   1     L8        gr25=#SPILL118(gr31,384)
  166| 002D2C ld       EB1F0430   1     L8        gr24=#SPILL100(gr31,1072)
  155| 002D30 add      7FACF214   1     A         gr29=gr12,gr30
  155| 002D34 add      7F9ADA14   1     A         gr28=gr26,gr27
  163| 002D38 lfd      C8CB0008   1     LFL       fp6=dx2bi(gr11,8)
  163| 002D3C lfd      C8EB0000   1     LFL       fp7=dx2bi(gr11,0)
  155| 002D40 addi     395D0001   1     AI        gr10=gr29,1
  166| 002D44 lfd      C9190000   1     LFL       fp8=g32bi(gr25,0)
  157| 002D48 addi     393C0001   1     AI        gr9=gr28,1
  166| 002D4C lfd      C9380008   1     LFL       fp9=dx3bi(gr24,8)
  166| 002D50 lfd      C9580000   1     LFL       fp10=dx3bi(gr24,0)
    0| 002D54 bc       4185E810   1     BT        CL.298,cr1,0x2/gt,taken=50%(0,0)
    0| 002D58 b        48000050   1     B         CL.242,-1
    0| 002D5C ori      60210000   1     XNOP      
    0| 002D60 ori      60210000   1     XNOP      
    0|                              CL.292:
  153| 002D64 bc       409DF31C   1     BF        CL.78,cr7,0x2/gt,taken=50%(0,0)
  155| 002D68 ld       E97F0340   1     L8        gr11=#SPILL12(gr31,832)
  155| 002D6C ld       E99F0120   1     L8        gr12=#SPILL116(gr31,288)
  155| 002D70 ld       EBDF0348   1     L8        gr30=#SPILL0(gr31,840)
  155| 002D74 ld       EB7F0350   1     L8        gr27=#SPILL43(gr31,848)
  163| 002D78 ld       EB5F0178   1     L8        gr26=#SPILL117(gr31,376)
  166| 002D7C ld       EB3F0180   1     L8        gr25=#SPILL118(gr31,384)
  166| 002D80 ld       EB1F0430   1     L8        gr24=#SPILL100(gr31,1072)
  155| 002D84 add      7FAB6214   1     A         gr29=gr11,gr12
  155| 002D88 add      7F9BF214   1     A         gr28=gr27,gr30
  155| 002D8C addi     395D0001   1     AI        gr10=gr29,1
  157| 002D90 addi     393C0001   1     AI        gr9=gr28,1
  163| 002D94 lfd      C8DA0008   1     LFL       fp6=dx2bi(gr26,8)
  163| 002D98 lfd      C8FA0000   1     LFL       fp7=dx2bi(gr26,0)
  166| 002D9C lfd      C9190000   1     LFL       fp8=g32bi(gr25,0)
  166| 002DA0 lfd      C9380008   1     LFL       fp9=dx3bi(gr24,8)
  166| 002DA4 lfd      C9580000   1     LFL       fp10=dx3bi(gr24,0)
    0|                              CL.242:
  166| 002DA8 ld       EAFF0128   1     L8        gr23=#SPILL36(gr31,296)
  163| 002DAC ld       EADF0218   1     L8        gr22=#SPILL35(gr31,536)
  163| 002DB0 ld       EABF03D8   1     L8        gr21=#SPILL147(gr31,984)
  163| 002DB4 ld       EA9F0130   1     L8        gr20=#SPILL185(gr31,304)
  166| 002DB8 ld       EA7F03E0   1     L8        gr19=#SPILL180(gr31,992)
    0| 002DBC ld       EA5F03E8   1     L8        gr18=#SPILL121(gr31,1000)
  166| 002DC0 mulld    7FD7E9D2   1     M         gr30=gr23,gr29
  163| 002DC4 mulld    7D96E1D2   1     M         gr12=gr22,gr28
  163| 002DC8 mulld    7D4AB9D2   1     M         gr10=gr10,gr23
  166| 002DCC mulld    7D69B1D2   1     M         gr11=gr9,gr22
  163| 002DD0 add      7D2CF214   1     A         gr9=gr12,gr30
  163| 002DD4 add      7D4AAA14   1     A         gr10=gr10,gr21
  166| 002DD8 add      7FB5F214   1     A         gr29=gr21,gr30
  163| 002DDC add      7D29AA14   1     A         gr9=gr9,gr21
  163| 002DE0 add      7D4A6214   1     A         gr10=gr10,gr12
  166| 002DE4 add      7D6BEA14   1     A         gr11=gr11,gr29
  163| 002DE8 lfdux    7FEA34EE   1     LFDU      fp31,gr10=v1(gr10,gr6,0)
  163| 002DEC lfdux    7D8934EE   1     LFDU      fp12,gr9=v1(gr9,gr6,0)
  166| 002DF0 lfdux    7D6B34EE   1     LFDU      fp11,gr11=v1(gr11,gr6,0)
  163| 002DF4 add      7D8CA214   1     A         gr12=gr12,gr20
  166| 002DF8 add      7FDE9A14   1     A         gr30=gr30,gr19
  163| 002DFC lfdux    7FCC34EE   1     LFDU      fp30,gr12=v1(gr12,gr6,0)
  166| 002E00 lfdux    7DBE34EE   1     LFDU      fp13,gr30=v1(gr30,gr6,0)
  160| 002E04 ld       EBBF03F0   1     L8        gr29=#SPILL179(gr31,1008)
  163| 002E08 fsub     FFFF6028   1     SFL       fp31=fp31,fp12,fcr
  166| 002E0C ld       EB9F03B0   1     L8        gr28=#SPILL152(gr31,944)
  166| 002E10 fsub     FD6B6028   1     SFL       fp11=fp11,fp12,fcr
    0| 002E14 mtspr    7E4903A6   1     LCTR      ctr=gr18
  163| 002E18 fsub     FFCCF028   1     SFL       fp30=fp12,fp30,fcr
  160| 002E1C stfdu    DC1D0008   2     STFDU     gr29,dv12[].rns21.(gr29,8)=fp0
  163| 002E20 fmul     FF6607F2   1     MFL       fp27=fp6,fp31,fcr
  163| 002E24 ld       EB1F03C0   1     L8        gr24=#SPILL151(gr31,960)
  166| 002E28 fsub     FDAC6828   1     SFL       fp13=fp12,fp13,fcr
  166| 002E2C ld       EB7F0398   1     L8        gr27=#SPILL154(gr31,920)
  166| 002E30 fmul     FFE902F2   1     MFL       fp31=fp9,fp11,fcr
  163| 002E34 ld       EB5F03A0   1     L8        gr26=#SPILL155(gr31,928)
  161| 002E38 ld       EB3F03F8   1     L8        gr25=#SPILL171(gr31,1016)
  166| 002E3C lfdu     CD7C0008   1     LFDU      fp11,gr28=g31ai(gr28,8)
    0| 002E40 bc       424000CC   1     BCF       ctr=CL.526,taken=0%(0,100)
  163| 002E44 fmadd    FD87DFBA   1     FMA       fp12=fp27,fp7,fp30,fcr
  160| 002E48 stfdu    DC1D0008   2     STFDU     gr29,dv12[].rns21.(gr29,8)=fp0
  166| 002E4C fmadd    FFCAFB7A   1     FMA       fp30=fp31,fp10,fp13,fcr
  163| 002E50 lfdu     CF580008   1     LFDU      fp26,gr24=g2ai(gr24,8)
  163| 002E54 lfdux    7FEA34EE   1     LFDU      fp31,gr10=v1(gr10,gr6,0)
  163| 002E58 lfdux    7DA934EE   1     LFDU      fp13,gr9=v1(gr9,gr6,0)
  163| 002E5C fmul     FF6C0072   1     MFL       fp27=fp12,fp1,fcr
  166| 002E60 lfdux    7D8B34EE   1     LFDU      fp12,gr11=v1(gr11,gr6,0)
  166| 002E64 fmul     FFBE0072   1     MFL       fp29=fp30,fp1,fcr
  161| 002E68 stfdu    DC190008   2     STFDU     gr25,dv13[].rns23.(gr25,8)=fp0
  163| 002E6C lfdux    7FCC34EE   1     LFDU      fp30,gr12=v1(gr12,gr6,0)
  166| 002E70 lfdux    7F9E34EE   1     LFDU      fp28,gr30=v1(gr30,gr6,0)
  163| 002E74 fmul     FF7B06B2   1     MFL       fp27=fp27,fp26,fcr
  163| 002E78 fsub     FFFF6828   2     SFL       fp31=fp31,fp13,fcr
  166| 002E7C fmul     FFBD02F2   2     MFL       fp29=fp29,fp11,fcr
  166| 002E80 lfdu     CD7C0008   1     LFDU      fp11,gr28=g31ai(gr28,8)
  166| 002E84 fsub     FD8C6828   1     SFL       fp12=fp12,fp13,fcr
  163| 002E88 fsub     FFCDF028   2     SFL       fp30=fp13,fp30,fcr
  166| 002E8C fsub     FDADE028   2     SFL       fp13=fp13,fp28,fcr
  163| 002E90 stfdu    DF7A0008   2     STFDU     gr26,dv21[].rns24.(gr26,8)=fp27
  166| 002E94 fmul     FF880772   1     MFL       fp28=fp8,fp29,fcr
  163| 002E98 fmul     FF6607F2   2     MFL       fp27=fp6,fp31,fcr
  166| 002E9C fmul     FFE90332   2     MFL       fp31=fp9,fp12,fcr
    0| 002EA0 bc       42400068   1     BCF       ctr=CL.527,taken=0%(0,100)
    0|                              CL.528:
  163| 002EA4 lfdux    7D8A34EE   1     LFDU      fp12,gr10=v1(gr10,gr6,0)
  166| 002EA8 fmadd    FFAAFB7A   1     FMA       fp29=fp31,fp10,fp13,fcr
  166| 002EAC stfdu    DF9B0008   2     STFDU     gr27,dv31[].rns26.(gr27,8)=fp28
  163| 002EB0 fmadd    FF67DFBA   1     FMA       fp27=fp27,fp7,fp30,fcr
  163| 002EB4 lfdux    7DA934EE   1     LFDU      fp13,gr9=v1(gr9,gr6,0)
  166| 002EB8 lfdux    7FEB34EE   1     LFDU      fp31,gr11=v1(gr11,gr6,0)
  163| 002EBC lfdux    7FCC34EE   1     LFDU      fp30,gr12=v1(gr12,gr6,0)
  166| 002EC0 fmul     FFBD0072   1     MFL       fp29=fp29,fp1,fcr
  163| 002EC4 lfdu     CF980008   1     LFDU      fp28,gr24=g2ai(gr24,8)
  163| 002EC8 fmul     FF7B0072   1     MFL       fp27=fp27,fp1,fcr
  166| 002ECC lfdux    7F5E34EE   1     LFDU      fp26,gr30=v1(gr30,gr6,0)
  163| 002ED0 fsub     FD8C6828   1     SFL       fp12=fp12,fp13,fcr
  166| 002ED4 fsub     FFFF6828   2     SFL       fp31=fp31,fp13,fcr
  166| 002ED8 fmul     FD7D02F2   2     MFL       fp11=fp29,fp11,fcr
  163| 002EDC fsub     FFCDF028   2     SFL       fp30=fp13,fp30,fcr
  163| 002EE0 fmul     FFBB0732   2     MFL       fp29=fp27,fp28,fcr
  161| 002EE4 stfdu    DC190008   2     STFDU     gr25,dv13[].rns23.(gr25,8)=fp0
  166| 002EE8 fsub     FDADD028   1     SFL       fp13=fp13,fp26,fcr
  166| 002EEC fmul     FFE907F2   2     MFL       fp31=fp9,fp31,fcr
  166| 002EF0 fmul     FF8802F2   2     MFL       fp28=fp8,fp11,fcr
  163| 002EF4 fmul     FF660332   2     MFL       fp27=fp6,fp12,fcr
  160| 002EF8 stfdu    DC1D0008   2     STFDU     gr29,dv12[].rns21.(gr29,8)=fp0
  163| 002EFC stfdu    DFBA0008   1     STFDU     gr26,dv21[].rns24.(gr26,8)=fp29
  166| 002F00 lfdu     CD7C0008   1     LFDU      fp11,gr28=g31ai(gr28,8)
    0| 002F04 bc       4200FFA0   1     BCT       ctr=CL.528,taken=100%(100,0)
    0|                              CL.527:
  166| 002F08 stfdu    DF9B0008   1     STFDU     gr27,dv31[].rns26.(gr27,8)=fp28
    0|                              CL.526:
  166| 002F0C fmadd    FCCAFB7A   1     FMA       fp6=fp31,fp10,fp13,fcr
  163| 002F10 lfdu     CD380008   1     LFDU      fp9,gr24=g2ai(gr24,8)
  163| 002F14 fmadd    FCE7DFBA   1     FMA       fp7=fp27,fp7,fp30,fcr
  161| 002F18 stfdu    DC190008   2     STFDU     gr25,dv13[].rns23.(gr25,8)=fp0
  166| 002F1C fmul     FCC60072   1     MFL       fp6=fp6,fp1,fcr
  163| 002F20 fmul     FCE70072   2     MFL       fp7=fp7,fp1,fcr
  166| 002F24 fmul     FCC602F2   2     MFL       fp6=fp6,fp11,fcr
  163| 002F28 fmul     FCE70272   2     MFL       fp7=fp7,fp9,fcr
  166| 002F2C fmul     FCC801B2   2     MFL       fp6=fp8,fp6,fcr
  163| 002F30 stfdu    DCFA0008   2     STFDU     gr26,dv21[].rns24.(gr26,8)=fp7
  166| 002F34 stfdu    DCDB0008   1     STFDU     gr27,dv31[].rns26.(gr27,8)=fp6
    0| 002F38 b        4BFFEA80   1     B         CL.74,-1
    0|                              CL.291:
  105| 002F3C bc       4085FE28   1     BF        CL.292,cr1,0x2/gt,taken=50%(0,0)
  153| 002F40 bc       409DF140   1     BF        CL.78,cr7,0x2/gt,taken=50%(0,0)
  155| 002F44 ld       E97F0120   1     L8        gr11=#SPILL116(gr31,288)
  155| 002F48 ld       E99F0340   1     L8        gr12=#SPILL12(gr31,832)
  155| 002F4C ld       EBDF0348   1     L8        gr30=#SPILL0(gr31,840)
  155| 002F50 ld       EB7F0350   1     L8        gr27=#SPILL43(gr31,848)
  163| 002F54 ld       EB5F0178   1     L8        gr26=#SPILL117(gr31,376)
  166| 002F58 ld       EB3F0180   1     L8        gr25=#SPILL118(gr31,384)
  166| 002F5C ld       EB1F0430   1     L8        gr24=#SPILL100(gr31,1072)
  155| 002F60 add      7FAB6214   1     A         gr29=gr11,gr12
  155| 002F64 add      7F9BF214   1     A         gr28=gr27,gr30
  155| 002F68 addi     395D0001   1     AI        gr10=gr29,1
  157| 002F6C addi     393C0001   1     AI        gr9=gr28,1
  163| 002F70 lfd      C8DA0008   1     LFL       fp6=dx2bi(gr26,8)
  163| 002F74 lfd      C8FA0000   1     LFL       fp7=dx2bi(gr26,0)
  166| 002F78 lfd      C9190000   1     LFL       fp8=g32bi(gr25,0)
  166| 002F7C lfd      C9380008   1     LFL       fp9=dx3bi(gr24,8)
  166| 002F80 lfd      C9580000   1     LFL       fp10=dx3bi(gr24,0)
   79| 002F84 b        4BFFE5E0   1     B         CL.298,-1
     |               Tag Table
     | 002F88        00000000 00012222 92120000 00002F88 1F
     |               Instruction count         3042
     |               Straight-line exec time   3553
     |               Constant Area
     | 000000        00000000 3F000000 3E800000 3F800000 2B617F7D 4ED8C33E
     | 000018        40000000 40C00000 40400000 49424D20 BFD55555 55555555
     | 000030        3FC00000 BF800000 BEA00000 3EC00000 BF000000

 
 
>>>>> COMPILATION UNIT EPILOGUE SECTION <<<<<
 
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    grdv.f90                    07/08/15   15:47:45
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
 
    Source records read.......................................     276
1501-510  Compilation successful for file grdv.f90.
1501-543  Object file created.
