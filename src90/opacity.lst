IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- opacity.f90 07/08/15 15:48:27
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** opacity   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-534 (I) Loop (loop index 1) at opacity.f90 <line 43> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 2) at opacity.f90 <line 44> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 3) at opacity.f90 <line 45> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 3) at opacity.f90 <line 46> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][1ll + (($$CIV9 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][1ll + (($$CIV9 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 3) at opacity.f90 <line 46> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 3) at opacity.f90 <line 46> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][($$CIV9 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][($$CIV9 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 3) at opacity.f90 <line 46> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 3) at opacity.f90 <line 46> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][3ll + (($$CIV9 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][3ll + (($$CIV9 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 3) at opacity.f90 <line 46> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 3) at opacity.f90 <line 46> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][2ll + (($$CIV9 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][2ll + (($$CIV9 * 4ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 3) at opacity.f90 <line 46> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 4) at opacity.f90 <line 50> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 5) at opacity.f90 <line 51> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 6) at opacity.f90 <line 52> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 58> was not SIMD vectorized because it contains operation in min( 1.0000000000000000E+002,kpfrac * ((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][1ll + (($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 58> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 55> was not SIMD vectorized because it contains operation in max(min_coef,((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][1ll + (($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 55> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 55> was not SIMD vectorized because it contains operation in max(min_coef,((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 55> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 57> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 53> was not SIMD vectorized because it contains operation in (( 1.0000000000000000E+000 / rmfp0) * (((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] / rho0 EXP   xnu)) * (((double *)((char *)d-t%addr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[].rns0.[($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] / t_0 EXP   - powr) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 53> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 58> was not SIMD vectorized because it contains operation in min( 1.0000000000000000E+002,kpfrac * ((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 58> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 59> was not SIMD vectorized because it contains operation in - ((powr * ((double *)((char *).kp  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kp[][($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *)d-t%addr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[].rns0.[($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 59> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 57> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 56> was not SIMD vectorized because it contains operation in min(max_coef,((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][1ll + (($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 56> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 59> was not SIMD vectorized because it contains operation in - ((powr * ((double *)((char *).kp  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kp[][1ll + (($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *)d-t%addr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[].rns0.[1ll + (($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 59> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 56> was not SIMD vectorized because it contains operation in min(max_coef,((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 56> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at opacity.f90 <line 53> was not SIMD vectorized because it contains operation in (( 1.0000000000000000E+000 / rmfp0) * (((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][1ll + (($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] / rho0 EXP   xnu)) * (((double *)((char *)d-t%addr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[].rns0.[1ll + (($$CIVA * 2ll + (1ll + ((long long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] / t_0 EXP   - powr) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 6) at opacity.f90 <line 53> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 7) at opacity.f90 <line 61> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 8) at opacity.f90 <line 62> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 9) at opacity.f90 <line 63> was not SIMD vectorized because it is not profitable to vectorize.
1586-554 (I) Loop (loop index 9) at opacity.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 9) at opacity.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 9) at opacity.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 9) at opacity.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 9) at opacity.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 9) at opacity.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 9) at opacity.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 9) at opacity.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 13) at opacity.f90 <line 61> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 14) at opacity.f90 <line 62> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 15) at opacity.f90 <line 63> was not SIMD vectorized because it is not profitable to vectorize.
1586-554 (I) Loop (loop index 15) at opacity.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 15) at opacity.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 19) at opacity.f90 <line 50> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 20) at opacity.f90 <line 51> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 21) at opacity.f90 <line 52> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 21) at opacity.f90 <line 56> was not SIMD vectorized because it contains operation in min(max_coef,((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 21) at opacity.f90 <line 56> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 21) at opacity.f90 <line 53> was not SIMD vectorized because it contains operation in (( 1.0000000000000000E+000 / rmfp0) * (((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] / rho0 EXP   xnu)) * (((double *)((char *)d-t%addr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[].rns0.[(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3] / t_0 EXP   - powr) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 21) at opacity.f90 <line 53> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 21) at opacity.f90 <line 59> was not SIMD vectorized because it contains operation in - ((powr * ((double *)((char *).kp  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kp[][(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double *)((char *)d-t%addr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->t[].rns0.[(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 21) at opacity.f90 <line 59> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 21) at opacity.f90 <line 55> was not SIMD vectorized because it contains operation in max(min_coef,((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 21) at opacity.f90 <line 55> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 21) at opacity.f90 <line 58> was not SIMD vectorized because it contains operation in min( 1.0000000000000000E+002,kpfrac * ((double *)((char *).kr  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->kr[][(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 21) at opacity.f90 <line 58> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 21) at opacity.f90 <line 57> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 25) at opacity.f90 <line 43> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 26) at opacity.f90 <line 44> was not SIMD vectorized because the loop is not the innermost loop.
1586-550 (I) Loop (loop index 27) at opacity.f90 <line 45> was not SIMD vectorized because it is not profitable to vectorize.
1586-537 (I) Loop (loop index 27) at opacity.f90 <line 46> was not SIMD vectorized because it contains operation in (((((.gam->gam -  1.0000000000000000E+000) * mmw) *  1.6605299201696573E-024) *  7.2429128189679120E+015) * ((double *)((char *).e  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->e[][(long long) .kbeg->kbeg + $$CIV2][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0]) / ((double *)((char *).d  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->d[][(long long) .kbeg->kbeg + $$CIV2][(long long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 27) at opacity.f90 <line 46> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"6">. Total number of the innermost loops SIMD vectorized <"0">.


     7|         SUBROUTINE opacity (e, d, gam, kr, kp, sg, dkpdt, km, dkedt, ibeg, iend, jbeg, jend, kbeg, kend)
     7|           d-t%addr = _alloca((8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(&
                &   jn)),0) * max(int(%VAL(in)),0)))))
                  _alloca((8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0)))))
                  _alloca((8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0)))))
                  _alloca((8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0)))))
                  _alloca((8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0)))))
                  _alloca((8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0)))))
    43|           IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV2 = 0
       Id=25        DO $$CIV2 = $$CIV2, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(4))-1
    44|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV1 = 0
       Id=26            DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    45|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV0 = 0
       Id=27                DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    46|                       d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,int(kbeg) + $$CIV2) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,int(kbeg) + $$CIV2)) / d(int(&
                &               ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(kbeg) + &
                &               $$CIV2)
    47|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    43|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                    $$CIV9 = int(0)
       Id=1         DO $$CIV9 = $$CIV9, int(((int(kend) - (MOD((1 + (int(kend)&
                &        - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    44|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    45|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    46|                       d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,($$CIV9 * 4 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 4)) + int(kbeg)) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,($$CIV9 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg))) / d(int(&
                &               ibeg) + $$CIV0,int(jbeg) + $$CIV1,($$CIV9 * 4 + &
                &               MOD((1 + (int(kend) - int(kbeg))), 4)) + int(kbeg)&
                &               )
                              d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,1 + (($$CIV9 * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,1 + (($$CIV9 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + ((&
                &               $$CIV9 * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
                              d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,2 + (($$CIV9 * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,2 + (($$CIV9 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + ((&
                &               $$CIV9 * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
                              d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,3 + (($$CIV9 * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,3 + (($$CIV9 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + ((&
                &               $$CIV9 * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
    47|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    50|           IF ((MOD((1 + (int(kend) - int(kbeg))), 2) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV5 = 0
       Id=19        DO $$CIV5 = $$CIV5, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(2))-1
    51|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV4 = 0
       Id=20            DO $$CIV4 = $$CIV4, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    52|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV3 = 0
       Id=21                DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    53|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) = (( 1.0000000000000000E+000 / rmfp0) &
                &               * (d(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(&
                &               kbeg) + $$CIV5) / rho0 ** xnu)) * (&
                &               d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,int(jbeg) + &
                &               $$CIV4,int(kbeg) + $$CIV5) / t_0 ** (-powr))
    55|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) = max(min_coef,kr(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,int(kbeg) + $$CIV5))
    56|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) = min(max_coef,kr(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,int(kbeg) + $$CIV5))
    57|                       sg(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) =  0.0000000000000000E+000
    58|                       kp(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) = min( 1.0000000000000000E+002,kpfrac &
                &               * kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(&
                &               kbeg) + $$CIV5))
    59|                       dkpdt(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(&
                &               kbeg) + $$CIV5) = -((powr * kp(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,int(kbeg) + $$CIV5)) / &
                &               d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,int(jbeg) + &
                &               $$CIV4,int(kbeg) + $$CIV5))
    60|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    50|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 2))) THEN
                    $$CIVA = int(0)
       Id=4         DO $$CIVA = $$CIVA, int(((int(kend) - (MOD((1 + (int(kend)&
                &        - int(kbeg))), 2) + int(kbeg))) / 2 + 1))-1
    51|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV4 = 0
       Id=5             DO $$CIV4 = $$CIV4, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    52|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV3 = 0
       Id=6                 DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    53|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = (( 1.0000000000000000E+000 / rmfp0) &
                &               * (d(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,(&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg)) / rho0 ** xnu)) * (&
                &               d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,int(jbeg) + &
                &               $$CIV4,($$CIVA * 2 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 2)) + int(kbeg)) / t_0 ** (-powr))
    55|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = max(min_coef,kr(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,($$CIVA * 2 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 2)) + int(kbeg)))
    56|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = min(max_coef,kr(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,($$CIVA * 2 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 2)) + int(kbeg)))
    57|                       sg(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) =  0.0000000000000000E+000
    58|                       kp(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = min( 1.0000000000000000E+002,kpfrac &
                &               * kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,(&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg)))
    59|                       dkpdt(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,(&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg)) = -((powr * kp(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,($$CIVA * 2 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 2)) + int(kbeg))) / &
                &               d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,int(jbeg) + &
                &               $$CIV4,($$CIVA * 2 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 2)) + int(kbeg)))
    53|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = (( 1.0000000000000000E+000 / &
                &               rmfp0) * (d(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,&
                &               1 + (($$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg)&
                &               )), 2)) + int(kbeg))) / rho0 ** xnu)) * (&
                &               d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,int(jbeg) + &
                &               $$CIV4,1 + (($$CIVA * 2 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 2)) + int(kbeg))) / t_0 ** (-powr))
    55|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = max(min_coef,kr(int(ibeg) + &
                &               $$CIV3,int(jbeg) + $$CIV4,1 + (($$CIVA * 2 + MOD((&
                &               1 + (int(kend) - int(kbeg))), 2)) + int(kbeg))))
    56|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = min(max_coef,kr(int(ibeg) + &
                &               $$CIV3,int(jbeg) + $$CIV4,1 + (($$CIVA * 2 + MOD((&
                &               1 + (int(kend) - int(kbeg))), 2)) + int(kbeg))))
    57|                       sg(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) =  0.0000000000000000E+000
    58|                       kp(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = min( 1.0000000000000000E+002,&
                &               kpfrac * kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,&
                &               1 + (($$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg)&
                &               )), 2)) + int(kbeg))))
    59|                       dkpdt(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = -((powr * kp(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,1 + (($$CIVA * 2 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 2)) + int(kbeg)))) / &
                &               d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,int(jbeg) + &
                &               $$CIV4,1 + (($$CIVA * 2 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 2)) + int(kbeg))))
    60|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    61|           IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV8 = 0
       Id=13        DO $$CIV8 = $$CIV8, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(4))-1
    62|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV7 = 0
       Id=14            DO $$CIV7 = $$CIV7, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    63|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV6 = 0
       Id=15                DO $$CIV6 = $$CIV6, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(kbeg)&
                &                + $$CIV8) = kp(int(ibeg) + $$CIV6,int(jbeg) + &
                &               $$CIV7,int(kbeg) + $$CIV8)
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &               kbeg) + $$CIV8) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,int(kbeg) + $$CIV8)
    66|                     ENDDO
                          ENDIF
    67|                 ENDDO
                      ENDIF
    68|             ENDDO
                  ENDIF
    61|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                    $$CIVB = int(0)
       Id=7         DO $$CIVB = $$CIVB, int(((int(kend) - (MOD((1 + (int(kend)&
                &        - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    62|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV7 = 0
       Id=8             DO $$CIV7 = $$CIV7, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    63|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV6 = 0
       Id=9                 DO $$CIV6 = $$CIV6, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,($$CIVB &
                &               * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + &
                &               int(kbeg)) = kp(int(ibeg) + $$CIV6,int(jbeg) + &
                &               $$CIV7,($$CIVB * 4 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 4)) + int(kbeg))
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,(&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,($$CIVB * 4 + MOD((1 + (int(kend) &
                &               - int(kbeg))), 4)) + int(kbeg))
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = kp(int(ibeg) + $$CIV6,int(jbeg) &
                &               + $$CIV7,1 + (($$CIVB * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg)))
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,1 + (($$CIVB * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = kp(int(ibeg) + $$CIV6,int(jbeg) &
                &               + $$CIV7,2 + (($$CIVB * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg)))
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,2 + (($$CIVB * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = kp(int(ibeg) + $$CIV6,int(jbeg) &
                &               + $$CIV7,3 + (($$CIVB * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg)))
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,3 + (($$CIVB * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    66|                     ENDDO
                          ENDIF
    67|                 ENDDO
                      ENDIF
    68|             ENDDO
                  ENDIF
    71|           RETURN
                END SUBROUTINE opacity


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0            43            25    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            44            26    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            45            27    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            46                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][(long long) 
                                          .kbeg->kbeg + $$CIV2][(long long) .jbeg->jbeg + 
                                          $$CIV1][(long long) .ibeg->ibeg + $$CIV0]) / ((double 
                                          *)((char *).d  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->d[][(long long) .kbeg->kbeg + 
                                          $$CIV2][(long long) .jbeg->jbeg + $$CIV1][(long long) 
                                          .ibeg->ibeg + $$CIV0] which is not  suitable for SIMD 
                                          vectorization.
         0            46                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            43             1    Outer loop has been unrolled 4 time(s).
         0            43             1    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            44             2    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            45             3    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            46                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][($$CIV9 * 4ll + (1ll 
                                          + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) .kbeg->kbeg][(long 
                                          long) .jbeg->jbeg + $$CIV1][(long long) .ibeg->ibeg + 
                                          $$CIV0]) / ((double *)((char *).d  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->d[][($$CIV9 * 4ll + (1ll + ((long long) 
                                          .kend->kend - (long long) .kbeg->kbeg)) % 4ll) + 
                                          (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is 
                                          not  suitable for SIMD vectorization.
         0            46                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            46                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][1ll + (($$CIV9 * 4ll 
                                          + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long 
                                          long) .ibeg->ibeg + $$CIV0]) / ((double *)((char *).d 
                                          + -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->d[][1ll + (($$CIV9 * 4ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) 
                                          + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + 
                                          $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is 
                                          not  suitable for SIMD vectorization.
         0            46                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            46                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][2ll + (($$CIV9 * 4ll 
                                          + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long 
                                          long) .ibeg->ibeg + $$CIV0]) / ((double *)((char *).d 
                                          + -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->d[][2ll + (($$CIV9 * 4ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) 
                                          + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + 
                                          $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is 
                                          not  suitable for SIMD vectorization.
         0            46                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            46                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((.gam->gam -  
                                          1.0000000000000000E+000) * mmw) *  
                                          1.6605299201696573E-024) *  7.2429128189679120E+015) 
                                          * ((double *)((char *).e  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->e[][3ll + (($$CIV9 * 4ll 
                                          + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 4ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV1][(long 
                                          long) .ibeg->ibeg + $$CIV0]) / ((double *)((char *).d 
                                          + -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->d[][3ll + (($$CIV9 * 4ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 4ll) 
                                          + (long long) .kbeg->kbeg)][(long long) .jbeg->jbeg + 
                                          $$CIV1][(long long) .ibeg->ibeg + $$CIV0] which is 
                                          not  suitable for SIMD vectorization.
         0            46                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            50            19    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            51            20    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            52            21    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            53                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 1.0000000000000000E+000 / rmfp0) * 
                                          (((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][(long long) 
                                          .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3] / rho0 EXP  
                                          xnu)) * (((double *)((char *)d-t%addr  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->t[].rns0.[(long long) .kbeg->kbeg + 
                                          $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) 
                                          .ibeg->ibeg + $$CIV3] / t_0 EXP   - powr) which is 
                                          not  suitable for SIMD vectorization.
         0            53                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            55                  Loop was not SIMD vectorized because it contains 
                                          operation in max(min_coef,((double *)((char *).kr  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kr[][(long long) .kbeg->kbeg + 
                                          $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) 
                                          .ibeg->ibeg + $$CIV3]) which is not  suitable for 
                                          SIMD vectorization.
         0            55                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            56                  Loop was not SIMD vectorized because it contains 
                                          operation in min(max_coef,((double *)((char *).kr  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kr[][(long long) .kbeg->kbeg + 
                                          $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) 
                                          .ibeg->ibeg + $$CIV3]) which is not  suitable for 
                                          SIMD vectorization.
         0            56                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            57                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            58                  Loop was not SIMD vectorized because it contains 
                                          operation in min( 1.0000000000000000E+002,kpfrac * 
                                          ((double *)((char *).kr  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->kr[][(long long) 
                                          .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is 
                                          not  suitable for SIMD vectorization.
         0            58                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            59                  Loop was not SIMD vectorized because it contains 
                                          operation in - ((powr * ((double *)((char *).kp  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kp[][(long long) .kbeg->kbeg + 
                                          $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) 
                                          .ibeg->ibeg + $$CIV3]) / ((double *)((char *)d-t%addr 
                                          + -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->t[].rns0.[(long long) .kbeg->kbeg + 
                                          $$CIV5][(long long) .jbeg->jbeg + $$CIV4][(long long) 
                                          .ibeg->ibeg + $$CIV3]) which is not  suitable for 
                                          SIMD vectorization.
         0            59                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            50             4    Outer loop has been unrolled 2 time(s).
         0            50             4    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            51             5    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            52             6    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            53                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 1.0000000000000000E+000 / rmfp0) * 
                                          (((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][($$CIVA * 2ll + (1ll 
                                          + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long 
                                          long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3] / rho0 EXP   xnu)) * (((double *)((char 
                                          *)d-t%addr  + -8ll - (max((long long) in,0ll) * 8ll + 
                                          8ll * (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->t[].rns0.[($$CIVA * 2ll + (1ll + ((long 
                                          long) .kend->kend - (long long) .kbeg->kbeg)) % 2ll) 
                                          + (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3] / t_0 EXP   
                                          - powr) which is not  suitable for SIMD vectorization.
         0            53                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            55                  Loop was not SIMD vectorized because it contains 
                                          operation in max(min_coef,((double *)((char *).kr  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kr[][($$CIVA * 2ll + (1ll + ((long long) 
                                          .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + 
                                          (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is 
                                          not  suitable for SIMD vectorization.
         0            55                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            56                  Loop was not SIMD vectorized because it contains 
                                          operation in min(max_coef,((double *)((char *).kr  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kr[][($$CIVA * 2ll + (1ll + ((long long) 
                                          .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + 
                                          (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) which is 
                                          not  suitable for SIMD vectorization.
         0            56                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            57                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            58                  Loop was not SIMD vectorized because it contains 
                                          operation in min( 1.0000000000000000E+002,kpfrac * 
                                          ((double *)((char *).kr  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->kr[][($$CIVA * 2ll + 
                                          (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long 
                                          long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3]) which is not  suitable for SIMD 
                                          vectorization.
         0            58                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            59                  Loop was not SIMD vectorized because it contains 
                                          operation in - ((powr * ((double *)((char *).kp  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kp[][($$CIVA * 2ll + (1ll + ((long long) 
                                          .kend->kend - (long long) .kbeg->kbeg)) % 2ll) + 
                                          (long long) .kbeg->kbeg][(long long) .jbeg->jbeg + 
                                          $$CIV4][(long long) .ibeg->ibeg + $$CIV3]) / ((double 
                                          *)((char *)d-t%addr  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->t[].rns0.[($$CIVA * 2ll 
                                          + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 2ll) + (long long) .kbeg->kbeg][(long 
                                          long) .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3]) which is not  suitable for SIMD 
                                          vectorization.
         0            59                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            53                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 1.0000000000000000E+000 / rmfp0) * 
                                          (((double *)((char *).d  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->d[][1ll + (($$CIVA * 2ll 
                                          + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 2ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3] / rho0 EXP   xnu)) * 
                                          (((double *)((char *)d-t%addr  + -8ll - (max((long 
                                          long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) 
                                          * max((long long) in,0ll)))))->t[].rns0.[1ll + 
                                          (($$CIVA * 2ll + (1ll + ((long long) .kend->kend - 
                                          (long long) .kbeg->kbeg)) % 2ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3] / t_0 EXP   - powr) which 
                                          is not  suitable for SIMD vectorization.
         0            53                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            55                  Loop was not SIMD vectorized because it contains 
                                          operation in max(min_coef,((double *)((char *).kr  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kr[][1ll + (($$CIVA * 2ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 2ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3]) which is not  suitable for SIMD 
                                          vectorization.
         0            55                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            56                  Loop was not SIMD vectorized because it contains 
                                          operation in min(max_coef,((double *)((char *).kr  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kr[][1ll + (($$CIVA * 2ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 2ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3]) which is not  suitable for SIMD 
                                          vectorization.
         0            56                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            57                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            58                  Loop was not SIMD vectorized because it contains 
                                          operation in min( 1.0000000000000000E+002,kpfrac * 
                                          ((double *)((char *).kr  + -8ll - (max((long long) 
                                          in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * 
                                          max((long long) in,0ll)))))->kr[][1ll + (($$CIVA * 
                                          2ll + (1ll + ((long long) .kend->kend - (long long) 
                                          .kbeg->kbeg)) % 2ll) + (long long) 
                                          .kbeg->kbeg)][(long long) .jbeg->jbeg + $$CIV4][(long 
                                          long) .ibeg->ibeg + $$CIV3]) which is not  suitable 
                                          for SIMD vectorization.
         0            58                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            59                  Loop was not SIMD vectorized because it contains 
                                          operation in - ((powr * ((double *)((char *).kp  + 
                                          -8ll - (max((long long) in,0ll) * 8ll + 8ll * 
                                          (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->kp[][1ll + (($$CIVA * 2ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 2ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3]) / ((double *)((char *)d-t%addr  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->t[].rns0.[1ll + (($$CIVA * 2ll + (1ll + 
                                          ((long long) .kend->kend - (long long) .kbeg->kbeg)) 
                                          % 2ll) + (long long) .kbeg->kbeg)][(long long) 
                                          .jbeg->jbeg + $$CIV4][(long long) .ibeg->ibeg + 
                                          $$CIV3]) which is not  suitable for SIMD 
                                          vectorization.
         0            59                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            61            13    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            62            14    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            63            15    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            61             7    Outer loop has been unrolled 4 time(s).
         0            61             7    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            62             8    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            63             9    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.


     7|         SUBROUTINE opacity (e, d, gam, kr, kp, sg, dkpdt, km, dkedt, ibeg, iend, jbeg, jend, kbeg, kend)
    46|           d-t%addr = _alloca(8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(&
                &   jn)),0) * max(int(%VAL(in)),0))))
                  _alloca(8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0))))
                  _alloca(8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0))))
                  _alloca(8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0))))
                  _alloca(8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0))))
                  _alloca(8 * (max(int(%VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &   max(int(%VAL(in)),0))))
    43|           IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV2 = 0
       Id=25        DO $$CIV2 = $$CIV2, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(4))-1
    44|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV1 = 0
       Id=26            DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    45|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV0 = 0
       Id=27                DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    46|                       d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,int(kbeg) + $$CIV2) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,int(kbeg) + $$CIV2)) / d(int(&
                &               ibeg) + $$CIV0,int(jbeg) + $$CIV1,int(kbeg) + &
                &               $$CIV2)
    47|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    43|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                    $$CIV9 = int(0)
       Id=1         DO $$CIV9 = $$CIV9, int(((int(kend) - (MOD((1 + (int(kend)&
                &        - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    44|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    45|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    46|                       d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,($$CIV9 * 4 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 4)) + int(kbeg)) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,($$CIV9 * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg))) / d(int(&
                &               ibeg) + $$CIV0,int(jbeg) + $$CIV1,($$CIV9 * 4 + &
                &               MOD((1 + (int(kend) - int(kbeg))), 4)) + int(kbeg)&
                &               )
                              d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,1 + (($$CIV9 * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,1 + (($$CIV9 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,1 + ((&
                &               $$CIV9 * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
                              d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,2 + (($$CIV9 * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,2 + (($$CIV9 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,2 + ((&
                &               $$CIV9 * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
                              d-t%addr%t[].rns0.(int(ibeg) + $$CIV0,int(jbeg) + &
                &               $$CIV1,3 + (($$CIV9 * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg))) = (((((gam -  &
                &               1.0000000000000000E+000) * mmw) *  &
                &               1.6605299201696573E-024) *  &
                &               7.2429128189679120E+015) * e(int(ibeg) + $$CIV0,&
                &               int(jbeg) + $$CIV1,3 + (($$CIV9 * 4 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 4)) + int(kbeg)))) / d(&
                &               int(ibeg) + $$CIV0,int(jbeg) + $$CIV1,3 + ((&
                &               $$CIV9 * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)))
    47|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    50|           IF ((MOD((1 + (int(kend) - int(kbeg))), 2) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV5 = 0
       Id=19        DO $$CIV5 = $$CIV5, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(2))-1
    51|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV4 = 0
       Id=20            DO $$CIV4 = $$CIV4, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    52|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV3 = 0
       Id=21                DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    53|                       $$csx0 = (( 1.0000000000000000E+000 / rmfp0) * (d(&
                &               int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg) + &
                &               $$CIV5) / rho0 ** xnu)) * (d-t%addr%t[].rns0.(int(&
                &               ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg) + &
                &               $$CIV5) / t_0 ** (-powr))
                              kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) = $$csx0
    55|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) = max(min_coef,$$csx0)
    56|                       $$csx1 = min(max_coef,kr(int(ibeg) + $$CIV3,int(&
                &               jbeg) + $$CIV4,int(kbeg) + $$CIV5))
                              kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) = $$csx1
    57|                       sg(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) =  0.0000000000000000E+000
    58|                       kp(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(kbeg)&
                &                + $$CIV5) = min( 1.0000000000000000E+002,kpfrac &
                &               * $$csx1)
    59|                       dkpdt(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,int(&
                &               kbeg) + $$CIV5) = -((powr * kp(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,int(kbeg) + $$CIV5)) / &
                &               d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,int(jbeg) + &
                &               $$CIV4,int(kbeg) + $$CIV5))
    60|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    50|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 2))) THEN
                    $$CIVA = int(0)
       Id=4         DO $$CIVA = $$CIVA, int(((int(kend) - (MOD((1 + (int(kend)&
                &        - int(kbeg))), 2) + int(kbeg))) / 2 + 1))-1
    51|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV4 = 0
       Id=5             DO $$CIV4 = $$CIV4, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    52|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV3 = 0
       Id=6                 DO $$CIV3 = $$CIV3, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    53|                       $$csx2 = (( 1.0000000000000000E+000 / rmfp0) * (d(&
                &               int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA * 2 &
                &               + MOD((1 + (int(kend) - int(kbeg))), 2)) + int(&
                &               kbeg)) / rho0 ** xnu)) * (d-t%addr%t[].rns0.(int(&
                &               ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA * 2 + &
                &               MOD((1 + (int(kend) - int(kbeg))), 2)) + int(kbeg)&
                &               ) / t_0 ** (-powr))
                              kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = $$csx2
    55|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = max(min_coef,$$csx2)
    56|                       $$csx3 = min(max_coef,kr(int(ibeg) + $$CIV3,int(&
                &               jbeg) + $$CIV4,($$CIVA * 2 + MOD((1 + (int(kend) &
                &               - int(kbeg))), 2)) + int(kbeg)))
                              kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = $$csx3
    57|                       sg(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) =  0.0000000000000000E+000
    58|                       kp(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,($$CIVA &
                &               * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)) + &
                &               int(kbeg)) = min( 1.0000000000000000E+002,kpfrac &
                &               * $$csx3)
    59|                       dkpdt(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,(&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg)) = -((powr * kp(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,($$CIVA * 2 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 2)) + int(kbeg))) / &
                &               d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,int(jbeg) + &
                &               $$CIV4,($$CIVA * 2 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 2)) + int(kbeg)))
    53|                       $$csx4 = d-t%addr%t[].rns0.(int(ibeg) + $$CIV3,&
                &               int(jbeg) + $$CIV4,1 + (($$CIVA * 2 + MOD((1 + (&
                &               int(kend) - int(kbeg))), 2)) + int(kbeg)))
                              kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = (( 1.0000000000000000E+000 / &
                &               rmfp0) * (d(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,&
                &               1 + (($$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg)&
                &               )), 2)) + int(kbeg))) / rho0 ** xnu)) * ($$csx4 / &
                &               t_0 ** (-powr))
    55|                       $$csx5 = max(min_coef,kr(int(ibeg) + $$CIV3,int(&
                &               jbeg) + $$CIV4,1 + (($$CIVA * 2 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 2)) + int(kbeg))))
                              kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = $$csx5
    56|                       kr(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = min(max_coef,$$csx5)
    57|                       sg(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) =  0.0000000000000000E+000
    58|                       $$csx6 = min( 1.0000000000000000E+002,kpfrac * kr(&
                &               int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))))
                              kp(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = $$csx6
    59|                       dkpdt(int(ibeg) + $$CIV3,int(jbeg) + $$CIV4,1 + ((&
                &               $$CIVA * 2 + MOD((1 + (int(kend) - int(kbeg))), 2)&
                &               ) + int(kbeg))) = -((powr * $$csx6) / $$csx4)
    60|                     ENDDO
                          ENDIF
                        ENDDO
                      ENDIF
                    ENDDO
                  ENDIF
    61|           IF ((MOD((1 + (int(kend) - int(kbeg))), 4) > 0  .AND.  1 + (&
                &   int(kend) - int(kbeg)) > 0)) THEN
                    $$CIV8 = 0
       Id=13        DO $$CIV8 = $$CIV8, MOD((1 + (int(kend) - int(kbeg))), &
                &       int(4))-1
    62|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV7 = 0
       Id=14            DO $$CIV7 = $$CIV7, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    63|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV6 = 0
       Id=15                DO $$CIV6 = $$CIV6, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(kbeg)&
                &                + $$CIV8) = kp(int(ibeg) + $$CIV6,int(jbeg) + &
                &               $$CIV7,int(kbeg) + $$CIV8)
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,int(&
                &               kbeg) + $$CIV8) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,int(kbeg) + $$CIV8)
    66|                     ENDDO
                          ENDIF
    67|                 ENDDO
                      ENDIF
    68|             ENDDO
                  ENDIF
    61|           IF ((1 + (int(kend) - int(kbeg)) > 0  .AND.  1 + (int(kend) - &
                &   int(kbeg)) > MOD((1 + (int(kend) - int(kbeg))), 4))) THEN
                    $$CIVB = int(0)
       Id=7         DO $$CIVB = $$CIVB, int(((int(kend) - (MOD((1 + (int(kend)&
                &        - int(kbeg))), 4) + int(kbeg))) / 4 + 1))-1
    62|               IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                        $$CIV7 = 0
       Id=8             DO $$CIV7 = $$CIV7, int((1 + (int(jend) - int(jbeg))))&
                &           -1
    63|                   IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                            $$CIV6 = 0
       Id=9                 DO $$CIV6 = $$CIV6, int((1 + (int(iend) - int(&
                &               ibeg))))-1
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,($$CIVB &
                &               * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)) + &
                &               int(kbeg)) = kp(int(ibeg) + $$CIV6,int(jbeg) + &
                &               $$CIV7,($$CIVB * 4 + MOD((1 + (int(kend) - int(&
                &               kbeg))), 4)) + int(kbeg))
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,(&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg)) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,($$CIVB * 4 + MOD((1 + (int(kend) &
                &               - int(kbeg))), 4)) + int(kbeg))
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = kp(int(ibeg) + $$CIV6,int(jbeg) &
                &               + $$CIV7,1 + (($$CIVB * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg)))
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,1 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,1 + (($$CIVB * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = kp(int(ibeg) + $$CIV6,int(jbeg) &
                &               + $$CIV7,2 + (($$CIVB * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg)))
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,2 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,2 + (($$CIVB * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    64|                       km(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = kp(int(ibeg) + $$CIV6,int(jbeg) &
                &               + $$CIV7,3 + (($$CIVB * 4 + MOD((1 + (int(kend) - &
                &               int(kbeg))), 4)) + int(kbeg)))
    65|                       dkedt(int(ibeg) + $$CIV6,int(jbeg) + $$CIV7,3 + ((&
                &               $$CIVB * 4 + MOD((1 + (int(kend) - int(kbeg))), 4)&
                &               ) + int(kbeg))) = dkpdt(int(ibeg) + $$CIV6,int(&
                &               jbeg) + $$CIV7,3 + (($$CIVB * 4 + MOD((1 + (int(&
                &               kend) - int(kbeg))), 4)) + int(kbeg)))
    66|                     ENDDO
                          ENDIF
    67|                 ENDDO
                      ENDIF
    68|             ENDDO
                  ENDIF
    71|           RETURN
                END SUBROUTINE opacity

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   ssus ssss ssss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ssss  ssss ssss ssss ssss
 CCR's set/used:   ssss ssss
     | 000000                           PDEF     opacity
    7|                                  PROC      .e,.d,.gam,.kr,.kp,.sg,.dkpdt,.km,.dkedt,.ibeg,.iend,.jbeg,.jend,.kbeg,.kend,gr3-gr10
    0| 000000 stfd     DBE1FFF8   1     STFL      #stack(gr1,-8)=fp31
    0| 000004 stfd     DBC1FFF0   1     STFL      #stack(gr1,-16)=fp30
    0| 000008 stfd     DBA1FFE8   1     STFL      #stack(gr1,-24)=fp29
    0| 00000C stfd     DB81FFE0   1     STFL      #stack(gr1,-32)=fp28
    0| 000010 stfd     DB61FFD8   1     STFL      #stack(gr1,-40)=fp27
    0| 000014 stfd     DB41FFD0   1     STFL      #stack(gr1,-48)=fp26
    0| 000018 stfd     DB21FFC8   1     STFL      #stack(gr1,-56)=fp25
    0| 00001C stfd     DB01FFC0   1     STFL      #stack(gr1,-64)=fp24
    0| 000020 stfd     DAE1FFB8   1     STFL      #stack(gr1,-72)=fp23
    0| 000024 stfd     DAC1FFB0   1     STFL      #stack(gr1,-80)=fp22
    0| 000028 stfd     DAA1FFA8   1     STFL      #stack(gr1,-88)=fp21
    0| 00002C stfd     DA81FFA0   1     STFL      #stack(gr1,-96)=fp20
    0| 000030 stfd     DA61FF98   1     STFL      #stack(gr1,-104)=fp19
    0| 000034 stfd     DA41FF90   1     STFL      #stack(gr1,-112)=fp18
    0| 000038 stfd     DA21FF88   1     STFL      #stack(gr1,-120)=fp17
    0| 00003C stfd     DA01FF80   1     STFL      #stack(gr1,-128)=fp16
    0| 000040 stfd     D9E1FF78   1     STFL      #stack(gr1,-136)=fp15
    0| 000044 stfd     D9C1FF70   1     STFL      #stack(gr1,-144)=fp14
    0| 000048 std      FBE1FF68   1     ST8       #stack(gr1,-152)=gr31
    0| 00004C std      FBC1FF60   1     ST8       #stack(gr1,-160)=gr30
    0| 000050 std      FBA1FF58   1     ST8       #stack(gr1,-168)=gr29
    0| 000054 std      FB81FF50   1     ST8       #stack(gr1,-176)=gr28
    0| 000058 std      FB61FF48   1     ST8       #stack(gr1,-184)=gr27
    0| 00005C std      FB41FF40   1     ST8       #stack(gr1,-192)=gr26
    0| 000060 std      FB21FF38   1     ST8       #stack(gr1,-200)=gr25
    0| 000064 std      FB01FF30   1     ST8       #stack(gr1,-208)=gr24
    0| 000068 std      FAE1FF28   1     ST8       #stack(gr1,-216)=gr23
    0| 00006C std      FAC1FF20   1     ST8       #stack(gr1,-224)=gr22
    0| 000070 std      FAA1FF18   1     ST8       #stack(gr1,-232)=gr21
    0| 000074 std      FA81FF10   1     ST8       #stack(gr1,-240)=gr20
    0| 000078 std      FA61FF08   1     ST8       #stack(gr1,-248)=gr19
    0| 00007C std      FA41FF00   1     ST8       #stack(gr1,-256)=gr18
    0| 000080 std      FA21FEF8   1     ST8       #stack(gr1,-264)=gr17
    0| 000084 std      FA01FEF0   1     ST8       #stack(gr1,-272)=gr16
    0| 000088 std      F9E1FEE8   1     ST8       #stack(gr1,-280)=gr15
    0| 00008C std      F9C1FEE0   1     ST8       #stack(gr1,-288)=gr14
    0| 000090 mfspr    7C0802A6   1     LFLR      gr0=lr
    0| 000094 mfcr     7D800026   1     LFCR      gr12=cr[234],2
    0| 000098 stw      91810008   1     ST4A      #stack(gr1,8)=gr12
    0| 00009C std      F8010010   1     ST8       #stack(gr1,16)=gr0
    0| 0000A0 stdu     F821FD01   1     ST8U      gr1,#stack(gr1,-768)=gr1
    0| 0000A4 or       7C3F0B78   1     LR        gr31=gr1
   39| 0000A8 lfd      C9050000   1     LFL       fp8=gam(gr5,0)
    0| 0000AC std      F89F0148   1     ST8       #SPILL24(gr31,328)=gr4
   47| 0000B0 ld       E9620000   1     L8        gr11=.&&N&&opac_law(gr2,0)
   47| 0000B4 ld       EB220000   1     L8        gr25=.+CONSTANT_AREA(gr2,0)
    0| 0000B8 std      F8DF0128   1     ST8       #SPILL20(gr31,296)=gr6
    0| 0000BC ld       EBC20000   1     L8        gr30=.&&N&&param(gr2,0)
   42| 0000C0 ld       EB9F0398   1     L8        gr28=.kbeg(gr31,920)
   42| 0000C4 ld       EBBF03A0   1     L8        gr29=.kend(gr31,928)
   39| 0000C8 stfd     D91F00F0   1     STFL      #SPILL13(gr31,240)=fp8
   47| 0000CC lfd      C84B0028   1     LFL       fp2=<s118:d40:l8>(gr11,40)
   47| 0000D0 lfs      C3F90000   1     LFS       fp31=+CONSTANT_AREA(gr25,0)
    0| 0000D4 lwa      E99E0002   1     L4A       gr12=<s24:d0:l4>(gr30,0)
   53| 0000D8 lfd      C8AB0040   1     LFL       fp5=<s118:d64:l8>(gr11,64)
   53| 0000DC lfd      C8CB0048   1     LFL       fp6=<s118:d72:l8>(gr11,72)
   53| 0000E0 lfd      C8EB0038   1     LFL       fp7=<s118:d56:l8>(gr11,56)
    0| 0000E4 std      F8FF00B8   1     ST8       #SPILL6(gr31,184)=gr7
   47| 0000E8 qvfre    10001030   1     QVFRE     fp0=fp2
    0| 0000EC std      F91F0138   1     ST8       #SPILL22(gr31,312)=gr8
    0| 0000F0 lwa      EB5E0006   1     L4A       gr26=<s24:d4:l4>(gr30,4)
   42| 0000F4 lwa      EB1C0002   1     L4A       gr24=kbeg(gr28,0)
   46| 0000F8 sradi    7D9CFE76   1     SRA8      gr28=gr12,63,ca"
    0| 0000FC std      F93F00C0   1     ST8       #SPILL7(gr31,192)=gr9
   47| 000100 fmsub    FC22F838   1     FMS       fp1=fp31,fp2,fp0,fcr
   46| 000104 andc     7D96E078   1     ANDC      gr22=gr12,gr28
   46| 000108 sradi    7F5BFE76   1     SRA8      gr27=gr26,63,ca"
   46| 00010C lwa      EBDE000A   1     L4A       gr30=<s24:d8:l4>(gr30,8)
   46| 000110 std      FADF0098   1     ST8       #SPILL2(gr31,152)=gr22
   46| 000114 andc     7F57D878   1     ANDC      gr23=gr26,gr27
   47| 000118 fnmsub   FC00007C   1     FNMS      fp0=fp0,fp0,fp1,fcr
   42| 00011C lwa      EBBD0002   1     L4A       gr29=kend(gr29,0)
   46| 000120 mulld    7D96B9D2   1     M         gr12=gr22,gr23
   47| 000124 fmsub    FC22F838   1     FMS       fp1=fp31,fp2,fp0,fcr
    0| 000128 std      F95F00C8   1     ST8       #SPILL8(gr31,200)=gr10
   46| 00012C sradi    7FDCFE76   1     SRA8      gr28=gr30,63,ca"
   42| 000130 subf     7FB8E850   1     S         gr29=gr29,gr24
   46| 000134 andc     7FDEE078   1     ANDC      gr30=gr30,gr28
   53| 000138 stfd     D8BF00D8   1     STFL      #SPILL10(gr31,216)=fp5
   47| 00013C fnmsub   FC00007C   1     FNMS      fp0=fp0,fp0,fp1,fcr
   42| 000140 addi     3ABD0001   1     AI        gr21=gr29,1
   46| 000144 mulld    7FCCF1D2   1     M         gr30=gr12,gr30
   47| 000148 fmsub    FC22F838   1     FMS       fp1=fp31,fp2,fp0,fcr
   53| 00014C stfd     D8DF00E0   1     STFL      #SPILL11(gr31,224)=fp6
   42| 000150 sradi    7EAC1674   1     SRA8CA    gr12,ca=gr21,2
   46| 000154 rldicr   7BDE1F24   1     SLL8      gr30=gr30,3
   42| 000158 addze    7D8C0194   1     ADDE      gr12,ca=gr12,0,ca
   46| 00015C ld       E8010000   1     L8        gr0=#stack(gr1,0)
   47| 000160 fnmsub   FC60007C   1     FNMS      fp3=fp0,fp0,fp1,fcr
   53| 000164 stfd     D8FF00E8   1     STFL      #SPILL12(gr31,232)=fp7
   43| 000168 rldicr   79941764   1     SLL8      gr20=gr12,2
   46| 00016C ld       E9820000   1     L8        gr12=.&&N&&cons(gr2,0)
   46| 000170 neg      7FDE00D0   1     COMP      gr30=gr30
   43| 000174 subf     7E74A851   1     S_R       gr19,cr0=gr21,gr20
   46| 000178 rldicr   7BDE06A4   1     RN8       gr30=gr30,0,0xFFFFFFFFFFFFFFE0
   47| 00017C stfd     D87F00B0   1     STFL      #SPILL5(gr31,176)=fp3
   46| 000180 stdux    7C01F16A   1     ST8U      gr1,#stack(gr1,gr30,0)=gr0
   46| 000184 lfd      C88C0008   1     LFL       fp4=<s115:d8:l8>(gr12,8)
   43| 000188 cmpdi    2CB50000   1     C8        cr1=gr21,0
   46| 00018C addi     3A410080   1     AI        gr18=gr1,128
   43| 000190 crand    4E012A02   1     CR_N      cr4=cr[01],0x1/lt,0x2/gt,0x2/gt,cr4
   47| 000194 std      FB3F0178   1     ST8       #SPILL30(gr31,376)=gr25
   42| 000198 std      FB1F0088   1     ST8       #SPILL0(gr31,136)=gr24
   46| 00019C std      FAFF0090   1     ST8       #SPILL1(gr31,144)=gr23
   42| 0001A0 std      FABF01B0   1     ST8       #SPILL37(gr31,432)=gr21
   43| 0001A4 std      FA9F00A0   1     ST8       #SPILL3(gr31,160)=gr20
   43| 0001A8 std      FA7F00A8   1     ST8       #SPILL4(gr31,168)=gr19
   46| 0001AC stfd     D89F00D0   1     STFL      #SPILL9(gr31,208)=fp4
   53| 0001B0 lfd      CBCB0030   1     LFL       fp30=<s118:d48:l8>(gr11,48)
   55| 0001B4 lfd      CBAB0008   1     LFL       fp29=<s118:d8:l8>(gr11,8)
   56| 0001B8 lfd      CB8B0010   1     LFL       fp28=<s118:d16:l8>(gr11,16)
   58| 0001BC lfd      CB6B0000   1     LFL       fp27=<s118:d0:l8>(gr11,0)
   46| 0001C0 std      FA5F0118   1     ST8       #SPILL18(gr31,280)=gr18
   43| 0001C4 bc       40900120   1     BF        CL.102,cr4,0x1/lt,taken=50%(0,0)
   43| 0001C8 ld       E8BF0388   1     L8        gr5=.jbeg(gr31,904)
   43| 0001CC ld       E8DF0390   1     L8        gr6=.jend(gr31,912)
   43| 0001D0 addi     38800000   1     LI        gr4=0
   43| 0001D4 lwa      E8A50002   1     L4A       gr5=jbeg(gr5,0)
   43| 0001D8 lwa      E8060002   1     L4A       gr0=jend(gr6,0)
   43| 0001DC subf     7CC50050   1     S         gr6=gr0,gr5
   43| 0001E0 addic.   34060001   1     AI_R      gr0,cr0=gr6,1,ca"
    0| 0001E4 bc       40811624   1     BF        CL.301,cr0,0x2/gt,taken=50%(0,0)
    0| 0001E8 rldicr   7AE71F24   1     SLL8      gr7=gr23,3
    0| 0001EC rldicr   7AC91F24   1     SLL8      gr9=gr22,3
    0| 0001F0 mulld    7D47B1D2   1     M         gr10=gr7,gr22
    0| 0001F4 ld       E97F0378   1     L8        gr11=.ibeg(gr31,888)
    0| 0001F8 ld       E8DF0380   1     L8        gr6=.iend(gr31,896)
    0| 0001FC neg      7D0700D0   1     COMP      gr8=gr7
    0| 000200 mulld    7CA549D2   1     M         gr5=gr5,gr9
    0| 000204 mulld    7CEAC1D2   1     M         gr7=gr10,gr24
    0| 000208 lwa      E96B0002   1     L4A       gr11=ibeg(gr11,0)
    0| 00020C lwa      E9860002   1     L4A       gr12=iend(gr6,0)
    0| 000210 mulld    7D08B1D2   1     M         gr8=gr8,gr22
    0| 000214 addi     38C5FFF0   1     AI        gr6=gr5,-16
    0| 000218 subf     7CE93850   1     S         gr7=gr7,gr9
    0| 00021C subf     7CAB6050   1     S         gr5=gr12,gr11
    0| 000220 ld       EB7F0148   1     L8        gr27=#SPILL24(gr31,328)
    0| 000224 add      7CC63A14   1     A         gr6=gr6,gr7
    0| 000228 addic.   34A50001   1     AI_R      gr5,cr0=gr5,1,ca"
    0| 00022C add      7CA64214   1     A         gr5=gr6,gr8
    0| 000230 lfs      C0190004   1     LFS       fp0=+CONSTANT_AREA(gr25,4)
    0| 000234 add      7FC32A14   1     A         gr30=gr3,gr5
    0| 000238 add      7FA5DA14   1     A         gr29=gr5,gr27
    0| 00023C add      7F859214   1     A         gr28=gr5,gr18
    0| 000240 lfs      C0390008   1     LFS       fp1=+CONSTANT_AREA(gr25,8)
    0| 000244 lfd      C8590010   1     LFL       fp2=+CONSTANT_AREA(gr25,16)
    0| 000248 mcrf     4C800000   1     LRCR      cr1=cr0
   43|                              CL.97:
   44| 00024C addi     38A00000   1     LI        gr5=0
    0| 000250 bc       40850078   1     BF        CL.101,cr1,0x2/gt,taken=20%(20,80)
    0| 000254 lfd      C89F00F0   1     LFL       fp4=#SPILL13(gr31,240)
    0| 000258 lfd      C8BF00D0   1     LFL       fp5=#SPILL9(gr31,208)
    0| 00025C subfic   20EB0001   1     SFI       gr7=1,gr11,ca"
    0| 000260 rldicr   79661F24   1     SLL8      gr6=gr11,3
    0| 000264 add      7F676214   1     A         gr27=gr7,gr12
    0| 000268 add      7F46EA14   1     A         gr26=gr6,gr29
    0| 00026C add      7F26E214   1     A         gr25=gr6,gr28
    0| 000270 fadd     FC64002A   1     AFL       fp3=fp4,fp0,fcr
    0| 000274 add      7F06F214   1     A         gr24=gr6,gr30
    0| 000278 fmul     FC6500F2   1     MFL       fp3=fp5,fp3,fcr
    0| 00027C fmul     FC630072   2     MFL       fp3=fp3,fp1,fcr
    0| 000280 fmul     FC6300B2   2     MFL       fp3=fp3,fp2,fcr
   44|                              CL.98:
   46| 000284 or       7F26CB78   1     LR        gr6=gr25
   46| 000288 or       7F07C378   1     LR        gr7=gr24
   46| 00028C or       7F48D378   1     LR        gr8=gr26
    0| 000290 mtspr    7F6903A6   1     LCTR      ctr=gr27
    0| 000294 ori      60210000   1     XNOP      
   45|                              CL.99:
   46| 000298 lfdu     CC870008   1     LFDU      fp4,gr7=e[](gr7,8)
   46| 00029C lfdu     CCA80008   1     LFDU      fp5,gr8=d[](gr8,8)
   46| 0002A0 fmul     FC830132   1     MFL       fp4=fp3,fp4,fcr
   46| 0002A4 fdiv     FC842824   2     DFL       fp4=fp4,fp5,fcr
   46| 0002A8 stfdu    DC860008   2     STFDU     gr6,t[].rns0.(gr6,8)=fp4
   47| 0002AC bc       4200FFEC   1     BCT       ctr=CL.99,taken=100%(100,0)
   47| 0002B0 addi     38A50001   1     AI        gr5=gr5,1
    0| 0002B4 add      7F49D214   1     A         gr26=gr9,gr26
   47| 0002B8 cmpld    7C250040   1     CL8       cr0=gr5,gr0
    0| 0002BC add      7F29CA14   1     A         gr25=gr9,gr25
    0| 0002C0 add      7F09C214   1     A         gr24=gr9,gr24
   47| 0002C4 bc       4180FFC0   1     BT        CL.98,cr0,0x8/llt,taken=80%(80,20)
   47|                              CL.101:
   47| 0002C8 ld       E8BF00A8   1     L8        gr5=#SPILL4(gr31,168)
   47| 0002CC addi     38840001   1     AI        gr4=gr4,1
    0| 0002D0 add      7F8AE214   1     A         gr28=gr10,gr28
    0| 0002D4 add      7FAAEA14   1     A         gr29=gr10,gr29
    0| 0002D8 add      7FCAF214   1     A         gr30=gr10,gr30
   47| 0002DC cmpd     7C252000   1     C8        cr0=gr5,gr4
   47| 0002E0 bc       4181FF6C   1     BT        CL.97,cr0,0x2/gt,taken=80%(80,20)
   47|                              CL.102:
   43| 0002E4 cmpd     7DB59800   1     C8        cr3=gr21,gr19
   43| 0002E8 cmpdi    2C350000   1     C8        cr0=gr21,0
   43| 0002EC crand    4DA16A02   1     CR_N      cr3=cr[03],0x2/gt,0x2/gt,0x2/gt,cr3
   43| 0002F0 bc       408D06C4   1     BF        CL.37,cr3,0x2/gt,taken=50%(0,0)
   43| 0002F4 ld       E8BF0388   1     L8        gr5=.jbeg(gr31,904)
   43| 0002F8 ld       E89F0390   1     L8        gr4=.jend(gr31,912)
    0| 0002FC rldicr   7AE61F24   1     SLL8      gr6=gr23,3
   47| 000300 or       7E8CA378   1     LR        gr12=gr20
    0| 000304 mulld    7CE6B1D2   1     M         gr7=gr6,gr22
   43| 000308 lwa      E9050002   1     L4A       gr8=jbeg(gr5,0)
   43| 00030C lwa      E8840002   1     L4A       gr4=jend(gr4,0)
   47| 000310 addi     380CFFFF   1     AI        gr0=gr12,-1
    0| 000314 ld       EB9F0088   1     L8        gr28=#SPILL0(gr31,136)
   47| 000318 sradi    7C051674   1     SRA8CA    gr5,ca=gr0,2
    0| 00031C rldicr   7AC01F24   1     SLL8      gr0=gr22,3
   47| 000320 addze    7CA50194   1     ADDE      gr5,ca=gr5,0,ca
   43| 000324 subf     7C882050   1     S         gr4=gr4,gr8
   43| 000328 addi     3BA00000   1     LI        gr29=0
   43| 00032C addic.   34840001   1     AI_R      gr4,cr0=gr4,1,ca"
   43| 000330 std      FBBF00F8   1     ST8       #SPILL14(gr31,248)=gr29
    0| 000334 or       7EDEB378   1     LR        gr30=gr22
    0| 000338 mulld    7D4041D2   1     M         gr10=gr0,gr8
    0| 00033C mulld    7D67E1D2   1     M         gr11=gr7,gr28
    0| 000340 neg      7CC600D0   1     COMP      gr6=gr6
    0| 000344 bc       40810670   1     BF        CL.37,cr0,0x2/gt,taken=20%(20,80)
    0| 000348 ld       E99F0380   1     L8        gr12=.iend(gr31,896)
    0| 00034C or       7FCEF378   1     LR        gr14=gr30
    0| 000350 ld       EBDF0378   1     L8        gr30=.ibeg(gr31,888)
    0| 000354 rldicr   7AE826E4   1     SLL8      gr8=gr23,4
    0| 000358 mulld    7D2799D2   1     M         gr9=gr7,gr19
    0| 00035C lwa      EB2C0002   1     L4A       gr25=iend(gr12,0)
    0| 000360 addi     398AFFF0   1     AI        gr12=gr10,-16
    0| 000364 subf     7D605850   1     S         gr11=gr11,gr0
    0| 000368 rldicr   7AEA2EA4   1     SLL8      gr10=gr23,5
    0| 00036C lwa      EB5E0002   1     L4A       gr26=ibeg(gr30,0)
    0| 000370 add      7D6B6214   1     A         gr11=gr11,gr12
    0| 000374 std      FB3F0108   1     ST8       #SPILL16(gr31,264)=gr25
    0| 000378 ld       EABF0148   1     L8        gr21=#SPILL24(gr31,328)
    0| 00037C mulld    7CC6B1D2   1     M         gr6=gr6,gr22
    0| 000380 std      FB5F0100   1     ST8       #SPILL15(gr31,256)=gr26
    0| 000384 mulld    7D08B1D2   1     M         gr8=gr8,gr22
    0| 000388 add      7D695A14   1     A         gr11=gr9,gr11
    0| 00038C subf     7D3AC850   1     S         gr9=gr25,gr26
    0| 000390 add      7ECB9214   1     A         gr22=gr11,gr18
    0| 000394 mulld    7E4A71D2   1     M         gr18=gr10,gr14
    0| 000398 std      FADF0110   1     ST8       #SPILL17(gr31,272)=gr22
    0| 00039C std      FA5F0140   1     ST8       #SPILL23(gr31,320)=gr18
    0| 0003A0 add      7E8BAA14   1     A         gr20=gr11,gr21
    0| 0003A4 add      7E635A14   1     A         gr19=gr3,gr11
    0| 0003A8 std      FA9F0120   1     ST8       #SPILL19(gr31,288)=gr20
    0| 0003AC std      FA7F0130   1     ST8       #SPILL21(gr31,304)=gr19
    0| 0003B0 addic.   34690001   1     AI_R      gr3,cr0=gr9,1,ca"
    0| 0003B4 add      7E27B214   1     A         gr17=gr7,gr22
    0| 0003B8 add      7E06B214   1     A         gr16=gr6,gr22
    0| 0003BC std      FA3F0150   1     ST8       #SPILL25(gr31,336)=gr17
    0| 0003C0 std      FA1F0158   1     ST8       #SPILL26(gr31,344)=gr16
    0| 0003C4 add      7DE8B214   1     A         gr15=gr8,gr22
    0| 0003C8 add      7FC7A214   1     A         gr30=gr7,gr20
    0| 0003CC std      F9FF0160   1     ST8       #SPILL27(gr31,352)=gr15
    0| 0003D0 std      FBDF0168   1     ST8       #SPILL28(gr31,360)=gr30
    0| 0003D4 add      7D86A214   1     A         gr12=gr6,gr20
    0| 0003D8 add      7D48A214   1     A         gr10=gr8,gr20
    0| 0003DC std      F99F0170   1     ST8       #SPILL29(gr31,368)=gr12
    0| 0003E0 std      F95F0180   1     ST8       #SPILL31(gr31,384)=gr10
    0| 0003E4 add      7D689A14   1     A         gr11=gr8,gr19
    0| 0003E8 add      7D079A14   1     A         gr8=gr7,gr19
    0| 0003EC std      F97F0188   1     ST8       #SPILL32(gr31,392)=gr11
    0| 0003F0 std      F91F0190   1     ST8       #SPILL33(gr31,400)=gr8
    0| 0003F4 add      7CE69A14   1     A         gr7=gr6,gr19
    0| 0003F8 addi     38C50001   1     AI        gr6=gr5,1
    0| 0003FC std      F8FF0198   1     ST8       #SPILL34(gr31,408)=gr7
    0| 000400 std      F8DF01A0   1     ST8       #SPILL35(gr31,416)=gr6
    0| 000404 mcrf     4F800000   1     LRCR      cr7=cr0
   43|                              CL.38:
   44| 000408 addi     38600000   1     LI        gr3=0
    0| 00040C bc       409D04FC   1     BF        CL.39,cr7,0x2/gt,taken=20%(20,80)
    0| 000410 ld       E8FF0178   1     L8        gr7=#SPILL30(gr31,376)
    0| 000414 lfd      C83F00F0   1     LFL       fp1=#SPILL13(gr31,240)
    0| 000418 lfd      C87F00D0   1     LFL       fp3=#SPILL9(gr31,208)
    0| 00041C ld       E91F0100   1     L8        gr8=#SPILL15(gr31,256)
    0| 000420 ld       EA3F0168   1     L8        gr17=#SPILL28(gr31,360)
    0| 000424 ld       EA1F0150   1     L8        gr16=#SPILL25(gr31,336)
    0| 000428 lfs      C0470004   1     LFS       fp2=+CONSTANT_AREA(gr7,4)
    0| 00042C lfs      C0870008   1     LFS       fp4=+CONSTANT_AREA(gr7,8)
    0| 000430 ld       E9FF0160   1     L8        gr15=#SPILL27(gr31,352)
    0| 000434 ld       E9DF0170   1     L8        gr14=#SPILL29(gr31,368)
    0| 000438 ld       E93F0108   1     L8        gr9=#SPILL16(gr31,264)
    0| 00043C rldicr   79051F24   1     SLL8      gr5=gr8,3
    0| 000440 subfic   20C80001   1     SFI       gr6=1,gr8,ca"
    0| 000444 fadd     FC01102A   1     AFL       fp0=fp1,fp2,fcr
    0| 000448 lfd      C8A70010   1     LFL       fp5=+CONSTANT_AREA(gr7,16)
    0| 00044C ld       E95F0190   1     L8        gr10=#SPILL33(gr31,400)
    0| 000450 ld       E97F0188   1     L8        gr11=#SPILL32(gr31,392)
    0| 000454 ld       E99F0198   1     L8        gr12=#SPILL34(gr31,408)
    0| 000458 ld       EBDF0130   1     L8        gr30=#SPILL21(gr31,304)
    0| 00045C fmul     FC030032   1     MFL       fp0=fp3,fp0,fcr
    0| 000460 ld       EBBF0110   1     L8        gr29=#SPILL17(gr31,272)
    0| 000464 ld       EB9F0120   1     L8        gr28=#SPILL19(gr31,288)
    0| 000468 ld       EB7F0180   1     L8        gr27=#SPILL31(gr31,384)
    0| 00046C add      7E458A14   1     A         gr18=gr5,gr17
    0| 000470 add      7E258214   1     A         gr17=gr5,gr16
    0| 000474 fmul     FC000132   1     MFL       fp0=fp0,fp4,fcr
    0| 000478 add      7E057A14   1     A         gr16=gr5,gr15
    0| 00047C add      7DE57214   1     A         gr15=gr5,gr14
    0| 000480 ld       E9DF0158   1     L8        gr14=#SPILL26(gr31,344)
    0| 000484 add      7CC64A14   1     A         gr6=gr6,gr9
    0| 000488 add      7F455214   1     A         gr26=gr5,gr10
    0| 00048C fmul     FC000172   1     MFL       fp0=fp0,fp5,fcr
    0| 000490 rldicl   78D9F842   1     SRL8      gr25=gr6,1
    0| 000494 add      7F055A14   1     A         gr24=gr5,gr11
    0| 000498 add      7EE56214   1     A         gr23=gr5,gr12
    0| 00049C add      7EC5F214   1     A         gr22=gr5,gr30
    0| 0004A0 add      7EA5EA14   1     A         gr21=gr5,gr29
    0| 0004A4 add      7E85E214   1     A         gr20=gr5,gr28
    0| 0004A8 add      7E65DA14   1     A         gr19=gr5,gr27
    0| 0004AC add      7DCE2A14   1     A         gr14=gr14,gr5
    0| 0004B0 andi.    70C50001   1     RN4_R     gr5,cr0=gr6,0,0x1
    0| 0004B4 cmpdi    2CB90000   1     C8        cr1=gr25,0
   44|                              CL.40:
   46| 0004B8 or       7DE57B78   1     LR        gr5=gr15
   46| 0004BC or       7E86A378   1     LR        gr6=gr20
   46| 0004C0 or       7E479378   1     LR        gr7=gr18
   46| 0004C4 or       7E689B78   1     LR        gr8=gr19
   46| 0004C8 or       7EE9BB78   1     LR        gr9=gr23
   46| 0004CC or       7ECAB378   1     LR        gr10=gr22
   46| 0004D0 or       7F4BD378   1     LR        gr11=gr26
   46| 0004D4 or       7F0CC378   1     LR        gr12=gr24
   46| 0004D8 or       7DDE7378   1     LR        gr30=gr14
   46| 0004DC or       7EBDAB78   1     LR        gr29=gr21
   46| 0004E0 or       7E3C8B78   1     LR        gr28=gr17
   46| 0004E4 or       7E1B8378   1     LR        gr27=gr16
    0| 0004E8 mtspr    7F2903A6   1     LCTR      ctr=gr25
    0| 0004EC bc       418200C8   1     BT        CL.446,cr0,0x4/eq,taken=50%(0,0)
   46| 0004F0 lfdu     CC250008   1     LFDU      fp1,gr5=d[](gr5,8)
   46| 0004F4 lfdu     CC460008   1     LFDU      fp2,gr6=d[](gr6,8)
   46| 0004F8 lfdu     CC670008   1     LFDU      fp3,gr7=d[](gr7,8)
   46| 0004FC lfdu     CC880008   1     LFDU      fp4,gr8=d[](gr8,8)
   46| 000500 lfdu     CD690008   1     LFDU      fp11,gr9=e[](gr9,8)
   46| 000504 lfdu     CDAA0008   1     LFDU      fp13,gr10=e[](gr10,8)
   46| 000508 lfdu     CCAB0008   1     LFDU      fp5,gr11=e[](gr11,8)
   46| 00050C qvfre    10C00830   1     QVFRE     fp6=fp1
   46| 000510 lfdu     CCEC0008   1     LFDU      fp7,gr12=e[](gr12,8)
   46| 000514 qvfre    11001030   1     QVFRE     fp8=fp2
   46| 000518 qvfre    11201830   1     QVFRE     fp9=fp3
   46| 00051C qvfre    11402030   1     QVFRE     fp10=fp4
   46| 000520 fmul     FD6002F2   1     MFL       fp11=fp0,fp11,fcr
   46| 000524 fmsub    FD81F9B8   2     FMS       fp12=fp31,fp1,fp6,fcr
   46| 000528 fmul     FDA00372   2     MFL       fp13=fp0,fp13,fcr
   46| 00052C fmsub    FF42FA38   2     FMS       fp26=fp31,fp2,fp8,fcr
   46| 000530 fmsub    FF23FA78   2     FMS       fp25=fp31,fp3,fp9,fcr
   46| 000534 fmsub    FF04FAB8   2     FMS       fp24=fp31,fp4,fp10,fcr
   46| 000538 fmul     FCA00172   2     MFL       fp5=fp0,fp5,fcr
   46| 00053C fnmsub   FCC6333C   2     FNMS      fp6=fp6,fp6,fp12,fcr
   46| 000540 fmul     FCE001F2   2     MFL       fp7=fp0,fp7,fcr
   46| 000544 fnmsub   FD0846BC   2     FNMS      fp8=fp8,fp8,fp26,fcr
   46| 000548 fnmsub   FD294E7C   2     FNMS      fp9=fp9,fp9,fp25,fcr
   46| 00054C fnmsub   FD4A563C   2     FNMS      fp10=fp10,fp10,fp24,fcr
   46| 000550 fmsub    FD81F9B8   2     FMS       fp12=fp31,fp1,fp6,fcr
   46| 000554 fmsub    FF42FA38   2     FMS       fp26=fp31,fp2,fp8,fcr
   46| 000558 fmsub    FF23FA78   2     FMS       fp25=fp31,fp3,fp9,fcr
   46| 00055C fmsub    FF04FAB8   2     FMS       fp24=fp31,fp4,fp10,fcr
   46| 000560 fnmsub   FCC6333C   2     FNMS      fp6=fp6,fp6,fp12,fcr
   46| 000564 fnmsub   FD0846BC   2     FNMS      fp8=fp8,fp8,fp26,fcr
   46| 000568 fnmsub   FD294E7C   2     FNMS      fp9=fp9,fp9,fp25,fcr
   46| 00056C fnmsub   FD4A563C   2     FNMS      fp10=fp10,fp10,fp24,fcr
   46| 000570 fmul     FD8B01B2   2     MFL       fp12=fp11,fp6,fcr
   46| 000574 fmul     FF4D0232   2     MFL       fp26=fp13,fp8,fcr
   46| 000578 fmul     FF250272   2     MFL       fp25=fp5,fp9,fcr
   46| 00057C fmul     FF0702B2   2     MFL       fp24=fp7,fp10,fcr
   46| 000580 fmsub    FC215B38   2     FMS       fp1=fp11,fp1,fp12,fcr
   46| 000584 fmsub    FC426EB8   2     FMS       fp2=fp13,fp2,fp26,fcr
   46| 000588 fmsub    FC632E78   2     FMS       fp3=fp5,fp3,fp25,fcr
   46| 00058C fmsub    FC843E38   2     FMS       fp4=fp7,fp4,fp24,fcr
   46| 000590 fnmsub   FC26607C   2     FNMS      fp1=fp12,fp6,fp1,fcr
   46| 000594 fnmsub   FC48D0BC   2     FNMS      fp2=fp26,fp8,fp2,fcr
   46| 000598 fnmsub   FC69C8FC   2     FNMS      fp3=fp25,fp9,fp3,fcr
   46| 00059C fnmsub   FC8AC13C   2     FNMS      fp4=fp24,fp10,fp4,fcr
   46| 0005A0 stfdu    DC3E0008   2     STFDU     gr30,t[].rns0.(gr30,8)=fp1
   46| 0005A4 stfdu    DC5D0008   1     STFDU     gr29,t[].rns0.(gr29,8)=fp2
   46| 0005A8 stfdu    DC7C0008   1     STFDU     gr28,t[].rns0.(gr28,8)=fp3
   46| 0005AC stfdu    DC9B0008   1     STFDU     gr27,t[].rns0.(gr27,8)=fp4
    0| 0005B0 bc       4186031C   1     BT        CL.407,cr1,0x4/eq,taken=20%(20,80)
    0|                              CL.446:
   46| 0005B4 lfd      C8650008   1     LFL       fp3=d[](gr5,8)
   46| 0005B8 lfd      C8860008   1     LFL       fp4=d[](gr6,8)
   46| 0005BC lfd      C8A70008   1     LFL       fp5=d[](gr7,8)
   46| 0005C0 lfd      C8C80008   1     LFL       fp6=d[](gr8,8)
   46| 0005C4 lfdu     CCE50010   1     LFDU      fp7,gr5=d[](gr5,16)
   46| 0005C8 lfd      CA690008   1     LFL       fp19=e[](gr9,8)
   46| 0005CC lfd      C90A0008   1     LFL       fp8=e[](gr10,8)
   46| 0005D0 qvfre    11201830   1     QVFRE     fp9=fp3
   46| 0005D4 lfd      C94B0008   1     LFL       fp10=e[](gr11,8)
   46| 0005D8 qvfre    11602030   1     QVFRE     fp11=fp4
   46| 0005DC lfd      C9AC0008   1     LFL       fp13=e[](gr12,8)
   46| 0005E0 qvfre    11802830   1     QVFRE     fp12=fp5
   46| 0005E4 lfdu     CF290010   1     LFDU      fp25,gr9=e[](gr9,16)
   46| 0005E8 qvfre    13403030   1     QVFRE     fp26=fp6
   46| 0005EC lfdu     CC260010   1     LFDU      fp1,gr6=d[](gr6,16)
   46| 0005F0 qvfre    13003830   1     QVFRE     fp24=fp7
   46| 0005F4 lfdu     CC470010   1     LFDU      fp2,gr7=d[](gr7,16)
   46| 0005F8 fmsub    FE43FA78   1     FMS       fp18=fp31,fp3,fp9,fcr
   46| 0005FC lfdu     CDEA0010   1     LFDU      fp15,gr10=e[](gr10,16)
   46| 000600 fmsub    FE84FAF8   1     FMS       fp20=fp31,fp4,fp11,fcr
   46| 000604 fmsub    FEA5FB38   2     FMS       fp21=fp31,fp5,fp12,fcr
   46| 000608 fmsub    FEC6FEB8   2     FMS       fp22=fp31,fp6,fp26,fcr
   46| 00060C fmsub    FEE7FE38   2     FMS       fp23=fp31,fp7,fp24,fcr
   46| 000610 fnmsub   FD294CBC   2     FNMS      fp9=fp9,fp9,fp18,fcr
   46| 000614 fmul     FE2004F2   2     MFL       fp17=fp0,fp19,fcr
   46| 000618 fnmsub   FD6B5D3C   2     FNMS      fp11=fp11,fp11,fp20,fcr
   46| 00061C fnmsub   FD8C657C   2     FNMS      fp12=fp12,fp12,fp21,fcr
   46| 000620 fnmsub   FF5AD5BC   2     FNMS      fp26=fp26,fp26,fp22,fcr
   46| 000624 fnmsub   FF18C5FC   2     FNMS      fp24=fp24,fp24,fp23,fcr
   46| 000628 fmsub    FE63FA78   2     FMS       fp19=fp31,fp3,fp9,fcr
   46| 00062C fmul     FD000232   2     MFL       fp8=fp0,fp8,fcr
   46| 000630 fmsub    FE84FAF8   2     FMS       fp20=fp31,fp4,fp11,fcr
   46| 000634 fmsub    FEA5FB38   2     FMS       fp21=fp31,fp5,fp12,fcr
   46| 000638 fmsub    FEC6FEB8   2     FMS       fp22=fp31,fp6,fp26,fcr
   46| 00063C fmsub    FEE7FE38   2     FMS       fp23=fp31,fp7,fp24,fcr
   46| 000640 fnmsub   FD294CFC   2     FNMS      fp9=fp9,fp9,fp19,fcr
   46| 000644 fmul     FD4002B2   2     MFL       fp10=fp0,fp10,fcr
   46| 000648 fnmsub   FD6B5D3C   2     FNMS      fp11=fp11,fp11,fp20,fcr
   46| 00064C fnmsub   FD8C657C   2     FNMS      fp12=fp12,fp12,fp21,fcr
   46| 000650 fmul     FDA00372   2     MFL       fp13=fp0,fp13,fcr
   46| 000654 fnmsub   FF5AD5BC   2     FNMS      fp26=fp26,fp26,fp22,fcr
   46| 000658 fmul     FF200672   2     MFL       fp25=fp0,fp25,fcr
   46| 00065C fnmsub   FF18C5FC   2     FNMS      fp24=fp24,fp24,fp23,fcr
   46| 000660 qvfre    12E00830   1     QVFRE     fp23=fp1
   46| 000664 fmul     FED10272   1     MFL       fp22=fp17,fp9,fcr
   46| 000668 fmul     FEA802F2   2     MFL       fp21=fp8,fp11,fcr
   46| 00066C fmul     FE8A0332   2     MFL       fp20=fp10,fp12,fcr
   46| 000670 fmul     FE6D06B2   2     MFL       fp19=fp13,fp26,fcr
   46| 000674 fmul     FE590632   2     MFL       fp18=fp25,fp24,fcr
   46| 000678 fmsub    FE01FDF8   2     FMS       fp16=fp31,fp1,fp23,fcr
   46| 00067C fmsub    FC638DB8   2     FMS       fp3=fp17,fp3,fp22,fcr
   46| 000680 fmsub    FC844578   2     FMS       fp4=fp8,fp4,fp21,fcr
   46| 000684 fmsub    FCA55538   2     FMS       fp5=fp10,fp5,fp20,fcr
   46| 000688 fmsub    FCC66CF8   2     FMS       fp6=fp13,fp6,fp19,fcr
   46| 00068C fmsub    FCE7CCB8   2     FMS       fp7=fp25,fp7,fp18,fcr
   46| 000690 fnmsub   FD17BC3C   2     FNMS      fp8=fp23,fp23,fp16,fcr
   46| 000694 fnmsub   FC69B0FC   2     FNMS      fp3=fp22,fp9,fp3,fcr
   46| 000698 fnmsub   FC8BA93C   2     FNMS      fp4=fp21,fp11,fp4,fcr
   46| 00069C fnmsub   FD2CA17C   2     FNMS      fp9=fp20,fp12,fp5,fcr
   46| 0006A0 fnmsub   FCDA99BC   2     FNMS      fp6=fp19,fp26,fp6,fcr
   46| 0006A4 fnmsub   FD5891FC   2     FNMS      fp10=fp18,fp24,fp7,fcr
   46| 0006A8 fmsub    FCE1FA38   2     FMS       fp7=fp31,fp1,fp8,fcr
   46| 0006AC qvfre    10A01030   1     QVFRE     fp5=fp2
   46| 0006B0 stfd     D87E0008   1     STFL      t[].rns0.(gr30,8)=fp3
   46| 0006B4 fmul     FC6003F2   1     MFL       fp3=fp0,fp15,fcr
   46| 0006B8 stfd     D89D0008   1     STFL      t[].rns0.(gr29,8)=fp4
   46| 0006BC stfd     D93C0008   1     STFL      t[].rns0.(gr28,8)=fp9
   46| 0006C0 fnmsub   FCE841FC   1     FNMS      fp7=fp8,fp8,fp7,fcr
   46| 0006C4 stfd     D8DB0008   1     STFL      t[].rns0.(gr27,8)=fp6
   46| 0006C8 stfdu    DD5E0010   1     STFDU     gr30,t[].rns0.(gr30,16)=fp10
    0| 0006CC bc       42400198   1     BCF       ctr=CL.464,taken=0%(0,100)
    0| 0006D0 stfd     DBDF01A8   1     STFL      #SPILL36(gr31,424)=fp30
    0| 0006D4 ori      60210000   1     XNOP      
    0|                              CL.465:
   46| 0006D8 lfd      C9490008   1     LFL       fp10=e[](gr9,8)
   46| 0006DC lfd      C96A0008   1     LFL       fp11=e[](gr10,8)
   46| 0006E0 lfd      C98B0018   1     LFL       fp12=e[](gr11,24)
   46| 0006E4 fmsub    FC82F978   1     FMS       fp4=fp31,fp2,fp5,fcr
   46| 0006E8 fmul     FD0301F2   2     MFL       fp8=fp3,fp7,fcr
   46| 0006EC lfd      C9AC0018   1     LFL       fp13=e[](gr12,24)
   46| 0006F0 lfdu     CF490010   1     LFDU      fp26,gr9=e[](gr9,16)
   46| 0006F4 lfdu     CF2A0010   1     LFDU      fp25,gr10=e[](gr10,16)
   46| 0006F8 lfdu     CECB0010   1     LFDU      fp22,gr11=e[](gr11,16)
   46| 0006FC fnmsub   FEE5293C   1     FNMS      fp23=fp5,fp5,fp4,fcr
   46| 000700 fmsub    FC211A38   2     FMS       fp1=fp3,fp1,fp8,fcr
   46| 000704 lfdu     CF0C0010   1     LFDU      fp24,gr12=e[](gr12,16)
   46| 000708 lfd      C8850008   1     LFL       fp4=d[](gr5,8)
   46| 00070C lfd      C8A60008   1     LFL       fp5=d[](gr6,8)
   46| 000710 lfdu     CCC80010   1     LFDU      fp6,gr8=d[](gr8,16)
   46| 000714 fmsub    FEA2FDF8   1     FMS       fp21=fp31,fp2,fp23,fcr
   46| 000718 fnmsub   FC27407C   2     FNMS      fp1=fp8,fp7,fp1,fcr
   46| 00071C lfd      C8E70008   1     LFL       fp7=d[](gr7,8)
   46| 000720 lfd      C9080008   1     LFL       fp8=d[](gr8,8)
   46| 000724 lfdu     CD250010   1     LFDU      fp9,gr5=d[](gr5,16)
   46| 000728 fmul     FC6005B2   1     MFL       fp3=fp0,fp22,fcr
   46| 00072C qvfre    12803030   1     QVFRE     fp20=fp6
   46| 000730 fnmsub   FEF7BD7C   1     FNMS      fp23=fp23,fp23,fp21,fcr
   46| 000734 stfdu    DC3D0010   2     STFDU     gr29,t[].rns0.(gr29,16)=fp1
   46| 000738 lfdu     CC260010   1     LFDU      fp1,gr6=d[](gr6,16)
    0| 00073C fmr      FEA01090   1     LRFL      fp21=fp2
   46| 000740 lfdu     CC470010   1     LFDU      fp2,gr7=d[](gr7,16)
   46| 000744 fmsub    FE66FD38   1     FMS       fp19=fp31,fp6,fp20,fcr
   46| 000748 fmul     FEC305F2   2     MFL       fp22=fp3,fp23,fcr
   46| 00074C fmul     FD4002B2   2     MFL       fp10=fp0,fp10,fcr
   46| 000750 fmul     FD6002F2   2     MFL       fp11=fp0,fp11,fcr
   46| 000754 fmul     FD800332   2     MFL       fp12=fp0,fp12,fcr
   46| 000758 fmul     FDA00372   2     MFL       fp13=fp0,fp13,fcr
   46| 00075C fnmsub   FE74A4FC   2     FNMS      fp19=fp20,fp20,fp19,fcr
   46| 000760 fmsub    FEB51DB8   2     FMS       fp21=fp3,fp21,fp22,fcr
   46| 000764 fmul     FF4006B2   2     MFL       fp26=fp0,fp26,fcr
   46| 000768 fmul     FC600672   2     MFL       fp3=fp0,fp25,fcr
   46| 00076C fmul     FF200632   2     MFL       fp25=fp0,fp24,fcr
   46| 000770 qvfre    13002030   1     QVFRE     fp24=fp4
   46| 000774 fmsub    FE26FCF8   1     FMS       fp17=fp31,fp6,fp19,fcr
   46| 000778 fnmsub   FE57B57C   2     FNMS      fp18=fp22,fp23,fp21,fcr
   46| 00077C qvfre    12E02830   1     QVFRE     fp23=fp5
   46| 000780 qvfre    12C03830   1     QVFRE     fp22=fp7
   46| 000784 qvfre    12A04030   1     QVFRE     fp21=fp8
   46| 000788 qvfre    12804830   1     QVFRE     fp20=fp9
   46| 00078C fmsub    FFC4FE38   1     FMS       fp30=fp31,fp4,fp24,fcr
   46| 000790 fnmsub   FE739C7C   2     FNMS      fp19=fp19,fp19,fp17,fcr
   46| 000794 stfdu    DE5C0010   2     STFDU     gr28,t[].rns0.(gr28,16)=fp18
   46| 000798 fmsub    FE45FDF8   1     FMS       fp18=fp31,fp5,fp23,fcr
   46| 00079C fmsub    FE27FDB8   2     FMS       fp17=fp31,fp7,fp22,fcr
   46| 0007A0 fmsub    FE08FD78   2     FMS       fp16=fp31,fp8,fp21,fcr
   46| 0007A4 fmsub    FDE9FD38   2     FMS       fp15=fp31,fp9,fp20,fcr
   46| 0007A8 fmul     FDD904F2   2     MFL       fp14=fp25,fp19,fcr
   46| 0007AC fnmsub   FF18C7BC   2     FNMS      fp24=fp24,fp24,fp30,fcr
   46| 0007B0 fnmsub   FEF7BCBC   2     FNMS      fp23=fp23,fp23,fp18,fcr
   46| 0007B4 fnmsub   FED6B47C   2     FNMS      fp22=fp22,fp22,fp17,fcr
   46| 0007B8 fnmsub   FEB5AC3C   2     FNMS      fp21=fp21,fp21,fp16,fcr
   46| 0007BC fnmsub   FE94A3FC   2     FNMS      fp20=fp20,fp20,fp15,fcr
   46| 0007C0 fmsub    FCC6CBB8   2     FMS       fp6=fp25,fp6,fp14,fcr
   46| 0007C4 fmsub    FF24FE38   2     FMS       fp25=fp31,fp4,fp24,fcr
   46| 0007C8 fmsub    FE45FDF8   2     FMS       fp18=fp31,fp5,fp23,fcr
   46| 0007CC fmsub    FE27FDB8   2     FMS       fp17=fp31,fp7,fp22,fcr
   46| 0007D0 fmsub    FE08FD78   2     FMS       fp16=fp31,fp8,fp21,fcr
   46| 0007D4 fmsub    FDE9FD38   2     FMS       fp15=fp31,fp9,fp20,fcr
   46| 0007D8 fnmsub   FCD371BC   2     FNMS      fp6=fp14,fp19,fp6,fcr
   46| 0007DC qvfre    12600830   1     QVFRE     fp19=fp1
   46| 0007E0 fnmsub   FF38C67C   1     FNMS      fp25=fp24,fp24,fp25,fcr
   46| 0007E4 fnmsub   FF17BCBC   2     FNMS      fp24=fp23,fp23,fp18,fcr
   46| 0007E8 fnmsub   FEF6B47C   2     FNMS      fp23=fp22,fp22,fp17,fcr
   46| 0007EC fnmsub   FED5AC3C   2     FNMS      fp22=fp21,fp21,fp16,fcr
   46| 0007F0 fnmsub   FEB4A3FC   2     FNMS      fp21=fp20,fp20,fp15,fcr
   46| 0007F4 stfdu    DCDB0010   2     STFDU     gr27,t[].rns0.(gr27,16)=fp6
   46| 0007F8 fmsub    FCC1FCF8   1     FMS       fp6=fp31,fp1,fp19,fcr
   46| 0007FC fmul     FE8A0672   2     MFL       fp20=fp10,fp25,fcr
   46| 000800 fmul     FE4B0632   2     MFL       fp18=fp11,fp24,fcr
   46| 000804 fmul     FE2C05F2   2     MFL       fp17=fp12,fp23,fcr
   46| 000808 fmul     FE0D05B2   2     MFL       fp16=fp13,fp22,fcr
   46| 00080C fmul     FDFA0572   2     MFL       fp15=fp26,fp21,fcr
   46| 000810 fnmsub   FCD399BC   2     FNMS      fp6=fp19,fp19,fp6,fcr
   46| 000814 fmsub    FC845538   2     FMS       fp4=fp10,fp4,fp20,fcr
   46| 000818 fmsub    FCA55CB8   2     FMS       fp5=fp11,fp5,fp18,fcr
   46| 00081C fmsub    FCE76478   2     FMS       fp7=fp12,fp7,fp17,fcr
   46| 000820 fmsub    FD086C38   2     FMS       fp8=fp13,fp8,fp16,fcr
   46| 000824 fmsub    FD29D3F8   2     FMS       fp9=fp26,fp9,fp15,fcr
   46| 000828 fmsub    FD41F9B8   2     FMS       fp10=fp31,fp1,fp6,fcr
   46| 00082C fnmsub   FC99A13C   2     FNMS      fp4=fp20,fp25,fp4,fcr
   46| 000830 fnmsub   FD78917C   2     FNMS      fp11=fp18,fp24,fp5,fcr
   46| 000834 fnmsub   FD9789FC   2     FNMS      fp12=fp17,fp23,fp7,fcr
   46| 000838 fnmsub   FD16823C   2     FNMS      fp8=fp16,fp22,fp8,fcr
   46| 00083C fnmsub   FD357A7C   2     FNMS      fp9=fp15,fp21,fp9,fcr
   46| 000840 qvfre    10A01030   1     QVFRE     fp5=fp2
   46| 000844 fnmsub   FCE632BC   1     FNMS      fp7=fp6,fp6,fp10,fcr
   46| 000848 stfd     D89E0008   1     STFL      t[].rns0.(gr30,8)=fp4
   46| 00084C stfd     D97D0008   1     STFL      t[].rns0.(gr29,8)=fp11
   46| 000850 stfd     D99C0008   1     STFL      t[].rns0.(gr28,8)=fp12
   46| 000854 stfd     D91B0008   1     STFL      t[].rns0.(gr27,8)=fp8
   46| 000858 stfdu    DD3E0010   1     STFDU     gr30,t[].rns0.(gr30,16)=fp9
    0| 00085C bc       4200FE7C   1     BCT       ctr=CL.465,taken=100%(100,0)
    0| 000860 lfd      CBDF01A8   1     LFL       fp30=#SPILL36(gr31,424)
    0|                              CL.464:
   46| 000864 lfdu     CC880010   1     LFDU      fp4,gr8=d[](gr8,16)
   46| 000868 fmul     FD2301F2   1     MFL       fp9=fp3,fp7,fcr
   46| 00086C lfdu     CD0B0010   1     LFDU      fp8,gr11=e[](gr11,16)
   46| 000870 fmsub    FCC2F978   1     FMS       fp6=fp31,fp2,fp5,fcr
   46| 000874 lfdu     CD4C0010   1     LFDU      fp10,gr12=e[](gr12,16)
   46| 000878 qvfre    11602030   1     QVFRE     fp11=fp4
   46| 00087C fmsub    FC211A78   1     FMS       fp1=fp3,fp1,fp9,fcr
   46| 000880 fnmsub   FCA529BC   2     FNMS      fp5=fp5,fp5,fp6,fcr
   46| 000884 fmul     FCC00232   2     MFL       fp6=fp0,fp8,fcr
   46| 000888 fmul     FC6002B2   2     MFL       fp3=fp0,fp10,fcr
   46| 00088C fmsub    FD04FAF8   2     FMS       fp8=fp31,fp4,fp11,fcr
   46| 000890 fnmsub   FC27487C   2     FNMS      fp1=fp9,fp7,fp1,fcr
   46| 000894 fmsub    FD42F978   2     FMS       fp10=fp31,fp2,fp5,fcr
   46| 000898 fnmsub   FCEB5A3C   2     FNMS      fp7=fp11,fp11,fp8,fcr
   46| 00089C stfdu    DC3D0010   2     STFDU     gr29,t[].rns0.(gr29,16)=fp1
   46| 0008A0 fnmsub   FCA52ABC   1     FNMS      fp5=fp5,fp5,fp10,fcr
   46| 0008A4 fmsub    FC24F9F8   2     FMS       fp1=fp31,fp4,fp7,fcr
   46| 0008A8 fmul     FD060172   2     MFL       fp8=fp6,fp5,fcr
   46| 0008AC fnmsub   FC27387C   2     FNMS      fp1=fp7,fp7,fp1,fcr
   46| 0008B0 fmsub    FC423238   2     FMS       fp2=fp6,fp2,fp8,fcr
   46| 0008B4 fmul     FCC30072   2     MFL       fp6=fp3,fp1,fcr
   46| 0008B8 fnmsub   FC4540BC   2     FNMS      fp2=fp8,fp5,fp2,fcr
   46| 0008BC fmsub    FC6419B8   2     FMS       fp3=fp3,fp4,fp6,fcr
   46| 0008C0 stfdu    DC5C0010   2     STFDU     gr28,t[].rns0.(gr28,16)=fp2
   46| 0008C4 fnmsub   FC2130FC   1     FNMS      fp1=fp6,fp1,fp3,fcr
   46| 0008C8 stfdu    DC3B0010   2     STFDU     gr27,t[].rns0.(gr27,16)=fp1
    0|                              CL.407:
   47| 0008CC addi     38630001   1     AI        gr3=gr3,1
    0| 0008D0 add      7F5A0214   1     A         gr26=gr26,gr0
   47| 0008D4 cmpld    7F232040   1     CL8       cr6=gr3,gr4
    0| 0008D8 add      7F180214   1     A         gr24=gr24,gr0
    0| 0008DC add      7EF70214   1     A         gr23=gr23,gr0
    0| 0008E0 add      7ED60214   1     A         gr22=gr22,gr0
    0| 0008E4 add      7EB50214   1     A         gr21=gr21,gr0
    0| 0008E8 add      7E940214   1     A         gr20=gr20,gr0
    0| 0008EC add      7E730214   1     A         gr19=gr19,gr0
    0| 0008F0 add      7E520214   1     A         gr18=gr18,gr0
    0| 0008F4 add      7E310214   1     A         gr17=gr17,gr0
    0| 0008F8 add      7E100214   1     A         gr16=gr16,gr0
    0| 0008FC add      7DEF0214   1     A         gr15=gr15,gr0
    0| 000900 add      7DCE0214   1     A         gr14=gr14,gr0
   47| 000904 bc       4198FBB4   1     BT        CL.40,cr6,0x8/llt,taken=80%(80,20)
   47|                              CL.39:
   47| 000908 ld       E87F00F8   1     L8        gr3=#SPILL14(gr31,248)
    0| 00090C ld       E8BF0140   1     L8        gr5=#SPILL23(gr31,320)
    0| 000910 ld       E8DF0150   1     L8        gr6=#SPILL25(gr31,336)
   47| 000914 ld       E8FF01A0   1     L8        gr7=#SPILL35(gr31,416)
    0| 000918 ld       E91F0158   1     L8        gr8=#SPILL26(gr31,344)
    0| 00091C ld       E93F0160   1     L8        gr9=#SPILL27(gr31,352)
    0| 000920 ld       E95F0110   1     L8        gr10=#SPILL17(gr31,272)
    0| 000924 ld       E97F0168   1     L8        gr11=#SPILL28(gr31,360)
    0| 000928 ld       E99F0170   1     L8        gr12=#SPILL29(gr31,368)
    0| 00092C ld       EBDF0180   1     L8        gr30=#SPILL31(gr31,384)
    0| 000930 ld       EBBF0120   1     L8        gr29=#SPILL19(gr31,288)
    0| 000934 ld       EB9F0188   1     L8        gr28=#SPILL32(gr31,392)
    0| 000938 ld       EB7F0190   1     L8        gr27=#SPILL33(gr31,400)
    0| 00093C ld       EB5F0130   1     L8        gr26=#SPILL21(gr31,304)
    0| 000940 ld       EB3F0198   1     L8        gr25=#SPILL34(gr31,408)
   47| 000944 addi     38630001   1     AI        gr3=gr3,1
    0| 000948 add      7CC53214   1     A         gr6=gr5,gr6
   47| 00094C std      F87F00F8   1     ST8       #SPILL14(gr31,248)=gr3
    0| 000950 std      F8DF0150   1     ST8       #SPILL25(gr31,336)=gr6
   47| 000954 cmpld    7C233840   1     CL8       cr0=gr3,gr7
    0| 000958 add      7D054214   1     A         gr8=gr5,gr8
    0| 00095C add      7D254A14   1     A         gr9=gr5,gr9
    0| 000960 std      F91F0158   1     ST8       #SPILL26(gr31,344)=gr8
    0| 000964 std      F93F0160   1     ST8       #SPILL27(gr31,352)=gr9
    0| 000968 add      7D455214   1     A         gr10=gr5,gr10
    0| 00096C add      7D655A14   1     A         gr11=gr5,gr11
    0| 000970 std      F95F0110   1     ST8       #SPILL17(gr31,272)=gr10
    0| 000974 std      F97F0168   1     ST8       #SPILL28(gr31,360)=gr11
    0| 000978 add      7D856214   1     A         gr12=gr5,gr12
    0| 00097C add      7FC5F214   1     A         gr30=gr5,gr30
    0| 000980 std      F99F0170   1     ST8       #SPILL29(gr31,368)=gr12
    0| 000984 std      FBDF0180   1     ST8       #SPILL31(gr31,384)=gr30
    0| 000988 add      7FA5EA14   1     A         gr29=gr5,gr29
    0| 00098C add      7F85E214   1     A         gr28=gr5,gr28
    0| 000990 std      FBBF0120   1     ST8       #SPILL19(gr31,288)=gr29
    0| 000994 std      FB9F0188   1     ST8       #SPILL32(gr31,392)=gr28
    0| 000998 add      7F65DA14   1     A         gr27=gr5,gr27
    0| 00099C add      7F45D214   1     A         gr26=gr5,gr26
    0| 0009A0 std      FB7F0190   1     ST8       #SPILL33(gr31,400)=gr27
    0| 0009A4 std      FB5F0130   1     ST8       #SPILL21(gr31,304)=gr26
    0| 0009A8 add      7F25CA14   1     A         gr25=gr5,gr25
    0| 0009AC std      FB3F0198   1     ST8       #SPILL34(gr31,408)=gr25
   47| 0009B0 bc       4180FA58   1     BT        CL.38,cr0,0x8/llt,taken=80%(80,20)
   47|                              CL.37:
   47| 0009B4 ld       E87F01B0   1     L8        gr3=#SPILL37(gr31,432)
   47| 0009B8 sradi    7C600E74   1     SRA8CA    gr0,ca=gr3,1
   50| 0009BC cmpdi    2CA30000   1     C8        cr1=gr3,0
   47| 0009C0 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
   50| 0009C4 rldicr   78040FA4   1     SLL8      gr4=gr0,1
   50| 0009C8 subf     7CA41851   1     S_R       gr5,cr0=gr3,gr4
   50| 0009CC std      F89F00F8   1     ST8       #SPILL14(gr31,248)=gr4
   50| 0009D0 crand    4C250A02   1     CR_N      cr0=cr[10],0x2/gt,0x2/gt,0x2/gt,cr0
   50| 0009D4 std      F8BF00F0   1     ST8       #SPILL13(gr31,240)=gr5
   50| 0009D8 bc       408102BC   1     BF        CL.90,cr0,0x2/gt,taken=50%(0,0)
   50| 0009DC ld       E89F0388   1     L8        gr4=.jbeg(gr31,904)
   50| 0009E0 ld       E87F0390   1     L8        gr3=.jend(gr31,912)
   50| 0009E4 addi     38C00000   1     LI        gr6=0
   50| 0009E8 std      F8DF0100   1     ST8       #SPILL15(gr31,256)=gr6
   50| 0009EC lwa      E8840002   1     L4A       gr4=jbeg(gr4,0)
   50| 0009F0 lwa      E8030002   1     L4A       gr0=jend(gr3,0)
   50| 0009F4 subf     7C640050   1     S         gr3=gr0,gr4
   50| 0009F8 addic.   37C30001   1     AI_R      gr30,cr0=gr3,1,ca"
    0| 0009FC bc       40810DF0   1     BF        CL.311,cr0,0x2/gt,taken=50%(0,0)
    0| 000A00 ld       E8FF0090   1     L8        gr7=#SPILL1(gr31,144)
    0| 000A04 ld       E91F0098   1     L8        gr8=#SPILL2(gr31,152)
    0| 000A08 ld       E95F0088   1     L8        gr10=#SPILL0(gr31,136)
    0| 000A0C ld       E8BF0378   1     L8        gr5=.ibeg(gr31,888)
    0| 000A10 ld       E87F0380   1     L8        gr3=.iend(gr31,896)
    0| 000A14 ld       EB7F00C0   1     L8        gr27=#SPILL7(gr31,192)
    0| 000A18 rldicr   78E01F24   1     SLL8      gr0=gr7,3
    0| 000A1C rldicr   791D1F24   1     SLL8      gr29=gr8,3
    0| 000A20 mulld    7D2041D2   1     M         gr9=gr0,gr8
    0| 000A24 neg      7C0000D0   1     COMP      gr0=gr0
    0| 000A28 std      F93F0108   1     ST8       #SPILL16(gr31,264)=gr9
    0| 000A2C mulld    7C84E9D2   1     M         gr4=gr4,gr29
    0| 000A30 mulld    7CC951D2   1     M         gr6=gr9,gr10
    0| 000A34 lwa      E9650002   1     L4A       gr11=ibeg(gr5,0)
    0| 000A38 lwa      E8630002   1     L4A       gr3=iend(gr3,0)
    0| 000A3C mulld    7C0041D2   1     M         gr0=gr0,gr8
    0| 000A40 std      F97F0110   1     ST8       #SPILL17(gr31,272)=gr11
    0| 000A44 addi     3884FFF0   1     AI        gr4=gr4,-16
    0| 000A48 subf     7CBD3050   1     S         gr5=gr6,gr29
    0| 000A4C ld       EB3F0128   1     L8        gr25=#SPILL20(gr31,296)
    0| 000A50 ld       EAFF0118   1     L8        gr23=#SPILL18(gr31,280)
    0| 000A54 ld       EABF0138   1     L8        gr21=#SPILL22(gr31,312)
    0| 000A58 ld       EA7F0148   1     L8        gr19=#SPILL24(gr31,328)
    0| 000A5C ld       EA3F00B8   1     L8        gr17=#SPILL6(gr31,184)
    0| 000A60 add      7C842A14   1     A         gr4=gr4,gr5
    0| 000A64 lfd      C81F00E8   1     LFL       fp0=#SPILL12(gr31,232)
    0| 000A68 lfd      C83F00D8   1     LFL       fp1=#SPILL10(gr31,216)
    0| 000A6C lfd      C85F00E0   1     LFL       fp2=#SPILL11(gr31,224)
    0| 000A70 ld       E99F0178   1     L8        gr12=#SPILL30(gr31,376)
    0| 000A74 subf     7C6B1850   1     S         gr3=gr3,gr11
    0| 000A78 add      7C002214   1     A         gr0=gr0,gr4
    0| 000A7C addic.   37830001   1     AI_R      gr28,cr0=gr3,1,ca"
    0| 000A80 fneg     FF400050   1     COMPFL    fp26=fp0
    0| 000A84 add      7F40DA14   1     A         gr26=gr0,gr27
    0| 000A88 qvfre    12200830   1     QVFRE     fp17=fp1
    0| 000A8C std      FB5F0120   1     ST8       #SPILL19(gr31,288)=gr26
    0| 000A90 qvfre    13201030   1     QVFRE     fp25=fp2
    0| 000A94 add      7F00CA14   1     A         gr24=gr0,gr25
    0| 000A98 add      7EC0BA14   1     A         gr22=gr0,gr23
    0| 000A9C std      FB1F0130   1     ST8       #SPILL21(gr31,304)=gr24
    0| 000AA0 std      FADF0140   1     ST8       #SPILL23(gr31,320)=gr22
    0| 000AA4 add      7E80AA14   1     A         gr20=gr0,gr21
    0| 000AA8 add      7E409A14   1     A         gr18=gr0,gr19
    0| 000AAC std      FA9F0150   1     ST8       #SPILL25(gr31,336)=gr20
    0| 000AB0 add      7E008A14   1     A         gr16=gr0,gr17
    0| 000AB4 std      FA5F0158   1     ST8       #SPILL26(gr31,344)=gr18
    0| 000AB8 lfs      C30C0018   1     LFS       fp24=+CONSTANT_AREA(gr12,24)
    0| 000ABC std      FA1F0160   1     ST8       #SPILL27(gr31,352)=gr16
    0| 000AC0 lfs      C2EC001C   1     LFS       fp23=+CONSTANT_AREA(gr12,28)
    0| 000AC4 lfs      C2CC0020   1     LFS       fp22=+CONSTANT_AREA(gr12,32)
    0| 000AC8 mcrf     4D000000   1     LRCR      cr2=cr0
   52| 000ACC lfd      CA1F00D8   1     LFL       fp16=#SPILL10(gr31,216)
   52| 000AD0 lfd      C9FF00B0   1     LFL       fp15=#SPILL5(gr31,176)
   52| 000AD4 lfd      C9DF00E0   1     LFL       fp14=#SPILL11(gr31,224)
   50|                              CL.85:
   51| 000AD8 addi     3B600000   1     LI        gr27=0
    0| 000ADC bc       40890154   1     BF        CL.89,cr2,0x2/gt,taken=20%(20,80)
    0| 000AE0 lfd      C89F00D8   1     LFL       fp4=#SPILL10(gr31,216)
    0| 000AE4 lfd      C8BF00E0   1     LFL       fp5=#SPILL11(gr31,224)
    0| 000AE8 ld       E87F0110   1     L8        gr3=#SPILL17(gr31,272)
    0| 000AEC ld       E89F0150   1     L8        gr4=#SPILL25(gr31,336)
    0| 000AF0 ld       E8BF0130   1     L8        gr5=#SPILL21(gr31,304)
    0| 000AF4 ld       E8DF0140   1     L8        gr6=#SPILL23(gr31,320)
    0| 000AF8 ld       E8FF0158   1     L8        gr7=#SPILL26(gr31,344)
    0| 000AFC fmsub    FC24FC78   1     FMS       fp1=fp31,fp4,fp17,fcr
    0| 000B00 ld       E91F0160   1     L8        gr8=#SPILL27(gr31,352)
    0| 000B04 fmsub    FC05FE78   1     FMS       fp0=fp31,fp5,fp25,fcr
    0| 000B08 ld       E93F0120   1     L8        gr9=#SPILL19(gr31,288)
    0| 000B0C rldicr   78601F24   1     SLL8      gr0=gr3,3
    0| 000B10 fnmsub   FC71887C   1     FNMS      fp3=fp17,fp17,fp1,fcr
    0| 000B14 add      7F402214   1     A         gr26=gr0,gr4
    0| 000B18 fnmsub   FC19C83C   1     FNMS      fp0=fp25,fp25,fp0,fcr
    0| 000B1C add      7F202A14   1     A         gr25=gr0,gr5
    0| 000B20 add      7F003214   1     A         gr24=gr0,gr6
    0| 000B24 add      7EE03A14   1     A         gr23=gr0,gr7
    0| 000B28 fmsub    FC44F8F8   1     FMS       fp2=fp31,fp4,fp3,fcr
    0| 000B2C add      7EC04214   1     A         gr22=gr0,gr8
    0| 000B30 fmsub    FC25F838   1     FMS       fp1=fp31,fp5,fp0,fcr
    0| 000B34 add      7EA04A14   1     A         gr21=gr0,gr9
    0| 000B38 fnmsub   FEA318BC   1     FNMS      fp21=fp3,fp3,fp2,fcr
    0| 000B3C fnmsub   FE80007C   2     FNMS      fp20=fp0,fp0,fp1,fcr
    0| 000B40 ori      60210000   2     XNOP      
    0| 000B44 ori      60210000   1     XNOP      
   51|                              CL.86:
   52| 000B48 stfd     DB3F00D0   1     STFL      #SPILL9(gr31,208)=fp25
   56| 000B4C or       7F34CB78   1     LR        gr20=gr25
   53| 000B50 or       7EF3BB78   1     LR        gr19=gr23
   57| 000B54 or       7F52D378   1     LR        gr18=gr26
   53| 000B58 or       7F11C378   1     LR        gr17=gr24
   59| 000B5C or       7EB0AB78   1     LR        gr16=gr21
   58| 000B60 or       7ECFB378   1     LR        gr15=gr22
   52| 000B64 addi     39C00000   1     LI        gr14=0
   52| 000B68 lfd      CB3F00E8   1     LFL       fp25=#SPILL12(gr31,232)
   52|                              CL.87:
   53| 000B6C lfdu     CC130008   1     LFDU      fp0,gr19=d[](gr19,8)
   53| 000B70 fmr      FC40F090   1     LRFL      fp2=fp30
   53| 000B74 fmul     FC200572   2     MFL       fp1=fp0,fp21,fcr
   53| 000B78 fmsub    FC100078   2     FMS       fp0=fp0,fp16,fp1,fcr
   53| 000B7C fnmsub   FC35083C   2     FNMS      fp1=fp1,fp21,fp0,fcr
   53| 000B80 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   53| 000B84 ori      60000000   1
   53| 000B88 fmr      FC40D090   1     LRFL      fp2=fp26
   53| 000B8C lfdu     CE710008   2     LFDU      fp19,gr17=t[].rns0.(gr17,8)
   53| 000B90 fmul     FE4F0072   1     MFL       fp18=fp15,fp1,fcr
   53| 000B94 fmul     FC130532   2     MFL       fp0=fp19,fp20,fcr
   53| 000B98 fmsub    FC2E9838   2     FMS       fp1=fp19,fp14,fp0,fcr
   53| 000B9C fnmsub   FC34007C   2     FNMS      fp1=fp0,fp20,fp1,fcr
   53| 000BA0 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   53| 000BA4 ori      60000000   1
   59| 000BA8 qvfre    10009830   1     QVFRE     fp0=fp19
   57| 000BAC stfdu    DF120008   1     STFDU     gr18,sg[](gr18,8)=fp24
   60| 000BB0 addi     39CE0001   1     AI        gr14=gr14,1
   53| 000BB4 fmul     FC520072   1     MFL       fp2=fp18,fp1,fcr
   60| 000BB8 cmpld    7CAEE040   1     CL8       cr1=gr14,gr28
   55| 000BBC fmsub    FC32E878   1     FMS       fp1=fp29,fp18,fp1,fcr
   59| 000BC0 fmsub    FC73F838   2     FMS       fp3=fp31,fp19,fp0,fcr
   55| 000BC4 fsel     FC21E8AE   2     FSEL      fp1=fp1,fp29,fp2
   59| 000BC8 fnmsub   FC0000FC   2     FNMS      fp0=fp0,fp0,fp3,fcr
   56| 000BCC fsub     FC41E028   2     SFL       fp2=fp1,fp28,fcr
   59| 000BD0 fmsub    FC73F838   2     FMS       fp3=fp31,fp19,fp0,fcr
   56| 000BD4 fsel     FC220F2E   2     FSEL      fp1=fp2,fp1,fp28
   59| 000BD8 fnmsub   FC0000FC   2     FNMS      fp0=fp0,fp0,fp3,fcr
   58| 000BDC fmul     FC5B0072   2     MFL       fp2=fp27,fp1,fcr
   56| 000BE0 stfdu    DC340008   2     STFDU     gr20,kr[](gr20,8)=fp1
   58| 000BE4 fmadd    FC3BB07A   1     FMA       fp1=fp22,fp27,fp1,fcr
   58| 000BE8 fsel     FC2115EE   2     FSEL      fp1=fp1,fp2,fp23
   59| 000BEC fmul     FC590072   2     MFL       fp2=fp25,fp1,fcr
   58| 000BF0 stfdu    DC2F0008   2     STFDU     gr15,kp[](gr15,8)=fp1
   59| 000BF4 fmul     FC220032   1     MFL       fp1=fp2,fp0,fcr
   59| 000BF8 fmsub    FC531078   2     FMS       fp2=fp2,fp19,fp1,fcr
   59| 000BFC fmsub    FC0008B8   2     FMS       fp0=fp1,fp0,fp2,fcr
   59| 000C00 stfdu    DC100008   2     STFDU     gr16,dkpdt[](gr16,8)=fp0
   60| 000C04 bc       4184FF68   1     BT        CL.87,cr1,0x8/llt,taken=80%(80,20)
   60| 000C08 addi     3B7B0001   1     AI        gr27=gr27,1
   60| 000C0C lfd      CB3F00D0   1     LFL       fp25=#SPILL9(gr31,208)
   60| 000C10 cmpld    7CBBF040   1     CL8       cr1=gr27,gr30
    0| 000C14 add      7F5AEA14   1     A         gr26=gr26,gr29
    0| 000C18 add      7F39EA14   1     A         gr25=gr25,gr29
    0| 000C1C add      7F18EA14   1     A         gr24=gr24,gr29
    0| 000C20 add      7EF7EA14   1     A         gr23=gr23,gr29
    0| 000C24 add      7ED6EA14   1     A         gr22=gr22,gr29
    0| 000C28 add      7EB5EA14   1     A         gr21=gr21,gr29
   60| 000C2C bc       4184FF1C   1     BT        CL.86,cr1,0x8/llt,taken=80%(80,20)
   60|                              CL.89:
   60| 000C30 ld       E87F0100   1     L8        gr3=#SPILL15(gr31,256)
    0| 000C34 ld       E81F0108   1     L8        gr0=#SPILL16(gr31,264)
    0| 000C38 ld       E89F0160   1     L8        gr4=#SPILL27(gr31,352)
   60| 000C3C ld       E8BF00F0   1     L8        gr5=#SPILL13(gr31,240)
    0| 000C40 ld       E8DF0158   1     L8        gr6=#SPILL26(gr31,344)
    0| 000C44 ld       E8FF0150   1     L8        gr7=#SPILL25(gr31,336)
    0| 000C48 ld       E91F0140   1     L8        gr8=#SPILL23(gr31,320)
    0| 000C4C ld       E93F0130   1     L8        gr9=#SPILL21(gr31,304)
    0| 000C50 ld       E95F0120   1     L8        gr10=#SPILL19(gr31,288)
   60| 000C54 addi     38630001   1     AI        gr3=gr3,1
    0| 000C58 add      7C802214   1     A         gr4=gr0,gr4
   60| 000C5C std      F87F0100   1     ST8       #SPILL15(gr31,256)=gr3
    0| 000C60 std      F89F0160   1     ST8       #SPILL27(gr31,352)=gr4
   60| 000C64 cmpd     7CA51800   1     C8        cr1=gr5,gr3
    0| 000C68 add      7CC03214   1     A         gr6=gr0,gr6
    0| 000C6C add      7CE03A14   1     A         gr7=gr0,gr7
    0| 000C70 std      F8DF0158   1     ST8       #SPILL26(gr31,344)=gr6
    0| 000C74 std      F8FF0150   1     ST8       #SPILL25(gr31,336)=gr7
    0| 000C78 add      7D004214   1     A         gr8=gr0,gr8
    0| 000C7C add      7D204A14   1     A         gr9=gr0,gr9
    0| 000C80 std      F91F0140   1     ST8       #SPILL23(gr31,320)=gr8
    0| 000C84 std      F93F0130   1     ST8       #SPILL21(gr31,304)=gr9
    0| 000C88 add      7D405214   1     A         gr10=gr0,gr10
    0| 000C8C std      F95F0120   1     ST8       #SPILL19(gr31,288)=gr10
   60| 000C90 bc       4185FE48   1     BT        CL.85,cr1,0x2/gt,taken=80%(80,20)
   60|                              CL.90:
   50| 000C94 ld       E81F01B0   1     L8        gr0=#SPILL37(gr31,432)
   50| 000C98 ld       E87F00F0   1     L8        gr3=#SPILL13(gr31,240)
   50| 000C9C cmpdi    2F200000   1     C8        cr6=gr0,0
   50| 000CA0 cmpd     7CA01800   1     C8        cr1=gr0,gr3
   50| 000CA4 crand    4C392A02   1     CR_N      cr0=cr[61],0x2/gt,0x2/gt,0x2/gt,cr0
   50| 000CA8 bc       408104F4   1     BF        CL.43,cr0,0x2/gt,taken=50%(0,0)
    0| 000CAC ld       E91F0090   1     L8        gr8=#SPILL1(gr31,144)
    0| 000CB0 ld       E95F0098   1     L8        gr10=#SPILL2(gr31,152)
   50| 000CB4 ld       E8BF0388   1     L8        gr5=.jbeg(gr31,904)
   50| 000CB8 ld       E87F0390   1     L8        gr3=.jend(gr31,912)
   60| 000CBC ld       E93F00F8   1     L8        gr9=#SPILL14(gr31,248)
    0| 000CC0 ld       EBBF0088   1     L8        gr29=#SPILL0(gr31,136)
    0| 000CC4 rldicr   79001F24   1     SLL8      gr0=gr8,3
    0| 000CC8 rldicr   795E1F24   1     SLL8      gr30=gr10,3
   50| 000CCC lwa      E8A50002   1     L4A       gr5=jbeg(gr5,0)
   50| 000CD0 lwa      E8C30002   1     L4A       gr6=jend(gr3,0)
   60| 000CD4 addi     38E9FFFF   1     AI        gr7=gr9,-1
    0| 000CD8 mulld    7C8051D2   1     M         gr4=gr0,gr10
   60| 000CDC sradi    7CE30E74   1     SRA8CA    gr3,ca=gr7,1
   50| 000CE0 subf     7CC53050   1     S         gr6=gr6,gr5
   60| 000CE4 addze    7C630194   1     ADDE      gr3,ca=gr3,0,ca
   50| 000CE8 addi     39600000   1     LI        gr11=0
   50| 000CEC addic.   35860001   1     AI_R      gr12,cr0=gr6,1,ca"
   50| 000CF0 std      F97F00F8   1     ST8       #SPILL14(gr31,248)=gr11
   50| 000CF4 std      F99F0100   1     ST8       #SPILL15(gr31,256)=gr12
    0| 000CF8 neg      7C0000D0   1     COMP      gr0=gr0
    0| 000CFC mulld    7CA5F1D2   1     M         gr5=gr5,gr30
    0| 000D00 mulld    7CE4E9D2   1     M         gr7=gr4,gr29
    0| 000D04 bc       40810498   1     BF        CL.43,cr0,0x2/gt,taken=20%(20,80)
    0| 000D08 ld       EB7F00F0   1     L8        gr27=#SPILL13(gr31,240)
    0| 000D0C ld       E93F0378   1     L8        gr9=.ibeg(gr31,888)
    0| 000D10 ld       E91F0380   1     L8        gr8=.iend(gr31,896)
    0| 000D14 ld       EB5F0090   1     L8        gr26=#SPILL1(gr31,144)
    0| 000D18 mulld    7CC051D2   1     M         gr6=gr0,gr10
    0| 000D1C addi     38A5FFF0   1     AI        gr5=gr5,-16
    0| 000D20 subf     7CFE3850   1     S         gr7=gr7,gr30
    0| 000D24 lwa      EB890002   1     L4A       gr28=ibeg(gr9,0)
    0| 000D28 lwa      E8080002   1     L4A       gr0=iend(gr8,0)
    0| 000D2C mulld    7C84D9D2   1     M         gr4=gr4,gr27
    0| 000D30 std      FB9F0108   1     ST8       #SPILL16(gr31,264)=gr28
    0| 000D34 add      7D053A14   1     A         gr8=gr5,gr7
    0| 000D38 rldicr   7B4526E4   1     SLL8      gr5=gr26,4
    0| 000D3C ld       EB1F0118   1     L8        gr24=#SPILL18(gr31,280)
    0| 000D40 ld       EADF00C0   1     L8        gr22=#SPILL7(gr31,192)
    0| 000D44 ld       EA9F0128   1     L8        gr20=#SPILL20(gr31,296)
    0| 000D48 ld       EA5F00B8   1     L8        gr18=#SPILL6(gr31,184)
    0| 000D4C ld       EA1F0138   1     L8        gr16=#SPILL22(gr31,312)
    0| 000D50 ld       E93F0148   1     L8        gr9=#SPILL24(gr31,328)
    0| 000D54 add      7CE64214   1     A         gr7=gr6,gr8
    0| 000D58 subf     7CDC0050   1     S         gr6=gr0,gr28
    0| 000D5C add      7C044214   1     A         gr0=gr4,gr8
    0| 000D60 add      7C843A14   1     A         gr4=gr4,gr7
    0| 000D64 lfd      C81F00E8   1     LFL       fp0=#SPILL12(gr31,232)
    0| 000D68 lfd      C83F00D8   1     LFL       fp1=#SPILL10(gr31,216)
    0| 000D6C lfd      C85F00E0   1     LFL       fp2=#SPILL11(gr31,224)
    0| 000D70 addic.   37A60001   1     AI_R      gr29,cr0=gr6,1,ca"
    0| 000D74 mulld    7F2551D2   1     M         gr25=gr5,gr10
    0| 000D78 fneg     FF400050   1     COMPFL    fp26=fp0
    0| 000D7C qvfre    12000830   1     QVFRE     fp16=fp1
    0| 000D80 add      7EE0C214   1     A         gr23=gr0,gr24
    0| 000D84 qvfre    12201030   1     QVFRE     fp17=fp2
    0| 000D88 std      FB3F0110   1     ST8       #SPILL17(gr31,272)=gr25
    0| 000D8C std      FAFF0118   1     ST8       #SPILL18(gr31,280)=gr23
    0| 000D90 add      7EA4B214   1     A         gr21=gr4,gr22
    0| 000D94 add      7E64A214   1     A         gr19=gr4,gr20
    0| 000D98 std      FABF0120   1     ST8       #SPILL19(gr31,288)=gr21
    0| 000D9C std      FA7F0128   1     ST8       #SPILL20(gr31,296)=gr19
    0| 000DA0 add      7E249214   1     A         gr17=gr4,gr18
    0| 000DA4 add      7DE08214   1     A         gr15=gr0,gr16
    0| 000DA8 std      FA3F0130   1     ST8       #SPILL21(gr31,304)=gr17
    0| 000DAC std      F9FF0138   1     ST8       #SPILL22(gr31,312)=gr15
    0| 000DB0 add      7DC48214   1     A         gr14=gr4,gr16
    0| 000DB4 add      7F644A14   1     A         gr27=gr4,gr9
    0| 000DB8 std      F9DF0140   1     ST8       #SPILL23(gr31,320)=gr14
    0| 000DBC std      FB7F0148   1     ST8       #SPILL24(gr31,328)=gr27
    0| 000DC0 add      7D00A214   1     A         gr8=gr0,gr20
    0| 000DC4 add      7CA0B214   1     A         gr5=gr0,gr22
    0| 000DC8 std      F91F0150   1     ST8       #SPILL25(gr31,336)=gr8
    0| 000DCC std      F8BF0158   1     ST8       #SPILL26(gr31,344)=gr5
    0| 000DD0 add      7CE4C214   1     A         gr7=gr4,gr24
    0| 000DD4 add      7CC09214   1     A         gr6=gr0,gr18
    0| 000DD8 std      F8FF0160   1     ST8       #SPILL27(gr31,352)=gr7
    0| 000DDC std      F8DF0168   1     ST8       #SPILL28(gr31,360)=gr6
    0| 000DE0 add      7C804A14   1     A         gr4=gr0,gr9
    0| 000DE4 addi     38030001   1     AI        gr0=gr3,1
    0| 000DE8 ld       E87F0178   1     L8        gr3=#SPILL30(gr31,376)
    0| 000DEC std      F89F0170   1     ST8       #SPILL29(gr31,368)=gr4
    0| 000DF0 std      F81F01D0   1     ST8       #SPILL41(gr31,464)=gr0
    0| 000DF4 mcrf     4D000000   1     LRCR      cr2=cr0
   52| 000DF8 lfd      C9FF00D8   1     LFL       fp15=#SPILL10(gr31,216)
   52| 000DFC lfd      C9DF00B0   1     LFL       fp14=#SPILL5(gr31,176)
    0| 000E00 lfs      C3230018   1     LFS       fp25=+CONSTANT_AREA(gr3,24)
    0| 000E04 lfs      C303001C   1     LFS       fp24=+CONSTANT_AREA(gr3,28)
    0| 000E08 lfs      C2E30020   1     LFS       fp23=+CONSTANT_AREA(gr3,32)
   50|                              CL.44:
   51| 000E0C addi     38000000   1     LI        gr0=0
   51| 000E10 std      F81F0178   1     ST8       #SPILL30(gr31,376)=gr0
    0| 000E14 bc       408902DC   1     BF        CL.45,cr2,0x2/gt,taken=20%(20,80)
    0| 000E18 lfd      C89F00D8   1     LFL       fp4=#SPILL10(gr31,216)
    0| 000E1C lfd      C8BF00E0   1     LFL       fp5=#SPILL11(gr31,224)
    0| 000E20 ld       E87F0108   1     L8        gr3=#SPILL16(gr31,264)
    0| 000E24 ld       E89F0170   1     L8        gr4=#SPILL29(gr31,368)
    0| 000E28 ld       E8DF0128   1     L8        gr6=#SPILL20(gr31,296)
    0| 000E2C ld       E91F0120   1     L8        gr8=#SPILL19(gr31,288)
    0| 000E30 ld       E95F0130   1     L8        gr10=#SPILL21(gr31,304)
    0| 000E34 fmsub    FC24FC38   1     FMS       fp1=fp31,fp4,fp16,fcr
    0| 000E38 ld       E99F0160   1     L8        gr12=#SPILL27(gr31,352)
    0| 000E3C fmsub    FC05FC78   1     FMS       fp0=fp31,fp5,fp17,fcr
    0| 000E40 ld       EB3F0148   1     L8        gr25=#SPILL24(gr31,328)
    0| 000E44 ld       EAFF0138   1     L8        gr23=#SPILL22(gr31,312)
    0| 000E48 ld       EABF0168   1     L8        gr21=#SPILL28(gr31,360)
    0| 000E4C fnmsub   FC70807C   1     FNMS      fp3=fp16,fp16,fp1,fcr
    0| 000E50 ld       EA7F0118   1     L8        gr19=#SPILL18(gr31,280)
    0| 000E54 fnmsub   FC11883C   1     FNMS      fp0=fp17,fp17,fp0,fcr
    0| 000E58 ld       EA3F0158   1     L8        gr17=#SPILL26(gr31,344)
    0| 000E5C ld       E9FF0150   1     L8        gr15=#SPILL25(gr31,336)
    0| 000E60 ld       E9DF0140   1     L8        gr14=#SPILL23(gr31,320)
    0| 000E64 fmsub    FC44F8F8   1     FMS       fp2=fp31,fp4,fp3,fcr
    0| 000E68 rldicr   78601F24   2     SLL8      gr0=gr3,3
    0| 000E6C fmsub    FC25F838   1     FMS       fp1=fp31,fp5,fp0,fcr
    0| 000E70 add      7CA02214   1     A         gr5=gr0,gr4
    0| 000E74 add      7CE03214   1     A         gr7=gr0,gr6
    0| 000E78 std      F8BF0180   1     ST8       #SPILL31(gr31,384)=gr5
    0| 000E7C fnmsub   FEC318BC   1     FNMS      fp22=fp3,fp3,fp2,fcr
    0| 000E80 std      F8FF0188   1     ST8       #SPILL32(gr31,392)=gr7
    0| 000E84 fnmsub   FEA0007C   1     FNMS      fp21=fp0,fp0,fp1,fcr
    0| 000E88 add      7D204214   1     A         gr9=gr0,gr8
    0| 000E8C add      7D605214   1     A         gr11=gr0,gr10
    0| 000E90 std      F93F0190   1     ST8       #SPILL33(gr31,400)=gr9
    0| 000E94 std      F97F0198   1     ST8       #SPILL34(gr31,408)=gr11
    0| 000E98 add      7F406214   1     A         gr26=gr0,gr12
    0| 000E9C add      7F00CA14   1     A         gr24=gr0,gr25
    0| 000EA0 std      FB5F01A0   1     ST8       #SPILL35(gr31,416)=gr26
    0| 000EA4 std      FB1F01A8   1     ST8       #SPILL36(gr31,424)=gr24
    0| 000EA8 add      7EC0BA14   1     A         gr22=gr0,gr23
    0| 000EAC add      7E80AA14   1     A         gr20=gr0,gr21
    0| 000EB0 std      FADF01B0   1     ST8       #SPILL37(gr31,432)=gr22
    0| 000EB4 std      FA9F01B8   1     ST8       #SPILL38(gr31,440)=gr20
    0| 000EB8 add      7E409A14   1     A         gr18=gr0,gr19
    0| 000EBC add      7E008A14   1     A         gr16=gr0,gr17
    0| 000EC0 std      FA5F01C0   1     ST8       #SPILL39(gr31,448)=gr18
    0| 000EC4 std      FA1F01C8   1     ST8       #SPILL40(gr31,456)=gr16
    0| 000EC8 add      7F807A14   1     A         gr28=gr0,gr15
    0| 000ECC add      7F607214   1     A         gr27=gr0,gr14
   51|                              CL.46:
   52| 000ED0 stfd     DA3F00D0   1     STFL      #SPILL9(gr31,208)=fp17
   53| 000ED4 fmr      FC40F090   1     LRFL      fp2=fp30
   59| 000ED8 ld       EB5F01C8   1     L8        gr26=#SPILL40(gr31,456)
   53| 000EDC ld       EB3F01C0   1     L8        gr25=#SPILL39(gr31,448)
   53| 000EE0 ld       EB1F0180   1     L8        gr24=#SPILL31(gr31,384)
   59| 000EE4 ld       EAFF0190   1     L8        gr23=#SPILL33(gr31,400)
   56| 000EE8 or       7F96E378   1     LR        gr22=gr28
   57| 000EEC ld       EABF01B0   1     L8        gr21=#SPILL37(gr31,432)
   58| 000EF0 ld       EA9F01B8   1     L8        gr20=#SPILL38(gr31,440)
   52| 000EF4 stfd     DA1F00F0   1     STFL      #SPILL13(gr31,240)=fp16
   58| 000EF8 ld       EA7F0198   1     L8        gr19=#SPILL34(gr31,408)
   53| 000EFC ld       EA5F01A0   1     L8        gr18=#SPILL35(gr31,416)
   53| 000F00 ld       EA3F01A8   1     L8        gr17=#SPILL36(gr31,424)
   56| 000F04 ld       EA1F0188   1     L8        gr16=#SPILL32(gr31,392)
   57| 000F08 or       7F6FDB78   1     LR        gr15=gr27
   52| 000F0C addi     39C00000   1     LI        gr14=0
   52| 000F10 lfd      CA3F00E0   1     LFL       fp17=#SPILL11(gr31,224)
   52| 000F14 lfd      CA1F00E8   1     LFL       fp16=#SPILL12(gr31,232)
    0| 000F18 ori      60210000   1     XNOP      
    0| 000F1C ori      60210000   1     XNOP      
    0| 000F20 ori      60210000   1     XNOP      
   52|                              CL.48:
   53| 000F24 lfdu     CC110008   1     LFDU      fp0,gr17=d[](gr17,8)
   53| 000F28 fmul     FC2005B2   1     MFL       fp1=fp0,fp22,fcr
   53| 000F2C fmsub    FC0F0078   2     FMS       fp0=fp0,fp15,fp1,fcr
   53| 000F30 fnmsub   FC36083C   2     FNMS      fp1=fp1,fp22,fp0,fcr
   53| 000F34 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   53| 000F38 ori      60000000   1
   53| 000F3C fmr      FC40D090   1     LRFL      fp2=fp26
   53| 000F40 lfdu     CE920008   2     LFDU      fp20,gr18=t[].rns0.(gr18,8)
   53| 000F44 fmul     FE6E0072   1     MFL       fp19=fp14,fp1,fcr
   53| 000F48 fmul     FC140572   2     MFL       fp0=fp20,fp21,fcr
   53| 000F4C fmsub    FC31A038   2     FMS       fp1=fp20,fp17,fp0,fcr
   53| 000F50 fnmsub   FC35007C   2     FNMS      fp1=fp0,fp21,fp1,fcr
   53| 000F54 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   53| 000F58 ori      60000000   1
   59| 000F5C qvfre    1000A030   1     QVFRE     fp0=fp20
   57| 000F60 stfdu    DF2F0008   1     STFDU     gr15,sg[](gr15,8)=fp25
   53| 000F64 fmr      FC40F090   1     LRFL      fp2=fp30
   53| 000F68 lfdu     CC780008   1     LFDU      fp3,gr24=d[](gr24,8)
   53| 000F6C fmul     FC930072   1     MFL       fp4=fp19,fp1,fcr
   53| 000F70 lfdu     CE590008   1     LFDU      fp18,gr25=t[].rns0.(gr25,8)
   55| 000F74 fmsub    FC33E878   1     FMS       fp1=fp29,fp19,fp1,fcr
   59| 000F78 fmsub    FCB4F838   2     FMS       fp5=fp31,fp20,fp0,fcr
   53| 000F7C fmul     FCC305B2   2     MFL       fp6=fp3,fp22,fcr
   55| 000F80 fsel     FC81E92E   2     FSEL      fp4=fp1,fp29,fp4
   59| 000F84 fnmsub   FC00017C   2     FNMS      fp0=fp0,fp0,fp5,fcr
   53| 000F88 fmsub    FC2F19B8   2     FMS       fp1=fp3,fp15,fp6,fcr
   56| 000F8C fsub     FC64E028   2     SFL       fp3=fp4,fp28,fcr
   59| 000F90 fmsub    FCB4F838   2     FMS       fp5=fp31,fp20,fp0,fcr
   53| 000F94 fnmsub   FC36307C   2     FNMS      fp1=fp6,fp22,fp1,fcr
   56| 000F98 fsel     FC63272E   2     FSEL      fp3=fp3,fp4,fp28
   59| 000F9C fnmsub   FC00017C   2     FNMS      fp0=fp0,fp0,fp5,fcr
   58| 000FA0 fmul     FC9B00F2   2     MFL       fp4=fp27,fp3,fcr
   56| 000FA4 stfdu    DC700008   2     STFDU     gr16,kr[](gr16,8)=fp3
   58| 000FA8 fmadd    FC7BB8FA   1     FMA       fp3=fp23,fp27,fp3,fcr
   58| 000FAC fsel     FC63262E   2     FSEL      fp3=fp3,fp4,fp24
   59| 000FB0 fmul     FC9000F2   2     MFL       fp4=fp16,fp3,fcr
   58| 000FB4 stfdu    DC730008   2     STFDU     gr19,kp[](gr19,8)=fp3
   59| 000FB8 fmul     FC640032   1     MFL       fp3=fp4,fp0,fcr
   59| 000FBC fmsub    FC9420F8   2     FMS       fp4=fp4,fp20,fp3,fcr
   59| 000FC0 fmsub    FC001938   2     FMS       fp0=fp3,fp0,fp4,fcr
   59| 000FC4 stfdu    DC170008   2     STFDU     gr23,dkpdt[](gr23,8)=fp0
   53| 000FC8 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   53| 000FCC ori      60000000   1
   53| 000FD0 fmul     FC120572   1     MFL       fp0=fp18,fp21,fcr
   53| 000FD4 fmul     FE8E0072   2     MFL       fp20=fp14,fp1,fcr
   53| 000FD8 fmr      FC40D090   2     LRFL      fp2=fp26
   53| 000FDC fmsub    FC319038   2     FMS       fp1=fp18,fp17,fp0,fcr
   53| 000FE0 fnmsub   FC35007C   2     FNMS      fp1=fp0,fp21,fp1,fcr
   53| 000FE4 bl       48000001   1     CALLN     fp1=__xl_pow,2,fp1,fp2,#MX_TEMP1",__xl_pow",gr1,gr31,cr[01567]",gr0",gr3"-gr12",fp0",fp2"-fp13",mq",lr",xer",fsr",ca",ctr"
   53| 000FE8 ori      60000000   1
   59| 000FEC qvfre    10009030   1     QVFRE     fp0=fp18
   57| 000FF0 stfdu    DF350008   1     STFDU     gr21,sg[](gr21,8)=fp25
   53| 000FF4 fmr      FC40F090   1     LRFL      fp2=fp30
   60| 000FF8 addi     39CE0001   1     AI        gr14=gr14,1
   53| 000FFC fmul     FC740072   1     MFL       fp3=fp20,fp1,fcr
   60| 001000 cmpld    7C2EE840   1     CL8       cr0=gr14,gr29
   55| 001004 fmsub    FC34E878   1     FMS       fp1=fp29,fp20,fp1,fcr
   59| 001008 fmsub    FC92F838   2     FMS       fp4=fp31,fp18,fp0,fcr
   55| 00100C fsel     FC21E8EE   2     FSEL      fp1=fp1,fp29,fp3
   59| 001010 fnmsub   FC00013C   2     FNMS      fp0=fp0,fp0,fp4,fcr
   56| 001014 fsub     FC61E028   2     SFL       fp3=fp1,fp28,fcr
   59| 001018 fmsub    FC92F838   2     FMS       fp4=fp31,fp18,fp0,fcr
   56| 00101C fsel     FC230F2E   2     FSEL      fp1=fp3,fp1,fp28
   59| 001020 fnmsub   FC00013C   2     FNMS      fp0=fp0,fp0,fp4,fcr
   58| 001024 fmul     FC7B0072   2     MFL       fp3=fp27,fp1,fcr
   56| 001028 stfdu    DC360008   2     STFDU     gr22,kr[](gr22,8)=fp1
   58| 00102C fmadd    FC3BB87A   1     FMA       fp1=fp23,fp27,fp1,fcr
   58| 001030 fsel     FC211E2E   2     FSEL      fp1=fp1,fp3,fp24
   59| 001034 fmul     FC700072   2     MFL       fp3=fp16,fp1,fcr
   58| 001038 stfdu    DC340008   2     STFDU     gr20,kp[](gr20,8)=fp1
   59| 00103C fmul     FC230032   1     MFL       fp1=fp3,fp0,fcr
   59| 001040 fmsub    FC721878   2     FMS       fp3=fp3,fp18,fp1,fcr
   59| 001044 fmsub    FC0008F8   2     FMS       fp0=fp1,fp0,fp3,fcr
   59| 001048 stfdu    DC1A0008   2     STFDU     gr26,dkpdt[](gr26,8)=fp0
   60| 00104C bc       4180FED8   1     BT        CL.48,cr0,0x8/llt,taken=80%(80,20)
   60| 001050 ld       E87F0178   1     L8        gr3=#SPILL30(gr31,376)
    0| 001054 ld       E81F0180   1     L8        gr0=#SPILL31(gr31,384)
   60| 001058 ld       E89F0100   1     L8        gr4=#SPILL15(gr31,256)
    0| 00105C ld       E8BF0188   1     L8        gr5=#SPILL32(gr31,392)
    0| 001060 ld       E8DF0190   1     L8        gr6=#SPILL33(gr31,400)
    0| 001064 ld       E8FF0198   1     L8        gr7=#SPILL34(gr31,408)
    0| 001068 ld       E91F01A0   1     L8        gr8=#SPILL35(gr31,416)
    0| 00106C ld       E93F01A8   1     L8        gr9=#SPILL36(gr31,424)
    0| 001070 ld       E95F01B0   1     L8        gr10=#SPILL37(gr31,432)
    0| 001074 ld       E97F01B8   1     L8        gr11=#SPILL38(gr31,440)
    0| 001078 ld       E99F01C0   1     L8        gr12=#SPILL39(gr31,448)
    0| 00107C ld       EB5F01C8   1     L8        gr26=#SPILL40(gr31,456)
   60| 001080 addi     38630001   1     AI        gr3=gr3,1
    0| 001084 add      7C00F214   1     A         gr0=gr0,gr30
   60| 001088 std      F87F0178   1     ST8       #SPILL30(gr31,376)=gr3
    0| 00108C std      F81F0180   1     ST8       #SPILL31(gr31,384)=gr0
   60| 001090 cmpld    7C232040   1     CL8       cr0=gr3,gr4
    0| 001094 add      7CA5F214   1     A         gr5=gr5,gr30
    0| 001098 add      7CC6F214   1     A         gr6=gr6,gr30
    0| 00109C std      F8BF0188   1     ST8       #SPILL32(gr31,392)=gr5
    0| 0010A0 std      F8DF0190   1     ST8       #SPILL33(gr31,400)=gr6
    0| 0010A4 add      7CE7F214   1     A         gr7=gr7,gr30
    0| 0010A8 add      7D08F214   1     A         gr8=gr8,gr30
    0| 0010AC std      F8FF0198   1     ST8       #SPILL34(gr31,408)=gr7
    0| 0010B0 std      F91F01A0   1     ST8       #SPILL35(gr31,416)=gr8
    0| 0010B4 add      7D29F214   1     A         gr9=gr9,gr30
    0| 0010B8 add      7D4AF214   1     A         gr10=gr10,gr30
    0| 0010BC std      F93F01A8   1     ST8       #SPILL36(gr31,424)=gr9
    0| 0010C0 std      F95F01B0   1     ST8       #SPILL37(gr31,432)=gr10
    0| 0010C4 add      7D6BF214   1     A         gr11=gr11,gr30
    0| 0010C8 add      7D8CF214   1     A         gr12=gr12,gr30
    0| 0010CC add      7F5AF214   1     A         gr26=gr26,gr30
    0| 0010D0 std      F97F01B8   1     ST8       #SPILL38(gr31,440)=gr11
    0| 0010D4 std      F99F01C0   1     ST8       #SPILL39(gr31,448)=gr12
   60| 0010D8 lfd      CA1F00F0   1     LFL       fp16=#SPILL13(gr31,240)
   60| 0010DC lfd      CA3F00D0   1     LFL       fp17=#SPILL9(gr31,208)
    0| 0010E0 std      FB5F01C8   1     ST8       #SPILL40(gr31,456)=gr26
    0| 0010E4 add      7F9CF214   1     A         gr28=gr28,gr30
    0| 0010E8 add      7F7BF214   1     A         gr27=gr27,gr30
   60| 0010EC bc       4180FDE4   1     BT        CL.46,cr0,0x8/llt,taken=80%(80,20)
   60|                              CL.45:
   60| 0010F0 ld       E87F00F8   1     L8        gr3=#SPILL14(gr31,248)
    0| 0010F4 ld       E81F0110   1     L8        gr0=#SPILL17(gr31,272)
    0| 0010F8 ld       E89F0118   1     L8        gr4=#SPILL18(gr31,280)
   60| 0010FC ld       E8BF01D0   1     L8        gr5=#SPILL41(gr31,464)
    0| 001100 ld       E8DF0120   1     L8        gr6=#SPILL19(gr31,288)
    0| 001104 ld       E8FF0128   1     L8        gr7=#SPILL20(gr31,296)
    0| 001108 ld       E91F0130   1     L8        gr8=#SPILL21(gr31,304)
    0| 00110C ld       E93F0138   1     L8        gr9=#SPILL22(gr31,312)
    0| 001110 ld       E95F0140   1     L8        gr10=#SPILL23(gr31,320)
    0| 001114 ld       E97F0148   1     L8        gr11=#SPILL24(gr31,328)
    0| 001118 ld       E99F0150   1     L8        gr12=#SPILL25(gr31,336)
    0| 00111C ld       EB9F0158   1     L8        gr28=#SPILL26(gr31,344)
    0| 001120 ld       EB7F0160   1     L8        gr27=#SPILL27(gr31,352)
    0| 001124 ld       EB5F0168   1     L8        gr26=#SPILL28(gr31,360)
    0| 001128 ld       EB3F0170   1     L8        gr25=#SPILL29(gr31,368)
   60| 00112C addi     38630001   1     AI        gr3=gr3,1
    0| 001130 add      7C802214   1     A         gr4=gr0,gr4
   60| 001134 std      F87F00F8   1     ST8       #SPILL14(gr31,248)=gr3
    0| 001138 std      F89F0118   1     ST8       #SPILL18(gr31,280)=gr4
   60| 00113C cmpld    7C232840   1     CL8       cr0=gr3,gr5
    0| 001140 add      7CC03214   1     A         gr6=gr0,gr6
    0| 001144 add      7CE03A14   1     A         gr7=gr0,gr7
    0| 001148 std      F8DF0120   1     ST8       #SPILL19(gr31,288)=gr6
    0| 00114C std      F8FF0128   1     ST8       #SPILL20(gr31,296)=gr7
    0| 001150 add      7D004214   1     A         gr8=gr0,gr8
    0| 001154 add      7D204A14   1     A         gr9=gr0,gr9
    0| 001158 std      F91F0130   1     ST8       #SPILL21(gr31,304)=gr8
    0| 00115C std      F93F0138   1     ST8       #SPILL22(gr31,312)=gr9
    0| 001160 add      7D405214   1     A         gr10=gr0,gr10
    0| 001164 add      7D605A14   1     A         gr11=gr0,gr11
    0| 001168 std      F95F0140   1     ST8       #SPILL23(gr31,320)=gr10
    0| 00116C std      F97F0148   1     ST8       #SPILL24(gr31,328)=gr11
    0| 001170 add      7D806214   1     A         gr12=gr0,gr12
    0| 001174 add      7F80E214   1     A         gr28=gr0,gr28
    0| 001178 std      F99F0150   1     ST8       #SPILL25(gr31,336)=gr12
    0| 00117C std      FB9F0158   1     ST8       #SPILL26(gr31,344)=gr28
    0| 001180 add      7F60DA14   1     A         gr27=gr0,gr27
    0| 001184 add      7F40D214   1     A         gr26=gr0,gr26
    0| 001188 std      FB7F0160   1     ST8       #SPILL27(gr31,352)=gr27
    0| 00118C std      FB5F0168   1     ST8       #SPILL28(gr31,360)=gr26
    0| 001190 add      7F20CA14   1     A         gr25=gr0,gr25
    0| 001194 std      FB3F0170   1     ST8       #SPILL29(gr31,368)=gr25
   60| 001198 bc       4180FC74   1     BT        CL.44,cr0,0x8/llt,taken=80%(80,20)
   60|                              CL.43:
   61| 00119C bc       40900138   1     BF        CL.78,cr4,0x1/lt,taken=50%(0,0)
   61| 0011A0 ld       E89F0388   1     L8        gr4=.jbeg(gr31,904)
   61| 0011A4 ld       E8BF0390   1     L8        gr5=.jend(gr31,912)
   61| 0011A8 addi     38600000   1     LI        gr3=0
   61| 0011AC lwa      E8840002   1     L4A       gr4=jbeg(gr4,0)
   61| 0011B0 lwa      E8050002   1     L4A       gr0=jend(gr5,0)
   61| 0011B4 subf     7CA40050   1     S         gr5=gr0,gr4
   61| 0011B8 addic.   34050001   1     AI_R      gr0,cr0=gr5,1,ca"
    0| 0011BC bc       40810618   1     BF        CL.321,cr0,0x2/gt,taken=50%(0,0)
    0| 0011C0 ld       EB5F0090   1     L8        gr26=#SPILL1(gr31,144)
    0| 0011C4 ld       EB3F0098   1     L8        gr25=#SPILL2(gr31,152)
    0| 0011C8 ld       EB1F0088   1     L8        gr24=#SPILL0(gr31,136)
    0| 0011CC ld       E91F0378   1     L8        gr8=.ibeg(gr31,888)
    0| 0011D0 ld       EAFF00C8   1     L8        gr23=#SPILL8(gr31,200)
    0| 0011D4 ld       EADF00C0   1     L8        gr22=#SPILL7(gr31,192)
    0| 0011D8 rldicr   7B451F24   1     SLL8      gr5=gr26,3
    0| 0011DC rldicr   7B291F24   1     SLL8      gr9=gr25,3
    0| 0011E0 mulld    7D45C9D2   1     M         gr10=gr5,gr25
    0| 0011E4 neg      7CE500D0   1     COMP      gr7=gr5
    0| 0011E8 ld       E8BF0380   1     L8        gr5=.iend(gr31,896)
    0| 0011EC mulld    7C8449D2   1     M         gr4=gr4,gr9
    0| 0011F0 mulld    7CCAC1D2   1     M         gr6=gr10,gr24
    0| 0011F4 mulld    7CE7C9D2   1     M         gr7=gr7,gr25
    0| 0011F8 lwa      E9680002   1     L4A       gr11=ibeg(gr8,0)
    0| 0011FC lwa      E9850002   1     L4A       gr12=iend(gr5,0)
    0| 001200 addi     3884FFF0   1     AI        gr4=gr4,-16
    0| 001204 subf     7CA93050   1     S         gr5=gr6,gr9
    0| 001208 ld       EABF00B8   1     L8        gr21=#SPILL6(gr31,184)
    0| 00120C add      7C842A14   1     A         gr4=gr4,gr5
    0| 001210 add      7FC43A14   1     A         gr30=gr4,gr7
    0| 001214 subf     7C8B6050   1     S         gr4=gr12,gr11
    0| 001218 add      7FB7F214   1     A         gr29=gr23,gr30
    0| 00121C add      7F96F214   1     A         gr28=gr22,gr30
    0| 001220 add      7F75F214   1     A         gr27=gr21,gr30
    0| 001224 addic.   34840001   1     AI_R      gr4,cr0=gr4,1,ca"
   61|                              CL.73:
    0| 001228 rldicr   79651F24   1     SLL8      gr5=gr11,3
   62| 00122C addi     38800000   1     LI        gr4=0
    0| 001230 bc       40810084   1     BF        CL.77,cr0,0x2/gt,taken=20%(20,80)
    0| 001234 subfic   20CB0001   1     SFI       gr6=1,gr11,ca"
    0| 001238 add      7F45F214   1     A         gr26=gr5,gr30
    0| 00123C add      7F266214   1     A         gr25=gr6,gr12
    0| 001240 add      7F05E214   1     A         gr24=gr5,gr28
    0| 001244 add      7EE5DA14   1     A         gr23=gr5,gr27
    0| 001248 add      7EC5EA14   1     A         gr22=gr5,gr29
    0| 00124C ld       EABF0370   1     L8        gr21=.dkedt(gr31,880)
   62|                              CL.74:
   64| 001250 or       7EE5BB78   1     LR        gr5=gr23
   65| 001254 or       7F06C378   1     LR        gr6=gr24
    0| 001258 mtspr    7F2903A6   1     LCTR      ctr=gr25
   64| 00125C lfdu     CC050008   1     LFDU      fp0,gr5=kp[](gr5,8)
   65| 001260 lfdu     CC260008   1     LFDU      fp1,gr6=dkpdt[](gr6,8)
   65| 001264 add      7CF5D214   1     A         gr7=gr21,gr26
   64| 001268 or       7EC8B378   1     LR        gr8=gr22
    0| 00126C bc       42400024   1     BCF       ctr=CL.466,taken=0%(0,100)
    0| 001270 ori      60210000   1     XNOP      
    0|                              CL.467:
   64| 001274 lfdu     CC450008   1     LFDU      fp2,gr5=kp[](gr5,8)
   64| 001278 stfdu    DC080008   1     STFDU     gr8,km[](gr8,8)=fp0
    0| 00127C fmr      FC000890   1     LRFL      fp0=fp1
   65| 001280 lfdu     CC260008   1     LFDU      fp1,gr6=dkpdt[](gr6,8)
   65| 001284 stfdu    DC070008   1     STFDU     gr7,dkedt[](gr7,8)=fp0
    0| 001288 fmr      FC001090   1     LRFL      fp0=fp2
    0| 00128C bc       4200FFE8   1     BCT       ctr=CL.467,taken=100%(100,0)
    0|                              CL.466:
   65| 001290 stfdu    DC270008   1     STFDU     gr7,dkedt[](gr7,8)=fp1
   67| 001294 addi     38840001   1     AI        gr4=gr4,1
   64| 001298 stfdu    DC080008   1     STFDU     gr8,km[](gr8,8)=fp0
   67| 00129C cmpld    7CA40040   1     CL8       cr1=gr4,gr0
    0| 0012A0 add      7F5A4A14   1     A         gr26=gr26,gr9
    0| 0012A4 add      7F184A14   1     A         gr24=gr24,gr9
    0| 0012A8 add      7EF74A14   1     A         gr23=gr23,gr9
    0| 0012AC add      7ED64A14   1     A         gr22=gr22,gr9
   67| 0012B0 bc       4184FFA0   1     BT        CL.74,cr1,0x8/llt,taken=80%(80,20)
   67|                              CL.77:
   68| 0012B4 ld       E89F00A8   1     L8        gr4=#SPILL4(gr31,168)
   68| 0012B8 addi     38630001   1     AI        gr3=gr3,1
    0| 0012BC add      7FCAF214   1     A         gr30=gr10,gr30
    0| 0012C0 add      7F6ADA14   1     A         gr27=gr10,gr27
    0| 0012C4 add      7F8AE214   1     A         gr28=gr10,gr28
    0| 0012C8 add      7FAAEA14   1     A         gr29=gr10,gr29
   68| 0012CC cmpd     7CA41800   1     C8        cr1=gr4,gr3
   68| 0012D0 bc       4185FF58   1     BT        CL.73,cr1,0x2/gt,taken=80%(80,20)
   68|                              CL.78:
   61| 0012D4 bc       408D0450   1     BF        CL.116,cr3,0x2/gt,taken=30%(30,70)
    0| 0012D8 ld       E93F0090   1     L8        gr9=#SPILL1(gr31,144)
    0| 0012DC ld       EBDF0098   1     L8        gr30=#SPILL2(gr31,152)
   61| 0012E0 ld       E8DF0388   1     L8        gr6=.jbeg(gr31,904)
   61| 0012E4 ld       E87F0390   1     L8        gr3=.jend(gr31,912)
   68| 0012E8 ld       E99F00A0   1     L8        gr12=#SPILL3(gr31,160)
    0| 0012EC ld       EBBF0088   1     L8        gr29=#SPILL0(gr31,136)
    0| 0012F0 rldicr   79251F24   1     SLL8      gr5=gr9,3
    0| 0012F4 rldicr   7BC01F24   1     SLL8      gr0=gr30,3
   61| 0012F8 lwa      E8C60002   1     L4A       gr6=jbeg(gr6,0)
   61| 0012FC lwa      E8E30002   1     L4A       gr7=jend(gr3,0)
   68| 001300 addi     390CFFFF   1     AI        gr8=gr12,-1
    0| 001304 mulld    7C85F1D2   1     M         gr4=gr5,gr30
   68| 001308 sradi    7D031674   1     SRA8CA    gr3,ca=gr8,2
   61| 00130C subf     7CE63850   1     S         gr7=gr7,gr6
   68| 001310 addze    7C630194   1     ADDE      gr3,ca=gr3,0,ca
   61| 001314 addic.   37870001   1     AI_R      gr28,cr0=gr7,1,ca"
   61| 001318 addi     3B600000   1     LI        gr27=0
   61| 00131C std      FB9F0088   1     ST8       #SPILL0(gr31,136)=gr28
   61| 001320 std      FB7F0098   1     ST8       #SPILL2(gr31,152)=gr27
    0| 001324 mulld    7D44E9D2   1     M         gr10=gr4,gr29
    0| 001328 mulld    7D6031D2   1     M         gr11=gr0,gr6
    0| 00132C bc       408103F8   1     BF        CL.116,cr0,0x2/gt,taken=20%(20,80)
    0| 001330 ld       E99F00A8   1     L8        gr12=#SPILL4(gr31,168)
    0| 001334 ld       E91F0378   1     L8        gr8=.ibeg(gr31,888)
    0| 001338 ld       EB3F0090   1     L8        gr25=#SPILL1(gr31,144)
    0| 00133C ld       E8FF0380   1     L8        gr7=.iend(gr31,896)
    0| 001340 neg      7CC500D0   1     COMP      gr6=gr5
    0| 001344 rldicr   792526E4   1     SLL8      gr5=gr9,4
    0| 001348 mulld    7D2461D2   1     M         gr9=gr4,gr12
    0| 00134C addi     396BFFF0   1     AI        gr11=gr11,-16
    0| 001350 subf     7D405050   1     S         gr10=gr10,gr0
    0| 001354 lwa      EBA80002   1     L4A       gr29=ibeg(gr8,0)
    0| 001358 rldicr   7B282EA4   1     SLL8      gr8=gr25,5
    0| 00135C ld       EAFF00C0   1     L8        gr23=#SPILL7(gr31,192)
    0| 001360 ld       EABF00B8   1     L8        gr21=#SPILL6(gr31,184)
    0| 001364 ld       EA7F00C8   1     L8        gr19=#SPILL8(gr31,200)
    0| 001368 add      7D4A5A14   1     A         gr10=gr10,gr11
    0| 00136C std      FBBF00A0   1     ST8       #SPILL3(gr31,160)=gr29
    0| 001370 lwa      EB470002   1     L4A       gr26=iend(gr7,0)
    0| 001374 mulld    7CE6F1D2   1     M         gr7=gr6,gr30
    0| 001378 std      FB5F00A8   1     ST8       #SPILL4(gr31,168)=gr26
    0| 00137C mulld    7CC5F1D2   1     M         gr6=gr5,gr30
    0| 001380 add      7F095214   1     A         gr24=gr9,gr10
    0| 001384 mulld    7FDE41D2   1     M         gr30=gr30,gr8
    0| 001388 std      FB1F0090   1     ST8       #SPILL1(gr31,144)=gr24
    0| 00138C std      FBDF00C8   1     ST8       #SPILL8(gr31,200)=gr30
    0| 001390 add      7ED7C214   1     A         gr22=gr23,gr24
    0| 001394 add      7E95C214   1     A         gr20=gr21,gr24
    0| 001398 std      FADF00B0   1     ST8       #SPILL5(gr31,176)=gr22
    0| 00139C std      FA9F00B8   1     ST8       #SPILL6(gr31,184)=gr20
    0| 0013A0 add      7E53C214   1     A         gr18=gr19,gr24
    0| 0013A4 subf     7CBDD050   1     S         gr5=gr26,gr29
    0| 0013A8 std      FA5F00C0   1     ST8       #SPILL7(gr31,192)=gr18
    0| 0013AC add      7E27B214   1     A         gr17=gr7,gr22
    0| 0013B0 add      7E06B214   1     A         gr16=gr6,gr22
    0| 0013B4 std      FA3F00D0   1     ST8       #SPILL9(gr31,208)=gr17
    0| 0013B8 std      FA1F00D8   1     ST8       #SPILL10(gr31,216)=gr16
    0| 0013BC add      7DE4B214   1     A         gr15=gr4,gr22
    0| 0013C0 add      7DC6C214   1     A         gr14=gr6,gr24
    0| 0013C4 std      F9FF00E0   1     ST8       #SPILL11(gr31,224)=gr15
    0| 0013C8 std      F9DF00E8   1     ST8       #SPILL12(gr31,232)=gr14
    0| 0013CC add      7D26A214   1     A         gr9=gr6,gr20
    0| 0013D0 add      7D87C214   1     A         gr12=gr7,gr24
    0| 0013D4 std      F93F00F0   1     ST8       #SPILL13(gr31,240)=gr9
    0| 0013D8 std      F99F00F8   1     ST8       #SPILL14(gr31,248)=gr12
    0| 0013DC add      7D64C214   1     A         gr11=gr4,gr24
    0| 0013E0 add      7D47A214   1     A         gr10=gr7,gr20
    0| 0013E4 std      F97F0100   1     ST8       #SPILL15(gr31,256)=gr11
    0| 0013E8 std      F95F0108   1     ST8       #SPILL16(gr31,264)=gr10
    0| 0013EC add      7D079214   1     A         gr8=gr7,gr18
    0| 0013F0 add      7CE49214   1     A         gr7=gr4,gr18
    0| 0013F4 std      F91F0110   1     ST8       #SPILL17(gr31,272)=gr8
    0| 0013F8 std      F8FF0118   1     ST8       #SPILL18(gr31,280)=gr7
    0| 0013FC add      7F269214   1     A         gr25=gr6,gr18
    0| 001400 add      7CC4A214   1     A         gr6=gr4,gr20
    0| 001404 std      FB3F0120   1     ST8       #SPILL19(gr31,288)=gr25
    0| 001408 std      F8DF0128   1     ST8       #SPILL20(gr31,296)=gr6
    0| 00140C addi     38830001   1     AI        gr4=gr3,1
    0| 001410 addic.   34650001   1     AI_R      gr3,cr0=gr5,1,ca"
    0| 001414 std      F89F0130   1     ST8       #SPILL21(gr31,304)=gr4
   61|                              CL.50:
    0| 001418 ld       E89F00A0   1     L8        gr4=#SPILL3(gr31,160)
   62| 00141C addi     38A00000   1     LI        gr5=0
   62| 001420 std      F8BF0138   1     ST8       #SPILL22(gr31,312)=gr5
    0| 001424 rldicr   78831F24   1     SLL8      gr3=gr4,3
    0| 001428 bc       40810220   1     BF        CL.51,cr0,0x2/gt,taken=20%(20,80)
    0| 00142C ld       E91F00A8   1     L8        gr8=#SPILL4(gr31,168)
    0| 001430 ld       EABF00B8   1     L8        gr21=#SPILL6(gr31,184)
    0| 001434 ld       EA9F00B0   1     L8        gr20=#SPILL5(gr31,176)
    0| 001438 ld       EA7F00C0   1     L8        gr19=#SPILL7(gr31,192)
    0| 00143C ld       EA5F0118   1     L8        gr18=#SPILL18(gr31,280)
    0| 001440 ld       EA3F00E0   1     L8        gr17=#SPILL11(gr31,224)
    0| 001444 ld       EA1F00D8   1     L8        gr16=#SPILL10(gr31,216)
    0| 001448 ld       E9FF0120   1     L8        gr15=#SPILL19(gr31,288)
    0| 00144C ld       E9DF0110   1     L8        gr14=#SPILL17(gr31,272)
    0| 001450 subfic   20840001   1     SFI       gr4=1,gr4,ca"
    0| 001454 ld       E8DF00E8   1     L8        gr6=#SPILL12(gr31,232)
    0| 001458 add      7D244214   1     A         gr9=gr4,gr8
    0| 00145C ld       E95F0100   1     L8        gr10=#SPILL15(gr31,256)
    0| 001460 std      F93F0148   1     ST8       #SPILL24(gr31,328)=gr9
    0| 001464 ld       E99F00F8   1     L8        gr12=#SPILL14(gr31,248)
    0| 001468 ld       EBBF0090   1     L8        gr29=#SPILL1(gr31,144)
    0| 00146C ld       EB7F0128   1     L8        gr27=#SPILL20(gr31,296)
    0| 001470 ld       EB3F00F0   1     L8        gr25=#SPILL13(gr31,240)
    0| 001474 ld       E89F0108   1     L8        gr4=#SPILL16(gr31,264)
    0| 001478 add      7EC3AA14   1     A         gr22=gr3,gr21
    0| 00147C add      7EA3A214   1     A         gr21=gr3,gr20
    0| 001480 add      7E839A14   1     A         gr20=gr3,gr19
    0| 001484 add      7E639214   1     A         gr19=gr3,gr18
    0| 001488 add      7E438A14   1     A         gr18=gr3,gr17
    0| 00148C add      7E238214   1     A         gr17=gr3,gr16
    0| 001490 add      7E037A14   1     A         gr16=gr3,gr15
    0| 001494 add      7DE37214   1     A         gr15=gr3,gr14
    0| 001498 ld       E9DF00D0   1     L8        gr14=#SPILL9(gr31,208)
    0| 00149C add      7CE33214   1     A         gr7=gr3,gr6
    0| 0014A0 add      7D635214   1     A         gr11=gr3,gr10
    0| 0014A4 std      F8FF0140   1     ST8       #SPILL23(gr31,320)=gr7
    0| 0014A8 std      F97F0150   1     ST8       #SPILL25(gr31,336)=gr11
    0| 0014AC add      7FC36214   1     A         gr30=gr3,gr12
    0| 0014B0 add      7F83EA14   1     A         gr28=gr3,gr29
    0| 0014B4 std      FBDF0158   1     ST8       #SPILL26(gr31,344)=gr30
    0| 0014B8 std      FB9F0160   1     ST8       #SPILL27(gr31,352)=gr28
    0| 0014BC add      7F43DA14   1     A         gr26=gr3,gr27
    0| 0014C0 add      7F03CA14   1     A         gr24=gr3,gr25
    0| 0014C4 std      FB5F0168   1     ST8       #SPILL28(gr31,360)=gr26
    0| 0014C8 add      7EE32214   1     A         gr23=gr3,gr4
    0| 0014CC add      7DCE1A14   1     A         gr14=gr14,gr3
    0| 0014D0 ld       E87F0370   1     L8        gr3=.dkedt(gr31,880)
    0| 0014D4 std      F87F0170   1     ST8       #SPILL29(gr31,368)=gr3
   62|                              CL.52:
   64| 0014D8 ld       E8BF0168   1     L8        gr5=#SPILL28(gr31,360)
   65| 0014DC ld       EB9F0158   1     L8        gr28=#SPILL26(gr31,344)
   65| 0014E0 ld       EB3F0170   1     L8        gr25=#SPILL29(gr31,368)
   65| 0014E4 ld       EB7F0160   1     L8        gr27=#SPILL27(gr31,352)
   65| 0014E8 ld       EB5F0150   1     L8        gr26=#SPILL25(gr31,336)
    0| 0014EC ld       EBDF0148   1     L8        gr30=#SPILL24(gr31,328)
   64| 0014F0 or       7EE3BB78   1     LR        gr3=gr23
   64| 0014F4 or       7EC4B378   1     LR        gr4=gr22
   64| 0014F8 lfdu     CC030008   1     LFDU      fp0,gr3=kp[](gr3,8)
   64| 0014FC lfdu     CC440008   1     LFDU      fp2,gr4=kp[](gr4,8)
   64| 001500 lfdu     CC250008   1     LFDU      fp1,gr5=kp[](gr5,8)
   65| 001504 add      7FB9E214   1     A         gr29=gr25,gr28
   65| 001508 add      7F99DA14   1     A         gr28=gr25,gr27
   65| 00150C add      7F79D214   1     A         gr27=gr25,gr26
   65| 001510 ld       EB5F0140   1     L8        gr26=#SPILL23(gr31,320)
    0| 001514 mtspr    7FC903A6   1     LCTR      ctr=gr30
   65| 001518 or       7DC67378   1     LR        gr6=gr14
   65| 00151C or       7EA7AB78   1     LR        gr7=gr21
   65| 001520 or       7E489378   1     LR        gr8=gr18
   64| 001524 or       7F09C378   1     LR        gr9=gr24
   64| 001528 or       7DEA7B78   1     LR        gr10=gr15
   64| 00152C or       7E8BA378   1     LR        gr11=gr20
   64| 001530 stfdu    DC0A0008   1     STFDU     gr10,km[](gr10,8)=fp0
   64| 001534 stfdu    DC4B0008   1     STFDU     gr11,km[](gr11,8)=fp2
   64| 001538 or       7E6C9B78   1     LR        gr12=gr19
   65| 00153C lfdu     CC060008   1     LFDU      fp0,gr6=dkpdt[](gr6,8)
   64| 001540 stfdu    DC2C0008   1     STFDU     gr12,km[](gr12,8)=fp1
   65| 001544 or       7E3E8B78   1     LR        gr30=gr17
   65| 001548 lfdu     CC670008   1     LFDU      fp3,gr7=dkpdt[](gr7,8)
   65| 00154C lfdu     CC880008   1     LFDU      fp4,gr8=dkpdt[](gr8,8)
   64| 001550 lfdu     CC290008   1     LFDU      fp1,gr9=kp[](gr9,8)
   65| 001554 add      7F5ACA14   1     A         gr26=gr26,gr25
   64| 001558 or       7E198378   1     LR        gr25=gr16
    0| 00155C bc       42400054   1     BCF       ctr=CL.468,taken=0%(0,100)
    0| 001560 ori      60210000   1     XNOP      
    0| 001564 ori      60210000   1     XNOP      
    0| 001568 ori      60210000   1     XNOP      
    0|                              CL.469:
   64| 00156C lfdu     CC430008   1     LFDU      fp2,gr3=kp[](gr3,8)
   64| 001570 stfdu    DC390008   1     STFDU     gr25,km[](gr25,8)=fp1
   65| 001574 lfdu     CC3E0008   1     LFDU      fp1,gr30=dkpdt[](gr30,8)
   65| 001578 stfdu    DC1D0008   1     STFDU     gr29,dkedt[](gr29,8)=fp0
   65| 00157C stfdu    DC7C0008   1     STFDU     gr28,dkedt[](gr28,8)=fp3
   65| 001580 stfdu    DC9B0008   1     STFDU     gr27,dkedt[](gr27,8)=fp4
   64| 001584 lfdu     CC640008   1     LFDU      fp3,gr4=kp[](gr4,8)
   64| 001588 lfdu     CC850008   1     LFDU      fp4,gr5=kp[](gr5,8)
   65| 00158C lfdu     CC060008   1     LFDU      fp0,gr6=dkpdt[](gr6,8)
   65| 001590 stfdu    DC3A0008   1     STFDU     gr26,dkedt[](gr26,8)=fp1
   64| 001594 lfdu     CC290008   1     LFDU      fp1,gr9=kp[](gr9,8)
   64| 001598 stfdu    DC4A0008   1     STFDU     gr10,km[](gr10,8)=fp2
   64| 00159C stfdu    DC6B0008   1     STFDU     gr11,km[](gr11,8)=fp3
   64| 0015A0 stfdu    DC8C0008   1     STFDU     gr12,km[](gr12,8)=fp4
   65| 0015A4 lfdu     CC670008   1     LFDU      fp3,gr7=dkpdt[](gr7,8)
   65| 0015A8 lfdu     CC880008   1     LFDU      fp4,gr8=dkpdt[](gr8,8)
    0| 0015AC bc       4200FFC0   1     BCT       ctr=CL.469,taken=100%(100,0)
    0|                              CL.468:
    0| 0015B0 ld       E8BF0140   1     L8        gr5=#SPILL23(gr31,320)
    0| 0015B4 ld       E8DF0150   1     L8        gr6=#SPILL25(gr31,336)
    0| 0015B8 ld       E8FF0158   1     L8        gr7=#SPILL26(gr31,344)
   65| 0015BC stfdu    DC1D0008   1     STFDU     gr29,dkedt[](gr29,8)=fp0
    0| 0015C0 ld       E91F0160   1     L8        gr8=#SPILL27(gr31,352)
    0| 0015C4 ld       E93F0168   1     L8        gr9=#SPILL28(gr31,360)
   65| 0015C8 stfdu    DC7C0008   1     STFDU     gr28,dkedt[](gr28,8)=fp3
    0| 0015CC add      7CA50214   1     A         gr5=gr5,gr0
    0| 0015D0 add      7CC60214   1     A         gr6=gr6,gr0
   65| 0015D4 stfdu    DC9B0008   1     STFDU     gr27,dkedt[](gr27,8)=fp4
    0| 0015D8 add      7CE70214   1     A         gr7=gr7,gr0
    0| 0015DC add      7D080214   1     A         gr8=gr8,gr0
   64| 0015E0 stfdu    DC390008   1     STFDU     gr25,km[](gr25,8)=fp1
    0| 0015E4 add      7D290214   1     A         gr9=gr9,gr0
    0| 0015E8 std      F8BF0140   1     ST8       #SPILL23(gr31,320)=gr5
    0| 0015EC std      F8DF0150   1     ST8       #SPILL25(gr31,336)=gr6
   67| 0015F0 ld       E87F0138   1     L8        gr3=#SPILL22(gr31,312)
   67| 0015F4 ld       E89F0088   1     L8        gr4=#SPILL0(gr31,136)
    0| 0015F8 std      F8FF0158   1     ST8       #SPILL26(gr31,344)=gr7
   65| 0015FC lfdu     CC1E0008   1     LFDU      fp0,gr30=dkpdt[](gr30,8)
    0| 001600 std      F91F0160   1     ST8       #SPILL27(gr31,352)=gr8
    0| 001604 std      F93F0168   1     ST8       #SPILL28(gr31,360)=gr9
   67| 001608 addi     38630001   1     AI        gr3=gr3,1
    0| 00160C add      7F180214   1     A         gr24=gr24,gr0
   67| 001610 cmpld    7CA32040   1     CL8       cr1=gr3,gr4
   67| 001614 std      F87F0138   1     ST8       #SPILL22(gr31,312)=gr3
    0| 001618 add      7EF70214   1     A         gr23=gr23,gr0
   65| 00161C stfdu    DC1A0008   1     STFDU     gr26,dkedt[](gr26,8)=fp0
    0| 001620 add      7ED60214   1     A         gr22=gr22,gr0
    0| 001624 add      7EB50214   1     A         gr21=gr21,gr0
    0| 001628 add      7E940214   1     A         gr20=gr20,gr0
    0| 00162C add      7E730214   1     A         gr19=gr19,gr0
    0| 001630 add      7E520214   1     A         gr18=gr18,gr0
    0| 001634 add      7E310214   1     A         gr17=gr17,gr0
    0| 001638 add      7E100214   1     A         gr16=gr16,gr0
    0| 00163C add      7DEF0214   1     A         gr15=gr15,gr0
    0| 001640 add      7DCE0214   1     A         gr14=gr14,gr0
   67| 001644 bc       4184FE94   1     BT        CL.52,cr1,0x8/llt,taken=80%(80,20)
   67|                              CL.51:
   68| 001648 ld       E87F0098   1     L8        gr3=#SPILL2(gr31,152)
    0| 00164C ld       E89F00C8   1     L8        gr4=#SPILL8(gr31,200)
    0| 001650 ld       E8BF00D0   1     L8        gr5=#SPILL9(gr31,208)
   68| 001654 ld       E8DF0130   1     L8        gr6=#SPILL21(gr31,304)
    0| 001658 ld       E8FF00D8   1     L8        gr7=#SPILL10(gr31,216)
    0| 00165C ld       E91F00E0   1     L8        gr8=#SPILL11(gr31,224)
    0| 001660 ld       E93F00E8   1     L8        gr9=#SPILL12(gr31,232)
    0| 001664 ld       E95F00B0   1     L8        gr10=#SPILL5(gr31,176)
    0| 001668 ld       E97F00F0   1     L8        gr11=#SPILL13(gr31,240)
    0| 00166C ld       E99F00F8   1     L8        gr12=#SPILL14(gr31,248)
    0| 001670 ld       EBDF0100   1     L8        gr30=#SPILL15(gr31,256)
    0| 001674 ld       EBBF0108   1     L8        gr29=#SPILL16(gr31,264)
    0| 001678 ld       EB9F0110   1     L8        gr28=#SPILL17(gr31,272)
    0| 00167C ld       EB7F0090   1     L8        gr27=#SPILL1(gr31,144)
    0| 001680 ld       EB5F0118   1     L8        gr26=#SPILL18(gr31,280)
    0| 001684 ld       EB3F00C0   1     L8        gr25=#SPILL7(gr31,192)
    0| 001688 ld       EB1F0120   1     L8        gr24=#SPILL19(gr31,288)
    0| 00168C ld       EAFF0128   1     L8        gr23=#SPILL20(gr31,296)
    0| 001690 ld       EADF00B8   1     L8        gr22=#SPILL6(gr31,184)
   68| 001694 addi     38630001   1     AI        gr3=gr3,1
    0| 001698 add      7CA42A14   1     A         gr5=gr4,gr5
   68| 00169C std      F87F0098   1     ST8       #SPILL2(gr31,152)=gr3
    0| 0016A0 std      F8BF00D0   1     ST8       #SPILL9(gr31,208)=gr5
   68| 0016A4 cmpld    7CA33040   1     CL8       cr1=gr3,gr6
    0| 0016A8 add      7CE43A14   1     A         gr7=gr4,gr7
    0| 0016AC add      7D044214   1     A         gr8=gr4,gr8
    0| 0016B0 std      F8FF00D8   1     ST8       #SPILL10(gr31,216)=gr7
    0| 0016B4 std      F91F00E0   1     ST8       #SPILL11(gr31,224)=gr8
    0| 0016B8 add      7D244A14   1     A         gr9=gr4,gr9
    0| 0016BC add      7D445214   1     A         gr10=gr4,gr10
    0| 0016C0 std      F93F00E8   1     ST8       #SPILL12(gr31,232)=gr9
    0| 0016C4 std      F95F00B0   1     ST8       #SPILL5(gr31,176)=gr10
    0| 0016C8 add      7D645A14   1     A         gr11=gr4,gr11
    0| 0016CC add      7D846214   1     A         gr12=gr4,gr12
    0| 0016D0 std      F97F00F0   1     ST8       #SPILL13(gr31,240)=gr11
    0| 0016D4 std      F99F00F8   1     ST8       #SPILL14(gr31,248)=gr12
    0| 0016D8 add      7FC4F214   1     A         gr30=gr4,gr30
    0| 0016DC add      7FA4EA14   1     A         gr29=gr4,gr29
    0| 0016E0 std      FBDF0100   1     ST8       #SPILL15(gr31,256)=gr30
    0| 0016E4 std      FBBF0108   1     ST8       #SPILL16(gr31,264)=gr29
    0| 0016E8 add      7F84E214   1     A         gr28=gr4,gr28
    0| 0016EC add      7F64DA14   1     A         gr27=gr4,gr27
    0| 0016F0 std      FB9F0110   1     ST8       #SPILL17(gr31,272)=gr28
    0| 0016F4 std      FB7F0090   1     ST8       #SPILL1(gr31,144)=gr27
    0| 0016F8 add      7F44D214   1     A         gr26=gr4,gr26
    0| 0016FC add      7F24CA14   1     A         gr25=gr4,gr25
    0| 001700 std      FB5F0118   1     ST8       #SPILL18(gr31,280)=gr26
    0| 001704 std      FB3F00C0   1     ST8       #SPILL7(gr31,192)=gr25
    0| 001708 add      7F04C214   1     A         gr24=gr4,gr24
    0| 00170C add      7EE4BA14   1     A         gr23=gr4,gr23
    0| 001710 std      FB1F0120   1     ST8       #SPILL19(gr31,288)=gr24
    0| 001714 std      FAFF0128   1     ST8       #SPILL20(gr31,296)=gr23
    0| 001718 add      7EC4B214   1     A         gr22=gr4,gr22
    0| 00171C std      FADF00B8   1     ST8       #SPILL6(gr31,184)=gr22
   68| 001720 bc       4184FCF8   1     BT        CL.50,cr1,0x8/llt,taken=80%(80,20)
   71|                              CL.116:
   71| 001724 ld       E8210000   1     L8        gr1=#stack(gr1,0),gr31"
   71| 001728 ld       E8010010   1     L8        gr0=#stack(gr1,16)
   71| 00172C lwa      E981000A   1     L4A       gr12=#stack(gr1,8)
   71| 001730 ld       E9C1FEE0   1     L8        gr14=#stack(gr1,-288)
   71| 001734 ld       E9E1FEE8   1     L8        gr15=#stack(gr1,-280)
   71| 001738 ld       EA01FEF0   1     L8        gr16=#stack(gr1,-272)
   71| 00173C ld       EA21FEF8   1     L8        gr17=#stack(gr1,-264)
   71| 001740 mtspr    7C0803A6   1     LLR       lr=gr0
   71| 001744 ld       EA41FF00   1     L8        gr18=#stack(gr1,-256)
   71| 001748 ld       EA61FF08   1     L8        gr19=#stack(gr1,-248)
   71| 00174C ld       EA81FF10   1     L8        gr20=#stack(gr1,-240)
   71| 001750 ld       EAA1FF18   1     L8        gr21=#stack(gr1,-232)
   71| 001754 ld       EAC1FF20   1     L8        gr22=#stack(gr1,-224)
   71| 001758 ld       EAE1FF28   1     L8        gr23=#stack(gr1,-216)
   71| 00175C ld       EB01FF30   1     L8        gr24=#stack(gr1,-208)
   71| 001760 ld       EB21FF38   1     L8        gr25=#stack(gr1,-200)
   71| 001764 ld       EB41FF40   1     L8        gr26=#stack(gr1,-192)
   71| 001768 ld       EB61FF48   1     L8        gr27=#stack(gr1,-184)
   71| 00176C ld       EB81FF50   1     L8        gr28=#stack(gr1,-176)
   71| 001770 ld       EBA1FF58   1     L8        gr29=#stack(gr1,-168)
   71| 001774 ld       EBC1FF60   1     L8        gr30=#stack(gr1,-160)
   71| 001778 ld       EBE1FF68   1     L8        gr31=#stack(gr1,-152)
   71| 00177C mtcrf    7D820120   1     MTCRF     cr2=gr12
   71| 001780 mtcrf    7D810120   1     MTCRF     cr3=gr12
   71| 001784 mtcrf    7D808120   1     MTCRF     cr4=gr12
   71| 001788 lfd      CBE1FFF8   1     LFL       fp31=#stack(gr1,-8)
   71| 00178C lfd      CBC1FFF0   1     LFL       fp30=#stack(gr1,-16)
   71| 001790 lfd      CBA1FFE8   1     LFL       fp29=#stack(gr1,-24)
   71| 001794 lfd      CB81FFE0   1     LFL       fp28=#stack(gr1,-32)
   71| 001798 lfd      CB61FFD8   1     LFL       fp27=#stack(gr1,-40)
   71| 00179C lfd      CB41FFD0   1     LFL       fp26=#stack(gr1,-48)
   71| 0017A0 lfd      CB21FFC8   1     LFL       fp25=#stack(gr1,-56)
   71| 0017A4 lfd      CB01FFC0   1     LFL       fp24=#stack(gr1,-64)
   71| 0017A8 lfd      CAE1FFB8   1     LFL       fp23=#stack(gr1,-72)
   71| 0017AC lfd      CAC1FFB0   1     LFL       fp22=#stack(gr1,-80)
   71| 0017B0 lfd      CAA1FFA8   1     LFL       fp21=#stack(gr1,-88)
   71| 0017B4 lfd      CA81FFA0   1     LFL       fp20=#stack(gr1,-96)
   71| 0017B8 lfd      CA61FF98   1     LFL       fp19=#stack(gr1,-104)
   71| 0017BC lfd      CA41FF90   1     LFL       fp18=#stack(gr1,-112)
   71| 0017C0 lfd      CA21FF88   1     LFL       fp17=#stack(gr1,-120)
   71| 0017C4 lfd      CA01FF80   1     LFL       fp16=#stack(gr1,-128)
   71| 0017C8 lfd      C9E1FF78   1     LFL       fp15=#stack(gr1,-136)
   71| 0017CC lfd      C9C1FF70   1     LFL       fp14=#stack(gr1,-144)
   71| 0017D0 bclr     4E800020   1     BA        lr
   67|                              CL.321:
    0| 0017D4 ld       E81F00A8   1     L8        gr0=#SPILL4(gr31,168)
    0| 0017D8 mtspr    7C0903A6   1     LCTR      ctr=gr0
   67|                              CL.230:
   68| 0017DC addi     38630001   1     AI        gr3=gr3,1
   68| 0017E0 cmpd     7C230000   1     C8        cr0=gr3,gr0
   68| 0017E4 bc       4100FFF8   1     BCTT      ctr=CL.230,cr0,0x1/lt,taken=80%(80,20)
    0| 0017E8 b        4BFFFAEC   1     B         CL.78,-1
   60|                              CL.311:
    0| 0017EC mtspr    7CA903A6   1     LCTR      ctr=gr5
    0| 0017F0 addi     38600000   1     LI        gr3=0
    0| 0017F4 or       7CA02B78   1     LR        gr0=gr5
   60|                              CL.260:
   60| 0017F8 addi     38630001   1     AI        gr3=gr3,1
   60| 0017FC cmpd     7CA30000   1     C8        cr1=gr3,gr0
   60| 001800 bc       4104FFF8   1     BCTT      ctr=CL.260,cr1,0x1/lt,taken=80%(80,20)
    0| 001804 b        4BFFF490   1     B         CL.90,-1
   47|                              CL.301:
    0| 001808 mtspr    7E6903A6   1     LCTR      ctr=gr19
    0| 00180C or       7E609B78   1     LR        gr0=gr19
   47|                              CL.290:
   47| 001810 addi     38840001   1     AI        gr4=gr4,1
   47| 001814 cmpd     7C240000   1     C8        cr0=gr4,gr0
   47| 001818 bc       4100FFF8   1     BCTT      ctr=CL.290,cr0,0x1/lt,taken=80%(80,20)
    0| 00181C b        4BFFEAC8   1     B         CL.102,-1
     |               Tag Table
     | 001820        00000000 00012223 92120000 00001820 1F
     |               Instruction count         1544
     |               Straight-line exec time   1760
     |               Constant Area
     | 000000        3F800000 BF800000 18007A2F 49424D20 4339BB64 0DB6B568
     | 000018        00000000 42C80000 C2C80000

 
 
>>>>> COMPILATION UNIT EPILOGUE SECTION <<<<<
 
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    opacity.f90                 07/08/15   15:48:27
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
 
    Source records read.......................................      76
1501-510  Compilation successful for file opacity.f90.
1501-543  Object file created.
