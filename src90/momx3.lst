IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- momx3.f90 07/08/15 15:48:18
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** momx3   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-550 (I) Loop (loop index 1) at momx3.f90 <line 88> was not SIMD vectorized because it is not profitable to vectorize.
1586-536 (I) Loop (loop index 1) at momx3.f90 <line 89> was not SIMD vectorized because it contains memory references ((char *).atwid1  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV0)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 1) at momx3.f90 <line 89> was not SIMD vectorized because it contains operation in (( 5.0000000000000000E-001 * ((double *)((char *)d-g2a%addr  + d-g2a%rvo))->g2a[].rns2.[(long long) .ibeg->ibeg + $$CIV0]) * ((double *)((char *)d-dx1b%addr  + d-dx1b%rvo))->dx1b[].rns1.[(long long) .ibeg->ibeg + $$CIV0]) * ((double *)((char *)d-dvl1bi%addr  + d-dvl1bi%rvo))->dvl1bi[].rns0.[(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 1) at momx3.f90 <line 89> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 1) at momx3.f90 <line 91> was not SIMD vectorized because it contains memory references ((char *).atwid3  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV0)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 1) at momx3.f90 <line 91> was not SIMD vectorized because it contains operation in ((( 5.0000000000000000E-001 * ((double *)((char *)d-g31b%addr  + d-g31b%rvo))->g31b[].rns6.[(long long) .ibeg->ibeg + $$CIV0]) * ((double *)((char *)d-g2b%addr  + d-g2b%rvo))->g2b[].rns5.[(long long) .ibeg->ibeg + $$CIV0]) * ((double *)((char *)d-dx1a%addr  + d-dx1a%rvo))->dx1a[].rns4.[(long long) .ibeg->ibeg + $$CIV0]) * ((double *)((char *)d-dvl1ai%addr  + d-dvl1ai%rvo))->dvl1ai[].rns3.[(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 1) at momx3.f90 <line 91> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 1) at momx3.f90 <line 90> was not SIMD vectorized because it contains memory references ((char *).atwid2  + -8ll + (8ll)*((long long) .ibeg->ibeg + $$CIV0)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 1) at momx3.f90 <line 90> was not SIMD vectorized because it contains operation in ((( 5.0000000000000000E-001 * ((double *)((char *)d-g2b%addr  + d-g2b%rvo))->g2b[].rns5.[(long long) .ibeg->ibeg + $$CIV0]) * ((double *)((char *)d-g2b%addr  + d-g2b%rvo))->g2b[].rns5.[(long long) .ibeg->ibeg + $$CIV0]) * ((double *)((char *)d-dx1a%addr  + d-dx1a%rvo))->dx1a[].rns4.[(long long) .ibeg->ibeg + $$CIV0]) * ((double *)((char *)d-dvl1ai%addr  + d-dvl1ai%rvo))->dvl1ai[].rns3.[(long long) .ibeg->ibeg + $$CIV0] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 1) at momx3.f90 <line 90> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-550 (I) Loop (loop index 2) at momx3.f90 <line 93> was not SIMD vectorized because it is not profitable to vectorize.
1586-536 (I) Loop (loop index 2) at momx3.f90 <line 94> was not SIMD vectorized because it contains memory references ((char *).atwidj1  + -8ll + (8ll)*((long long) .jbeg->jbeg + $$CIV1)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 2) at momx3.f90 <line 94> was not SIMD vectorized because it contains operation in ((double *)((char *)d-dx2a%addr  + d-dx2a%rvo))->dx2a[].rns8.[(long long) .jbeg->jbeg + $$CIV1] * ((double *)((char *)d-dvl2ai%addr  + d-dvl2ai%rvo))->dvl2ai[].rns7.[(long long) .jbeg->jbeg + $$CIV1] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 2) at momx3.f90 <line 94> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 2) at momx3.f90 <line 95> was not SIMD vectorized because it contains memory references ((char *).atwidj2  + -8ll + (8ll)*((long long) .jbeg->jbeg + $$CIV1)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 2) at momx3.f90 <line 95> was not SIMD vectorized because it contains operation in ((double *)((char *)d-dx2b%addr  + d-dx2b%rvo))->dx2b[].rns10.[(long long) .jbeg->jbeg + $$CIV1] * ((double *)((char *)d-dvl2bi%addr  + d-dvl2bi%rvo))->dvl2bi[].rns9.[(long long) .jbeg->jbeg + $$CIV1] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 2) at momx3.f90 <line 95> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 2) at momx3.f90 <line 96> was not SIMD vectorized because it contains memory references ((char *).atwidj3  + -8ll + (8ll)*((long long) .jbeg->jbeg + $$CIV1)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 2) at momx3.f90 <line 96> was not SIMD vectorized because it contains operation in (((double *)((char *)d-g32b%addr  + d-g32b%rvo))->g32b[].rns11.[(long long) .jbeg->jbeg + $$CIV1] * ((double *)((char *)d-dx2a%addr  + d-dx2a%rvo))->dx2a[].rns8.[(long long) .jbeg->jbeg + $$CIV1]) * ((double *)((char *)d-dvl2ai%addr  + d-dvl2ai%rvo))->dvl2ai[].rns7.[(long long) .jbeg->jbeg + $$CIV1] which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 2) at momx3.f90 <line 96> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-534 (I) Loop (loop index 3) at momx3.f90 <line 101> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 4) at momx3.f90 <line 102> was not SIMD vectorized because the loop is not the innermost loop.
1586-535 (I) Loop (loop index 5) at momx3.f90 <line 113> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 5) at momx3.f90 <line 113> was not SIMD vectorized because it contains memory references dqm = (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3bi%addr  + d-dx3bi%rvo))->dx3bi[].rns12.[($$CIV2 + (long long) .kbeg->kbeg) - 1ll]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 5) at momx3.f90 <line 113> was not SIMD vectorized because it contains memory references dqp = (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[(long long) .kbeg->kbeg + $$CIV2][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3bi%addr  + d-dx3bi%rvo))->dx3bi[].rns12.[(long long) .kbeg->kbeg + $$CIV2]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 5) at momx3.f90 <line 114> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(($$CIV2 + (long long) .kbeg->kbeg) - 1ll) + (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg + $$CIVC) + (d-v1%bounds%mult[].off512)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 5) at momx3.f90 <line 114> was not SIMD vectorized because it contains operation in (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3bi%addr  + d-dx3bi%rvo))->dx3bi[].rns12.[($$CIV2 + (long long) .kbeg->kbeg) - 1ll] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 5) at momx3.f90 <line 114> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(($$CIV2 + (long long) .kbeg->kbeg) - 1ll) + (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg + $$CIVC) + (d-v1%bounds%mult[].off512)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 5) at momx3.f90 <line 114> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 5) at momx3.f90 <line 115> was not SIMD vectorized because it contains operation in dqm + dqp which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 5) at momx3.f90 <line 115> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 5) at momx3.f90 <line 116> was not SIMD vectorized because it contains operation in (max(dqm * dqp, 0.0000000000000000E+000) * $$RET0) / max(abs(dqm + dqp), 1.0000000000000000E-099) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 5) at momx3.f90 <line 116> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 5) at momx3.f90 <line 115> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg + $$CIV2) + (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg + $$CIVC) + (d-v1%bounds%mult[].off512)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 5) at momx3.f90 <line 115> was not SIMD vectorized because it contains operation in (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[(long long) .kbeg->kbeg + $$CIV2][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3bi%addr  + d-dx3bi%rvo))->dx3bi[].rns12.[(long long) .kbeg->kbeg + $$CIV2] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 5) at momx3.f90 <line 115> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg + $$CIV2) + (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg + $$CIVC) + (d-v1%bounds%mult[].off512)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 5) at momx3.f90 <line 115> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-535 (I) Loop (loop index 6) at momx3.f90 <line 129> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 6) at momx3.f90 <line 129> was not SIMD vectorized because it contains memory references ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV3] = (((((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][($$CIVB + (long long) .ibeg->ibeg) - 1ll] + ((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV3]) * ((double *)((char *).atwid1  + -8ll))->atwid1[][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).atwidj1  + -8ll))->atwidj1[][(long long) .jbeg->jbeg + $$CIVC]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 6) at momx3.f90 <line 129> was not SIMD vectorized because it contains memory references xi = ( 5.0000000000000000E-001 * (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][($$CIVB + (long long) .ibeg->ibeg) - 1ll] + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) - ((double *)((char *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) .kbeg->kbeg + $$CIV3]) * ((dt * ((double *)((char *)d-g31ai%addr  + d-g31ai%rvo))->g31ai[].rns15.[(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns14.[(long long) .jbeg->jbeg + $$CIVC]); with non-vectorizable strides.
1586-540 (I) Loop (loop index 6) at momx3.f90 <line 129> was not SIMD vectorized because it contains memory references ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV3] = ( 5.0000000000000000E-001 + q1) * (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[($$CIV3 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double *)((char *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[($$CIV3 + (long long) .kbeg->kbeg) - 1ll] - xi) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][($$CIV3 + (long long) .kbeg->kbeg) - 1ll]) + ( 5.0000000000000000E-001 - q1) * (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - (((double *)((char *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[(long long) .kbeg->kbeg + $$CIV3] + xi) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][(long long) .kbeg->kbeg + $$CIV3]); with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at momx3.f90 <line 133> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 6) at momx3.f90 <line 138> was not SIMD vectorized because it contains operation in (((((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][($$CIVB + (long long) .ibeg->ibeg) - 1ll] + ((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV3]) * ((double *)((char *).atwid1  + -8ll))->atwid1[][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).atwidj1  + -8ll))->atwidj1[][(long long) .jbeg->jbeg + $$CIVC] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 6) at momx3.f90 <line 138> was not SIMD vectorized because it contains memory references ((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll))) + (8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))*((long long) .kbeg->kbeg + $$CIV3) + (max((long long) in,0ll) * 8ll)*((long long) .jbeg->jbeg + $$CIVC) + (8ll)*(($$CIVB + (long long) .ibeg->ibeg) - 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at momx3.f90 <line 138> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 6) at momx3.f90 <line 132> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg + $$CIV3) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*(($$CIVB + (long long) .ibeg->ibeg) - 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 6) at momx3.f90 <line 132> was not SIMD vectorized because it contains operation in ( 5.0000000000000000E-001 * (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][($$CIVB + (long long) .ibeg->ibeg) - 1ll] + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) - ((double *)((char *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) .kbeg->kbeg + $$CIV3]) * ((dt * ((double *)((char *)d-g31ai%addr  + d-g31ai%rvo))->g31ai[].rns15.[(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns14.[(long long) .jbeg->jbeg + $$CIVC]) which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 6) at momx3.f90 <line 132> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg + $$CIV3) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*(($$CIVB + (long long) .ibeg->ibeg) - 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at momx3.f90 <line 132> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 6) at momx3.f90 <line 134> was not SIMD vectorized because it contains memory references ((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll + (max((long long) ijkn,0ll) * 8ll)*(1ll) + (8ll)*((long long) .kbeg->kbeg + $$CIV3)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 6) at momx3.f90 <line 134> was not SIMD vectorized because it contains operation in ( 5.0000000000000000E-001 + q1) * (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[($$CIV3 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double *)((char *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[($$CIV3 + (long long) .kbeg->kbeg) - 1ll] - xi) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][($$CIV3 + (long long) .kbeg->kbeg) - 1ll]) + ( 5.0000000000000000E-001 - q1) * (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[(long long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - (((double *)((char *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[(long long) .kbeg->kbeg + $$CIV3] + xi) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][(long long) .kbeg->kbeg + $$CIV3]) which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 6) at momx3.f90 <line 134> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(($$CIV3 + (long long) .kbeg->kbeg) - 1ll) + (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg + $$CIVC) + (d-v1%bounds%mult[].off512)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at momx3.f90 <line 134> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-538 (I) Loop (loop index 7) at momx3.f90 <line 142> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 7) at momx3.f90 <line 142> was not SIMD vectorized because it contains control flow.
1586-535 (I) Loop (loop index 8) at momx3.f90 <line 161> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 8) at momx3.f90 <line 161> was not SIMD vectorized because it contains memory references dqm.rnn1D = (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3bi%addr  + d-dx3bi%rvo))->dx3bi[].rns12.[($$CIV5 + (long long) .kbeg->kbeg) - 1ll]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at momx3.f90 <line 161> was not SIMD vectorized because it contains memory references dqp.rnn1B = (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3bi%addr  + d-dx3bi%rvo))->dx3bi[].rns12.[(long long) .kbeg->kbeg + $$CIV5]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 8) at momx3.f90 <line 162> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(($$CIV5 + (long long) .kbeg->kbeg) - 1ll) + (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg + $$CIVC) + (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 8) at momx3.f90 <line 162> was not SIMD vectorized because it contains operation in (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3bi%addr  + d-dx3bi%rvo))->dx3bi[].rns12.[($$CIV5 + (long long) .kbeg->kbeg) - 1ll] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 8) at momx3.f90 <line 162> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(($$CIV5 + (long long) .kbeg->kbeg) - 1ll) + (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg + $$CIVC) + (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at momx3.f90 <line 162> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 8) at momx3.f90 <line 163> was not SIMD vectorized because it contains operation in dqm.rnn1D + dqp.rnn1B which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 8) at momx3.f90 <line 163> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 8) at momx3.f90 <line 164> was not SIMD vectorized because it contains operation in (max(dqm.rnn1D * dqp.rnn1B, 0.0000000000000000E+000) * $$RET1) / max(abs(dqm.rnn1D + dqp.rnn1B), 1.0000000000000000E-099) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 8) at momx3.f90 <line 164> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 8) at momx3.f90 <line 163> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg + $$CIV5) + (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg + $$CIVC) + (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 8) at momx3.f90 <line 163> was not SIMD vectorized because it contains operation in (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[(long long) .kbeg->kbeg + $$CIV5][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3bi%addr  + d-dx3bi%rvo))->dx3bi[].rns12.[(long long) .kbeg->kbeg + $$CIV5] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 8) at momx3.f90 <line 163> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg + $$CIV5) + (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg + $$CIVC) + (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at momx3.f90 <line 163> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-535 (I) Loop (loop index 9) at momx3.f90 <line 177> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 9) at momx3.f90 <line 177> was not SIMD vectorized because it contains memory references xi.rnn19 = ( 5.0000000000000000E-001 * (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV6][($$CIVC + (long long) .jbeg->jbeg) - 1ll][(long long) .ibeg->ibeg + $$CIVB] + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) - ((double *)((char *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) .kbeg->kbeg + $$CIV6]) * ((dt * ((double *)((char *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns23.[(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-g32ai%addr  + d-g32ai%rvo))->g32ai[].rns22.[(long long) .jbeg->jbeg + $$CIVC]); with non-vectorizable strides.
1586-540 (I) Loop (loop index 9) at momx3.f90 <line 177> was not SIMD vectorized because it contains memory references ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV6] = ( 5.0000000000000000E-001 + q1.rnn17) * (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[($$CIV6 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double *)((char *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[($$CIV6 + (long long) .kbeg->kbeg) - 1ll] - xi.rnn19) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][($$CIV6 + (long long) .kbeg->kbeg) - 1ll]) + ( 5.0000000000000000E-001 - q1.rnn17) * (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[(long long) .kbeg->kbeg + $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - (((double *)((char *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[(long long) .kbeg->kbeg + $$CIV6] + xi.rnn19) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][(long long) .kbeg->kbeg + $$CIV6]); with non-vectorizable strides.
1586-540 (I) Loop (loop index 9) at momx3.f90 <line 177> was not SIMD vectorized because it contains memory references ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV6] = (((((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV6][($$CIVC + (long long) .jbeg->jbeg) - 1ll][(long long) .ibeg->ibeg + $$CIVB] + ((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV6]) * ((double *)((char *).atwid2  + -8ll))->atwid2[][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).atwidj2  + -8ll))->atwidj2[][(long long) .jbeg->jbeg + $$CIVC]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 9) at momx3.f90 <line 180> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg + $$CIV6) + (d-v3%bounds%mult[].off696)*(($$CIVC + (long long) .jbeg->jbeg) - 1ll) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 9) at momx3.f90 <line 180> was not SIMD vectorized because it contains operation in ( 5.0000000000000000E-001 * (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV6][($$CIVC + (long long) .jbeg->jbeg) - 1ll][(long long) .ibeg->ibeg + $$CIVB] + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) - ((double *)((char *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) .kbeg->kbeg + $$CIV6]) * ((dt * ((double *)((char *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns23.[(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-g32ai%addr  + d-g32ai%rvo))->g32ai[].rns22.[(long long) .jbeg->jbeg + $$CIVC]) which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 9) at momx3.f90 <line 180> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg + $$CIV6) + (d-v3%bounds%mult[].off696)*(($$CIVC + (long long) .jbeg->jbeg) - 1ll) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 9) at momx3.f90 <line 180> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 9) at momx3.f90 <line 182> was not SIMD vectorized because it contains memory references ((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll + (max((long long) ijkn,0ll) * 8ll)*(1ll) + (8ll)*((long long) .kbeg->kbeg + $$CIV6)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 9) at momx3.f90 <line 182> was not SIMD vectorized because it contains operation in ( 5.0000000000000000E-001 + q1.rnn17) * (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[($$CIV6 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double *)((char *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[($$CIV6 + (long long) .kbeg->kbeg) - 1ll] - xi.rnn19) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][($$CIV6 + (long long) .kbeg->kbeg) - 1ll]) + ( 5.0000000000000000E-001 - q1.rnn17) * (((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns21.[(long long) .kbeg->kbeg + $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - (((double *)((char *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[(long long) .kbeg->kbeg + $$CIV6] + xi.rnn19) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][(long long) .kbeg->kbeg + $$CIV6]) which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 9) at momx3.f90 <line 182> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(($$CIV6 + (long long) .kbeg->kbeg) - 1ll) + (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg + $$CIVC) + (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 9) at momx3.f90 <line 182> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 9) at momx3.f90 <line 186> was not SIMD vectorized because it contains operation in (((((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV6][($$CIVC + (long long) .jbeg->jbeg) - 1ll][(long long) .ibeg->ibeg + $$CIVB] + ((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV6]) * ((double *)((char *).atwid2  + -8ll))->atwid2[][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).atwidj2  + -8ll))->atwidj2[][(long long) .jbeg->jbeg + $$CIVC] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 9) at momx3.f90 <line 186> was not SIMD vectorized because it contains memory references ((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll))) + (8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))*((long long) .kbeg->kbeg + $$CIV6) + (max((long long) in,0ll) * 8ll)*(($$CIVC + (long long) .jbeg->jbeg) - 1ll) + (8ll)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 9) at momx3.f90 <line 186> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-554 (I) Loop (loop index 9) at momx3.f90 <line 181> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-538 (I) Loop (loop index 10) at momx3.f90 <line 190> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 10) at momx3.f90 <line 190> was not SIMD vectorized because it contains control flow.
1586-535 (I) Loop (loop index 11) at momx3.f90 <line 209> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 11) at momx3.f90 <line 209> was not SIMD vectorized because it contains memory references dqp.rnn1A = (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV8][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3ai%addr  + d-dx3ai%rvo))->dx3ai[].rns24.[($$CIV8 + (long long) .kbeg->kbeg) - 1ll]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 11) at momx3.f90 <line 209> was not SIMD vectorized because it contains memory references dqm.rnn1C = (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3ai%addr  + d-dx3ai%rvo))->dx3ai[].rns24.[($$CIV8 + (long long) .kbeg->kbeg) - 2ll]; with non-vectorizable strides.
1586-537 (I) Loop (loop index 11) at momx3.f90 <line 211> was not SIMD vectorized because it contains operation in dqm.rnn1C + dqp.rnn1A which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 11) at momx3.f90 <line 211> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 11) at momx3.f90 <line 212> was not SIMD vectorized because it contains operation in (max(dqm.rnn1C * dqp.rnn1A, 0.0000000000000000E+000) * $$RET2) / max(abs(dqm.rnn1C + dqp.rnn1A), 1.0000000000000000E-099) which is not suitable for SIMD vectorization.
1586-554 (I) Loop (loop index 11) at momx3.f90 <line 212> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 11) at momx3.f90 <line 211> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg + $$CIV8) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 11) at momx3.f90 <line 211> was not SIMD vectorized because it contains operation in (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV8][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3ai%addr  + d-dx3ai%rvo))->dx3ai[].rns24.[($$CIV8 + (long long) .kbeg->kbeg) - 1ll] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 11) at momx3.f90 <line 211> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg + $$CIV8) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 11) at momx3.f90 <line 211> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 11) at momx3.f90 <line 210> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(($$CIV8 + (long long) .kbeg->kbeg) - 1ll) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 11) at momx3.f90 <line 210> was not SIMD vectorized because it contains operation in (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-dx3ai%addr  + d-dx3ai%rvo))->dx3ai[].rns24.[($$CIV8 + (long long) .kbeg->kbeg) - 2ll] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 11) at momx3.f90 <line 210> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(($$CIV8 + (long long) .kbeg->kbeg) - 1ll) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 11) at momx3.f90 <line 210> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-535 (I) Loop (loop index 12) at momx3.f90 <line 225> was not SIMD vectorized because the aliasing-induced dependence prevents SIMD vectorization.
1586-540 (I) Loop (loop index 12) at momx3.f90 <line 225> was not SIMD vectorized because it contains memory references xi.rnn18 = ((( 5.0000000000000000E-001 * (((((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV9 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[($$CIV9 + (long long) .kbeg->kbeg) - 1ll]) + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) - ((double *)((char *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) .kbeg->kbeg + $$CIV9])) * dt) * ((double *)((char *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns23.[(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns14.[(long long) .jbeg->jbeg + $$CIVC]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at momx3.f90 <line 225> was not SIMD vectorized because it contains memory references ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][($$CIV9 + (long long) .kbeg->kbeg) - 1ll] = ( 5.0000000000000000E-001 + q1.rnn16) * (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV9 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double *)((char *)d-dx3b%addr  + d-dx3b%rvo))->dx3b[].rns25.[($$CIV9 + (long long) .kbeg->kbeg) - 1ll] - xi.rnn18) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][($$CIV9 + (long long) .kbeg->kbeg) - 1ll]) + ( 5.0000000000000000E-001 - q1.rnn16) * (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - (((double *)((char *)d-dx3b%addr  + d-dx3b%rvo))->dx3b[].rns25.[(long long) .kbeg->kbeg + $$CIV9] + xi.rnn18) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][(long long) .kbeg->kbeg + $$CIV9]); with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at momx3.f90 <line 225> was not SIMD vectorized because it contains memory references ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][($$CIV9 + (long long) .kbeg->kbeg) - 1ll] = (((((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][($$CIV9 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + ((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][($$CIV9 + (long long) .kbeg->kbeg) - 1ll]) * ((double *)((char *).atwid3  + -8ll))->atwid3[][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).atwidj3  + -8ll))->atwidj3[][(long long) .jbeg->jbeg + $$CIVC]; with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at momx3.f90 <line 229> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 12) at momx3.f90 <line 228> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(($$CIV9 + (long long) .kbeg->kbeg) - 1ll) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 12) at momx3.f90 <line 228> was not SIMD vectorized because it contains operation in ((( 5.0000000000000000E-001 * (((((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV9 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[($$CIV9 + (long long) .kbeg->kbeg) - 1ll]) + ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) - ((double *)((char *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) .kbeg->kbeg + $$CIV9])) * dt) * ((double *)((char *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns23.[(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns14.[(long long) .jbeg->jbeg + $$CIVC] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 12) at momx3.f90 <line 228> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(($$CIV9 + (long long) .kbeg->kbeg) - 1ll) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at momx3.f90 <line 228> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-536 (I) Loop (loop index 12) at momx3.f90 <line 230> was not SIMD vectorized because it contains memory references ((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll + (max((long long) ijkn,0ll) * 8ll)*(1ll) + (8ll)*(($$CIV9 + (long long) .kbeg->kbeg) - 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 12) at momx3.f90 <line 230> was not SIMD vectorized because it contains operation in ( 5.0000000000000000E-001 + q1.rnn16) * (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[($$CIV9 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double *)((char *)d-dx3b%addr  + d-dx3b%rvo))->dx3b[].rns25.[($$CIV9 + (long long) .kbeg->kbeg) - 1ll] - xi.rnn18) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][($$CIV9 + (long long) .kbeg->kbeg) - 1ll]) + ( 5.0000000000000000E-001 - q1.rnn16) * (((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - (((double *)((char *)d-dx3b%addr  + d-dx3b%rvo))->dx3b[].rns25.[(long long) .kbeg->kbeg + $$CIV9] + xi.rnn18) * ((double *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 8ll))->dq[][1ll][(long long) .kbeg->kbeg + $$CIV9]) which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 12) at momx3.f90 <line 230> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(($$CIV9 + (long long) .kbeg->kbeg) - 1ll) + (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at momx3.f90 <line 230> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-537 (I) Loop (loop index 12) at momx3.f90 <line 234> was not SIMD vectorized because it contains operation in (((((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][($$CIV9 + (long long) .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + ((double *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + -8ll - max((long long) ijkn,0ll) * 8ll))->sflx[][1ll][($$CIV9 + (long long) .kbeg->kbeg) - 1ll]) * ((double *)((char *).atwid3  + -8ll))->atwid3[][(long long) .ibeg->ibeg + $$CIVB]) * ((double *)((char *).atwidj3  + -8ll))->atwidj3[][(long long) .jbeg->jbeg + $$CIVC] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 12) at momx3.f90 <line 234> was not SIMD vectorized because it contains memory references ((char *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) * max((long long) in,0ll))) + (8ll * (max((long long) jn,0ll) * max((long long) in,0ll)))*(($$CIV9 + (long long) .kbeg->kbeg) - 1ll) + (max((long long) in,0ll) * 8ll)*((long long) .jbeg->jbeg + $$CIVC) + (8ll)*((long long) .ibeg->ibeg + $$CIVB)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at momx3.f90 <line 234> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-538 (I) Loop (loop index 13) at momx3.f90 <line 238> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 13) at momx3.f90 <line 238> was not SIMD vectorized because it contains control flow.
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"11">. Total number of the innermost loops SIMD vectorized <"0">.


    11|         SUBROUTINE momx3 (ibeg, iend, jbeg, jend, kbeg, kend, s1, s2, s3, mflx, atwid1, atwid2, atwid3, atwidj1, atwidj2, atwidj3, sflx, dq)
    88|           IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                    $$CIV0 = 0
       Id=1         DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(ibeg))))-1
    89|               atwid1(int(ibeg) + $$CIV0) = (( 5.0000000000000000E-001 * &
                &       d-g2a%addr%g2a(int(ibeg) + $$CIV0)) * d-dx1b%addr%dx1b(&
                &       int(ibeg) + $$CIV0)) * d-dvl1bi%addr%dvl1bi(int(ibeg) + &
                &       $$CIV0)
    90|               atwid2(int(ibeg) + $$CIV0) = ((( 5.0000000000000000E-001 &
                &       * d-g2b%addr%g2b(int(ibeg) + $$CIV0)) * d-g2b%addr%g2b(&
                &       int(ibeg) + $$CIV0)) * d-dx1a%addr%dx1a(int(ibeg) + &
                &       $$CIV0)) * d-dvl1ai%addr%dvl1ai(int(ibeg) + $$CIV0)
    91|               atwid3(int(ibeg) + $$CIV0) = ((( 5.0000000000000000E-001 &
                &       * d-g31b%addr%g31b(int(ibeg) + $$CIV0)) * d-g2b%addr%g2b(&
                &       int(ibeg) + $$CIV0)) * d-dx1a%addr%dx1a(int(ibeg) + &
                &       $$CIV0)) * d-dvl1ai%addr%dvl1ai(int(ibeg) + $$CIV0)
    92|             ENDDO
                  ENDIF
    93|           IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                    $$CIV1 = 0
       Id=2         DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))))-1
    94|               atwidj1(int(jbeg) + $$CIV1) = d-dx2a%addr%dx2a(int(jbeg) &
                &       + $$CIV1) * d-dvl2ai%addr%dvl2ai(int(jbeg) + $$CIV1)
    95|               atwidj2(int(jbeg) + $$CIV1) = d-dx2b%addr%dx2b(int(jbeg) &
                &       + $$CIV1) * d-dvl2bi%addr%dvl2bi(int(jbeg) + $$CIV1)
    96|               atwidj3(int(jbeg) + $$CIV1) = (d-g32b%addr%g32b(int(jbeg) &
                &       + $$CIV1) * d-dx2a%addr%dx2a(int(jbeg) + $$CIV1)) * &
                &       d-dvl2ai%addr%dvl2ai(int(jbeg) + $$CIV1)
    97|             ENDDO
                  ENDIF
   101|           IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                    $$CIVC = 0
       Id=3         DO $$CIVC = $$CIVC, int((1 + (int(jend) - int(jbeg))))-1
   102|               IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                        $$CIVB = 0
       Id=4             DO $$CIVB = $$CIVB, int((1 + (int(iend) - int(ibeg))))&
                &           -1
   113|                   IF ((1 + (int((kend + 1)) - int((kbeg - 1))) > 0)) &
                &           THEN
                            $$CIV2 = 0
                            $$PRC20 = d-dx3bi%addr%dx3bi(int(kbeg) - 1)
                            $$PRC22 = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 2)
                            $$PRC23 = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=5                 DO $$CIV2 = $$CIV2, int((1 + (int((kend + 1)) - &
                &               int((kbeg - 1)))))-1
                              $$PRC21 = d-dx3bi%addr%dx3bi(int(kbeg) + $$CIV2)
                              $$PRC24 = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC &
                &               + int(jbeg),int(kbeg) + $$CIV2)
   114|                       dqm = ($$PRC23 - $$PRC22) * $$PRC20
   115|                       dqp = ($$PRC24 - $$PRC23) * $$PRC21
                              $$RET0 = __cpdsign( 1.0000000000000000E+000,(%VAL(&
                &               dqm) + %VAL(dqp)))
   116|                       dq(($$CIV2 + int(kbeg)) - 1,1) = (max(dqm * dqp, &
                &               0.0000000000000000E+000) * $$RET0) / max(abs(dqm &
                &               + dqp), 1.0000000000000000E-099)
                              $$PRC22 = $$PRC23
                              $$PRC23 = $$PRC24
                              $$PRC20 = $$PRC21
   119|                     ENDDO
                          ENDIF
   129|                   IF ((1 + (int((kend + 1)) - int(kbeg)) > 0)) THEN
                            $$CIV3 = 0
                            $$PRC1A = dq(int(kbeg) - 1,1)
                            $$PRC1C = d-dx3a%addr%dx3a(int(kbeg) - 1)
                            $$PRC1E = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=6                 DO $$CIV3 = $$CIV3, int((1 + (int((kend + 1)) - &
                &               int(kbeg))))-1
                              $$PRC1B = dq(int(kbeg) + $$CIV3,1)
                              $$PRC1D = d-dx3a%addr%dx3a(int(kbeg) + $$CIV3)
                              $$PRC1F = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC &
                &               + int(jbeg),int(kbeg) + $$CIV3)
   132|                       xi = ( 5.0000000000000000E-001 * (d-v3%addr%v3((&
                &               $$CIVB + int(ibeg)) - 1,int(jbeg) + $$CIVC,int(&
                &               kbeg) + $$CIV3) + d-v3%addr%v3(int(ibeg) + $$CIVB,&
                &               int(jbeg) + $$CIVC,int(kbeg) + $$CIV3)) - &
                &               d-vg3%addr%vg3(int(kbeg) + $$CIV3)) * ((dt * &
                &               d-g31ai%addr%g31ai(int(ibeg) + $$CIVB)) * &
                &               d-g32bi%addr%g32bi(int(jbeg) + $$CIVC))
   133|                       q1 = __cpdsign( 5.0000000000000000E-001,%VAL(xi))
   134|                       sflx(int(kbeg) + $$CIV3,1) = ( &
                &               5.0000000000000000E-001 + q1) * ($$PRC1E + (&
                &               $$PRC1C - xi) * $$PRC1A) + ( &
                &               5.0000000000000000E-001 - q1) * ($$PRC1F - (&
                &               $$PRC1D + xi) * $$PRC1B)
   138|                       sflx(int(kbeg) + $$CIV3,1) = (((mflx(($$CIVB + &
                &               int(ibeg)) - 1,int(jbeg) + $$CIVC,int(kbeg) + &
                &               $$CIV3) + mflx(int(ibeg) + $$CIVB,int(jbeg) + &
                &               $$CIVC,int(kbeg) + $$CIV3)) * sflx(int(kbeg) + &
                &               $$CIV3,1)) * atwid1(int(ibeg) + $$CIVB)) * &
                &               atwidj1(int(jbeg) + $$CIVC)
                              $$PRC1E = $$PRC1F
                              $$PRC1C = $$PRC1D
                              $$PRC1A = $$PRC1B
   140|                     ENDDO
                          ENDIF
   142|                   IF ((1 + (int(kend) - int(kbeg)) > 0)) THEN
                            $$CIV4 = 0
       Id=7                 DO $$CIV4 = $$CIV4, int((1 + (int(kend) - int(&
                &               kbeg))))-1
   143|                       IF ((0 <> (xvgrid  .AND.  1))) THEN
   144|                         s1(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIV4) = ((s1(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIV4) * &
                &                 d-dvl3a%addr%dvl3a(int(kbeg) + $$CIV4) - sflx(1 &
                &                 + ($$CIV4 + int(kbeg)),1)) + sflx(int(kbeg) + &
                &                 $$CIV4,1)) * d-dvl3ani%addr%dvl3ani(int(kbeg) + &
                &                 $$CIV4)
   146|                       ELSE
   147|                         s1(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIV4) = ((s1(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIV4) * &
                &                 d-dvl3a%addr%dvl3a(int(kbeg) + $$CIV4) - sflx(1 &
                &                 + ($$CIV4 + int(kbeg)),1)) + sflx(int(kbeg) + &
                &                 $$CIV4,1)) * d-dvl3ai%addr%dvl3ai(int(kbeg) + &
                &                 $$CIV4)
   149|                       ENDIF
   150|                     ENDDO
                          ENDIF
   161|                   IF ((1 + (int((kend + 1)) - int((kbeg - 1))) > 0)) &
                &           THEN
                            $$CIV5 = 0
                            $$PRC15 = d-dx3bi%addr%dx3bi(int(kbeg) - 1)
                            $$PRC17 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 2)
                            $$PRC18 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=8                 DO $$CIV5 = $$CIV5, int((1 + (int((kend + 1)) - &
                &               int((kbeg - 1)))))-1
                              $$PRC16 = d-dx3bi%addr%dx3bi(int(kbeg) + $$CIV5)
                              $$PRC19 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC &
                &               + int(jbeg),int(kbeg) + $$CIV5)
   162|                       dqm.rnn1D = ($$PRC18 - $$PRC17) * $$PRC15
   163|                       dqp.rnn1B = ($$PRC19 - $$PRC18) * $$PRC16
                              $$RET1 = __cpdsign( 1.0000000000000000E+000,(%VAL(&
                &               dqm.rnn1D) + %VAL(dqp.rnn1B)))
   164|                       dq(($$CIV5 + int(kbeg)) - 1,1) = (max(dqm.rnn1D * &
                &               dqp.rnn1B, 0.0000000000000000E+000) * $$RET1) / &
                &               max(abs(dqm.rnn1D + dqp.rnn1B), &
                &               1.0000000000000000E-099)
                              $$PRC17 = $$PRC18
                              $$PRC18 = $$PRC19
                              $$PRC15 = $$PRC16
   167|                     ENDDO
                          ENDIF
   177|                   IF ((1 + (int((kend + 1)) - int(kbeg)) > 0)) THEN
                            $$CIV6 = 0
                            $$PRCF = dq(int(kbeg) - 1,1)
                            $$PRC11 = d-dx3a%addr%dx3a(int(kbeg) - 1)
                            $$PRC13 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=9                 DO $$CIV6 = $$CIV6, int((1 + (int((kend + 1)) - &
                &               int(kbeg))))-1
                              $$PRC10 = dq(int(kbeg) + $$CIV6,1)
                              $$PRC12 = d-dx3a%addr%dx3a(int(kbeg) + $$CIV6)
                              $$PRC14 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC &
                &               + int(jbeg),int(kbeg) + $$CIV6)
   180|                       xi.rnn19 = ( 5.0000000000000000E-001 * (&
                &               d-v3%addr%v3(int(ibeg) + $$CIVB,($$CIVC + int(&
                &               jbeg)) - 1,int(kbeg) + $$CIV6) + d-v3%addr%v3(int(&
                &               ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(kbeg) + &
                &               $$CIV6)) - d-vg3%addr%vg3(int(kbeg) + $$CIV6)) * (&
                &               (dt * d-g31bi%addr%g31bi(int(ibeg) + $$CIVB)) * &
                &               d-g32ai%addr%g32ai(int(jbeg) + $$CIVC))
   181|                       q1.rnn17 = __cpdsign( 5.0000000000000000E-001,&
                &               %VAL(xi.rnn19))
   182|                       sflx(int(kbeg) + $$CIV6,1) = ( &
                &               5.0000000000000000E-001 + q1.rnn17) * ($$PRC13 + (&
                &               $$PRC11 - xi.rnn19) * $$PRCF) + ( &
                &               5.0000000000000000E-001 - q1.rnn17) * ($$PRC14 - (&
                &               $$PRC12 + xi.rnn19) * $$PRC10)
   186|                       sflx(int(kbeg) + $$CIV6,1) = (((mflx(int(ibeg) + &
                &               $$CIVB,($$CIVC + int(jbeg)) - 1,int(kbeg) + &
                &               $$CIV6) + mflx(int(ibeg) + $$CIVB,int(jbeg) + &
                &               $$CIVC,int(kbeg) + $$CIV6)) * sflx(int(kbeg) + &
                &               $$CIV6,1)) * atwid2(int(ibeg) + $$CIVB)) * &
                &               atwidj2(int(jbeg) + $$CIVC)
                              $$PRC13 = $$PRC14
                              $$PRC11 = $$PRC12
                              $$PRCF = $$PRC10
   188|                     ENDDO
                          ENDIF
   190|                   IF ((1 + (int(kend) - int(kbeg)) > 0)) THEN
                            $$CIV7 = 0
       Id=10                DO $$CIV7 = $$CIV7, int((1 + (int(kend) - int(&
                &               kbeg))))-1
   191|                       IF ((0 <> (xvgrid  .AND.  1))) THEN
   192|                         s2(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIV7) = ((s2(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIV7) * &
                &                 d-dvl3a%addr%dvl3a(int(kbeg) + $$CIV7) - sflx(1 &
                &                 + ($$CIV7 + int(kbeg)),1)) + sflx(int(kbeg) + &
                &                 $$CIV7,1)) * d-dvl3ani%addr%dvl3ani(int(kbeg) + &
                &                 $$CIV7)
   194|                       ELSE
   195|                         s2(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIV7) = ((s2(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIV7) * &
                &                 d-dvl3a%addr%dvl3a(int(kbeg) + $$CIV7) - sflx(1 &
                &                 + ($$CIV7 + int(kbeg)),1)) + sflx(int(kbeg) + &
                &                 $$CIV7,1)) * d-dvl3ai%addr%dvl3ai(int(kbeg) + &
                &                 $$CIV7)
   197|                       ENDIF
   198|                     ENDDO
                          ENDIF
   209|                   IF ((1 + (int((kend + 1)) - int((kbeg - 1))) > 0)) &
                &           THEN
                            $$CIV8 = 0
                            $$PRCA = d-dx3ai%addr%dx3ai(int(kbeg) - 2)
                            $$PRCC = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 2)
                            $$PRCD = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=11                DO $$CIV8 = $$CIV8, int((1 + (int((kend + 1)) - &
                &               int((kbeg - 1)))))-1
                              $$PRCB = d-dx3ai%addr%dx3ai((int(kbeg) + $$CIV8) &
                &               - 1)
                              $$PRCE = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &               int(jbeg),int(kbeg) + $$CIV8)
   210|                       dqm.rnn1C = ($$PRCD - $$PRCC) * $$PRCA
   211|                       dqp.rnn1A = ($$PRCE - $$PRCD) * $$PRCB
                              $$RET2 = __cpdsign( 1.0000000000000000E+000,(%VAL(&
                &               dqm.rnn1C) + %VAL(dqp.rnn1A)))
   212|                       dq(($$CIV8 + int(kbeg)) - 1,1) = (max(dqm.rnn1C * &
                &               dqp.rnn1A, 0.0000000000000000E+000) * $$RET2) / &
                &               max(abs(dqm.rnn1C + dqp.rnn1A), &
                &               1.0000000000000000E-099)
                              $$PRCC = $$PRCD
                              $$PRCD = $$PRCE
                              $$PRCA = $$PRCB
   215|                     ENDDO
                          ENDIF
   225|                   IF ((1 + (int(kend) - int((kbeg - 1))) > 0)) THEN
                            $$CIV9 = 0
                            $$PRC0 = dq(int(kbeg) - 1,1)
                            $$PRC2 = d-dx3b%addr%dx3b(int(kbeg) - 1)
                            $$PRC4 = d-vg3%addr%vg3(int(kbeg) - 1)
                            $$PRC6 = mflx($$CIVB + int(ibeg),$$CIVC + int(jbeg),&
                &             int(kbeg) - 1)
                            $$PRC8 = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=12                DO $$CIV9 = $$CIV9, int((1 + (int(kend) - int((&
                &               kbeg - 1)))))-1
                              $$PRC1 = dq(int(kbeg) + $$CIV9,1)
                              $$PRC3 = d-dx3b%addr%dx3b(int(kbeg) + $$CIV9)
                              $$PRC5 = d-vg3%addr%vg3(int(kbeg) + $$CIV9)
                              $$PRC7 = mflx($$CIVB + int(ibeg),$$CIVC + int(&
                &               jbeg),int(kbeg) + $$CIV9)
                              $$PRC9 = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &               int(jbeg),int(kbeg) + $$CIV9)
   228|                       xi.rnn18 = ((( 5.0000000000000000E-001 * (((&
                &               $$PRC8 - $$PRC4) + $$PRC9) - $$PRC5)) * dt) * &
                &               d-g31bi%addr%g31bi(int(ibeg) + $$CIVB)) * &
                &               d-g32bi%addr%g32bi(int(jbeg) + $$CIVC)
   229|                       q1.rnn16 = __cpdsign( 5.0000000000000000E-001,&
                &               %VAL(xi.rnn18))
   230|                       sflx(($$CIV9 + int(kbeg)) - 1,1) = ( &
                &               5.0000000000000000E-001 + q1.rnn16) * ($$PRC8 + (&
                &               $$PRC2 - xi.rnn18) * $$PRC0) + ( &
                &               5.0000000000000000E-001 - q1.rnn16) * ($$PRC9 - (&
                &               $$PRC3 + xi.rnn18) * $$PRC1)
   234|                       sflx(($$CIV9 + int(kbeg)) - 1,1) = ((($$PRC6 + &
                &               $$PRC7) * sflx(($$CIV9 + int(kbeg)) - 1,1)) * &
                &               atwid3(int(ibeg) + $$CIVB)) * atwidj3(int(jbeg) + &
                &               $$CIVC)
                              $$PRC8 = $$PRC9
                              $$PRC6 = $$PRC7
                              $$PRC4 = $$PRC5
                              $$PRC2 = $$PRC3
                              $$PRC0 = $$PRC1
   236|                     ENDDO
                          ENDIF
   238|                   IF ((1 + (int(kend) - int(kbeg)) > 0)) THEN
                            $$CIVA = 0
       Id=13                DO $$CIVA = $$CIVA, int((1 + (int(kend) - int(&
                &               kbeg))))-1
   239|                       IF ((0 <> (xvgrid  .AND.  1))) THEN
   240|                         s3(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIVA) = ((s3(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIVA) * &
                &                 d-dvl3b%addr%dvl3b(int(kbeg) + $$CIVA) - sflx(&
                &                 int(kbeg) + $$CIVA,1)) + sflx(($$CIVA + int(&
                &                 kbeg)) - 1,1)) * d-dvl3bni%addr%dvl3bni(int(&
                &                 kbeg) + $$CIVA)
   242|                       ELSE
   243|                         s3(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIVA) = ((s3(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIVA) * &
                &                 d-dvl3b%addr%dvl3b(int(kbeg) + $$CIVA) - sflx(&
                &                 int(kbeg) + $$CIVA,1)) + sflx(($$CIVA + int(&
                &                 kbeg)) - 1,1)) * d-dvl3bi%addr%dvl3bi(int(kbeg) &
                &                 + $$CIVA)
   245|                       ENDIF
   246|                     ENDDO
                          ENDIF
   247|                 ENDDO
                      ENDIF
   248|             ENDDO
                  ENDIF
   251|           RETURN
                END SUBROUTINE momx3


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0            88             1    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            89                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).atwid1  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV0))  with 
                                          non-vectorizable alignment.
         0            89                  Loop was not SIMD vectorized because it contains 
                                          operation in (( 5.0000000000000000E-001 * ((double 
                                          *)((char *)d-g2a%addr  + 
                                          d-g2a%rvo))->g2a[].rns2.[(long long) .ibeg->ibeg + 
                                          $$CIV0]) * ((double *)((char *)d-dx1b%addr  + 
                                          d-dx1b%rvo))->dx1b[].rns1.[(long long) .ibeg->ibeg + 
                                          $$CIV0]) * ((double *)((char *)d-dvl1bi%addr  + 
                                          d-dvl1bi%rvo))->dvl1bi[].rns0.[(long long) 
                                          .ibeg->ibeg + $$CIV0] which is not  suitable for SIMD 
                                          vectorization.
         0            89                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            90                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).atwid2  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV0))  with 
                                          non-vectorizable alignment.
         0            90                  Loop was not SIMD vectorized because it contains 
                                          operation in ((( 5.0000000000000000E-001 * ((double 
                                          *)((char *)d-g2b%addr  + 
                                          d-g2b%rvo))->g2b[].rns5.[(long long) .ibeg->ibeg + 
                                          $$CIV0]) * ((double *)((char *)d-g2b%addr  + 
                                          d-g2b%rvo))->g2b[].rns5.[(long long) .ibeg->ibeg + 
                                          $$CIV0]) * ((double *)((char *)d-dx1a%addr  + 
                                          d-dx1a%rvo))->dx1a[].rns4.[(long long) .ibeg->ibeg + 
                                          $$CIV0]) * ((double *)((char *)d-dvl1ai%addr  + 
                                          d-dvl1ai%rvo))->dvl1ai[].rns3.[(long long) 
                                          .ibeg->ibeg + $$CIV0] which is not  suitable for SIMD 
                                          vectorization.
         0            90                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            91                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).atwid3  + -8ll + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIV0))  with 
                                          non-vectorizable alignment.
         0            91                  Loop was not SIMD vectorized because it contains 
                                          operation in ((( 5.0000000000000000E-001 * ((double 
                                          *)((char *)d-g31b%addr  + 
                                          d-g31b%rvo))->g31b[].rns6.[(long long) .ibeg->ibeg + 
                                          $$CIV0]) * ((double *)((char *)d-g2b%addr  + 
                                          d-g2b%rvo))->g2b[].rns5.[(long long) .ibeg->ibeg + 
                                          $$CIV0]) * ((double *)((char *)d-dx1a%addr  + 
                                          d-dx1a%rvo))->dx1a[].rns4.[(long long) .ibeg->ibeg + 
                                          $$CIV0]) * ((double *)((char *)d-dvl1ai%addr  + 
                                          d-dvl1ai%rvo))->dvl1ai[].rns3.[(long long) 
                                          .ibeg->ibeg + $$CIV0] which is not  suitable for SIMD 
                                          vectorization.
         0            91                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            93             2    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0            94                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).atwidj1  + -8ll + 
                                          (8ll)*((long long) .jbeg->jbeg + $$CIV1))  with 
                                          non-vectorizable alignment.
         0            94                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *)d-dx2a%addr  + 
                                          d-dx2a%rvo))->dx2a[].rns8.[(long long) .jbeg->jbeg + 
                                          $$CIV1] * ((double *)((char *)d-dvl2ai%addr  + 
                                          d-dvl2ai%rvo))->dvl2ai[].rns7.[(long long) 
                                          .jbeg->jbeg + $$CIV1] which is not  suitable for SIMD 
                                          vectorization.
         0            94                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            95                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).atwidj2  + -8ll + 
                                          (8ll)*((long long) .jbeg->jbeg + $$CIV1))  with 
                                          non-vectorizable alignment.
         0            95                  Loop was not SIMD vectorized because it contains 
                                          operation in ((double *)((char *)d-dx2b%addr  + 
                                          d-dx2b%rvo))->dx2b[].rns10.[(long long) .jbeg->jbeg + 
                                          $$CIV1] * ((double *)((char *)d-dvl2bi%addr  + 
                                          d-dvl2bi%rvo))->dvl2bi[].rns9.[(long long) 
                                          .jbeg->jbeg + $$CIV1] which is not  suitable for SIMD 
                                          vectorization.
         0            95                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            96                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).atwidj3  + -8ll + 
                                          (8ll)*((long long) .jbeg->jbeg + $$CIV1))  with 
                                          non-vectorizable alignment.
         0            96                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-g32b%addr  + 
                                          d-g32b%rvo))->g32b[].rns11.[(long long) .jbeg->jbeg + 
                                          $$CIV1] * ((double *)((char *)d-dx2a%addr  + 
                                          d-dx2a%rvo))->dx2a[].rns8.[(long long) .jbeg->jbeg + 
                                          $$CIV1]) * ((double *)((char *)d-dvl2ai%addr  + 
                                          d-dvl2ai%rvo))->dvl2ai[].rns7.[(long long) 
                                          .jbeg->jbeg + $$CIV1] which is not  suitable for SIMD 
                                          vectorization.
         0            96                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           101             3    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           102             4    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           113             5    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0           114                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(($$CIV2 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v1%bounds%mult[].off512)*((long long) 
                                          .ibeg->ibeg + $$CIVB))  with non-vectorizable 
                                          alignment.
         0           114                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-v1%addr  + 
                                          d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double 
                                          *)((char *)d-v1%addr  + 
                                          d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) 
                                          .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double 
                                          *)((char *)d-dx3bi%addr  + 
                                          d-dx3bi%rvo))->dx3bi[].rns12.[($$CIV2 + (long long) 
                                          .kbeg->kbeg) - 1ll] which is not  suitable for SIMD 
                                          vectorization.
         0           114                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(($$CIV2 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v1%bounds%mult[].off512)*((long long) 
                                          .ibeg->ibeg + $$CIVB)) with  non-vectorizable strides.
         0           114                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           115                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg 
                                          + $$CIV2) + (d-v1%bounds%mult[].off488)*((long long) 
                                          .jbeg->jbeg + $$CIVC) + 
                                          (d-v1%bounds%mult[].off512)*((long long) .ibeg->ibeg 
                                          + $$CIVB))  with non-vectorizable alignment.
         0           115                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-v1%addr  + 
                                          d-v1%rvo))->v1[].rns13.[(long long) .kbeg->kbeg + 
                                          $$CIV2][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v1%addr 
                                          + d-v1%rvo))->v1[].rns13.[($$CIV2 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double 
                                          *)((char *)d-dx3bi%addr  + 
                                          d-dx3bi%rvo))->dx3bi[].rns12.[(long long) .kbeg->kbeg 
                                          + $$CIV2] which is not  suitable for SIMD 
                                          vectorization.
         0           115                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*((long long) .kbeg->kbeg 
                                          + $$CIV2) + (d-v1%bounds%mult[].off488)*((long long) 
                                          .jbeg->jbeg + $$CIVC) + 
                                          (d-v1%bounds%mult[].off512)*((long long) .ibeg->ibeg 
                                          + $$CIVB)) with  non-vectorizable strides.
         0           115                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           115                  Loop was not SIMD vectorized because it contains 
                                          operation in dqm + dqp which is not  suitable for 
                                          SIMD vectorization.
         0           115                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           116                  Loop was not SIMD vectorized because it contains 
                                          operation in (max(dqm * dqp, 0.0000000000000000E+000) 
                                          * $$RET0) / max(abs(dqm + dqp), 
                                          1.0000000000000000E-099) which is not  suitable for 
                                          SIMD vectorization.
         0           116                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           129             6    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0           132                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg 
                                          + $$CIV3) + (d-v3%bounds%mult[].off696)*((long long) 
                                          .jbeg->jbeg + $$CIVC) + 
                                          (d-v3%bounds%mult[].off720)*(($$CIVB + (long long) 
                                          .ibeg->ibeg) - 1ll))  with non-vectorizable alignment.
         0           132                  Loop was not SIMD vectorized because it contains 
                                          operation in ( 5.0000000000000000E-001 * (((double 
                                          *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long 
                                          long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + 
                                          $$CIVC][($$CIVB + (long long) .ibeg->ibeg) - 1ll] + 
                                          ((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + 
                                          $$CIV3][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB]) - ((double *)((char 
                                          *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) 
                                          .kbeg->kbeg + $$CIV3]) * ((dt * ((double *)((char 
                                          *)d-g31ai%addr  + d-g31ai%rvo))->g31ai[].rns15.[(long 
                                          long) .ibeg->ibeg + $$CIVB]) * ((double *)((char 
                                          *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns14.[(long 
                                          long) .jbeg->jbeg + $$CIVC]) which is not  suitable 
                                          for SIMD vectorization.
         0           132                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg 
                                          + $$CIV3) + (d-v3%bounds%mult[].off696)*((long long) 
                                          .jbeg->jbeg + $$CIVC) + 
                                          (d-v3%bounds%mult[].off720)*(($$CIVB + (long long) 
                                          .ibeg->ibeg) - 1ll)) with  non-vectorizable strides.
         0           132                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           133                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           134                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).sflx  + -8ll - max((long 
                                          long) ijkn,0ll) * 8ll + (max((long long) ijkn,0ll) * 
                                          8ll)*(1ll) + (8ll)*((long long) .kbeg->kbeg + 
                                          $$CIV3))  with non-vectorizable alignment.
         0           134                  Loop was not SIMD vectorized because it contains 
                                          operation in ( 5.0000000000000000E-001 + q1) * 
                                          (((double *)((char *)d-v1%addr  + 
                                          d-v1%rvo))->v1[].rns13.[($$CIV3 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double 
                                          *)((char *)d-dx3a%addr  + 
                                          d-dx3a%rvo))->dx3a[].rns18.[($$CIV3 + (long long) 
                                          .kbeg->kbeg) - 1ll] - xi) * ((double *)((char *).dq  
                                          + -8ll - max((long long) ijkn,0ll) * 
                                          8ll))->dq[][1ll][($$CIV3 + (long long) .kbeg->kbeg) - 
                                          1ll]) + ( 5.0000000000000000E-001 - q1) * (((double 
                                          *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns13.[(long 
                                          long) .kbeg->kbeg + $$CIV3][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - (((double 
                                          *)((char *)d-dx3a%addr  + 
                                          d-dx3a%rvo))->dx3a[].rns18.[(long long) .kbeg->kbeg + 
                                          $$CIV3] + xi) * ((double *)((char *).dq  + -8ll - 
                                          max((long long) ijkn,0ll) * 8ll))->dq[][1ll][(long 
                                          long) .kbeg->kbeg + $$CIV3]) which is not  suitable 
                                          for SIMD vectorization.
         0           134                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(($$CIV3 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v1%bounds%mult[].off488)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v1%bounds%mult[].off512)*((long long) 
                                          .ibeg->ibeg + $$CIVB)) with  non-vectorizable strides.
         0           134                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           138                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((double *)((char *).mflx  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->mflx[][(long long) .kbeg->kbeg + 
                                          $$CIV3][(long long) .jbeg->jbeg + $$CIVC][($$CIVB + 
                                          (long long) .ibeg->ibeg) - 1ll] + ((double *)((char 
                                          *).mflx  + -8ll - (max((long long) in,0ll) * 8ll + 
                                          8ll * (max((long long) jn,0ll) * max((long long) 
                                          in,0ll)))))->mflx[][(long long) .kbeg->kbeg + 
                                          $$CIV3][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + 
                                          -8ll - max((long long) ijkn,0ll) * 
                                          8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV3]) 
                                          * ((double *)((char *).atwid1  + 
                                          -8ll))->atwid1[][(long long) .ibeg->ibeg + $$CIVB]) * 
                                          ((double *)((char *).atwidj1  + 
                                          -8ll))->atwidj1[][(long long) .jbeg->jbeg + $$CIVC] 
                                          which is not  suitable for SIMD vectorization.
         0           138                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).mflx  + -8ll - (max((long 
                                          long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) 
                                          * max((long long) in,0ll))) + (8ll * (max((long long) 
                                          jn,0ll) * max((long long) in,0ll)))*((long long) 
                                          .kbeg->kbeg + $$CIV3) + (max((long long) in,0ll) * 
                                          8ll)*((long long) .jbeg->jbeg + $$CIVC) + 
                                          (8ll)*(($$CIVB + (long long) .ibeg->ibeg) - 1ll)) 
                                          with  non-vectorizable strides.
         0           138                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           142             7    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           142             7    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           161             8    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0           162                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(($$CIV5 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v2%bounds%mult[].off616)*((long long) 
                                          .ibeg->ibeg + $$CIVB))  with non-vectorizable 
                                          alignment.
         0           162                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double 
                                          *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) 
                                          .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double 
                                          *)((char *)d-dx3bi%addr  + 
                                          d-dx3bi%rvo))->dx3bi[].rns12.[($$CIV5 + (long long) 
                                          .kbeg->kbeg) - 1ll] which is not  suitable for SIMD 
                                          vectorization.
         0           162                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(($$CIV5 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v2%bounds%mult[].off616)*((long long) 
                                          .ibeg->ibeg + $$CIVB)) with  non-vectorizable strides.
         0           162                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           163                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg 
                                          + $$CIV5) + (d-v2%bounds%mult[].off592)*((long long) 
                                          .jbeg->jbeg + $$CIVC) + 
                                          (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg 
                                          + $$CIVB))  with non-vectorizable alignment.
         0           163                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns21.[(long long) .kbeg->kbeg + 
                                          $$CIV5][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v2%addr 
                                          + d-v2%rvo))->v2[].rns21.[($$CIV5 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double 
                                          *)((char *)d-dx3bi%addr  + 
                                          d-dx3bi%rvo))->dx3bi[].rns12.[(long long) .kbeg->kbeg 
                                          + $$CIV5] which is not  suitable for SIMD 
                                          vectorization.
         0           163                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*((long long) .kbeg->kbeg 
                                          + $$CIV5) + (d-v2%bounds%mult[].off592)*((long long) 
                                          .jbeg->jbeg + $$CIVC) + 
                                          (d-v2%bounds%mult[].off616)*((long long) .ibeg->ibeg 
                                          + $$CIVB)) with  non-vectorizable strides.
         0           163                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           163                  Loop was not SIMD vectorized because it contains 
                                          operation in dqm.rnn1D + dqp.rnn1B which is not  
                                          suitable for SIMD vectorization.
         0           163                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           164                  Loop was not SIMD vectorized because it contains 
                                          operation in (max(dqm.rnn1D * dqp.rnn1B, 
                                          0.0000000000000000E+000) * $$RET1) / 
                                          max(abs(dqm.rnn1D + dqp.rnn1B), 
                                          1.0000000000000000E-099) which is not  suitable for 
                                          SIMD vectorization.
         0           164                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           177             9    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0           180                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg 
                                          + $$CIV6) + (d-v3%bounds%mult[].off696)*(($$CIVC + 
                                          (long long) .jbeg->jbeg) - 1ll) + 
                                          (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg 
                                          + $$CIVB))  with non-vectorizable alignment.
         0           180                  Loop was not SIMD vectorized because it contains 
                                          operation in ( 5.0000000000000000E-001 * (((double 
                                          *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns17.[(long 
                                          long) .kbeg->kbeg + $$CIV6][($$CIVC + (long long) 
                                          .jbeg->jbeg) - 1ll][(long long) .ibeg->ibeg + $$CIVB] 
                                          + ((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + 
                                          $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB]) - ((double *)((char 
                                          *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) 
                                          .kbeg->kbeg + $$CIV6]) * ((dt * ((double *)((char 
                                          *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns23.[(long 
                                          long) .ibeg->ibeg + $$CIVB]) * ((double *)((char 
                                          *)d-g32ai%addr  + d-g32ai%rvo))->g32ai[].rns22.[(long 
                                          long) .jbeg->jbeg + $$CIVC]) which is not  suitable 
                                          for SIMD vectorization.
         0           180                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg 
                                          + $$CIV6) + (d-v3%bounds%mult[].off696)*(($$CIVC + 
                                          (long long) .jbeg->jbeg) - 1ll) + 
                                          (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg 
                                          + $$CIVB)) with  non-vectorizable strides.
         0           180                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           181                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           182                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).sflx  + -8ll - max((long 
                                          long) ijkn,0ll) * 8ll + (max((long long) ijkn,0ll) * 
                                          8ll)*(1ll) + (8ll)*((long long) .kbeg->kbeg + 
                                          $$CIV6))  with non-vectorizable alignment.
         0           182                  Loop was not SIMD vectorized because it contains 
                                          operation in ( 5.0000000000000000E-001 + q1.rnn17) * 
                                          (((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns21.[($$CIV6 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double 
                                          *)((char *)d-dx3a%addr  + 
                                          d-dx3a%rvo))->dx3a[].rns18.[($$CIV6 + (long long) 
                                          .kbeg->kbeg) - 1ll] - xi.rnn19) * ((double *)((char 
                                          *).dq  + -8ll - max((long long) ijkn,0ll) * 
                                          8ll))->dq[][1ll][($$CIV6 + (long long) .kbeg->kbeg) - 
                                          1ll]) + ( 5.0000000000000000E-001 - q1.rnn17) * 
                                          (((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns21.[(long long) .kbeg->kbeg + 
                                          $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB] - (((double *)((char 
                                          *)d-dx3a%addr  + d-dx3a%rvo))->dx3a[].rns18.[(long 
                                          long) .kbeg->kbeg + $$CIV6] + xi.rnn19) * ((double 
                                          *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 
                                          8ll))->dq[][1ll][(long long) .kbeg->kbeg + $$CIV6]) 
                                          which is not  suitable for SIMD vectorization.
         0           182                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(($$CIV6 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v2%bounds%mult[].off592)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v2%bounds%mult[].off616)*((long long) 
                                          .ibeg->ibeg + $$CIVB)) with  non-vectorizable strides.
         0           182                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           186                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((double *)((char *).mflx  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->mflx[][(long long) .kbeg->kbeg + 
                                          $$CIV6][($$CIVC + (long long) .jbeg->jbeg) - 
                                          1ll][(long long) .ibeg->ibeg + $$CIVB] + ((double 
                                          *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + 
                                          $$CIV6][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + 
                                          -8ll - max((long long) ijkn,0ll) * 
                                          8ll))->sflx[][1ll][(long long) .kbeg->kbeg + $$CIV6]) 
                                          * ((double *)((char *).atwid2  + 
                                          -8ll))->atwid2[][(long long) .ibeg->ibeg + $$CIVB]) * 
                                          ((double *)((char *).atwidj2  + 
                                          -8ll))->atwidj2[][(long long) .jbeg->jbeg + $$CIVC] 
                                          which is not  suitable for SIMD vectorization.
         0           186                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).mflx  + -8ll - (max((long 
                                          long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) 
                                          * max((long long) in,0ll))) + (8ll * (max((long long) 
                                          jn,0ll) * max((long long) in,0ll)))*((long long) 
                                          .kbeg->kbeg + $$CIV6) + (max((long long) in,0ll) * 
                                          8ll)*(($$CIVC + (long long) .jbeg->jbeg) - 1ll) + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIVB)) with  
                                          non-vectorizable strides.
         0           186                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           190            10    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           190            10    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0           209            11    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0           210                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(($$CIV8 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) 
                                          .ibeg->ibeg + $$CIVB))  with non-vectorizable 
                                          alignment.
         0           210                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double 
                                          *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) 
                                          .kbeg->kbeg) - 2ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double 
                                          *)((char *)d-dx3ai%addr  + 
                                          d-dx3ai%rvo))->dx3ai[].rns24.[($$CIV8 + (long long) 
                                          .kbeg->kbeg) - 2ll] which is not  suitable for SIMD 
                                          vectorization.
         0           210                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(($$CIV8 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) 
                                          .ibeg->ibeg + $$CIVB)) with  non-vectorizable strides.
         0           210                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           211                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg 
                                          + $$CIV8) + (d-v3%bounds%mult[].off696)*((long long) 
                                          .jbeg->jbeg + $$CIVC) + 
                                          (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg 
                                          + $$CIVB))  with non-vectorizable alignment.
         0           211                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + 
                                          $$CIV8][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB] - ((double *)((char *)d-v3%addr 
                                          + d-v3%rvo))->v3[].rns17.[($$CIV8 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB]) * ((double 
                                          *)((char *)d-dx3ai%addr  + 
                                          d-dx3ai%rvo))->dx3ai[].rns24.[($$CIV8 + (long long) 
                                          .kbeg->kbeg) - 1ll] which is not  suitable for SIMD 
                                          vectorization.
         0           211                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*((long long) .kbeg->kbeg 
                                          + $$CIV8) + (d-v3%bounds%mult[].off696)*((long long) 
                                          .jbeg->jbeg + $$CIVC) + 
                                          (d-v3%bounds%mult[].off720)*((long long) .ibeg->ibeg 
                                          + $$CIVB)) with  non-vectorizable strides.
         0           211                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           211                  Loop was not SIMD vectorized because it contains 
                                          operation in dqm.rnn1C + dqp.rnn1A which is not  
                                          suitable for SIMD vectorization.
         0           211                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           212                  Loop was not SIMD vectorized because it contains 
                                          operation in (max(dqm.rnn1C * dqp.rnn1A, 
                                          0.0000000000000000E+000) * $$RET2) / 
                                          max(abs(dqm.rnn1C + dqp.rnn1A), 
                                          1.0000000000000000E-099) which is not  suitable for 
                                          SIMD vectorization.
         0           212                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           225            12    Loop was not SIMD vectorized because the 
                                          aliasing-induced dependence  prevents SIMD 
                                          vectorization.
         0           228                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) 
                                          .ibeg->ibeg + $$CIVB))  with non-vectorizable 
                                          alignment.
         0           228                  Loop was not SIMD vectorized because it contains 
                                          operation in ((( 5.0000000000000000E-001 * 
                                          (((((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns17.[($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] - ((double 
                                          *)((char *)d-vg3%addr  + 
                                          d-vg3%rvo))->vg3[].rns16.[($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll]) + ((double *)((char *)d-v3%addr  
                                          + d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + 
                                          $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB]) - ((double *)((char 
                                          *)d-vg3%addr  + d-vg3%rvo))->vg3[].rns16.[(long long) 
                                          .kbeg->kbeg + $$CIV9])) * dt) * ((double *)((char 
                                          *)d-g31bi%addr  + d-g31bi%rvo))->g31bi[].rns23.[(long 
                                          long) .ibeg->ibeg + $$CIVB]) * ((double *)((char 
                                          *)d-g32bi%addr  + d-g32bi%rvo))->g32bi[].rns14.[(long 
                                          long) .jbeg->jbeg + $$CIVC] which is not  suitable 
                                          for SIMD vectorization.
         0           228                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) 
                                          .ibeg->ibeg + $$CIVB)) with  non-vectorizable strides.
         0           228                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           229                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           230                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).sflx  + -8ll - max((long 
                                          long) ijkn,0ll) * 8ll + (max((long long) ijkn,0ll) * 
                                          8ll)*(1ll) + (8ll)*(($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll))  with non-vectorizable alignment.
         0           230                  Loop was not SIMD vectorized because it contains 
                                          operation in ( 5.0000000000000000E-001 + q1.rnn16) * 
                                          (((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns17.[($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + (((double 
                                          *)((char *)d-dx3b%addr  + 
                                          d-dx3b%rvo))->dx3b[].rns25.[($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll] - xi.rnn18) * ((double *)((char 
                                          *).dq  + -8ll - max((long long) ijkn,0ll) * 
                                          8ll))->dq[][1ll][($$CIV9 + (long long) .kbeg->kbeg) - 
                                          1ll]) + ( 5.0000000000000000E-001 - q1.rnn16) * 
                                          (((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns17.[(long long) .kbeg->kbeg + 
                                          $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB] - (((double *)((char 
                                          *)d-dx3b%addr  + d-dx3b%rvo))->dx3b[].rns25.[(long 
                                          long) .kbeg->kbeg + $$CIV9] + xi.rnn18) * ((double 
                                          *)((char *).dq  + -8ll - max((long long) ijkn,0ll) * 
                                          8ll))->dq[][1ll][(long long) .kbeg->kbeg + $$CIV9]) 
                                          which is not  suitable for SIMD vectorization.
         0           230                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll) + 
                                          (d-v3%bounds%mult[].off696)*((long long) .jbeg->jbeg 
                                          + $$CIVC) + (d-v3%bounds%mult[].off720)*((long long) 
                                          .ibeg->ibeg + $$CIVB)) with  non-vectorizable strides.
         0           230                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           234                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((double *)((char *).mflx  + -8ll - 
                                          (max((long long) in,0ll) * 8ll + 8ll * (max((long 
                                          long) jn,0ll) * max((long long) 
                                          in,0ll)))))->mflx[][($$CIV9 + (long long) 
                                          .kbeg->kbeg) - 1ll][(long long) .jbeg->jbeg + 
                                          $$CIVC][(long long) .ibeg->ibeg + $$CIVB] + ((double 
                                          *)((char *).mflx  + -8ll - (max((long long) in,0ll) * 
                                          8ll + 8ll * (max((long long) jn,0ll) * max((long 
                                          long) in,0ll)))))->mflx[][(long long) .kbeg->kbeg + 
                                          $$CIV9][(long long) .jbeg->jbeg + $$CIVC][(long long) 
                                          .ibeg->ibeg + $$CIVB]) * ((double *)((char *).sflx  + 
                                          -8ll - max((long long) ijkn,0ll) * 
                                          8ll))->sflx[][1ll][($$CIV9 + (long long) .kbeg->kbeg) 
                                          - 1ll]) * ((double *)((char *).atwid3  + 
                                          -8ll))->atwid3[][(long long) .ibeg->ibeg + $$CIVB]) * 
                                          ((double *)((char *).atwidj3  + 
                                          -8ll))->atwidj3[][(long long) .jbeg->jbeg + $$CIVC] 
                                          which is not  suitable for SIMD vectorization.
         0           234                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *).mflx  + -8ll - (max((long 
                                          long) in,0ll) * 8ll + 8ll * (max((long long) jn,0ll) 
                                          * max((long long) in,0ll))) + (8ll * (max((long long) 
                                          jn,0ll) * max((long long) in,0ll)))*(($$CIV9 + (long 
                                          long) .kbeg->kbeg) - 1ll) + (max((long long) in,0ll) 
                                          * 8ll)*((long long) .jbeg->jbeg + $$CIVC) + 
                                          (8ll)*((long long) .ibeg->ibeg + $$CIVB)) with  
                                          non-vectorizable strides.
         0           234                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           238            13    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           238            13    Loop was not SIMD vectorized because it contains 
                                          control flow.


    11|         SUBROUTINE momx3 (ibeg, iend, jbeg, jend, kbeg, kend, s1, s2, s3, mflx, atwid1, atwid2, atwid3, atwidj1, atwidj2, atwidj3, sflx, dq)
    88|           IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                    $$CIV0 = 0
       Id=1         DO $$CIV0 = $$CIV0, int((1 + (int(iend) - int(ibeg))))-1
    89|               atwid1(int(ibeg) + $$CIV0) = (( 5.0000000000000000E-001 * &
                &       d-g2a%addr%g2a(int(ibeg) + $$CIV0)) * d-dx1b%addr%dx1b(&
                &       int(ibeg) + $$CIV0)) * d-dvl1bi%addr%dvl1bi(int(ibeg) + &
                &       $$CIV0)
    90|               atwid2(int(ibeg) + $$CIV0) = ((( 5.0000000000000000E-001 &
                &       * d-g2b%addr%g2b(int(ibeg) + $$CIV0)) * d-g2b%addr%g2b(&
                &       int(ibeg) + $$CIV0)) * d-dx1a%addr%dx1a(int(ibeg) + &
                &       $$CIV0)) * d-dvl1ai%addr%dvl1ai(int(ibeg) + $$CIV0)
    91|               atwid3(int(ibeg) + $$CIV0) = ((( 5.0000000000000000E-001 &
                &       * d-g31b%addr%g31b(int(ibeg) + $$CIV0)) * d-g2b%addr%g2b(&
                &       int(ibeg) + $$CIV0)) * d-dx1a%addr%dx1a(int(ibeg) + &
                &       $$CIV0)) * d-dvl1ai%addr%dvl1ai(int(ibeg) + $$CIV0)
    92|             ENDDO
                  ENDIF
    93|           IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                    $$CIV1 = 0
       Id=2         DO $$CIV1 = $$CIV1, int((1 + (int(jend) - int(jbeg))))-1
    94|               atwidj1(int(jbeg) + $$CIV1) = d-dx2a%addr%dx2a(int(jbeg) &
                &       + $$CIV1) * d-dvl2ai%addr%dvl2ai(int(jbeg) + $$CIV1)
    95|               atwidj2(int(jbeg) + $$CIV1) = d-dx2b%addr%dx2b(int(jbeg) &
                &       + $$CIV1) * d-dvl2bi%addr%dvl2bi(int(jbeg) + $$CIV1)
    96|               atwidj3(int(jbeg) + $$CIV1) = (d-g32b%addr%g32b(int(jbeg) &
                &       + $$CIV1) * d-dx2a%addr%dx2a(int(jbeg) + $$CIV1)) * &
                &       d-dvl2ai%addr%dvl2ai(int(jbeg) + $$CIV1)
    97|             ENDDO
                  ENDIF
   101|           IF ((1 + (int(jend) - int(jbeg)) > 0)) THEN
                    $$CIVC = 0
       Id=3         DO $$CIVC = $$CIVC, int((1 + (int(jend) - int(jbeg))))-1
   102|               IF ((1 + (int(iend) - int(ibeg)) > 0)) THEN
                        $$CIVB = 0
       Id=4             DO $$CIVB = $$CIVB, int((1 + (int(iend) - int(ibeg))))&
                &           -1
   113|                   IF ((1 + (int((kend + 1)) - int((kbeg - 1))) > 0)) &
                &           THEN
                            $$CIV2 = 0
                            $$PRC20 = d-dx3bi%addr%dx3bi(int(kbeg) - 1)
                            $$PRC22 = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 2)
                            $$PRC23 = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=5                 DO $$CIV2 = $$CIV2, int((1 + (int((kend + 1)) - &
                &               int((kbeg - 1)))))-1
                              $$PRC21 = d-dx3bi%addr%dx3bi(int(kbeg) + $$CIV2)
                              $$PRC24 = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC &
                &               + int(jbeg),int(kbeg) + $$CIV2)
   114|                       dqm = ($$PRC23 - $$PRC22) * $$PRC20
   115|                       dqp = ($$PRC24 - $$PRC23) * $$PRC21
                              $$RET0 = __cpdsign( 1.0000000000000000E+000,%VAL(&
                &               dqm) + %VAL(dqp))
   116|                       dq(($$CIV2 + int(kbeg)) - 1,1) = (max(dqm * dqp, &
                &               0.0000000000000000E+000) * $$RET0) / max(abs(dqm &
                &               + dqp), 1.0000000000000000E-099)
                              $$PRC22 = $$PRC23
                              $$PRC23 = $$PRC24
                              $$PRC20 = $$PRC21
   119|                     ENDDO
                          ENDIF
   129|                   IF ((1 + (int((kend + 1)) - int(kbeg)) > 0)) THEN
                            $$CIV3 = 0
                            $$PRC1A = dq(int(kbeg) - 1,1)
                            $$PRC1C = d-dx3a%addr%dx3a(int(kbeg) - 1)
                            $$PRC1E = d-v1%addr%v1($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
                            $$ICM0 = $$CIVB + int(ibeg)
                            $$ICM1 = int(jbeg) + $$CIVC
   132|                     $$ICM2 = d-g32bi%addr%g32bi(int(jbeg) + $$CIVC)
                            $$ICM3 = d-g31ai%addr%g31ai(int(ibeg) + $$CIVB)
   138|                     $$ICM4 = atwidj1(int(jbeg) + $$CIVC)
                            $$ICM5 = atwid1(int(ibeg) + $$CIVB)
   129|Id=6                 DO $$CIV3 = $$CIV3, int((1 + (int((kend + 1)) - &
                &               int(kbeg))))-1
                              $$PRC1B = dq(int(kbeg) + $$CIV3,1)
                              $$PRC1D = d-dx3a%addr%dx3a(int(kbeg) + $$CIV3)
                              $$PRC1F = d-v1%addr%v1($$ICM0,$$ICM1,int(kbeg) + &
                &               $$CIV3)
   132|                       xi = ( 5.0000000000000000E-001 * (d-v3%addr%v3((&
                &               $$CIVB + int(ibeg)) - 1,$$ICM1,int(kbeg) + $$CIV3)&
                &                + d-v3%addr%v3($$ICM0,$$ICM1,int(kbeg) + $$CIV3))&
                &                - d-vg3%addr%vg3(int(kbeg) + $$CIV3)) * ((dt * &
                &               $$ICM3) * $$ICM2)
   133|                       q1 = __cpdsign( 5.0000000000000000E-001,%VAL(xi))
   134|                       sflx(int(kbeg) + $$CIV3,1) = ( &
                &               5.0000000000000000E-001 + q1) * ($$PRC1E + (&
                &               $$PRC1C - xi) * $$PRC1A) + ( &
                &               5.0000000000000000E-001 - q1) * ($$PRC1F - (&
                &               $$PRC1D + xi) * $$PRC1B)
   138|                       sflx(int(kbeg) + $$CIV3,1) = (((mflx(($$CIVB + &
                &               int(ibeg)) - 1,$$ICM1,int(kbeg) + $$CIV3) + mflx(&
                &               $$ICM0,$$ICM1,int(kbeg) + $$CIV3)) * sflx(int(&
                &               kbeg) + $$CIV3,1)) * $$ICM5) * $$ICM4
                              $$PRC1E = $$PRC1F
                              $$PRC1C = $$PRC1D
                              $$PRC1A = $$PRC1B
   140|                     ENDDO
                          ENDIF
   142|                   IF ((1 + (int(kend) - int(kbeg)) > 0)) THEN
                            $$CIV4 = 0
       Id=7                 DO $$CIV4 = $$CIV4, int((1 + (int(kend) - int(&
                &               kbeg))))-1
   143|                       IF ((0 <> (xvgrid  .AND.  1))) THEN
   144|                         s1(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIV4) = ((s1(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIV4) * &
                &                 d-dvl3a%addr%dvl3a(int(kbeg) + $$CIV4) - sflx(1 &
                &                 + ($$CIV4 + int(kbeg)),1)) + sflx(int(kbeg) + &
                &                 $$CIV4,1)) * d-dvl3ani%addr%dvl3ani(int(kbeg) + &
                &                 $$CIV4)
   146|                       ELSE
   147|                         s1(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIV4) = ((s1(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIV4) * &
                &                 d-dvl3a%addr%dvl3a(int(kbeg) + $$CIV4) - sflx(1 &
                &                 + ($$CIV4 + int(kbeg)),1)) + sflx(int(kbeg) + &
                &                 $$CIV4,1)) * d-dvl3ai%addr%dvl3ai(int(kbeg) + &
                &                 $$CIV4)
   149|                       ENDIF
   150|                     ENDDO
                          ENDIF
   161|                   IF ((1 + (int((kend + 1)) - int((kbeg - 1))) > 0)) &
                &           THEN
                            $$CIV5 = 0
                            $$PRC15 = d-dx3bi%addr%dx3bi(int(kbeg) - 1)
                            $$PRC17 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 2)
                            $$PRC18 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=8                 DO $$CIV5 = $$CIV5, int((1 + (int((kend + 1)) - &
                &               int((kbeg - 1)))))-1
                              $$PRC16 = d-dx3bi%addr%dx3bi(int(kbeg) + $$CIV5)
                              $$PRC19 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC &
                &               + int(jbeg),int(kbeg) + $$CIV5)
   162|                       dqm.rnn1D = ($$PRC18 - $$PRC17) * $$PRC15
   163|                       dqp.rnn1B = ($$PRC19 - $$PRC18) * $$PRC16
                              $$RET1 = __cpdsign( 1.0000000000000000E+000,%VAL(&
                &               dqm.rnn1D) + %VAL(dqp.rnn1B))
   164|                       dq(($$CIV5 + int(kbeg)) - 1,1) = (max(dqm.rnn1D * &
                &               dqp.rnn1B, 0.0000000000000000E+000) * $$RET1) / &
                &               max(abs(dqm.rnn1D + dqp.rnn1B), &
                &               1.0000000000000000E-099)
                              $$PRC17 = $$PRC18
                              $$PRC18 = $$PRC19
                              $$PRC15 = $$PRC16
   167|                     ENDDO
                          ENDIF
   177|                   IF ((1 + (int((kend + 1)) - int(kbeg)) > 0)) THEN
                            $$CIV6 = 0
                            $$PRCF = dq(int(kbeg) - 1,1)
                            $$PRC11 = d-dx3a%addr%dx3a(int(kbeg) - 1)
                            $$PRC13 = d-v2%addr%v2($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
                            $$ICM0 = int(ibeg) + $$CIVB
                            $$ICM1 = $$CIVC + int(jbeg)
   180|                     $$ICM6 = d-g32ai%addr%g32ai(int(jbeg) + $$CIVC)
                            $$ICM7 = d-g31bi%addr%g31bi(int(ibeg) + $$CIVB)
   186|                     $$ICM8 = atwidj2(int(jbeg) + $$CIVC)
                            $$ICM9 = atwid2(int(ibeg) + $$CIVB)
   177|Id=9                 DO $$CIV6 = $$CIV6, int((1 + (int((kend + 1)) - &
                &               int(kbeg))))-1
                              $$PRC10 = dq(int(kbeg) + $$CIV6,1)
                              $$PRC12 = d-dx3a%addr%dx3a(int(kbeg) + $$CIV6)
                              $$PRC14 = d-v2%addr%v2($$ICM0,$$ICM1,int(kbeg) + &
                &               $$CIV6)
   180|                       xi.rnn19 = ( 5.0000000000000000E-001 * (&
                &               d-v3%addr%v3($$ICM0,($$CIVC + int(jbeg)) - 1,int(&
                &               kbeg) + $$CIV6) + d-v3%addr%v3($$ICM0,$$ICM1,int(&
                &               kbeg) + $$CIV6)) - d-vg3%addr%vg3(int(kbeg) + &
                &               $$CIV6)) * ((dt * $$ICM7) * $$ICM6)
   181|                       q1.rnn17 = __cpdsign( 5.0000000000000000E-001,&
                &               %VAL(xi.rnn19))
   182|                       sflx(int(kbeg) + $$CIV6,1) = ( &
                &               5.0000000000000000E-001 + q1.rnn17) * ($$PRC13 + (&
                &               $$PRC11 - xi.rnn19) * $$PRCF) + ( &
                &               5.0000000000000000E-001 - q1.rnn17) * ($$PRC14 - (&
                &               $$PRC12 + xi.rnn19) * $$PRC10)
   186|                       sflx(int(kbeg) + $$CIV6,1) = (((mflx($$ICM0,(&
                &               $$CIVC + int(jbeg)) - 1,int(kbeg) + $$CIV6) + &
                &               mflx($$ICM0,$$ICM1,int(kbeg) + $$CIV6)) * sflx(&
                &               int(kbeg) + $$CIV6,1)) * $$ICM9) * $$ICM8
                              $$PRC13 = $$PRC14
                              $$PRC11 = $$PRC12
                              $$PRCF = $$PRC10
   188|                     ENDDO
                          ENDIF
   190|                   IF ((1 + (int(kend) - int(kbeg)) > 0)) THEN
                            $$CIV7 = 0
       Id=10                DO $$CIV7 = $$CIV7, int((1 + (int(kend) - int(&
                &               kbeg))))-1
   191|                       IF ((0 <> (xvgrid  .AND.  1))) THEN
   192|                         s2(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIV7) = ((s2(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIV7) * &
                &                 d-dvl3a%addr%dvl3a(int(kbeg) + $$CIV7) - sflx(1 &
                &                 + ($$CIV7 + int(kbeg)),1)) + sflx(int(kbeg) + &
                &                 $$CIV7,1)) * d-dvl3ani%addr%dvl3ani(int(kbeg) + &
                &                 $$CIV7)
   194|                       ELSE
   195|                         s2(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIV7) = ((s2(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIV7) * &
                &                 d-dvl3a%addr%dvl3a(int(kbeg) + $$CIV7) - sflx(1 &
                &                 + ($$CIV7 + int(kbeg)),1)) + sflx(int(kbeg) + &
                &                 $$CIV7,1)) * d-dvl3ai%addr%dvl3ai(int(kbeg) + &
                &                 $$CIV7)
   197|                       ENDIF
   198|                     ENDDO
                          ENDIF
   209|                   IF ((1 + (int((kend + 1)) - int((kbeg - 1))) > 0)) &
                &           THEN
                            $$CIV8 = 0
                            $$PRCA = d-dx3ai%addr%dx3ai(int(kbeg) - 2)
                            $$PRCC = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 2)
                            $$PRCD = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
       Id=11                DO $$CIV8 = $$CIV8, int((1 + (int((kend + 1)) - &
                &               int((kbeg - 1)))))-1
                              $$PRCB = d-dx3ai%addr%dx3ai((int(kbeg) + $$CIV8) &
                &               - 1)
                              $$PRCE = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &               int(jbeg),int(kbeg) + $$CIV8)
   210|                       dqm.rnn1C = ($$PRCD - $$PRCC) * $$PRCA
   211|                       dqp.rnn1A = ($$PRCE - $$PRCD) * $$PRCB
                              $$RET2 = __cpdsign( 1.0000000000000000E+000,%VAL(&
                &               dqm.rnn1C) + %VAL(dqp.rnn1A))
   212|                       dq(($$CIV8 + int(kbeg)) - 1,1) = (max(dqm.rnn1C * &
                &               dqp.rnn1A, 0.0000000000000000E+000) * $$RET2) / &
                &               max(abs(dqm.rnn1C + dqp.rnn1A), &
                &               1.0000000000000000E-099)
                              $$PRCC = $$PRCD
                              $$PRCD = $$PRCE
                              $$PRCA = $$PRCB
   215|                     ENDDO
                          ENDIF
   225|                   IF ((1 + (int(kend) - int((kbeg - 1))) > 0)) THEN
                            $$CIV9 = 0
                            $$PRC0 = dq(int(kbeg) - 1,1)
                            $$PRC2 = d-dx3b%addr%dx3b(int(kbeg) - 1)
                            $$PRC4 = d-vg3%addr%vg3(int(kbeg) - 1)
                            $$PRC6 = mflx($$CIVB + int(ibeg),$$CIVC + int(jbeg),&
                &             int(kbeg) - 1)
                            $$PRC8 = d-v3%addr%v3($$CIVB + int(ibeg),$$CIVC + &
                &             int(jbeg),int(kbeg) - 1)
                            $$ICM0 = int(ibeg) + $$CIVB
                            $$ICM1 = int(jbeg) + $$CIVC
   228|                     $$ICM2 = d-g32bi%addr%g32bi(int(jbeg) + $$CIVC)
                            $$ICM7 = d-g31bi%addr%g31bi(int(ibeg) + $$CIVB)
   234|                     $$ICMA = atwidj3(int(jbeg) + $$CIVC)
                            $$ICMB = atwid3(int(ibeg) + $$CIVB)
   225|Id=12                DO $$CIV9 = $$CIV9, int((1 + (int(kend) - int((&
                &               kbeg - 1)))))-1
                              $$PRC1 = dq(int(kbeg) + $$CIV9,1)
                              $$PRC3 = d-dx3b%addr%dx3b(int(kbeg) + $$CIV9)
                              $$PRC5 = d-vg3%addr%vg3(int(kbeg) + $$CIV9)
                              $$PRC7 = mflx($$ICM0,$$ICM1,int(kbeg) + $$CIV9)
                              $$PRC9 = d-v3%addr%v3($$ICM0,$$ICM1,int(kbeg) + &
                &               $$CIV9)
   228|                       xi.rnn18 = ((( 5.0000000000000000E-001 * (((&
                &               $$PRC8 - $$PRC4) + $$PRC9) - $$PRC5)) * dt) * &
                &               $$ICM7) * $$ICM2
   229|                       q1.rnn16 = __cpdsign( 5.0000000000000000E-001,&
                &               %VAL(xi.rnn18))
   230|                       sflx(($$CIV9 + int(kbeg)) - 1,1) = ( &
                &               5.0000000000000000E-001 + q1.rnn16) * ($$PRC8 + (&
                &               $$PRC2 - xi.rnn18) * $$PRC0) + ( &
                &               5.0000000000000000E-001 - q1.rnn16) * ($$PRC9 - (&
                &               $$PRC3 + xi.rnn18) * $$PRC1)
   234|                       sflx(($$CIV9 + int(kbeg)) - 1,1) = ((($$PRC6 + &
                &               $$PRC7) * sflx(($$CIV9 + int(kbeg)) - 1,1)) * &
                &               $$ICMB) * $$ICMA
                              $$PRC8 = $$PRC9
                              $$PRC6 = $$PRC7
                              $$PRC4 = $$PRC5
                              $$PRC2 = $$PRC3
                              $$PRC0 = $$PRC1
   236|                     ENDDO
                          ENDIF
   238|                   IF ((1 + (int(kend) - int(kbeg)) > 0)) THEN
                            $$CIVA = 0
       Id=13                DO $$CIVA = $$CIVA, int((1 + (int(kend) - int(&
                &               kbeg))))-1
   239|                       IF ((0 <> (xvgrid  .AND.  1))) THEN
   240|                         s3(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIVA) = ((s3(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIVA) * &
                &                 d-dvl3b%addr%dvl3b(int(kbeg) + $$CIVA) - sflx(&
                &                 int(kbeg) + $$CIVA,1)) + sflx(($$CIVA + int(&
                &                 kbeg)) - 1,1)) * d-dvl3bni%addr%dvl3bni(int(&
                &                 kbeg) + $$CIVA)
   242|                       ELSE
   243|                         s3(int(ibeg) + $$CIVB,int(jbeg) + $$CIVC,int(&
                &                 kbeg) + $$CIVA) = ((s3(int(ibeg) + $$CIVB,int(&
                &                 jbeg) + $$CIVC,int(kbeg) + $$CIVA) * &
                &                 d-dvl3b%addr%dvl3b(int(kbeg) + $$CIVA) - sflx(&
                &                 int(kbeg) + $$CIVA,1)) + sflx(($$CIVA + int(&
                &                 kbeg)) - 1,1)) * d-dvl3bi%addr%dvl3bi(int(kbeg) &
                &                 + $$CIVA)
   245|                       ENDIF
   246|                     ENDDO
                          ENDIF
   247|                 ENDDO
                      ENDIF
   248|             ENDDO
                  ENDIF
   251|           RETURN
                END SUBROUTINE momx3

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   ssus ssss usss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ssss  ssss ssss ssss ssss
 CCR's set/used:   ssss ssss
     | 000000                           PDEF     momx3
   11|                                  PROC      .ibeg,.iend,.jbeg,.jend,.kbeg,.kend,.s1,.s2,.s3,.mflx,.atwid1,.atwid2,.atwid3,.atwidj1,.atwidj2,.atwidj3,.sflx,.dq,gr3-gr10
    0| 000000 stfd     DBE1FFF8   1     STFL      #stack(gr1,-8)=fp31
    0| 000004 stfd     DBC1FFF0   1     STFL      #stack(gr1,-16)=fp30
    0| 000008 stfd     DBA1FFE8   1     STFL      #stack(gr1,-24)=fp29
    0| 00000C stfd     DB81FFE0   1     STFL      #stack(gr1,-32)=fp28
    0| 000010 stfd     DB61FFD8   1     STFL      #stack(gr1,-40)=fp27
    0| 000014 stfd     DB41FFD0   1     STFL      #stack(gr1,-48)=fp26
    0| 000018 stfd     DB21FFC8   1     STFL      #stack(gr1,-56)=fp25
    0| 00001C stfd     DB01FFC0   1     STFL      #stack(gr1,-64)=fp24
    0| 000020 stfd     DAE1FFB8   1     STFL      #stack(gr1,-72)=fp23
    0| 000024 stfd     DAC1FFB0   1     STFL      #stack(gr1,-80)=fp22
    0| 000028 stfd     DAA1FFA8   1     STFL      #stack(gr1,-88)=fp21
    0| 00002C stfd     DA81FFA0   1     STFL      #stack(gr1,-96)=fp20
    0| 000030 stfd     DA61FF98   1     STFL      #stack(gr1,-104)=fp19
    0| 000034 stfd     DA41FF90   1     STFL      #stack(gr1,-112)=fp18
    0| 000038 stfd     DA21FF88   1     STFL      #stack(gr1,-120)=fp17
    0| 00003C stfd     DA01FF80   1     STFL      #stack(gr1,-128)=fp16
    0| 000040 stfd     D9E1FF78   1     STFL      #stack(gr1,-136)=fp15
    0| 000044 stfd     D9C1FF70   1     STFL      #stack(gr1,-144)=fp14
    0| 000048 std      FBE1FF68   1     ST8       #stack(gr1,-152)=gr31
    0| 00004C std      FBC1FF60   1     ST8       #stack(gr1,-160)=gr30
    0| 000050 std      FBA1FF58   1     ST8       #stack(gr1,-168)=gr29
    0| 000054 std      FB81FF50   1     ST8       #stack(gr1,-176)=gr28
    0| 000058 std      FB61FF48   1     ST8       #stack(gr1,-184)=gr27
    0| 00005C std      FB41FF40   1     ST8       #stack(gr1,-192)=gr26
    0| 000060 std      FB21FF38   1     ST8       #stack(gr1,-200)=gr25
    0| 000064 std      FB01FF30   1     ST8       #stack(gr1,-208)=gr24
    0| 000068 std      FAE1FF28   1     ST8       #stack(gr1,-216)=gr23
    0| 00006C std      FAC1FF20   1     ST8       #stack(gr1,-224)=gr22
    0| 000070 std      FAA1FF18   1     ST8       #stack(gr1,-232)=gr21
    0| 000074 std      FA81FF10   1     ST8       #stack(gr1,-240)=gr20
    0| 000078 std      FA61FF08   1     ST8       #stack(gr1,-248)=gr19
    0| 00007C std      FA41FF00   1     ST8       #stack(gr1,-256)=gr18
    0| 000080 std      FA21FEF8   1     ST8       #stack(gr1,-264)=gr17
    0| 000084 std      FA01FEF0   1     ST8       #stack(gr1,-272)=gr16
    0| 000088 std      F9E1FEE8   1     ST8       #stack(gr1,-280)=gr15
    0| 00008C std      F9C1FEE0   1     ST8       #stack(gr1,-288)=gr14
    0| 000090 mfcr     7D800026   1     LFCR      gr12=cr[234],2
    0| 000094 stw      91810008   1     ST4A      #stack(gr1,8)=gr12
    0| 000098 stdu     F821FB61   1     ST8U      gr1,#stack(gr1,-1184)=gr1
    0| 00009C lwa      EBC30002   1     L4A       gr30=ibeg(gr3,0)
    0| 0000A0 lwa      E9640002   1     L4A       gr11=iend(gr4,0)
    0| 0000A4 ld       EBE20000   1     L8        gr31=.&&N&&param(gr2,0)
    0| 0000A8 std      FBC10140   1     ST8       #SPILL0(gr1,320)=gr30
    0| 0000AC subf     7C7E5850   1     S         gr3=gr11,gr30
    0| 0000B0 lwa      E81F0002   1     L4A       gr0=<s27:d0:l4>(gr31,0)
    0| 0000B4 addic.   37A30001   1     AI_R      gr29,cr0=gr3,1,ca"
    0| 0000B8 lwa      E99F0006   1     L4A       gr12=<s27:d4:l4>(gr31,4)
   88| 0000BC mfcr     7F800026   1     LFCR      gr28=cr0,0
    0| 0000C0 std      FBA10090   1     ST8       #SPILL1(gr1,144)=gr29
   88| 0000C4 mtcrf    7F880120   1     MTCRF     cr0=gr28,0
    0| 0000C8 sradi    7C03FE76   1     SRA8      gr3=gr0,63,ca"
   88| 0000CC std      FB810370   1     ST8       #SPILL2(gr1,880)=gr28
    0| 0000D0 sradi    7D84FE76   1     SRA8      gr4=gr12,63,ca"
    0| 0000D4 andc     7C1B1878   1     ANDC      gr27=gr0,gr3
    0| 0000D8 andc     7D8F2078   1     ANDC      gr15=gr12,gr4
    0| 0000DC std      FB6102A8   1     ST8       #SPILL41(gr1,680)=gr27
   88| 0000E0 bc       4081027C   1     BF        CL.59,cr0,0x2/gt,taken=50%(0,0)
   90| 0000E4 ld       EAC20000   1     L8        gr22=.&&N&grid(gr2,0)
    0| 0000E8 subfic   209E0001   1     SFI       gr4=1,gr30,ca"
   91| 0000EC rldicr   7BC31F24   1     SLL8      gr3=gr30,3
    0| 0000F0 add      7C845A14   1     A         gr4=gr4,gr11
   91| 0000F4 addi     3803FFF8   1     AI        gr0=gr3,-8
    0| 0000F8 ld       EA010520   1     L8        gr16=.atwid1(gr1,1312)
   91| 0000FC ld       EA760B98   1     L8        gr19=<s104:d2968:l8>(gr22,2968)
   90| 000100 ld       EA560B78   1     L8        gr18=<s104:d2936:l8>(gr22,2936)
   90| 000104 ld       E9760150   1     L8        gr11=<s104:d336:l8>(gr22,336)
   89| 000108 ld       E9960498   1     L8        gr12=<s104:d1176:l8>(gr22,1176)
   89| 00010C ld       EBF60AB8   1     L8        gr31=<s104:d2744:l8>(gr22,2744)
   90| 000110 ld       EBD60B60   1     L8        gr30=<s104:d2912:l8>(gr22,2912)
   89| 000114 ld       EBB604B0   1     L8        gr29=<s104:d1200:l8>(gr22,1200)
   89| 000118 ld       EB960830   1     L8        gr28=<s104:d2096:l8>(gr22,2096)
   90| 00011C ld       EB760408   1     L8        gr27=<s104:d1032:l8>(gr22,1032)
   91| 000120 ld       EB560BB0   1     L8        gr26=<s104:d2992:l8>(gr22,2992)
   90| 000124 ld       EB3603F0   1     L8        gr25=<s104:d1008:l8>(gr22,1008)
   89| 000128 ld       EB160818   1     L8        gr24=<s104:d2072:l8>(gr22,2072)
   89| 00012C ld       EAF60AD0   1     L8        gr23=<s104:d2768:l8>(gr22,2768)
   90| 000130 ld       EAD60168   1     L8        gr22=<s104:d360:l8>(gr22,360)
    0| 000134 ld       EAA10528   1     L8        gr21=.atwid2(gr1,1320)
    0| 000138 ld       EA810530   1     L8        gr20=.atwid3(gr1,1328)
    0| 00013C ld       E9C20000   1     L8        gr14=.+CONSTANT_AREA(gr2,0)
   91| 000140 add      7E730214   1     A         gr19=gr19,gr0
   90| 000144 add      7E520214   1     A         gr18=gr18,gr0
    0| 000148 rldicl   7891F842   1     SRL8      gr17=gr4,1
   91| 00014C addi     3863FFF0   1     AI        gr3=gr3,-16
   91| 000150 add      7F5A9A14   1     A         gr26=gr26,gr19
   90| 000154 add      7F7B0214   1     A         gr27=gr27,gr0
   90| 000158 add      7D6B0214   1     A         gr11=gr11,gr0
   90| 00015C add      7FDE9214   1     A         gr30=gr30,gr18
   89| 000160 add      7FFF0214   1     A         gr31=gr31,gr0
   89| 000164 add      7F9C0214   1     A         gr28=gr28,gr0
   89| 000168 add      7D8CEA14   1     A         gr12=gr12,gr29
    0| 00016C andi.    70840001   1     RN4_R     gr4,cr0=gr4,0,0x1
    0| 000170 cmpdi    2CB10000   1     C8        cr1=gr17,0
   91| 000174 add      7C83A214   1     A         gr4=gr3,gr20
   90| 000178 add      7FA3AA14   1     A         gr29=gr3,gr21
   89| 00017C add      7C638214   1     A         gr3=gr3,gr16
   90| 000180 add      7F79DA14   1     A         gr27=gr25,gr27
   90| 000184 add      7D6BB214   1     A         gr11=gr11,gr22
   89| 000188 add      7FF7FA14   1     A         gr31=gr23,gr31
   89| 00018C add      7F98E214   1     A         gr28=gr24,gr28
   89| 000190 add      7D806214   1     A         gr12=gr0,gr12
    0| 000194 lfs      C00E0000   1     LFS       fp0=+CONSTANT_AREA(gr14,0)
    0| 000198 mtspr    7E2903A6   1     LCTR      ctr=gr17
    0| 00019C bc       4182005C   1     BT        CL.558,cr0,0x4/eq,taken=50%(0,0)
   90| 0001A0 lfdu     CC3E0008   1     LFDU      fp1,gr30=g2b(gr30,8)
   91| 0001A4 lfdu     CC5A0008   1     LFDU      fp2,gr26=g31b(gr26,8)
   89| 0001A8 lfdu     CC6C0008   1     LFDU      fp3,gr12=g2a(gr12,8)
   89| 0001AC lfdu     CC9C0008   1     LFDU      fp4,gr28=dx1b(gr28,8)
   90| 0001B0 lfdu     CCAB0008   1     LFDU      fp5,gr11=dx1a(gr11,8)
   89| 0001B4 lfdu     CCDF0008   1     LFDU      fp6,gr31=dvl1bi(gr31,8)
   90| 0001B8 lfdu     CCFB0008   1     LFDU      fp7,gr27=dvl1ai(gr27,8)
   90| 0001BC fmul     FD010032   1     MFL       fp8=fp1,fp0,fcr
   91| 0001C0 fmul     FC420032   2     MFL       fp2=fp2,fp0,fcr
   89| 0001C4 fmul     FC630032   2     MFL       fp3=fp3,fp0,fcr
   90| 0001C8 fmul     FD010232   2     MFL       fp8=fp1,fp8,fcr
   91| 0001CC fmul     FC2100B2   2     MFL       fp1=fp1,fp2,fcr
   89| 0001D0 fmul     FC430132   2     MFL       fp2=fp3,fp4,fcr
   90| 0001D4 fmul     FC680172   2     MFL       fp3=fp8,fp5,fcr
   91| 0001D8 fmul     FC250072   2     MFL       fp1=fp5,fp1,fcr
   89| 0001DC fmul     FC4201B2   2     MFL       fp2=fp2,fp6,fcr
   90| 0001E0 fmul     FC6301F2   2     MFL       fp3=fp3,fp7,fcr
   91| 0001E4 fmul     FC270072   2     MFL       fp1=fp7,fp1,fcr
   89| 0001E8 stfdu    DC430008   2     STFDU     gr3,atwid1[](gr3,8)=fp2
   90| 0001EC stfdu    DC7D0008   1     STFDU     gr29,atwid2[](gr29,8)=fp3
   91| 0001F0 stfdu    DC240008   1     STFDU     gr4,atwid3[](gr4,8)=fp1
    0| 0001F4 bc       41860168   1     BT        CL.59,cr1,0x4/eq,taken=20%(20,80)
    0|                              CL.558:
   89| 0001F8 lfd      C8CC0008   1     LFL       fp6=g2a(gr12,8)
   90| 0001FC lfd      C83E0008   1     LFL       fp1=g2b(gr30,8)
   91| 000200 lfd      C93A0008   1     LFL       fp9=g31b(gr26,8)
   89| 000204 lfd      C85C0008   1     LFL       fp2=dx1b(gr28,8)
   89| 000208 lfd      C87F0008   1     LFL       fp3=dvl1bi(gr31,8)
   90| 00020C lfd      C88B0008   1     LFL       fp4=dx1a(gr11,8)
   89| 000210 lfdu     CCBC0010   1     LFDU      fp5,gr28=dx1b(gr28,16)
   89| 000214 fmul     FCC60032   1     MFL       fp6=fp6,fp0,fcr
   90| 000218 lfd      C8FB0008   1     LFL       fp7=dvl1ai(gr27,8)
   90| 00021C fmul     FD010032   1     MFL       fp8=fp1,fp0,fcr
   90| 000220 lfdu     CD7E0010   1     LFDU      fp11,gr30=g2b(gr30,16)
   91| 000224 fmul     FD290032   1     MFL       fp9=fp9,fp0,fcr
   91| 000228 lfdu     CD5A0010   1     LFDU      fp10,gr26=g31b(gr26,16)
   89| 00022C fmul     FC4600B2   1     MFL       fp2=fp6,fp2,fcr
   90| 000230 fmul     FCC10232   2     MFL       fp6=fp1,fp8,fcr
   91| 000234 fmul     FC210272   2     MFL       fp1=fp1,fp9,fcr
   89| 000238 fmul     FC4200F2   2     MFL       fp2=fp2,fp3,fcr
   90| 00023C fmul     FC660132   2     MFL       fp3=fp6,fp4,fcr
   91| 000240 fmul     FC240072   2     MFL       fp1=fp4,fp1,fcr
    0| 000244 bc       424000BC   1     BCF       ctr=CL.588,taken=0%(0,100)
    0| 000248 ori      60210000   1     XNOP      
    0| 00024C ori      60210000   1     XNOP      
    0| 000250 ori      60210000   1     XNOP      
    0|                              CL.589:
   89| 000254 lfd      C88C0018   1     LFL       fp4=g2a(gr12,24)
   89| 000258 lfdu     CCCC0010   1     LFDU      fp6,gr12=g2a(gr12,16)
   90| 00025C fmul     FC6301F2   1     MFL       fp3=fp3,fp7,fcr
   91| 000260 fmul     FC270072   2     MFL       fp1=fp7,fp1,fcr
   89| 000264 stfd     D8430008   1     STFL      atwid1[](gr3,8)=fp2
   90| 000268 fmul     FC4B0032   1     MFL       fp2=fp11,fp0,fcr
   91| 00026C fmul     FCEA0032   2     MFL       fp7=fp10,fp0,fcr
   90| 000270 lfdu     CD0B0010   1     LFDU      fp8,gr11=dx1a(gr11,16)
   89| 000274 fmul     FCC60032   1     MFL       fp6=fp6,fp0,fcr
   90| 000278 stfd     D87D0008   1     STFL      atwid2[](gr29,8)=fp3
   91| 00027C stfd     D8240008   1     STFL      atwid3[](gr4,8)=fp1
   90| 000280 fmul     FC2B00B2   1     MFL       fp1=fp11,fp2,fcr
   91| 000284 fmul     FC4B01F2   2     MFL       fp2=fp11,fp7,fcr
   89| 000288 lfdu     CC7F0010   1     LFDU      fp3,gr31=dvl1bi(gr31,16)
   89| 00028C lfd      C8FC0008   1     LFL       fp7=dx1b(gr28,8)
   89| 000290 fmul     FCA60172   1     MFL       fp5=fp6,fp5,fcr
   90| 000294 lfdu     CCDB0010   1     LFDU      fp6,gr27=dvl1ai(gr27,16)
   90| 000298 fmul     FC210232   1     MFL       fp1=fp1,fp8,fcr
   91| 00029C fmul     FC4800B2   2     MFL       fp2=fp8,fp2,fcr
   89| 0002A0 fmul     FC840032   2     MFL       fp4=fp4,fp0,fcr
   90| 0002A4 lfd      C91E0008   1     LFL       fp8=g2b(gr30,8)
   91| 0002A8 lfd      C93A0008   1     LFL       fp9=g31b(gr26,8)
   89| 0002AC fmul     FC6500F2   1     MFL       fp3=fp5,fp3,fcr
   90| 0002B0 fmul     FC2101B2   2     MFL       fp1=fp1,fp6,fcr
   91| 0002B4 fmul     FCA600B2   2     MFL       fp5=fp6,fp2,fcr
   89| 0002B8 lfd      C85F0008   1     LFL       fp2=dvl1bi(gr31,8)
   89| 0002BC fmul     FC8401F2   1     MFL       fp4=fp4,fp7,fcr
   90| 0002C0 fmul     FCC80032   2     MFL       fp6=fp8,fp0,fcr
   91| 0002C4 fmul     FCE90032   2     MFL       fp7=fp9,fp0,fcr
   89| 0002C8 stfdu    DC630010   2     STFDU     gr3,atwid1[](gr3,16)=fp3
   90| 0002CC stfdu    DC3D0010   1     STFDU     gr29,atwid2[](gr29,16)=fp1
   91| 0002D0 stfdu    DCA40010   1     STFDU     gr4,atwid3[](gr4,16)=fp5
   90| 0002D4 lfd      C82B0008   1     LFL       fp1=dx1a(gr11,8)
   90| 0002D8 fmul     FC6801B2   1     MFL       fp3=fp8,fp6,fcr
   91| 0002DC fmul     FCC801F2   2     MFL       fp6=fp8,fp7,fcr
   89| 0002E0 lfdu     CCBC0010   1     LFDU      fp5,gr28=dx1b(gr28,16)
   89| 0002E4 fmul     FC4400B2   1     MFL       fp2=fp4,fp2,fcr
   90| 0002E8 lfd      C8FB0008   1     LFL       fp7=dvl1ai(gr27,8)
   90| 0002EC fmul     FC630072   1     MFL       fp3=fp3,fp1,fcr
   91| 0002F0 fmul     FC2101B2   2     MFL       fp1=fp1,fp6,fcr
   90| 0002F4 lfdu     CD7E0010   1     LFDU      fp11,gr30=g2b(gr30,16)
   91| 0002F8 lfdu     CD5A0010   1     LFDU      fp10,gr26=g31b(gr26,16)
    0| 0002FC bc       4200FF58   1     BCT       ctr=CL.589,taken=100%(100,0)
    0|                              CL.588:
   89| 000300 stfd     D8430008   1     STFL      atwid1[](gr3,8)=fp2
   90| 000304 fmul     FC4301F2   1     MFL       fp2=fp3,fp7,fcr
   89| 000308 lfdu     CC6C0010   1     LFDU      fp3,gr12=g2a(gr12,16)
   90| 00030C fmul     FC8B0032   1     MFL       fp4=fp11,fp0,fcr
   90| 000310 lfdu     CCCB0010   1     LFDU      fp6,gr11=dx1a(gr11,16)
   91| 000314 fmul     FD0A0032   1     MFL       fp8=fp10,fp0,fcr
   89| 000318 lfdu     CD3F0010   1     LFDU      fp9,gr31=dvl1bi(gr31,16)
   91| 00031C fmul     FC270072   1     MFL       fp1=fp7,fp1,fcr
   90| 000320 stfd     D85D0008   1     STFL      atwid2[](gr29,8)=fp2
   90| 000324 fmul     FC8B0132   1     MFL       fp4=fp11,fp4,fcr
   90| 000328 lfdu     CD5B0010   1     LFDU      fp10,gr27=dvl1ai(gr27,16)
   91| 00032C fmul     FD0B0232   1     MFL       fp8=fp11,fp8,fcr
   89| 000330 fmul     FC030032   2     MFL       fp0=fp3,fp0,fcr
   91| 000334 stfd     D8240008   1     STFL      atwid3[](gr4,8)=fp1
   90| 000338 fmul     FC4401B2   1     MFL       fp2=fp4,fp6,fcr
   91| 00033C fmul     FC660232   2     MFL       fp3=fp6,fp8,fcr
   89| 000340 fmul     FC000172   2     MFL       fp0=fp0,fp5,fcr
   90| 000344 fmul     FC2202B2   2     MFL       fp1=fp2,fp10,fcr
   91| 000348 fmul     FC4A00F2   2     MFL       fp2=fp10,fp3,fcr
   89| 00034C fmul     FC000272   2     MFL       fp0=fp0,fp9,fcr
   90| 000350 stfdu    DC3D0010   2     STFDU     gr29,atwid2[](gr29,16)=fp1
   91| 000354 stfdu    DC440010   1     STFDU     gr4,atwid3[](gr4,16)=fp2
   89| 000358 stfdu    DC030010   1     STFDU     gr3,atwid1[](gr3,16)=fp0
   92|                              CL.59:
   92| 00035C lwa      E8050002   1     L4A       gr0=jbeg(gr5,0)
   92| 000360 lwa      E8660002   1     L4A       gr3=jend(gr6,0)
   92| 000364 std      F8010130   1     ST8       #SPILL3(gr1,304)=gr0
   92| 000368 subf     7C801850   1     S         gr4=gr3,gr0
   92| 00036C addic.   34A40001   1     AI_R      gr5,cr0=gr4,1,ca"
   92| 000370 std      F8A10270   1     ST8       #SPILL4(gr1,624)=gr5
   93| 000374 bc       40812750   1     BF        CL.865,cr0,0x2/gt,taken=30%(30,70)
   94| 000378 ld       E9820000   1     L8        gr12=.&&N&grid(gr2,0)
   96| 00037C rldicr   78101F24   1     SLL8      gr16=gr0,3
    0| 000380 subfic   20000001   1     SFI       gr0=1,gr0,ca"
   96| 000384 addi     3B30FFF8   1     AI        gr25=gr16,-8
    0| 000388 add      7CA01A14   1     A         gr5=gr0,gr3
    0| 00038C ld       EB010538   1     L8        gr24=.atwidj1(gr1,1336)
   94| 000390 ld       E88C0188   1     L8        gr4=<s104:d392:l8>(gr12,392)
   96| 000394 ld       EBAC0CB0   1     L8        gr29=<s104:d3248:l8>(gr12,3248)
   94| 000398 ld       E96C01A0   1     L8        gr11=<s104:d416:l8>(gr12,416)
   95| 00039C ld       EB8C0850   1     L8        gr28=<s104:d2128:l8>(gr12,2128)
   94| 0003A0 ld       E8CC0440   1     L8        gr6=<s104:d1088:l8>(gr12,1088)
   95| 0003A4 ld       EB6C0B08   1     L8        gr27=<s104:d2824:l8>(gr12,2824)
   96| 0003A8 std      FB210190   1     ST8       #SPILL5(gr1,400)=gr25
   96| 0003AC ld       E86C0CC8   1     L8        gr3=<s104:d3272:l8>(gr12,3272)
   94| 0003B0 ld       E80C0428   1     L8        gr0=<s104:d1064:l8>(gr12,1064)
   95| 0003B4 ld       EBEC0AF0   1     L8        gr31=<s104:d2800:l8>(gr12,2800)
   95| 0003B8 ld       EBCC0868   1     L8        gr30=<s104:d2152:l8>(gr12,2152)
    0| 0003BC ld       EAE10540   1     L8        gr23=.atwidj2(gr1,1344)
    0| 0003C0 ld       EAC10548   1     L8        gr22=.atwidj3(gr1,1352)
    0| 0003C4 std      FB010250   1     ST8       #SPILL6(gr1,592)=gr24
   96| 0003C8 add      7F59EA14   1     A         gr26=gr25,gr29
   94| 0003CC add      7C845A14   1     A         gr4=gr4,gr11
    0| 0003D0 rldicl   78BDF842   1     SRL8      gr29=gr5,1
   96| 0003D4 addi     3970FFF0   1     AI        gr11=gr16,-16
   96| 0003D8 add      7C63D214   1     A         gr3=gr3,gr26
   95| 0003DC add      7F59DA14   1     A         gr26=gr25,gr27
    0| 0003E0 std      FAE10218   1     ST8       #SPILL7(gr1,536)=gr23
   95| 0003E4 add      7F99E214   1     A         gr28=gr25,gr28
   94| 0003E8 add      7F66CA14   1     A         gr27=gr6,gr25
   94| 0003EC add      7C84CA14   1     A         gr4=gr4,gr25
    0| 0003F0 andi.    70A50001   1     RN4_R     gr5,cr0=gr5,0,0x1
    0| 0003F4 cmpdi    2CBD0000   1     C8        cr1=gr29,0
    0| 0003F8 std      FAC10188   1     ST8       #SPILL8(gr1,392)=gr22
   96| 0003FC add      7CABB214   1     A         gr5=gr11,gr22
   95| 000400 add      7CCBBA14   1     A         gr6=gr11,gr23
   94| 000404 add      7D6BC214   1     A         gr11=gr11,gr24
   95| 000408 add      7FFFD214   1     A         gr31=gr31,gr26
   95| 00040C add      7FDEE214   1     A         gr30=gr30,gr28
   94| 000410 add      7F80DA14   1     A         gr28=gr0,gr27
    0| 000414 mtspr    7FA903A6   1     LCTR      ctr=gr29
    0| 000418 bc       41820038   1     BT        CL.586,cr0,0x4/eq,taken=50%(0,0)
   94| 00041C lfdu     CC040008   1     LFDU      fp0,gr4=dx2a(gr4,8)
   96| 000420 lfdu     CC230008   1     LFDU      fp1,gr3=g32b(gr3,8)
   94| 000424 lfdu     CC5C0008   1     LFDU      fp2,gr28=dvl2ai(gr28,8)
   95| 000428 lfdu     CC7E0008   1     LFDU      fp3,gr30=dx2b(gr30,8)
   95| 00042C lfdu     CC9F0008   1     LFDU      fp4,gr31=dvl2bi(gr31,8)
   96| 000430 fmul     FC200072   1     MFL       fp1=fp0,fp1,fcr
   94| 000434 fmul     FC0000B2   2     MFL       fp0=fp0,fp2,fcr
   95| 000438 fmul     FC630132   2     MFL       fp3=fp3,fp4,fcr
   96| 00043C fmul     FC220072   2     MFL       fp1=fp2,fp1,fcr
   94| 000440 stfdu    DC0B0008   2     STFDU     gr11,atwidj1[](gr11,8)=fp0
   95| 000444 stfdu    DC660008   1     STFDU     gr6,atwidj2[](gr6,8)=fp3
   96| 000448 stfdu    DC250008   1     STFDU     gr5,atwidj3[](gr5,8)=fp1
    0| 00044C bc       418600CC   1     BT        CL.437,cr1,0x4/eq,taken=20%(20,80)
    0|                              CL.586:
   94| 000450 lfd      C9040008   1     LFL       fp8=dx2a(gr4,8)
   96| 000454 lfd      C8230008   1     LFL       fp1=g32b(gr3,8)
   95| 000458 lfd      C87E0008   1     LFL       fp3=dx2b(gr30,8)
   95| 00045C lfd      C8DF0008   1     LFL       fp6=dvl2bi(gr31,8)
   94| 000460 lfd      C81C0008   1     LFL       fp0=dvl2ai(gr28,8)
   94| 000464 lfdu     CCA40010   1     LFDU      fp5,gr4=dx2a(gr4,16)
   96| 000468 lfdu     CCE30010   1     LFDU      fp7,gr3=g32b(gr3,16)
   95| 00046C lfdu     CC9E0010   1     LFDU      fp4,gr30=dx2b(gr30,16)
   96| 000470 fmul     FC480072   1     MFL       fp2=fp8,fp1,fcr
   95| 000474 lfdu     CC3F0010   1     LFDU      fp1,gr31=dvl2bi(gr31,16)
   95| 000478 fmul     FC6301B2   1     MFL       fp3=fp3,fp6,fcr
   94| 00047C lfdu     CCDC0010   1     LFDU      fp6,gr28=dvl2ai(gr28,16)
   94| 000480 fmul     FD080032   1     MFL       fp8=fp8,fp0,fcr
   96| 000484 fmul     FCE501F2   2     MFL       fp7=fp5,fp7,fcr
   96| 000488 fmul     FC0000B2   2     MFL       fp0=fp0,fp2,fcr
   95| 00048C stfd     D8660008   1     STFL      atwidj2[](gr6,8)=fp3
   94| 000490 stfd     D90B0008   1     STFL      atwidj1[](gr11,8)=fp8
   96| 000494 stfd     D8050008   1     STFL      atwidj3[](gr5,8)=fp0
    0| 000498 bc       42400068   1     BCF       ctr=CL.610,taken=0%(0,100)
    0|                              CL.611:
   95| 00049C lfd      C81E0008   1     LFL       fp0=dx2b(gr30,8)
   95| 0004A0 fmul     FC240072   1     MFL       fp1=fp4,fp1,fcr
   94| 0004A4 lfd      C8440008   1     LFL       fp2=dx2a(gr4,8)
   96| 0004A8 lfd      C8630008   1     LFL       fp3=g32b(gr3,8)
   96| 0004AC fmul     FC8601F2   1     MFL       fp4=fp6,fp7,fcr
   94| 0004B0 fmul     FCA501B2   2     MFL       fp5=fp5,fp6,fcr
   95| 0004B4 lfd      C8DF0008   1     LFL       fp6=dvl2bi(gr31,8)
   95| 0004B8 stfdu    DC260010   1     STFDU     gr6,atwidj2[](gr6,16)=fp1
   94| 0004BC lfd      C83C0008   1     LFL       fp1=dvl2ai(gr28,8)
   96| 0004C0 fmul     FC6200F2   1     MFL       fp3=fp2,fp3,fcr
   96| 0004C4 stfdu    DC850010   2     STFDU     gr5,atwidj3[](gr5,16)=fp4
   94| 0004C8 stfdu    DCAB0010   1     STFDU     gr11,atwidj1[](gr11,16)=fp5
   95| 0004CC lfdu     CC9E0010   1     LFDU      fp4,gr30=dx2b(gr30,16)
   95| 0004D0 fmul     FCC001B2   1     MFL       fp6=fp0,fp6,fcr
   94| 0004D4 lfdu     CCA40010   1     LFDU      fp5,gr4=dx2a(gr4,16)
   96| 0004D8 lfdu     CC030010   1     LFDU      fp0,gr3=g32b(gr3,16)
   96| 0004DC fmul     FC6100F2   1     MFL       fp3=fp1,fp3,fcr
   94| 0004E0 fmul     FC420072   2     MFL       fp2=fp2,fp1,fcr
   95| 0004E4 lfdu     CC3F0010   1     LFDU      fp1,gr31=dvl2bi(gr31,16)
   95| 0004E8 stfd     D8C60008   1     STFL      atwidj2[](gr6,8)=fp6
   94| 0004EC lfdu     CCDC0010   1     LFDU      fp6,gr28=dvl2ai(gr28,16)
   96| 0004F0 fmul     FCE50032   1     MFL       fp7=fp5,fp0,fcr
   96| 0004F4 stfd     D8650008   1     STFL      atwidj3[](gr5,8)=fp3
   94| 0004F8 stfd     D84B0008   1     STFL      atwidj1[](gr11,8)=fp2
    0| 0004FC bc       4200FFA0   1     BCT       ctr=CL.611,taken=100%(100,0)
    0|                              CL.610:
   95| 000500 fmul     FC040072   1     MFL       fp0=fp4,fp1,fcr
   96| 000504 fmul     FC2601F2   2     MFL       fp1=fp6,fp7,fcr
   94| 000508 fmul     FC4501B2   2     MFL       fp2=fp5,fp6,fcr
   95| 00050C stfdu    DC060010   2     STFDU     gr6,atwidj2[](gr6,16)=fp0
   96| 000510 stfdu    DC250010   1     STFDU     gr5,atwidj3[](gr5,16)=fp1
   94| 000514 stfdu    DC4B0010   1     STFDU     gr11,atwidj1[](gr11,16)=fp2
    0|                              CL.437:
  113| 000518 ld       E9620000   1     L8        gr11=.&&N&field(gr2,0)
  225| 00051C ld       EA8102A8   1     L8        gr20=#SPILL41(gr1,680)
  225| 000520 rldicr   79E026E4   1     SLL8      gr0=gr15,4
  147| 000524 ld       EBAC0460   1     L8        gr29=<s104:d1120:l8>(gr12,1120)
  225| 000528 neg      7C8000D0   1     COMP      gr4=gr0
  129| 00052C ld       EBEC01C0   1     L8        gr31=<s104:d448:l8>(gr12,448)
  132| 000530 ld       EAEB0270   1     L8        gr23=<s75:d624:l8>(gr11,624)
  132| 000534 ld       EB0B0288   1     L8        gr24=<s75:d648:l8>(gr11,648)
  243| 000538 ld       EB2C0B28   1     L8        gr25=<s104:d2856:l8>(gr12,2856)
  132| 00053C ld       E86B02A0   1     L8        gr3=<s75:d672:l8>(gr11,672)
  225| 000540 ld       EB8C0888   1     L8        gr28=<s104:d2184:l8>(gr12,2184)
  180| 000544 ld       E8CC0C40   1     L8        gr6=<s104:d3136:l8>(gr12,3136)
  225| 000548 mulld    7E64A1D2   1     M         gr19=gr4,gr20
  180| 00054C std      F8C102D0   1     ST8       #SPILL34(gr1,720)=gr6
  225| 000550 std      FA6102C0   1     ST8       #SPILL42(gr1,704)=gr19
    0| 000554 add      7ED7C214   1     A         gr22=gr23,gr24
    0| 000558 rldicr   79E41F24   1     SLL8      gr4=gr15,3
    0| 00055C std      FAC102E8   1     ST8       #SPILL38(gr1,744)=gr22
  147| 000560 addi     3ADDFFF8   1     AI        gr22=gr29,-8
  240| 000564 ld       EBAC23E0   1     L8        gr29=<s104:d9184:l8>(gr12,9184)
  240| 000568 ld       EB6C0A80   1     L8        gr27=<s104:d2688:l8>(gr12,2688)
  243| 00056C addi     39F9FFF8   1     AI        gr15=gr25,-8
  129| 000570 addi     3B3FFFF8   1     AI        gr25=gr31,-8
  225| 000574 rldicr   7A9F1F24   1     SLL8      gr31=gr20,3
    0| 000578 subf     7EE3B850   1     S         gr23=gr23,gr3
  225| 00057C std      FBE10148   1     ST8       #SPILL10(gr1,328)=gr31
  209| 000580 ld       EBCC0268   1     L8        gr30=<s104:d616:l8>(gr12,616)
  144| 000584 ld       E8AC03B8   1     L8        gr5=<s104:d952:l8>(gr12,952)
  132| 000588 ld       E8CC0E00   1     L8        gr6=<s104:d3584:l8>(gr12,3584)
  225| 00058C addi     3A3CFFF8   1     AI        gr17=gr28,-8
  144| 000590 ld       EBEC2140   1     L8        gr31=<s104:d8512:l8>(gr12,8512)
  113| 000594 ld       EB8C0930   1     L8        gr28=<s104:d2352:l8>(gr12,2352)
    0| 000598 add      7E57C214   1     A         gr18=gr23,gr24
    0| 00059C mulld    7C84A1D2   1     M         gr4=gr4,gr20
    0| 0005A0 std      FA4102D8   1     ST8       #SPILL9(gr1,728)=gr18
  240| 0005A4 addi     3A9DFFF8   1     AI        gr20=gr29,-8
  132| 0005A8 ld       EBAC0E18   1     L8        gr29=<s104:d3608:l8>(gr12,3608)
  113| 0005AC ld       EB4B01A0   1     L8        gr26=<s75:d416:l8>(gr11,416)
    0| 0005B0 addi     3A5BFFF8   1     AI        gr18=gr27,-8
  113| 0005B4 ld       EB6B01B8   1     L8        gr27=<s75:d440:l8>(gr11,440)
  209| 0005B8 addi     3A7EFFF0   1     AI        gr19=gr30,-16
  132| 0005BC addi     3BC6FFF8   1     AI        gr30=gr6,-8
    0| 0005C0 addi     3AE5FFF8   1     AI        gr23=gr5,-8
  113| 0005C4 ld       E8AB01D0   1     L8        gr5=<s75:d464:l8>(gr11,464)
  144| 0005C8 addi     3B1FFFF8   1     AI        gr24=gr31,-8
  113| 0005CC addi     3BFCFFF8   1     AI        gr31=gr28,-8
  132| 0005D0 add      7FDDF214   1     A         gr30=gr29,gr30
  113| 0005D4 std      FBE101E8   1     ST8       #SPILL39(gr1,488)=gr31
  132| 0005D8 std      FBC102F8   1     ST8       #SPILL12(gr1,760)=gr30
  129| 0005DC ld       EBEC01D8   1     L8        gr31=<s104:d472:l8>(gr12,472)
  144| 0005E0 ld       EBAC2158   1     L8        gr29=<s104:d8536:l8>(gr12,8536)
  113| 0005E4 add      7F9ADA14   1     A         gr28=gr26,gr27
  161| 0005E8 ld       EAAB0208   1     L8        gr21=<s75:d520:l8>(gr11,520)
  113| 0005EC std      FB8102B0   1     ST8       #SPILL43(gr1,688)=gr28
  161| 0005F0 ld       E8CB0238   1     L8        gr6=<s75:d568:l8>(gr11,568)
  113| 0005F4 subf     7F85D050   1     S         gr28=gr26,gr5
  147| 0005F8 ld       EBCC0478   1     L8        gr30=<s104:d1144:l8>(gr12,1144)
  113| 0005FC add      7F5BE214   1     A         gr26=gr27,gr28
  144| 000600 ld       EB8C03D0   1     L8        gr28=<s104:d976:l8>(gr12,976)
  113| 000604 std      FB4102E0   1     ST8       #SPILL11(gr1,736)=gr26
  129| 000608 add      7F39FA14   1     A         gr25=gr25,gr31
  161| 00060C ld       EBEB0220   1     L8        gr31=<s75:d544:l8>(gr11,544)
  129| 000610 std      FB210300   1     ST8       #SPILL13(gr1,768)=gr25
  144| 000614 add      7F78EA14   1     A         gr27=gr24,gr29
  209| 000618 ld       EBAC0280   1     L8        gr29=<s104:d640:l8>(gr12,640)
  144| 00061C std      FB610328   1     ST8       #SPILL15(gr1,808)=gr27
  132| 000620 ld       E9CC0578   1     L8        gr14=<s104:d1400:l8>(gr12,1400)
  147| 000624 add      7ED6F214   1     A         gr22=gr22,gr30
  161| 000628 subf     7FC6A850   1     S         gr30=gr21,gr6
  147| 00062C std      FAC10318   1     ST8       #SPILL16(gr1,792)=gr22
    0| 000630 add      7EF7E214   1     A         gr23=gr23,gr28
  161| 000634 add      7F15FA14   1     A         gr24=gr21,gr31
  132| 000638 std      F9C10368   1     ST8       #SPILL33(gr1,872)=gr14
    0| 00063C std      FAE102F0   1     ST8       #SPILL14(gr1,752)=gr23
  225| 000640 ld       EB8C08A0   1     L8        gr28=<s104:d2208:l8>(gr12,2208)
  161| 000644 add      7EBEFA14   1     A         gr21=gr30,gr31
  240| 000648 ld       EBCC0A98   1     L8        gr30=<s104:d2712:l8>(gr12,2712)
  161| 00064C std      FAA10308   1     ST8       #SPILL17(gr1,776)=gr21
  209| 000650 add      7E73EA14   1     A         gr19=gr19,gr29
  240| 000654 ld       EBEC23F8   1     L8        gr31=<s104:d9208:l8>(gr12,9208)
  209| 000658 std      FA610330   1     ST8       #SPILL18(gr1,816)=gr19
  243| 00065C ld       EBAC0B40   1     L8        gr29=<s104:d2880:l8>(gr12,2880)
  132| 000660 ld       E9CC0590   1     L8        gr14=<s104:d1424:l8>(gr12,1424)
  225| 000664 ld       EB4102C0   1     L8        gr26=#SPILL42(gr1,704)
  225| 000668 ld       EB210148   1     L8        gr25=#SPILL10(gr1,328)
  132| 00066C ld       EAEC0CE8   1     L8        gr23=<s104:d3304:l8>(gr12,3304)
  225| 000670 add      7E31E214   1     A         gr17=gr17,gr28
    0| 000674 add      7E52F214   1     A         gr18=gr18,gr30
  132| 000678 std      F9C102C8   1     ST8       #SPILL35(gr1,712)=gr14
  225| 00067C std      FA210320   1     ST8       #SPILL19(gr1,800)=gr17
    0| 000680 std      FA410310   1     ST8       #SPILL20(gr1,784)=gr18
  132| 000684 std      FAE10178   1     ST8       #SPILL23(gr1,376)=gr23
  240| 000688 add      7E94FA14   1     A         gr20=gr20,gr31
  243| 00068C add      7DEFEA14   1     A         gr15=gr15,gr29
  240| 000690 std      FA810340   1     ST8       #SPILL21(gr1,832)=gr20
  132| 000694 ld       E80B02D0   1     L8        gr0=<s75:d720:l8>(gr11,720)
  243| 000698 std      F9E10338   1     ST8       #SPILL22(gr1,824)=gr15
  180| 00069C ld       E9CC0C58   1     L8        gr14=<s104:d3160:l8>(gr12,3160)
  225| 0006A0 subf     7F99D050   1     S         gr28=gr26,gr25
  180| 0006A4 ld       EB4C0620   1     L8        gr26=<s104:d1568:l8>(gr12,1568)
  113| 0006A8 ld       EBAC0948   1     L8        gr29=<s104:d2376:l8>(gr12,2376)
  113| 0006AC ld       EBCB01E8   1     L8        gr30=<s75:d488:l8>(gr11,488)
  132| 0006B0 ld       EB6C0D00   1     L8        gr27=<s104:d3328:l8>(gr12,3328)
  180| 0006B4 ld       E98C0638   1     L8        gr12=<s104:d1592:l8>(gr12,1592)
  161| 0006B8 ld       EAEB0268   1     L8        gr23=<s75:d616:l8>(gr11,616)
  161| 0006BC ld       EB2B0250   1     L8        gr25=<s75:d592:l8>(gr11,592)
  113| 0006C0 ld       EBEB0200   1     L8        gr31=<s75:d512:l8>(gr11,512)
  113| 0006C4 std      FBC10240   1     ST8       #SPILL25(gr1,576)=gr30
    0| 0006C8 ld       EBC10140   1     L8        gr30=#SPILL0(gr1,320)
  180| 0006CC std      F98101F0   1     ST8       #SPILL24(gr1,496)=gr12
  225| 0006D0 addi     399CFFF8   1     AI        gr12=gr28,-8
  161| 0006D4 std      FAE100C0   1     ST8       #SPILL28(gr1,192)=gr23
  225| 0006D8 std      F9810348   1     ST8       #SPILL30(gr1,840)=gr12
    0| 0006DC ld       EAE102D8   1     L8        gr23=#SPILL9(gr1,728)
    0| 0006E0 mulld    7D80F1D2   1     M         gr12=gr0,gr30
  132| 0006E4 ld       E96B02B8   1     L8        gr11=<s75:d696:l8>(gr11,696)
  161| 0006E8 std      FB210200   1     ST8       #SPILL27(gr1,512)=gr25
    0| 0006EC add      7F2CBA14   1     A         gr25=gr12,gr23
  113| 0006F0 std      FBE100B8   1     ST8       #SPILL26(gr1,184)=gr31
  132| 0006F4 ld       EBE20000   1     L8        gr31=.&&N&&root(gr2,0)
  143| 0006F8 ld       EAE20000   1     L8        gr23=.&&N&&config(gr2,0)
  132| 0006FC std      F9610150   1     ST8       #SPILL29(gr1,336)=gr11
    0| 000700 subf     7D60C850   1     S         gr11=gr25,gr0
    0| 000704 ld       EAC102C8   1     L8        gr22=#SPILL35(gr1,712)
    0| 000708 std      F9610358   1     ST8       #SPILL31(gr1,856)=gr11
    0| 00070C rldicr   7BCB1F24   1     SLL8      gr11=gr30,3
  101| 000710 addi     3BC00000   1     LI        gr30=0
  132| 000714 lfd      C81F0078   1     LFL       fp0=<s366:d120:l8>(gr31,120)
  101| 000718 std      FBC10138   1     ST8       #SPILL32(gr1,312)=gr30
    0| 00071C ld       EBC10368   1     L8        gr30=#SPILL33(gr1,872)
    0| 000720 add      7F50D214   1     A         gr26=gr16,gr26
    0| 000724 add      7E10DA14   1     A         gr16=gr16,gr27
    0| 000728 ld       EB6102A8   1     L8        gr27=#SPILL41(gr1,680)
    0| 00072C std      FA010180   1     ST8       #SPILL40(gr1,384)=gr16
    0| 000730 add      7FEBF214   1     A         gr31=gr11,gr30
    0| 000734 ld       EBC102D0   1     L8        gr30=#SPILL34(gr1,720)
    0| 000738 add      7ED6FA14   1     A         gr22=gr22,gr31
  143| 00073C lwa      EBF7004A   1     L4A       gr31=<s375:d72:l4>(gr23,72)
    0| 000740 std      FAC10368   1     ST8       #SPILL33(gr1,872)=gr22
    0| 000744 add      7FDE5A14   1     A         gr30=gr30,gr11
    0| 000748 add      7DCEF214   1     A         gr14=gr14,gr30
    0| 00074C addi     3BCBFFF8   1     AI        gr30=gr11,-8
    0| 000750 addi     396BFFF0   1     AI        gr11=gr11,-16
    0| 000754 std      FBC102C8   1     ST8       #SPILL35(gr1,712)=gr30
    0| 000758 add      7EFCF214   1     A         gr23=gr28,gr30
    0| 00075C add      7FCBE214   1     A         gr30=gr11,gr28
    0| 000760 ld       E96102E8   1     L8        gr11=#SPILL38(gr1,744)
    0| 000764 std      FAE10350   1     ST8       #SPILL36(gr1,848)=gr23
    0| 000768 std      FBC10360   1     ST8       #SPILL37(gr1,864)=gr30
    0| 00076C rldicr   7B7E26E4   1     SLL8      gr30=gr27,4
    0| 000770 ld       EB610140   1     L8        gr27=#SPILL0(gr1,320)
    0| 000774 std      F9C102D0   1     ST8       #SPILL34(gr1,720)=gr14
    0| 000778 add      7EEB6214   1     A         gr23=gr11,gr12
    0| 00077C andi.    73EB0001   1     RN4_R     gr11,cr0=gr31,0,0x1
    0| 000780 ld       EBE100C0   1     L8        gr31=#SPILL28(gr1,192)
  113| 000784 ld       E98101E8   1     L8        gr12=#SPILL39(gr1,488)
    0| 000788 std      FB4101E8   1     ST8       #SPILL39(gr1,488)=gr26
    0| 00078C mcrf     4C800000   1     LRCR      cr1=cr0
    0| 000790 mulld    7D7BF9D2   1     M         gr11=gr27,gr31
  113| 000794 add      7FBD6214   1     A         gr29=gr29,gr12
    0| 000798 ld       EBE10130   1     L8        gr31=#SPILL3(gr1,304)
  113| 00079C std      FBA102E8   1     ST8       #SPILL38(gr1,744)=gr29
    0| 0007A0 add      7FABC214   1     A         gr29=gr11,gr24
    0| 0007A4 ld       EB0100B8   1     L8        gr24=#SPILL26(gr1,184)
    0| 0007A8 ld       E9610240   1     L8        gr11=#SPILL25(gr1,576)
    0| 0007AC mulld    7D98D9D2   1     M         gr12=gr24,gr27
    0| 0007B0 ld       EB010148   1     L8        gr24=#SPILL10(gr1,328)
    0| 0007B4 mulld    7D6BF9D2   1     M         gr11=gr11,gr31
    0| 0007B8 mulld    7FFFC1D2   1     M         gr31=gr31,gr24
    0| 0007BC add      7D8B6214   1     A         gr12=gr11,gr12
    0| 0007C0 ld       E96102C8   1     L8        gr11=#SPILL35(gr1,712)
    0| 0007C4 add      7D6BFA14   1     A         gr11=gr11,gr31
    0| 0007C8 ld       EBE102B0   1     L8        gr31=#SPILL43(gr1,688)
    0| 0007CC add      7E4BE214   1     A         gr18=gr11,gr28
    0| 0007D0 subf     7D7E5850   1     S         gr11=gr11,gr30
    0| 0007D4 std      FA4102A8   1     ST8       #SPILL41(gr1,680)=gr18
    0| 0007D8 ld       EBC102C0   1     L8        gr30=#SPILL42(gr1,704)
    0| 0007DC add      7D4A9214   1     A         gr10=gr10,gr18
    0| 0007E0 add      7FFF6214   1     A         gr31=gr31,gr12
    0| 0007E4 std      F94102B0   1     ST8       #SPILL43(gr1,688)=gr10
    0| 0007E8 add      7D299214   1     A         gr9=gr9,gr18
    0| 0007EC ld       EA410130   1     L8        gr18=#SPILL3(gr1,304)
    0| 0007F0 std      F92102B8   1     ST8       #SPILL44(gr1,696)=gr9
    0| 0007F4 add      7D8BF214   1     A         gr12=gr11,gr30
    0| 0007F8 ld       E9610200   1     L8        gr11=#SPILL27(gr1,512)
    0| 0007FC std      F98102C0   1     ST8       #SPILL42(gr1,704)=gr12
    0| 000800 ld       E9810150   1     L8        gr12=#SPILL29(gr1,336)
    0| 000804 subf     7F85F850   1     S         gr28=gr31,gr5
    0| 000808 std      FB8102A0   1     ST8       #SPILL93(gr1,672)=gr28
    0| 00080C mulld    7D4B91D2   1     M         gr10=gr11,gr18
    0| 000810 mulld    7D2C91D2   1     M         gr9=gr12,gr18
    0| 000814 add      7D4AEA14   1     A         gr10=gr10,gr29
    0| 000818 ld       EBA102D8   1     L8        gr29=#SPILL9(gr1,728)
    0| 00081C add      7F394A14   1     A         gr25=gr25,gr9
    0| 000820 subf     7FC65050   1     S         gr30=gr10,gr6
    0| 000824 std      FB210268   1     ST8       #SPILL45(gr1,616)=gr25
    0| 000828 std      FBC10290   1     ST8       #SPILL46(gr1,656)=gr30
    0| 00082C ld       EBC20000   1     L8        gr30=.+CONSTANT_AREA(gr2,0)
    0| 000830 add      7D69EA14   1     A         gr11=gr9,gr29
    0| 000834 subf     7E4C5850   1     S         gr18=gr11,gr12
    0| 000838 rldicr   786B0FA4   1     SLL8      gr11=gr3,1
    0| 00083C std      FA410280   1     ST8       #SPILL47(gr1,640)=gr18
    0| 000840 rldicr   78CC0FA4   1     SLL8      gr12=gr6,1
    0| 000844 subf     7D6BB850   1     S         gr11=gr23,gr11
    0| 000848 subf     7EEC5050   1     S         gr23=gr10,gr12
    0| 00084C add      7D495A14   1     A         gr10=gr9,gr11
    0| 000850 std      FAE10288   1     ST8       #SPILL48(gr1,648)=gr23
    0| 000854 rldicr   78A90FA4   1     SLL8      gr9=gr5,1
    0| 000858 std      F9410278   1     ST8       #SPILL49(gr1,632)=gr10
    0| 00085C lfs      C03E0000   1     LFS       fp1=+CONSTANT_AREA(gr30,0)
    0| 000860 lfs      C05E0004   1     LFS       fp2=+CONSTANT_AREA(gr30,4)
    0| 000864 lfs      C07E0008   1     LFS       fp3=+CONSTANT_AREA(gr30,8)
    0| 000868 lfd      C9DE0010   1     LFL       fp14=+CONSTANT_AREA(gr30,16)
    0| 00086C ld       EBC10520   1     L8        gr30=.atwid1(gr1,1312)
    0| 000870 subf     7D89F850   1     S         gr12=gr31,gr9
    0| 000874 ld       EBE10528   1     L8        gr31=.atwid2(gr1,1320)
    0| 000878 std      F9810298   1     ST8       #SPILL51(gr1,664)=gr12
    0| 00087C ld       E9610530   1     L8        gr11=.atwid3(gr1,1328)
    0| 000880 ld       EB010518   1     L8        gr24=.mflx(gr1,1304)
    0| 000884 std      FBC10258   1     ST8       #SPILL50(gr1,600)=gr30
    0| 000888 ld       EB610510   1     L8        gr27=.s3(gr1,1296)
    0| 00088C std      FBE10220   1     ST8       #SPILL52(gr1,544)=gr31
    0| 000890 ld       E9210558   1     L8        gr9=.dq(gr1,1368)
    0| 000894 std      F9610198   1     ST8       #SPILL53(gr1,408)=gr11
    0| 000898 std      FB010158   1     ST8       #SPILL54(gr1,344)=gr24
    0| 00089C ld       EA410550   1     L8        gr18=.sflx(gr1,1360)
    0| 0008A0 std      FB6100F8   1     ST8       #SPILL55(gr1,248)=gr27
  101|                              CL.64:
  102| 0008A4 ld       E9410370   1     L8        gr10=#SPILL2(gr1,880)
  102| 0008A8 mtcrf    7D480120   1     MTCRF     cr0=gr10,0
  102| 0008AC bc       40811D3C   1     BF        CL.65,cr0,0x2/gt,taken=20%(20,80)
  102| 0008B0 lwz      83C70000   1     L4Z       gr30=kbeg(gr7,0)
  113| 0008B4 lwz      83A80000   1     L4Z       gr29=kend(gr8,0)
    0| 0008B8 ld       EA820000   1     L8        gr20=.+CONSTANT_AREA(gr2,0)
    0| 0008BC ld       EA6102D0   1     L8        gr19=#SPILL34(gr1,720)
  102| 0008C0 addi     39400000   1     LI        gr10=0
    0| 0008C4 ld       E96102C8   1     L8        gr11=#SPILL35(gr1,712)
  102| 0008C8 addi     399EFFFF   1     AI        gr12=gr30,-1
  113| 0008CC extsw    7FBB07B4   1     EXTS4     gr27=gr29
  102| 0008D0 extsw    7D9F07B4   1     EXTS4     gr31=gr12
    0| 0008D4 std      FA6100D0   1     ST8       #SPILL56(gr1,208)=gr19
  102| 0008D8 addi     399D0001   1     AI        gr12=gr29,1
  215| 0008DC subf     7F5FD850   1     S         gr26=gr27,gr31
  102| 0008E0 extsw    7D9C07B4   1     EXTS4     gr28=gr12
    0| 0008E4 ld       EB340018   1     L8        gr25=+CONSTANT_AREA(gr20,24)
  102| 0008E8 subf     7D9FE050   1     S         gr12=gr28,gr31
  215| 0008EC addi     39FA0001   1     AI        gr15=gr26,1
  102| 0008F0 addic.   358C0001   1     AI_R      gr12,cr0=gr12,1,ca"
  215| 0008F4 std      F9E101B0   1     ST8       #SPILL57(gr1,432)=gr15
    0| 0008F8 addi     399B0001   1     AI        gr12=gr27,1
    0| 0008FC mcrf     4F000000   1     LRCR      cr6=cr0
    0| 000900 subf     7EBF6050   1     S         gr21=gr12,gr31
    0| 000904 subfic   23FF0001   1     SFI       gr31=1,gr31,ca"
    0| 000908 subf     7F5E6050   1     S         gr26=gr12,gr30
    0| 00090C add      7FFCFA14   1     A         gr31=gr28,gr31
    0| 000910 mulhd    7ED5C892   0     MULHD     gr22=gr21,gr25
    0| 000914 rldicl   7BF1F082   2     SRL8      gr17=gr31,2
    0| 000918 andi.    735F0001   1     RN4_R     gr31,cr0=gr26,0,0x1
  102| 00091C extsw    7FDF07B4   1     EXTS4     gr31=gr30
    0| 000920 addi     3B3D0002   1     AI        gr25=gr29,2
  140| 000924 subf     7EFFD850   1     S         gr23=gr27,gr31
    0| 000928 subf     7F5F6050   1     S         gr26=gr12,gr31
    0| 00092C subf     7F7EC850   1     S         gr27=gr25,gr30
    0| 000930 addi     399D0003   1     AI        gr12=gr29,3
  119| 000934 subf     7F1FE050   1     S         gr24=gr28,gr31
    0| 000938 subf     7D9E6050   1     S         gr12=gr12,gr30
    0| 00093C rlwinm   577E07FE   1     RN4       gr30=gr27,0,0x1
    0| 000940 rlwinm   559007BE   1     RN4       gr16=gr12,0,0x3
    0| 000944 std      FBC10228   1     ST8       #SPILL60(gr1,552)=gr30
    0| 000948 rldicl   7AAC0FE0   1     SRL8      gr12=gr21,63
    0| 00094C subfic   23DF0001   1     SFI       gr30=1,gr31,ca"
    0| 000950 add      7DECB214   1     A         gr15=gr12,gr22
    0| 000954 add      7D9CF214   1     A         gr12=gr28,gr30
    0| 000958 std      F9E10120   1     ST8       #SPILL61(gr1,288)=gr15
  140| 00095C addi     3BB70001   1     AI        gr29=gr23,1
    0| 000960 rldicl   799CF842   1     SRL8      gr28=gr12,1
  140| 000964 std      FBA10118   1     ST8       #SPILL59(gr1,280)=gr29
    0| 000968 std      FB8101E0   1     ST8       #SPILL62(gr1,480)=gr28
    0| 00096C rldicl   7B4CF842   1     SRL8      gr12=gr26,1
  119| 000970 addi     39D80001   1     AI        gr14=gr24,1
  132| 000974 mulld    7F23F9D2   1     M         gr25=gr3,gr31
  119| 000978 std      F9C10230   1     ST8       #SPILL58(gr1,560)=gr14
  113| 00097C mulld    7F05F9D2   1     M         gr24=gr5,gr31
    0| 000980 rldicl   7B4FF082   1     SRL8      gr15=gr26,2
    0| 000984 cmpdi    2EAC0000   1     C8        cr5=gr12,0
    0| 000988 rlwinm   574CFFFE   1     RN4       gr12=gr26,31,0x1
  132| 00098C ld       EB4102D8   1     L8        gr26=#SPILL9(gr1,728)
  113| 000990 ld       EBA102E0   1     L8        gr29=#SPILL11(gr1,736)
  113| 000994 ld       EB8102E8   1     L8        gr28=#SPILL38(gr1,744)
  161| 000998 mulld    7EE6F9D2   1     M         gr23=gr6,gr31
  225| 00099C mulld    7F64F9D2   1     M         gr27=gr4,gr31
  113| 0009A0 rldicr   7BFF1F24   1     SLL8      gr31=gr31,3
  132| 0009A4 add      7DD9D214   1     A         gr14=gr25,gr26
  113| 0009A8 add      7FD8EA14   1     A         gr30=gr24,gr29
  132| 0009AC std      F9C10160   1     ST8       #SPILL64(gr1,352)=gr14
  113| 0009B0 std      FBC10248   1     ST8       #SPILL65(gr1,584)=gr30
  113| 0009B4 add      7DDCFA14   1     A         gr14=gr28,gr31
    0| 0009B8 ld       EBC102F0   1     L8        gr30=#SPILL14(gr1,752)
  113| 0009BC std      F9C10238   1     ST8       #SPILL66(gr1,568)=gr14
  132| 0009C0 ld       EB8102F8   1     L8        gr28=#SPILL12(gr1,760)
  113| 0009C4 addi     3ADFFFF8   1     AI        gr22=gr31,-8
    0| 0009C8 mcrf     4F800000   1     LRCR      cr7=cr0
  113| 0009CC std      FAC101C0   1     ST8       #SPILL63(gr1,448)=gr22
    0| 0009D0 add      7FBEFA14   1     A         gr29=gr30,gr31
  116| 0009D4 addi     3BDFFFE8   1     AI        gr30=gr31,-24
    0| 0009D8 std      FBA101C8   1     ST8       #SPILL67(gr1,456)=gr29
  116| 0009DC std      FBC101A0   1     ST8       #SPILL69(gr1,416)=gr30
  132| 0009E0 add      7DDCFA14   1     A         gr14=gr28,gr31
  129| 0009E4 ld       EBA10300   1     L8        gr29=#SPILL13(gr1,768)
  132| 0009E8 std      F9C10170   1     ST8       #SPILL68(gr1,368)=gr14
  161| 0009EC ld       E9C10308   1     L8        gr14=#SPILL17(gr1,776)
    0| 0009F0 cmpdi    2E2F0000   1     C8        cr4=gr15,0
    0| 0009F4 cmpdi    2DAC0000   1     C8        cr3=gr12,0
  129| 0009F8 addi     399FFFF0   1     AI        gr12=gr31,-16
  129| 0009FC add      7F9DFA14   1     A         gr28=gr29,gr31
    0| 000A00 ld       EBA10310   1     L8        gr29=#SPILL20(gr1,784)
  129| 000A04 std      FB8101F8   1     ST8       #SPILL70(gr1,504)=gr28
  161| 000A08 add      7FCEBA14   1     A         gr30=gr14,gr23
  161| 000A0C std      FBC10210   1     ST8       #SPILL71(gr1,528)=gr30
  147| 000A10 ld       EBC10318   1     L8        gr30=#SPILL16(gr1,792)
    0| 000A14 add      7F9DFA14   1     A         gr28=gr29,gr31
  225| 000A18 ld       EBA10320   1     L8        gr29=#SPILL19(gr1,800)
    0| 000A1C std      FB810100   1     ST8       #SPILL72(gr1,256)=gr28
  147| 000A20 add      7DDEFA14   1     A         gr14=gr30,gr31
  144| 000A24 ld       EBC10328   1     L8        gr30=#SPILL15(gr1,808)
  147| 000A28 std      F9C101D0   1     ST8       #SPILL73(gr1,464)=gr14
  225| 000A2C add      7F9DFA14   1     A         gr28=gr29,gr31
  225| 000A30 std      FB810168   1     ST8       #SPILL74(gr1,360)=gr28
  144| 000A34 add      7DDEFA14   1     A         gr14=gr30,gr31
    0| 000A38 std      F8E10260   1     ST8       #SPILL91(gr1,608)=gr7
  209| 000A3C ld       EBA10330   1     L8        gr29=#SPILL18(gr1,816)
  180| 000A40 ld       EBC10280   1     L8        gr30=#SPILL47(gr1,640)
  144| 000A44 std      F9C101D8   1     ST8       #SPILL75(gr1,472)=gr14
    0| 000A48 ld       EA810368   1     L8        gr20=#SPILL33(gr1,872)
  209| 000A4C add      7F9DFA14   1     A         gr28=gr29,gr31
  180| 000A50 add      7DD9F214   1     A         gr14=gr25,gr30
  243| 000A54 ld       EBA10338   1     L8        gr29=#SPILL22(gr1,824)
  180| 000A58 std      F9C10208   1     ST8       #SPILL77(gr1,520)=gr14
    0| 000A5C std      FA8100E0   1     ST8       #SPILL89(gr1,224)=gr20
  225| 000A60 ld       E9C10348   1     L8        gr14=#SPILL30(gr1,840)
  240| 000A64 ld       EBC10340   1     L8        gr30=#SPILL21(gr1,832)
  209| 000A68 std      FB8101B8   1     ST8       #SPILL76(gr1,440)=gr28
  243| 000A6C add      7F9DFA14   1     A         gr28=gr29,gr31
    0| 000A70 ld       EA810120   1     L8        gr20=#SPILL61(gr1,288)
  243| 000A74 std      FB810108   1     ST8       #SPILL78(gr1,264)=gr28
  225| 000A78 add      7FAEDA14   1     A         gr29=gr14,gr27
    0| 000A7C ld       EB8102A8   1     L8        gr28=#SPILL41(gr1,680)
    0| 000A80 ld       E9C10358   1     L8        gr14=#SPILL31(gr1,856)
  225| 000A84 std      FBA101A8   1     ST8       #SPILL80(gr1,424)=gr29
  240| 000A88 add      7FFEFA14   1     A         gr31=gr30,gr31
    0| 000A8C ld       EBC10350   1     L8        gr30=#SPILL36(gr1,848)
  240| 000A90 std      FBE10110   1     ST8       #SPILL79(gr1,272)=gr31
    0| 000A94 add      7FFBE214   1     A         gr31=gr27,gr28
    0| 000A98 add      7F8ECA14   1     A         gr28=gr14,gr25
    0| 000A9C std      FB8100A0   1     ST8       #SPILL82(gr1,160)=gr28
    0| 000AA0 add      7FBBF214   1     A         gr29=gr27,gr30
    0| 000AA4 ld       EBC10360   1     L8        gr30=#SPILL37(gr1,864)
    0| 000AA8 ld       EB8102C0   1     L8        gr28=#SPILL42(gr1,704)
    0| 000AAC std      FBA10098   1     ST8       #SPILL81(gr1,152)=gr29
    0| 000AB0 add      7FBBF214   1     A         gr29=gr27,gr30
    0| 000AB4 add      7DDBE214   1     A         gr14=gr27,gr28
    0| 000AB8 std      FBA100A8   1     ST8       #SPILL83(gr1,168)=gr29
    0| 000ABC std      F9C100B0   1     ST8       #SPILL84(gr1,176)=gr14
    0| 000AC0 ld       EBA102A0   1     L8        gr29=#SPILL93(gr1,672)
    0| 000AC4 ld       EB810290   1     L8        gr28=#SPILL46(gr1,656)
    0| 000AC8 ld       E9C10268   1     L8        gr14=#SPILL45(gr1,616)
    0| 000ACC add      7FD8EA14   1     A         gr30=gr24,gr29
    0| 000AD0 add      7FB7E214   1     A         gr29=gr23,gr28
    0| 000AD4 add      7F8ECA14   1     A         gr28=gr14,gr25
    0| 000AD8 ld       E9C102B8   1     L8        gr14=#SPILL44(gr1,696)
    0| 000ADC add      7E6EDA14   1     A         gr19=gr14,gr27
    0| 000AE0 ld       E9C102B0   1     L8        gr14=#SPILL43(gr1,688)
    0| 000AE4 std      FA6100C8   1     ST8       #SPILL85(gr1,200)=gr19
    0| 000AE8 add      7DCEDA14   1     A         gr14=gr14,gr27
    0| 000AEC ld       EB610298   1     L8        gr27=#SPILL51(gr1,664)
    0| 000AF0 add      7F18DA14   1     A         gr24=gr24,gr27
    0| 000AF4 ld       EB610288   1     L8        gr27=#SPILL48(gr1,648)
    0| 000AF8 std      FB0100D8   1     ST8       #SPILL86(gr1,216)=gr24
    0| 000AFC add      7EF7DA14   1     A         gr23=gr23,gr27
    0| 000B00 ld       EB610278   1     L8        gr27=#SPILL49(gr1,632)
    0| 000B04 std      FAE100E8   1     ST8       #SPILL87(gr1,232)=gr23
    0| 000B08 add      7F39DA14   1     A         gr25=gr25,gr27
    0| 000B0C ld       EB610120   1     L8        gr27=#SPILL61(gr1,288)
    0| 000B10 std      FB2100F0   1     ST8       #SPILL88(gr1,240)=gr25
    0| 000B14 rldicr   7B7B1764   1     SLL8      gr27=gr27,2
    0| 000B18 subf     7F74D850   1     S         gr27=gr27,gr20
    0| 000B1C subf     7EBBA851   1     S_R       gr21,cr0=gr21,gr27
    0| 000B20 std      FAA10128   1     ST8       #SPILL90(gr1,296)=gr21
  102|                              CL.66:
  113| 000B24 bc       409903D0   1     BF        CL.67,cr6,0x2/gt,taken=50%(0,0)
  113| 000B28 ld       EB210238   1     L8        gr25=#SPILL66(gr1,568)
  113| 000B2C ld       EB0100D8   1     L8        gr24=#SPILL86(gr1,216)
  116| 000B30 ld       EAE101A0   1     L8        gr23=#SPILL69(gr1,416)
    0| 000B34 cmpdi    2D300000   1     C8        cr2=gr16,0
  113| 000B38 lfd      C8DE0000   1     LFL       fp6=v1(gr30,0)
  113| 000B3C or       7FDAF378   1     LR        gr26=gr30
  113| 000B40 lfd      C9790000   1     LFL       fp11=dx3bi(gr25,0)
  113| 000B44 lfd      C8980000   1     LFL       fp4=v1(gr24,0)
  116| 000B48 add      7F69BA14   1     A         gr27=gr9,gr23
    0| 000B4C bc       418A008C   1     BT        CL.394,cr2,0x4/eq,taken=50%(0,0)
    0| 000B50 mtspr    7E0903A6   1     LCTR      ctr=gr16
    0| 000B54 ori      60210000   1     XNOP      
    0| 000B58 ori      60210000   1     XNOP      
    0| 000B5C ori      60210000   1     XNOP      
  113|                              CL.393:
  113| 000B60 lfdux    7CBA2CEE   1     LFDU      fp5,gr26=v1(gr26,gr5,0)
  114| 000B64 fsub     FCE62028   1     SFL       fp7=fp6,fp4,fcr
  113| 000B68 lfdu     CD190008   1     LFDU      fp8,gr25=dx3bi(gr25,8)
  116| 000B6C fmr      FC803090   1     LRFL      fp4=fp6
  115| 000B70 fsub     FD253028   2     SFL       fp9=fp5,fp6,fcr
  116| 000B74 fmr      FCC02890   2     LRFL      fp6=fp5
  114| 000B78 fmul     FD4702F2   2     MFL       fp10=fp7,fp11,fcr
  115| 000B7C fmul     FCA90232   2     MFL       fp5=fp9,fp8,fcr
  115| 000B80 fmadd    FCE72AFA   2     FMA       fp7=fp5,fp7,fp11,fcr
  116| 000B84 fmul     FCAA0172   2     MFL       fp5=fp10,fp5,fcr
  116| 000B88 fmr      FD604090   2     LRFL      fp11=fp8
  115| 000B8C qvfcpsgn 11071010   1     CPYSFL    fp8=fp2,fp7
  116| 000B90 fabs     FCE03A10   1     ABSFL     fp7=fp7
  116| 000B94 fneg     FD202850   2     COMPFL    fp9=fp5
  116| 000B98 fsub     FD4E3828   2     SFL       fp10=fp14,fp7,fcr
  116| 000B9C fsel     FCA928EE   2     FSEL      fp5=fp9,fp5,fp3
  116| 000BA0 fsel     FCEA3BAE   2     FSEL      fp7=fp10,fp7,fp14
  116| 000BA4 fmul     FD250232   2     MFL       fp9=fp5,fp8,fcr
  116| 000BA8 qvfre    10A03830   1     QVFRE     fp5=fp7
  116| 000BAC fmsub    FD071178   1     FMS       fp8=fp2,fp7,fp5,fcr
  116| 000BB0 fnmsub   FCA52A3C   2     FNMS      fp5=fp5,fp5,fp8,fcr
  116| 000BB4 fmsub    FD071178   2     FMS       fp8=fp2,fp7,fp5,fcr
  116| 000BB8 fnmsub   FCA52A3C   2     FNMS      fp5=fp5,fp5,fp8,fcr
  116| 000BBC fmul     FD090172   2     MFL       fp8=fp9,fp5,fcr
  116| 000BC0 fmsub    FCE74A38   2     FMS       fp7=fp9,fp7,fp8,fcr
  116| 000BC4 fnmsub   FCA541FC   2     FNMS      fp5=fp8,fp5,fp7,fcr
  116| 000BC8 stfdu    DCBB0008   2     STFDU     gr27,dq[](gr27,8)=fp5
  119| 000BCC bc       4200FF94   1     BCT       ctr=CL.393,taken=100%(100,0)
    0| 000BD0 cmpdi    2D310000   1     C8        cr2=gr17,0
    0| 000BD4 bc       418A0320   1     BT        CL.67,cr2,0x4/eq,taken=20%(20,80)
    0|                              CL.394:
  113| 000BD8 lfdux    7D3A2CEE   1     LFDU      fp9,gr26=v1(gr26,gr5,0)
  114| 000BDC fsub     FF862028   1     SFL       fp28=fp6,fp4,fcr
  113| 000BE0 lfd      CBF90008   1     LFL       fp31=dx3bi(gr25,8)
  113| 000BE4 lfd      C9590010   1     LFL       fp10=dx3bi(gr25,16)
  113| 000BE8 lfd      C9990018   1     LFL       fp12=dx3bi(gr25,24)
  113| 000BEC lfdu     CC990020   1     LFDU      fp4,gr25=dx3bi(gr25,32)
    0| 000BF0 mtspr    7E2903A6   1     LCTR      ctr=gr17
  115| 000BF4 fsub     FCA93028   1     SFL       fp5=fp9,fp6,fcr
  113| 000BF8 lfdux    7DBA2CEE   1     LFDU      fp13,gr26=v1(gr26,gr5,0)
  114| 000BFC fmul     FCDC02F2   1     MFL       fp6=fp28,fp11,fcr
  114| 000C00 fmr      FFC02890   2     LRFL      fp30=fp5
  115| 000C04 fmul     FCE507F2   2     MFL       fp7=fp5,fp31,fcr
  113| 000C08 lfdux    7CBA2CEE   1     LFDU      fp5,gr26=v1(gr26,gr5,0)
  115| 000C0C fsub     FD0D4828   1     SFL       fp8=fp13,fp9,fcr
  114| 000C10 fmul     FD3E07F2   2     MFL       fp9=fp30,fp31,fcr
  115| 000C14 fmadd    FD7C3AFA   2     FMA       fp11=fp7,fp28,fp11,fcr
  116| 000C18 fmul     FCC601F2   2     MFL       fp6=fp6,fp7,fcr
  113| 000C1C lfdux    7CFA2CEE   1     LFDU      fp7,gr26=v1(gr26,gr5,0)
  115| 000C20 fsub     FF856828   1     SFL       fp28=fp5,fp13,fcr
  115| 000C24 fmul     FF0802B2   2     MFL       fp24=fp8,fp10,fcr
  114| 000C28 fmr      FFA04090   2     LRFL      fp29=fp8
  115| 000C2C qvfcpsgn 110B1010   1     CPYSFL    fp8=fp2,fp11
  116| 000C30 fabs     FD605A10   1     ABSFL     fp11=fp11
  114| 000C34 fmul     FDBD02B2   2     MFL       fp13=fp29,fp10,fcr
  115| 000C38 fsub     FF272828   2     SFL       fp25=fp7,fp5,fcr
  115| 000C3C fmul     FF5C0332   2     MFL       fp26=fp28,fp12,fcr
  115| 000C40 fmadd    FFFEC7FA   2     FMA       fp31=fp24,fp30,fp31,fcr
  116| 000C44 fsub     FFCE5828   2     SFL       fp30=fp14,fp11,fcr
  114| 000C48 fmr      FF60E090   2     LRFL      fp27=fp28
  116| 000C4C fmul     FD290632   2     MFL       fp9=fp9,fp24,fcr
  115| 000C50 fmul     FF390132   2     MFL       fp25=fp25,fp4,fcr
  115| 000C54 fmadd    FFBDD2BA   2     FMA       fp29=fp26,fp29,fp10,fcr
  115| 000C58 qvfcpsgn 115F1010   1     CPYSFL    fp10=fp2,fp31
  116| 000C5C fabs     FFE0FA10   1     ABSFL     fp31=fp31
  116| 000C60 fsel     FD7E5BAE   2     FSEL      fp11=fp30,fp11,fp14
  116| 000C64 fsub     FFCEF828   2     SFL       fp30=fp14,fp31,fcr
  115| 000C68 fmadd    FF7BCB3A   2     FMA       fp27=fp25,fp27,fp12,fcr
  115| 000C6C qvfcpsgn 119D1010   1     CPYSFL    fp12=fp2,fp29
  116| 000C70 fabs     FFA0EA10   1     ABSFL     fp29=fp29
  114| 000C74 fmr      FF80D090   2     LRFL      fp28=fp26
  116| 000C78 fmul     FDAD06B2   2     MFL       fp13=fp13,fp26,fcr
  116| 000C7C fsel     FFFEFBAE   2     FSEL      fp31=fp30,fp31,fp14
  115| 000C80 qvfcpsgn 13DB1010   1     CPYSFL    fp30=fp2,fp27
  116| 000C84 fabs     FF60DA10   1     ABSFL     fp27=fp27
  116| 000C88 fsub     FEEEE828   2     SFL       fp23=fp14,fp29,fcr
  116| 000C8C qvfre    13005830   1     QVFRE     fp24=fp11
  116| 000C90 fsub     FF4ED828   1     SFL       fp26=fp14,fp27,fcr
  116| 000C94 qvfre    12A0F830   1     QVFRE     fp21=fp31
  116| 000C98 fmul     FE7C0672   1     MFL       fp19=fp28,fp25,fcr
  116| 000C9C fneg     FF806850   2     COMPFL    fp28=fp13
  116| 000CA0 fsel     FFB7EBAE   2     FSEL      fp29=fp23,fp29,fp14
  116| 000CA4 fmsub    FEEB1638   2     FMS       fp23=fp2,fp11,fp24,fcr
  116| 000CA8 fsel     FF7ADBAE   2     FSEL      fp27=fp26,fp27,fp14
  116| 000CAC fmsub    FE9F1578   2     FMS       fp20=fp2,fp31,fp21,fcr
  116| 000CB0 fsel     FDBC68EE   2     FSEL      fp13=fp28,fp13,fp3
  116| 000CB4 fneg     FE409850   2     COMPFL    fp18=fp19
  116| 000CB8 qvfre    1340E830   1     QVFRE     fp26=fp29
  116| 000CBC fnmsub   FF18C5FC   1     FNMS      fp24=fp24,fp24,fp23,fcr
  116| 000CC0 qvfre    12E0D830   1     QVFRE     fp23=fp27
  116| 000CC4 fnmsub   FEB5AD3C   1     FNMS      fp21=fp21,fp21,fp20,fcr
  116| 000CC8 fneg     FF204850   2     COMPFL    fp25=fp9
  116| 000CCC fneg     FE803050   2     COMPFL    fp20=fp6
  116| 000CD0 fmsub    FEDD16B8   2     FMS       fp22=fp2,fp29,fp26,fcr
  116| 000CD4 fsel     FE7298EE   2     FSEL      fp19=fp18,fp19,fp3
  116| 000CD8 fmsub    FE3B15F8   2     FMS       fp17=fp2,fp27,fp23,fcr
  116| 000CDC fmsub    FE4B1638   2     FMS       fp18=fp2,fp11,fp24,fcr
  116| 000CE0 fsel     FD3948EE   2     FSEL      fp9=fp25,fp9,fp3
  116| 000CE4 fsel     FF9430EE   2     FSEL      fp28=fp20,fp6,fp3
  116| 000CE8 fnmsub   FF5AD5BC   2     FNMS      fp26=fp26,fp26,fp22,fcr
  116| 000CEC fmsub    FEDF1578   2     FMS       fp22=fp2,fp31,fp21,fcr
  116| 000CF0 fnmsub   FEF7BC7C   2     FNMS      fp23=fp23,fp23,fp17,fcr
  116| 000CF4 fmul     FD8D0332   2     MFL       fp12=fp13,fp12,fcr
  116| 000CF8 fnmsub   FF38C4BC   2     FNMS      fp25=fp24,fp24,fp18,fcr
  116| 000CFC fmul     FF1307B2   2     MFL       fp24=fp19,fp30,fcr
  116| 000D00 fmsub    FE9D16B8   2     FMS       fp20=fp2,fp29,fp26,fcr
  116| 000D04 fnmsub   FCD5ADBC   2     FNMS      fp6=fp21,fp21,fp22,fcr
  116| 000D08 fmsub    FDBB15F8   2     FMS       fp13=fp2,fp27,fp23,fcr
  116| 000D0C fmul     FD2902B2   2     MFL       fp9=fp9,fp10,fcr
  116| 000D10 fmul     FF9C0232   2     MFL       fp28=fp28,fp8,fcr
  116| 000D14 fnmsub   FEDAD53C   2     FNMS      fp22=fp26,fp26,fp20,fcr
  116| 000D18 fnmsub   FF57BB7C   2     FNMS      fp26=fp23,fp23,fp13,fcr
    0| 000D1C bc       42400198   1     BCF       ctr=CL.590,taken=0%(0,100)
    0| 000D20 fmr      FDE07090   1     LRFL      fp15=fp14
    0| 000D24 stfd     D9C10088   1     STFL      #SPILL92(gr1,136)=fp14
    0| 000D28 ori      60210000   1     XNOP      
    0| 000D2C ori      60210000   1     XNOP      
    0| 000D30 ori      60210000   1     XNOP      
    0|                              CL.591:
  116| 000D34 fmul     FEF806B2   1     MFL       fp23=fp24,fp26,fcr
  116| 000D38 fmul     FEAC05B2   2     MFL       fp21=fp12,fp22,fcr
  116| 000D3C fmul     FE8901B2   2     MFL       fp20=fp9,fp6,fcr
  113| 000D40 lfdux    7D1A2CEE   1     LFDU      fp8,gr26=v1(gr26,gr5,0)
  116| 000D44 fmul     FDBC0672   1     MFL       fp13=fp28,fp25,fcr
  113| 000D48 lfd      C9590010   1     LFL       fp10=dx3bi(gr25,16)
  116| 000D4C fmsub    FF7BC5F8   1     FMS       fp27=fp24,fp27,fp23,fcr
  116| 000D50 fmsub    FFBD6578   2     FMS       fp29=fp12,fp29,fp21,fcr
  116| 000D54 fmsub    FFFF4D38   2     FMS       fp31=fp9,fp31,fp20,fcr
  113| 000D58 lfd      C9990018   1     LFL       fp12=dx3bi(gr25,24)
  113| 000D5C lfdux    7D3A2CEE   1     LFDU      fp9,gr26=v1(gr26,gr5,0)
  116| 000D60 fmsub    FD6BE378   1     FMS       fp11=fp28,fp11,fp13,fcr
  116| 000D64 fnmsub   FF9ABEFC   2     FNMS      fp28=fp23,fp26,fp27,fcr
  116| 000D68 fnmsub   FF76AF7C   2     FNMS      fp27=fp21,fp22,fp29,fcr
  116| 000D6C fnmsub   FFE6A7FC   2     FNMS      fp31=fp20,fp6,fp31,fcr
  113| 000D70 lfd      CAB90008   1     LFL       fp21=dx3bi(gr25,8)
  114| 000D74 fsub     FCC72828   1     SFL       fp6=fp7,fp5,fcr
  113| 000D78 lfdux    7CBA2CEE   1     LFDU      fp5,gr26=v1(gr26,gr5,0)
  115| 000D7C fsub     FFA83828   1     SFL       fp29=fp8,fp7,fcr
  114| 000D80 fmr      FE40E890   2     LRFL      fp18=fp29
  116| 000D84 fnmsub   FD796AFC   2     FNMS      fp11=fp13,fp25,fp11,fcr
  116| 000D88 stfdu    DF9B0020   2     STFDU     gr27,dq[](gr27,32)=fp28
  114| 000D8C fmul     FF860132   1     MFL       fp28=fp6,fp4,fcr
  115| 000D90 fsub     FF294028   2     SFL       fp25=fp9,fp8,fcr
  113| 000D94 lfdux    7CFA2CEE   1     LFDU      fp7,gr26=v1(gr26,gr5,0)
  115| 000D98 fsub     FDA54828   1     SFL       fp13=fp5,fp9,fcr
  115| 000D9C fmul     FF5D0572   2     MFL       fp26=fp29,fp21,fcr
  116| 000DA0 stfd     DB7BFFF8   1     STFL      dq[](gr27,-8)=fp27
  115| 000DA4 fmul     FE7902B2   1     MFL       fp19=fp25,fp10,fcr
  114| 000DA8 fmr      FF006890   2     LRFL      fp24=fp13
  115| 000DAC fsub     FD272828   2     SFL       fp9=fp7,fp5,fcr
  115| 000DB0 fmadd    FD06D13A   2     FMA       fp8=fp26,fp6,fp4,fcr
  113| 000DB4 lfdu     CC990020   1     LFDU      fp4,gr25=dx3bi(gr25,32)
  115| 000DB8 fmul     FEED0332   1     MFL       fp23=fp13,fp12,fcr
  115| 000DBC fmadd    FCD29D7A   2     FMA       fp6=fp19,fp18,fp21,fcr
  116| 000DC0 stfd     DBFBFFF0   1     STFL      dq[](gr27,-16)=fp31
  116| 000DC4 stfd     D97BFFE8   1     STFL      dq[](gr27,-24)=fp11
  116| 000DC8 fabs     FD604210   1     ABSFL     fp11=fp8
  115| 000DCC qvfcpsgn 11081010   1     CPYSFL    fp8=fp2,fp8
  115| 000DD0 fmul     FDA90132   1     MFL       fp13=fp9,fp4,fcr
  115| 000DD4 fmadd    FD39BABA   2     FMA       fp9=fp23,fp25,fp10,fcr
  116| 000DD8 fabs     FFE03210   2     ABSFL     fp31=fp6
  116| 000DDC fsub     FF6F5828   2     SFL       fp27=fp15,fp11,fcr
  116| 000DE0 fsub     FECFF828   2     SFL       fp22=fp15,fp31,fcr
  115| 000DE4 fmadd    FD586B3A   2     FMA       fp10=fp13,fp24,fp12,fcr
  116| 000DE8 fabs     FFA04A10   2     ABSFL     fp29=fp9
  114| 000DEC fmul     FEB20572   2     MFL       fp21=fp18,fp21,fcr
  116| 000DF0 fsub     FF2FE828   2     SFL       fp25=fp15,fp29,fcr
  116| 000DF4 fsel     FFF6FBEE   2     FSEL      fp31=fp22,fp31,fp15
  116| 000DF8 fsel     FD7B5BEE   2     FSEL      fp11=fp27,fp11,fp15
  116| 000DFC fabs     FF605210   2     ABSFL     fp27=fp10
  114| 000E00 fmul     FE580332   2     MFL       fp18=fp24,fp12,fcr
  116| 000E04 fsub     FECFD828   2     SFL       fp22=fp15,fp27,fcr
  116| 000E08 fsel     FFB9EBEE   2     FSEL      fp29=fp25,fp29,fp15
  116| 000E0C qvfre    1320F830   1     QVFRE     fp25=fp31
  116| 000E10 qvfre    13005830   1     QVFRE     fp24=fp11
  116| 000E14 fmul     FD9305F2   1     MFL       fp12=fp19,fp23,fcr
  116| 000E18 fmul     FDB20372   2     MFL       fp13=fp18,fp13,fcr
  116| 000E1C fsel     FF76DBEE   2     FSEL      fp27=fp22,fp27,fp15
  116| 000E20 qvfre    1280E830   1     QVFRE     fp20=fp29
  116| 000E24 fmsub    FEDF1678   1     FMS       fp22=fp2,fp31,fp25,fcr
  116| 000E28 fmsub    FEEB1638   2     FMS       fp23=fp2,fp11,fp24,fcr
  116| 000E2C fmul     FFD504F2   2     MFL       fp30=fp21,fp19,fcr
  116| 000E30 fmul     FF9C06B2   2     MFL       fp28=fp28,fp26,fcr
  116| 000E34 qvfre    1340D830   1     QVFRE     fp26=fp27
  116| 000E38 fmsub    FE7D1538   1     FMS       fp19=fp2,fp29,fp20,fcr
  116| 000E3C fnmsub   FF39CDBC   2     FNMS      fp25=fp25,fp25,fp22,fcr
  116| 000E40 fnmsub   FF18C5FC   2     FNMS      fp24=fp24,fp24,fp23,fcr
  116| 000E44 fneg     FEE06850   2     COMPFL    fp23=fp13
  116| 000E48 fneg     FEC06050   2     COMPFL    fp22=fp12
  116| 000E4C fmsub    FEBB16B8   2     FMS       fp21=fp2,fp27,fp26,fcr
  116| 000E50 fnmsub   FE94A4FC   2     FNMS      fp20=fp20,fp20,fp19,fcr
  116| 000E54 fneg     FE60F050   2     COMPFL    fp19=fp30
  116| 000E58 fneg     FE40E050   2     COMPFL    fp18=fp28
  116| 000E5C fmsub    FE3F1678   2     FMS       fp17=fp2,fp31,fp25,fcr
  116| 000E60 fmsub    FE0B1638   2     FMS       fp16=fp2,fp11,fp24,fcr
  116| 000E64 fnmsub   FF5AD57C   2     FNMS      fp26=fp26,fp26,fp21,fcr
  116| 000E68 fmsub    FEBD1538   2     FMS       fp21=fp2,fp29,fp20,fcr
  116| 000E6C fsel     FDB768EE   2     FSEL      fp13=fp23,fp13,fp3
  116| 000E70 fsel     FD9660EE   2     FSEL      fp12=fp22,fp12,fp3
  116| 000E74 fsel     FFD3F0EE   2     FSEL      fp30=fp19,fp30,fp3
  116| 000E78 fsel     FF92E0EE   2     FSEL      fp28=fp18,fp28,fp3
  116| 000E7C fmsub    FEFB16B8   2     FMS       fp23=fp2,fp27,fp26,fcr
  115| 000E80 qvfcpsgn 114A1010   1     CPYSFL    fp10=fp2,fp10
  115| 000E84 qvfcpsgn 11291010   1     CPYSFL    fp9=fp2,fp9
  115| 000E88 qvfcpsgn 12661010   1     CPYSFL    fp19=fp2,fp6
  116| 000E8C fnmsub   FED4A57C   1     FNMS      fp22=fp20,fp20,fp21,fcr
  116| 000E90 fnmsub   FCD9CC7C   2     FNMS      fp6=fp25,fp25,fp17,fcr
  116| 000E94 fnmsub   FF5AD5FC   2     FNMS      fp26=fp26,fp26,fp23,fcr
  116| 000E98 fnmsub   FF38C43C   2     FNMS      fp25=fp24,fp24,fp16,fcr
  116| 000E9C fmul     FF0D02B2   2     MFL       fp24=fp13,fp10,fcr
  116| 000EA0 fmul     FD8C0272   2     MFL       fp12=fp12,fp9,fcr
  116| 000EA4 fmul     FD3E04F2   2     MFL       fp9=fp30,fp19,fcr
  116| 000EA8 fmul     FF9C0232   2     MFL       fp28=fp28,fp8,fcr
    0| 000EAC bc       4200FE88   1     BCT       ctr=CL.591,taken=100%(100,0)
    0| 000EB0 lfd      C9C10088   1     LFL       fp14=#SPILL92(gr1,136)
    0|                              CL.590:
  116| 000EB4 fmul     FC9806B2   1     MFL       fp4=fp24,fp26,fcr
  116| 000EB8 fmul     FCAC05B2   2     MFL       fp5=fp12,fp22,fcr
  116| 000EBC fmul     FCE901B2   2     MFL       fp7=fp9,fp6,fcr
  116| 000EC0 fmul     FD1C0672   2     MFL       fp8=fp28,fp25,fcr
  116| 000EC4 fmsub    FD5BC138   2     FMS       fp10=fp24,fp27,fp4,fcr
  116| 000EC8 fmsub    FD9D6178   2     FMS       fp12=fp12,fp29,fp5,fcr
  116| 000ECC fmsub    FD3F49F8   2     FMS       fp9=fp9,fp31,fp7,fcr
  116| 000ED0 fmsub    FD6BE238   2     FMS       fp11=fp28,fp11,fp8,fcr
  116| 000ED4 fnmsub   FC9A22BC   2     FNMS      fp4=fp4,fp26,fp10,fcr
  116| 000ED8 fnmsub   FCB62B3C   2     FNMS      fp5=fp5,fp22,fp12,fcr
  116| 000EDC fnmsub   FCC63A7C   2     FNMS      fp6=fp7,fp6,fp9,fcr
  116| 000EE0 fnmsub   FCF942FC   2     FNMS      fp7=fp8,fp25,fp11,fcr
  116| 000EE4 stfdu    DC9B0020   2     STFDU     gr27,dq[](gr27,32)=fp4
  116| 000EE8 stfd     D8BBFFF8   1     STFL      dq[](gr27,-8)=fp5
  116| 000EEC stfd     D8DBFFF0   1     STFL      dq[](gr27,-16)=fp6
  116| 000EF0 stfd     D8FBFFE8   1     STFL      dq[](gr27,-24)=fp7
  119|                              CL.67:
  129| 000EF4 ld       EB610230   1     L8        gr27=#SPILL58(gr1,560)
  129| 000EF8 cmpdi    2D3B0000   1     C8        cr2=gr27,0
  129| 000EFC bc       408903BC   1     BF        CL.69,cr2,0x2/gt,taken=50%(0,0)
  132| 000F00 ld       EB610178   1     L8        gr27=#SPILL23(gr1,376)
  132| 000F04 ld       EB210180   1     L8        gr25=#SPILL40(gr1,384)
  129| 000F08 ld       EAC10140   1     L8        gr22=#SPILL0(gr1,320)
  129| 000F0C ld       EAA10130   1     L8        gr21=#SPILL3(gr1,304)
  129| 000F10 ld       EA810138   1     L8        gr20=#SPILL32(gr1,312)
  138| 000F14 ld       EA610148   1     L8        gr19=#SPILL10(gr1,328)
  132| 000F18 ld       EB4100E0   1     L8        gr26=#SPILL89(gr1,224)
  132| 000F1C lfdx     7CDBCCAE   1     LFL       fp6=g32bi(gr27,gr25,0)
  129| 000F20 add      7EEAB214   1     A         gr23=gr10,gr22
  132| 000F24 ld       EAC10150   1     L8        gr22=#SPILL29(gr1,336)
  129| 000F28 add      7F34AA14   1     A         gr25=gr20,gr21
  129| 000F2C ld       EAA10240   1     L8        gr21=#SPILL25(gr1,576)
  129| 000F30 ld       EB0101F8   1     L8        gr24=#SPILL70(gr1,504)
  129| 000F34 ld       EA8100B8   1     L8        gr20=#SPILL26(gr1,184)
  132| 000F38 lfd      C8BA0000   1     LFL       fp5=g31ai(gr26,0)
  132| 000F3C mulld    7F56C9D2   1     M         gr26=gr22,gr25
  129| 000F40 lfd      CBD80000   1     LFL       fp30=dx3a(gr24,0)
    0| 000F44 fmul     FCA00172   1     MFL       fp5=fp0,fp5,fcr
  138| 000F48 mulld    7F13C9D2   1     M         gr24=gr19,gr25
    0| 000F4C fmul     FCA501B2   1     MFL       fp5=fp5,fp6,fcr
  129| 000F50 mulld    7F35C9D2   1     M         gr25=gr21,gr25
  138| 000F54 ld       EAA10158   1     L8        gr21=#SPILL54(gr1,344)
  132| 000F58 mulld    7F60B9D2   1     M         gr27=gr0,gr23
  129| 000F5C mulld    7E74B9D2   1     M         gr19=gr20,gr23
  132| 000F60 ld       EAE10160   1     L8        gr23=#SPILL64(gr1,352)
  138| 000F64 add      7ED5C214   1     A         gr22=gr21,gr24
  132| 000F68 ld       EB0100A0   1     L8        gr24=#SPILL82(gr1,160)
  138| 000F6C ld       EAA10250   1     L8        gr21=#SPILL6(gr1,592)
    0| 000F70 ld       E8E101E0   1     L8        gr7=#SPILL62(gr1,480)
  129| 000F74 lfdx     7C8964AE   1     LFL       fp4=dq[](gr9,gr12,0)
  132| 000F78 add      7F7BBA14   1     A         gr27=gr27,gr23
  129| 000F7C ld       EAE10248   1     L8        gr23=#SPILL65(gr1,584)
  132| 000F80 add      7F7ADA14   1     A         gr27=gr26,gr27
  132| 000F84 add      7F5AC214   1     A         gr26=gr26,gr24
  138| 000F88 ld       EB010190   1     L8        gr24=#SPILL5(gr1,400)
    0| 000F8C mtspr    7CE903A6   1     LCTR      ctr=gr7
    0| 000F90 ld       E8E10228   1     L8        gr7=#SPILL60(gr1,552)
  129| 000F94 add      7E97CA14   1     A         gr20=gr23,gr25
  138| 000F98 ld       EAE10258   1     L8        gr23=#SPILL50(gr1,600)
  129| 000F9C add      7F296214   1     A         gr25=gr9,gr12
  138| 000FA0 lfdx     7CF5C4AE   1     LFL       fp7=atwidj1[](gr21,gr24,0)
  138| 000FA4 ld       EAA10098   1     L8        gr21=#SPILL81(gr1,152)
    0| 000FA8 cmpdi    2D270000   1     C8        cr2=gr7,0
  129| 000FAC lfd      C8DE0000   1     LFL       fp6=v1(gr30,0)
  138| 000FB0 lfdx     7D175CAE   1     LFL       fp8=atwid1[](gr23,gr11,0)
  138| 000FB4 add      7F0C9214   1     A         gr24=gr12,gr18
  129| 000FB8 add      7E93A214   1     A         gr20=gr19,gr20
  138| 000FBC add      7EF5B214   1     A         gr23=gr21,gr22
  138| 000FC0 ld       EAA100A8   1     L8        gr21=#SPILL83(gr1,168)
  129| 000FC4 ld       EA6101F8   1     L8        gr19=#SPILL70(gr1,504)
  138| 000FC8 add      7ED5B214   1     A         gr22=gr21,gr22
  132| 000FCC ld       EAA10170   1     L8        gr21=#SPILL68(gr1,368)
    0| 000FD0 bc       418A0080   1     BT        CL.562,cr2,0x4/eq,taken=50%(0,0)
  132| 000FD4 lfdux    7D3A1CEE   1     LFDU      fp9,gr26=v3(gr26,gr3,0)
  132| 000FD8 lfdux    7D5B1CEE   1     LFDU      fp10,gr27=v3(gr27,gr3,0)
  129| 000FDC lfdu     CD930008   1     LFDU      fp12,gr19=dx3a(gr19,8)
  138| 000FE0 lfdux    7FB624EE   1     LFDU      fp29,gr22=mflx[](gr22,gr4,0)
  132| 000FE4 lfdu     CD750008   1     LFDU      fp11,gr21=vg3(gr21,8)
  138| 000FE8 lfdux    7F9724EE   1     LFDU      fp28,gr23=mflx[](gr23,gr4,0)
  129| 000FEC lfdu     CDB90008   1     LFDU      fp13,gr25=dq[](gr25,8)
  129| 000FF0 lfdux    7FF42CEE   1     LFDU      fp31,gr20=v1(gr20,gr5,0)
  132| 000FF4 fadd     FD29502A   1     AFL       fp9=fp9,fp10,fcr
    0| 000FF8 ld       E8E101E0   1     L8        gr7=#SPILL62(gr1,480)
  138| 000FFC fadd     FD5DE02A   1     AFL       fp10=fp29,fp28,fcr
  132| 001000 fmsub    FD295878   2     FMS       fp9=fp11,fp9,fp1,fcr
    0| 001004 cmpdi    2D270000   1     C8        cr2=gr7,0
  132| 001008 fmul     FD690172   1     MFL       fp11=fp9,fp5,fcr
  134| 00100C fmadd    FFA9617A   2     FMA       fp29=fp12,fp9,fp5,fcr
  134| 001010 fnmsub   FD29F17C   2     FNMS      fp9=fp30,fp9,fp5,fcr
  138| 001014 fmr      FFC06090   2     LRFL      fp30=fp12
  133| 001018 qvfcpsgn 116B0810   1     CPYSFL    fp11=fp1,fp11
  134| 00101C fsub     FD815828   1     SFL       fp12=fp1,fp11,fcr
  134| 001020 fnmsub   FFBDFB7C   2     FNMS      fp29=fp31,fp29,fp13,fcr
  134| 001024 fadd     FD6B082A   2     AFL       fp11=fp11,fp1,fcr
  134| 001028 fmadd    FD29313A   2     FMA       fp9=fp6,fp9,fp4,fcr
  138| 00102C fmr      FCC0F890   2     LRFL      fp6=fp31
  138| 001030 fmr      FC806890   2     LRFL      fp4=fp13
  134| 001034 fmul     FD8C0772   2     MFL       fp12=fp12,fp29,fcr
  134| 001038 fmadd    FD2B627A   2     FMA       fp9=fp12,fp11,fp9,fcr
  138| 00103C fmul     FD2A0272   2     MFL       fp9=fp10,fp9,fcr
  138| 001040 fmul     FD290232   2     MFL       fp9=fp9,fp8,fcr
  138| 001044 fmul     FD2901F2   2     MFL       fp9=fp9,fp7,fcr
  138| 001048 stfdu    DD380008   2     STFDU     gr24,sflx[](gr24,8)=fp9
    0| 00104C bc       418A026C   1     BT        CL.69,cr2,0x4/eq,taken=20%(20,80)
    0|                              CL.562:
  132| 001050 lfdux    7DBA1CEE   1     LFDU      fp13,gr26=v3(gr26,gr3,0)
  132| 001054 lfdux    7FFB1CEE   1     LFDU      fp31,gr27=v3(gr27,gr3,0)
  132| 001058 lfd      CB550008   1     LFL       fp26=vg3(gr21,8)
  132| 00105C lfdu     CD350010   1     LFDU      fp9,gr21=vg3(gr21,16)
  129| 001060 lfd      C9530008   1     LFL       fp10=dx3a(gr19,8)
  138| 001064 lfdux    7D7624EE   1     LFDU      fp11,gr22=mflx[](gr22,gr4,0)
  138| 001068 lfdux    7D9724EE   1     LFDU      fp12,gr23=mflx[](gr23,gr4,0)
  132| 00106C lfdux    7FBA1CEE   1     LFDU      fp29,gr26=v3(gr26,gr3,0)
  132| 001070 fadd     FF8DF82A   1     AFL       fp28=fp13,fp31,fcr
  132| 001074 lfdux    7F7B1CEE   1     LFDU      fp27,gr27=v3(gr27,gr3,0)
  129| 001078 lfd      C9B90008   1     LFL       fp13=dq[](gr25,8)
  129| 00107C lfdux    7FF42CEE   1     LFDU      fp31,gr20=v1(gr20,gr5,0)
  132| 001080 fmsub    FF9CD078   1     FMS       fp28=fp26,fp28,fp1,fcr
  132| 001084 fadd     FF3DD82A   2     AFL       fp25=fp29,fp27,fcr
  134| 001088 fnmsub   FF5CF17C   2     FNMS      fp26=fp30,fp28,fp5,fcr
    0| 00108C bc       424001A0   1     BCF       ctr=CL.592,taken=0%(0,100)
  132| 001090 fmsub    FF394878   1     FMS       fp25=fp9,fp25,fp1,fcr
  129| 001094 lfdu     CFD30010   2     LFDU      fp30,gr19=dx3a(gr19,16)
  132| 001098 fmul     FF1C0172   1     MFL       fp24=fp28,fp5,fcr
  138| 00109C lfdux    7FB624EE   1     LFDU      fp29,gr22=mflx[](gr22,gr4,0)
  134| 0010A0 fmadd    FEFC517A   1     FMA       fp23=fp10,fp28,fp5,fcr
  132| 0010A4 lfdux    7F9A1CEE   1     LFDU      fp28,gr26=v3(gr26,gr3,0)
  132| 0010A8 fmul     FD390172   1     MFL       fp9=fp25,fp5,fcr
  132| 0010AC lfdux    7F7B1CEE   1     LFDU      fp27,gr27=v3(gr27,gr3,0)
  134| 0010B0 fmadd    FF5A313A   1     FMA       fp26=fp6,fp26,fp4,fcr
  133| 0010B4 qvfcpsgn 13180810   1     CPYSFL    fp24=fp1,fp24
  134| 0010B8 fmadd    FED9F17A   1     FMA       fp22=fp30,fp25,fp5,fcr
  129| 0010BC lfdu     CC990010   1     LFDU      fp4,gr25=dq[](gr25,16)
  134| 0010C0 fnmsub   FE57FB7C   1     FNMS      fp18=fp31,fp23,fp13,fcr
  129| 0010C4 lfdux    7CD42CEE   1     LFDU      fp6,gr20=v1(gr20,gr5,0)
  134| 0010C8 fsub     FE01C028   1     SFL       fp16=fp1,fp24,fcr
  133| 0010CC qvfcpsgn 11290810   1     CPYSFL    fp9=fp1,fp9
  134| 0010D0 fnmsub   FE39517C   1     FNMS      fp17=fp10,fp25,fp5,fcr
  138| 0010D4 lfdux    7F3724EE   1     LFDU      fp25,gr23=mflx[](gr23,gr4,0)
  134| 0010D8 fadd     FF18082A   1     AFL       fp24=fp24,fp1,fcr
  132| 0010DC lfd      CAF50008   1     LFL       fp23=vg3(gr21,8)
  134| 0010E0 fnmsub   FED6313C   1     FNMS      fp22=fp6,fp22,fp4,fcr
  132| 0010E4 lfdux    7EBA1CEE   1     LFDU      fp21,gr26=v3(gr26,gr3,0)
  134| 0010E8 fsub     FE814828   1     SFL       fp20=fp1,fp9,fcr
  132| 0010EC lfdux    7E7B1CEE   1     LFDU      fp19,gr27=v3(gr27,gr3,0)
  134| 0010F0 fmul     FE5004B2   1     MFL       fp18=fp16,fp18,fcr
  129| 0010F4 lfd      C9530008   2     LFL       fp10=dx3a(gr19,8)
  134| 0010F8 fmadd    FE31FB7A   1     FMA       fp17=fp31,fp17,fp13,fcr
  129| 0010FC lfd      C9B90008   1     LFL       fp13=dq[](gr25,8)
  134| 001100 fadd     FE09082A   1     AFL       fp16=fp9,fp1,fcr
  132| 001104 lfdu     CD350010   1     LFDU      fp9,gr21=vg3(gr21,16)
  138| 001108 fadd     FDEB602A   1     AFL       fp15=fp11,fp12,fcr
  138| 00110C lfdux    7D7624EE   1     LFDU      fp11,gr22=mflx[](gr22,gr4,0)
  134| 001110 fmul     FED405B2   1     MFL       fp22=fp20,fp22,fcr
  138| 001114 lfdux    7D9724EE   1     LFDU      fp12,gr23=mflx[](gr23,gr4,0)
  134| 001118 fmadd    FF5896BA   1     FMA       fp26=fp18,fp24,fp26,fcr
  129| 00111C lfdux    7FF42CEE   1     LFDU      fp31,gr20=v1(gr20,gr5,0)
  132| 001120 fadd     FF9CD82A   1     AFL       fp28=fp28,fp27,fcr
  138| 001124 fadd     FFBDC82A   2     AFL       fp29=fp29,fp25,fcr
  134| 001128 fmadd    FF70B47A   2     FMA       fp27=fp22,fp16,fp17,fcr
  132| 00112C fadd     FF35982A   2     AFL       fp25=fp21,fp19,fcr
  138| 001130 fmul     FF4F06B2   2     MFL       fp26=fp15,fp26,fcr
  132| 001134 fmsub    FF9CB878   2     FMS       fp28=fp23,fp28,fp1,fcr
  138| 001138 fmul     FFBD06F2   2     MFL       fp29=fp29,fp27,fcr
  138| 00113C fmul     FF7A0232   2     MFL       fp27=fp26,fp8,fcr
  134| 001140 fnmsub   FF5CF17C   2     FNMS      fp26=fp30,fp28,fp5,fcr
  138| 001144 fmul     FF1D0232   2     MFL       fp24=fp29,fp8,fcr
  138| 001148 fmul     FFDB01F2   2     MFL       fp30=fp27,fp7,fcr
    0| 00114C bc       424000D4   1     BCF       ctr=CL.593,taken=0%(0,100)
    0| 001150 ori      60210000   1     XNOP      
    0|                              CL.594:
  132| 001154 lfd      CBB50008   1     LFL       fp29=vg3(gr21,8)
  138| 001158 lfdux    7F7624EE   1     LFDU      fp27,gr22=mflx[](gr22,gr4,0)
  132| 00115C fmsub    FD394878   1     FMS       fp9=fp9,fp25,fp1,fcr
  132| 001160 fmul     FF3C0172   2     MFL       fp25=fp28,fp5,fcr
  138| 001164 fmul     FF1801F2   2     MFL       fp24=fp24,fp7,fcr
  129| 001168 lfdu     CEF30010   2     LFDU      fp23,gr19=dx3a(gr19,16)
  132| 00116C lfdux    7EDA1CEE   1     LFDU      fp22,gr26=v3(gr26,gr3,0)
  134| 001170 fmadd    FEBC517A   1     FMA       fp21=fp10,fp28,fp5,fcr
  134| 001174 fnmsub   FD49517C   2     FNMS      fp10=fp10,fp9,fp5,fcr
  134| 001178 fmadd    FF5A313A   2     FMA       fp26=fp6,fp26,fp4,fcr
  129| 00117C lfdu     CC990010   1     LFDU      fp4,gr25=dq[](gr25,16)
  129| 001180 lfdux    7CD42CEE   1     LFDU      fp6,gr20=v1(gr20,gr5,0)
  134| 001184 fmadd    FF89B97A   1     FMA       fp28=fp23,fp9,fp5,fcr
  134| 001188 fnmsub   FEB5FB7C   2     FNMS      fp21=fp31,fp21,fp13,fcr
  132| 00118C lfdux    7E9B1CEE   1     LFDU      fp20,gr27=v3(gr27,gr3,0)
  132| 001190 fmul     FD290172   1     MFL       fp9=fp9,fp5,fcr
  133| 001194 qvfcpsgn 13390810   1     CPYSFL    fp25=fp1,fp25
  134| 001198 fsub     FE61C828   1     SFL       fp19=fp1,fp25,fcr
  134| 00119C fnmsub   FE5C313C   2     FNMS      fp18=fp6,fp28,fp4,fcr
  134| 0011A0 fmadd    FD4AFB7A   2     FMA       fp10=fp31,fp10,fp13,fcr
  134| 0011A4 fadd     FDB9082A   2     AFL       fp13=fp25,fp1,fcr
  132| 0011A8 fadd     FFF6A02A   2     AFL       fp31=fp22,fp20,fcr
  133| 0011AC qvfcpsgn 11290810   1     CPYSFL    fp9=fp1,fp9
  134| 0011B0 fsub     FF214828   1     SFL       fp25=fp1,fp9,fcr
  134| 0011B4 fadd     FD29082A   2     AFL       fp9=fp9,fp1,fcr
  134| 0011B8 fmul     FEB30572   2     MFL       fp21=fp19,fp21,fcr
  138| 0011BC lfdux    7ED724EE   1     LFDU      fp22,gr23=mflx[](gr23,gr4,0)
  132| 0011C0 fmsub    FF9FE878   1     FMS       fp28=fp29,fp31,fp1,fcr
  138| 0011C4 fadd     FD8B602A   2     AFL       fp12=fp11,fp12,fcr
  134| 0011C8 fmul     FD7904B2   2     MFL       fp11=fp25,fp18,fcr
  138| 0011CC stfdu    DF180010   2     STFDU     gr24,sflx[](gr24,16)=fp24
  134| 0011D0 fmadd    FDADAEBA   1     FMA       fp13=fp21,fp13,fp26,fcr
  138| 0011D4 stfd     DBD8FFF8   1     STFL      sflx[](gr24,-8)=fp30
  134| 0011D8 fnmsub   FF5CB97C   1     FNMS      fp26=fp23,fp28,fp5,fcr
  138| 0011DC fadd     FFFBB02A   2     AFL       fp31=fp27,fp22,fcr
  134| 0011E0 fmadd    FD295ABA   2     FMA       fp9=fp11,fp9,fp10,fcr
  138| 0011E4 lfdux    7D7624EE   1     LFDU      fp11,gr22=mflx[](gr22,gr4,0)
  138| 0011E8 fmul     FD4C0372   1     MFL       fp10=fp12,fp13,fcr
  132| 0011EC lfdux    7FBA1CEE   1     LFDU      fp29,gr26=v3(gr26,gr3,0)
  132| 0011F0 lfdux    7F7B1CEE   1     LFDU      fp27,gr27=v3(gr27,gr3,0)
  138| 0011F4 lfdux    7D9724EE   1     LFDU      fp12,gr23=mflx[](gr23,gr4,0)
  138| 0011F8 fmul     FFFF0272   1     MFL       fp31=fp31,fp9,fcr
  129| 0011FC lfd      C9B90008   1     LFL       fp13=dq[](gr25,8)
  138| 001200 fmul     FFCA0232   1     MFL       fp30=fp10,fp8,fcr
  129| 001204 lfd      C9530008   2     LFL       fp10=dx3a(gr19,8)
  132| 001208 lfdu     CD350010   1     LFDU      fp9,gr21=vg3(gr21,16)
  132| 00120C fadd     FF3DD82A   1     AFL       fp25=fp29,fp27,fcr
  138| 001210 fmul     FF1F0232   2     MFL       fp24=fp31,fp8,fcr
  129| 001214 lfdux    7FF42CEE   1     LFDU      fp31,gr20=v1(gr20,gr5,0)
  138| 001218 fmul     FFDE01F2   1     MFL       fp30=fp30,fp7,fcr
    0| 00121C bc       4200FF38   1     BCT       ctr=CL.594,taken=100%(100,0)
    0|                              CL.593:
  138| 001220 stfd     DBD80008   1     STFL      sflx[](gr24,8)=fp30
  138| 001224 fmul     FFD801F2   1     MFL       fp30=fp24,fp7,fcr
  138| 001228 stfdu    DFD80010   2     STFDU     gr24,sflx[](gr24,16)=fp30
    0|                              CL.592:
  132| 00122C fmsub    FD394878   1     FMS       fp9=fp9,fp25,fp1,fcr
  129| 001230 lfdu     CFD30010   2     LFDU      fp30,gr19=dx3a(gr19,16)
  132| 001234 fmul     FFBC0172   1     MFL       fp29=fp28,fp5,fcr
  129| 001238 lfdu     CF790010   1     LFDU      fp27,gr25=dq[](gr25,16)
  134| 00123C fmadd    FF9C517A   1     FMA       fp28=fp10,fp28,fp5,fcr
  129| 001240 lfdux    7F342CEE   1     LFDU      fp25,gr20=v1(gr20,gr5,0)
  132| 001244 fmul     FF090172   1     MFL       fp24=fp9,fp5,fcr
  138| 001248 lfdux    7EF624EE   1     LFDU      fp23,gr22=mflx[](gr22,gr4,0)
  134| 00124C fmadd    FFC9F17A   1     FMA       fp30=fp30,fp9,fp5,fcr
  133| 001250 qvfcpsgn 13BD0810   1     CPYSFL    fp29=fp1,fp29
  134| 001254 fnmsub   FCA9517C   1     FNMS      fp5=fp10,fp9,fp5,fcr
  138| 001258 lfdux    7D3724EE   1     LFDU      fp9,gr23=mflx[](gr23,gr4,0)
  134| 00125C fnmsub   FD5CFB7C   1     FNMS      fp10=fp31,fp28,fp13,fcr
  133| 001260 qvfcpsgn 13980810   1     CPYSFL    fp28=fp1,fp24
  134| 001264 fnmsub   FFDECEFC   1     FNMS      fp30=fp25,fp30,fp27,fcr
  134| 001268 fsub     FF61E028   2     SFL       fp27=fp1,fp28,fcr
  134| 00126C fsub     FF21E828   2     SFL       fp25=fp1,fp29,fcr
  134| 001270 fmadd    FCA5FB7A   2     FMA       fp5=fp31,fp5,fp13,fcr
  134| 001274 fadd     FDBC082A   2     AFL       fp13=fp28,fp1,fcr
  134| 001278 fmadd    FC9A313A   2     FMA       fp4=fp6,fp26,fp4,fcr
  134| 00127C fadd     FCDD082A   2     AFL       fp6=fp29,fp1,fcr
  134| 001280 fmul     FFFB07B2   2     MFL       fp31=fp27,fp30,fcr
  134| 001284 fmul     FD5902B2   2     MFL       fp10=fp25,fp10,fcr
  138| 001288 fadd     FD37482A   2     AFL       fp9=fp23,fp9,fcr
  138| 00128C fadd     FD6B602A   2     AFL       fp11=fp11,fp12,fcr
  134| 001290 fmadd    FCADF97A   2     FMA       fp5=fp31,fp13,fp5,fcr
  134| 001294 fmadd    FC86513A   2     FMA       fp4=fp10,fp6,fp4,fcr
  138| 001298 fmul     FCA90172   2     MFL       fp5=fp9,fp5,fcr
  138| 00129C fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  138| 0012A0 fmul     FCA50232   2     MFL       fp5=fp5,fp8,fcr
  138| 0012A4 fmul     FC840232   2     MFL       fp4=fp4,fp8,fcr
  138| 0012A8 fmul     FCA501F2   2     MFL       fp5=fp5,fp7,fcr
  138| 0012AC fmul     FC8401F2   2     MFL       fp4=fp4,fp7,fcr
  138| 0012B0 stfdu    DCB80010   2     STFDU     gr24,sflx[](gr24,16)=fp5
  138| 0012B4 stfd     D898FFF8   1     STFL      sflx[](gr24,-8)=fp4
  140|                              CL.69:
  142| 0012B8 ld       E8E10118   1     L8        gr7=#SPILL59(gr1,280)
  142| 0012BC cmpdi    2D270000   1     C8        cr2=gr7,0
  142| 0012C0 bc       40890120   1     BF        CL.71,cr2,0x2/gt,taken=50%(0,0)
    0| 0012C4 bc       418616E0   1     BT        CL.192,cr1,0x4/eq,taken=50%(0,0)
    0| 0012C8 ld       EAE101C0   1     L8        gr23=#SPILL63(gr1,448)
    0| 0012CC ld       EB6100C8   1     L8        gr27=#SPILL85(gr1,200)
    0| 0012D0 ld       EB2101C8   1     L8        gr25=#SPILL67(gr1,456)
  144| 0012D4 ld       EB0101D8   1     L8        gr24=#SPILL75(gr1,472)
    0| 0012D8 add      7F52BA14   1     A         gr26=gr18,gr23
    0| 0012DC bc       419E002C   1     BT        CL.384,cr7,0x4/eq,taken=50%(0,0)
    0| 0012E0 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 0012E4 lfdu     CCB90008   1     LFDU      fp5,gr25=dvl3a(gr25,8)
    0| 0012E8 lfd      C8DA0000   1     LFL       fp6=sflx[](gr26,0)
    0| 0012EC lfdu     CCFA0008   1     LFDU      fp7,gr26=sflx[](gr26,8)
  144| 0012F0 lfdu     CD180008   1     LFDU      fp8,gr24=dvl3ani(gr24,8)
    0| 0012F4 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
    0| 0012F8 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  144| 0012FC fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  144| 001300 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 001304 bc       419600DC   1     BT        CL.71,cr5,0x4/eq,taken=50%(0,0)
    0|                              CL.384:
    0| 001308 mtspr    7DE903A6   1     LCTR      ctr=gr15
    0| 00130C bc       418E004C   1     BT        CL.564,cr3,0x4/eq,taken=50%(0,0)
    0| 001310 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 001314 lfd      C8B90008   1     LFL       fp5=dvl3a(gr25,8)
    0| 001318 lfd      C8DA0008   1     LFL       fp6=sflx[](gr26,8)
    0| 00131C lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
  144| 001320 lfd      C9180008   1     LFL       fp8=dvl3ani(gr24,8)
    0| 001324 lfdu     CD390010   1     LFDU      fp9,gr25=dvl3a(gr25,16)
    0| 001328 lfdu     CD5A0010   1     LFDU      fp10,gr26=sflx[](gr26,16)
  144| 00132C lfdu     CD780010   1     LFDU      fp11,gr24=dvl3ani(gr24,16)
    0| 001330 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
    0| 001334 fadd     FC87202A   2     AFL       fp4=fp7,fp4,fcr
  144| 001338 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  144| 00133C stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 001340 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 001344 fmsub    FC845278   1     FMS       fp4=fp10,fp4,fp9,fcr
    0| 001348 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  144| 00134C fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  144| 001350 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 001354 bc       4192008C   1     BT        CL.71,cr4,0x4/eq,taken=20%(20,80)
    0|                              CL.564:
    0| 001358 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s1[](gr27,gr4,0)
    0| 00135C lfd      C8D90008   1     LFL       fp6=dvl3a(gr25,8)
    0| 001360 lfd      C89A0008   1     LFL       fp4=sflx[](gr26,8)
    0| 001364 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
    0| 001368 fmsub    FCA521B8   1     FMS       fp5=fp4-fp6,fcr
  144| 00136C lfd      C8D80008   1     LFL       fp6=dvl3ani(gr24,8)
    0| 001370 fadd     FCA7282A   1     AFL       fp5=fp7,fp5,fcr
  144| 001374 fmul     FCA60172   2     MFL       fp5=fp6,fp5,fcr
    0| 001378 lfd      C8D90010   1     LFL       fp6=dvl3a(gr25,16)
    0| 00137C lfd      C8FA0010   1     LFL       fp7=sflx[](gr26,16)
  144| 001380 stfd     D8BB0000   1     STFL      s1[](gr27,0)=fp5
    0| 001384 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s1[](gr27,gr4,0)
    0| 001388 fmsub    FCA539B8   1     FMS       fp5=fp7,fp5,fp6,fcr
  144| 00138C lfd      C8D80010   1     LFL       fp6=dvl3ani(gr24,16)
    0| 001390 fadd     FC84282A   1     AFL       fp4=fp4,fp5,fcr
  144| 001394 fmul     FC860132   2     MFL       fp4=fp6,fp4,fcr
    0| 001398 lfd      C8B90018   1     LFL       fp5=dvl3a(gr25,24)
    0| 00139C lfd      C8DA0018   1     LFL       fp6=sflx[](gr26,24)
  144| 0013A0 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 0013A4 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 0013A8 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
  144| 0013AC lfd      C8B80018   1     LFL       fp5=dvl3ani(gr24,24)
    0| 0013B0 fadd     FC87202A   1     AFL       fp4=fp7,fp4,fcr
  144| 0013B4 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
    0| 0013B8 lfdu     CCB90020   1     LFDU      fp5,gr25=dvl3a(gr25,32)
    0| 0013BC lfdu     CCFA0020   1     LFDU      fp7,gr26=sflx[](gr26,32)
  144| 0013C0 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 0013C4 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 0013C8 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
  144| 0013CC lfdu     CCB80020   1     LFDU      fp5,gr24=dvl3ani(gr24,32)
    0| 0013D0 fadd     FC86202A   1     AFL       fp4=fp6,fp4,fcr
  144| 0013D4 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
  144| 0013D8 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 0013DC bc       4200FF7C   1     BCT       ctr=CL.564,taken=100%(100,0)
  150|                              CL.71:
  161| 0013E0 bc       409903B0   1     BF        CL.73,cr6,0x2/gt,taken=50%(0,0)
  161| 0013E4 ld       EB210238   1     L8        gr25=#SPILL66(gr1,568)
  161| 0013E8 ld       E8E100E8   1     L8        gr7=#SPILL87(gr1,232)
  164| 0013EC ld       EB0101A0   1     L8        gr24=#SPILL69(gr1,416)
    0| 0013F0 cmpdi    2D300000   1     C8        cr2=gr16,0
  161| 0013F4 lfd      C8DD0000   1     LFL       fp6=v2(gr29,0)
  161| 0013F8 or       7FBAEB78   1     LR        gr26=gr29
  161| 0013FC lfd      C9790000   1     LFL       fp11=dx3bi(gr25,0)
  161| 001400 lfd      C8870000   1     LFL       fp4=v2(gr7,0)
  164| 001404 add      7F69C214   1     A         gr27=gr9,gr24
    0| 001408 bc       418A0080   1     BT        CL.408,cr2,0x4/eq,taken=50%(0,0)
    0| 00140C mtspr    7E0903A6   1     LCTR      ctr=gr16
  161|                              CL.407:
  161| 001410 lfdux    7CBA34EE   1     LFDU      fp5,gr26=v2(gr26,gr6,0)
  162| 001414 fsub     FCE62028   1     SFL       fp7=fp6,fp4,fcr
  161| 001418 lfdu     CD190008   1     LFDU      fp8,gr25=dx3bi(gr25,8)
  164| 00141C fmr      FC803090   1     LRFL      fp4=fp6
  163| 001420 fsub     FD253028   2     SFL       fp9=fp5,fp6,fcr
  164| 001424 fmr      FCC02890   2     LRFL      fp6=fp5
  162| 001428 fmul     FD4702F2   2     MFL       fp10=fp7,fp11,fcr
  163| 00142C fmul     FCA90232   2     MFL       fp5=fp9,fp8,fcr
  163| 001430 fmadd    FCE72AFA   2     FMA       fp7=fp5,fp7,fp11,fcr
  164| 001434 fmul     FCAA0172   2     MFL       fp5=fp10,fp5,fcr
  164| 001438 fmr      FD604090   2     LRFL      fp11=fp8
  163| 00143C qvfcpsgn 11071010   1     CPYSFL    fp8=fp2,fp7
  164| 001440 fabs     FCE03A10   1     ABSFL     fp7=fp7
  164| 001444 fneg     FD202850   2     COMPFL    fp9=fp5
  164| 001448 fsub     FD4E3828   2     SFL       fp10=fp14,fp7,fcr
  164| 00144C fsel     FCA928EE   2     FSEL      fp5=fp9,fp5,fp3
  164| 001450 fsel     FCEA3BAE   2     FSEL      fp7=fp10,fp7,fp14
  164| 001454 fmul     FD250232   2     MFL       fp9=fp5,fp8,fcr
  164| 001458 qvfre    10A03830   1     QVFRE     fp5=fp7
  164| 00145C fmsub    FD071178   1     FMS       fp8=fp2,fp7,fp5,fcr
  164| 001460 fnmsub   FCA52A3C   2     FNMS      fp5=fp5,fp5,fp8,fcr
  164| 001464 fmsub    FD071178   2     FMS       fp8=fp2,fp7,fp5,fcr
  164| 001468 fnmsub   FCA52A3C   2     FNMS      fp5=fp5,fp5,fp8,fcr
  164| 00146C fmul     FD090172   2     MFL       fp8=fp9,fp5,fcr
  164| 001470 fmsub    FCE74A38   2     FMS       fp7=fp9,fp7,fp8,fcr
  164| 001474 fnmsub   FCA541FC   2     FNMS      fp5=fp8,fp5,fp7,fcr
  164| 001478 stfdu    DCBB0008   2     STFDU     gr27,dq[](gr27,8)=fp5
  167| 00147C bc       4200FF94   1     BCT       ctr=CL.407,taken=100%(100,0)
    0| 001480 cmpdi    2D310000   1     C8        cr2=gr17,0
    0| 001484 bc       418A030C   1     BT        CL.73,cr2,0x4/eq,taken=20%(20,80)
    0|                              CL.408:
  161| 001488 lfdux    7D3A34EE   1     LFDU      fp9,gr26=v2(gr26,gr6,0)
  162| 00148C fsub     FF862028   1     SFL       fp28=fp6,fp4,fcr
  161| 001490 lfd      CBF90008   1     LFL       fp31=dx3bi(gr25,8)
  161| 001494 lfd      C9590010   1     LFL       fp10=dx3bi(gr25,16)
  161| 001498 lfd      C9990018   1     LFL       fp12=dx3bi(gr25,24)
  161| 00149C lfdu     CC990020   1     LFDU      fp4,gr25=dx3bi(gr25,32)
    0| 0014A0 mtspr    7E2903A6   1     LCTR      ctr=gr17
  163| 0014A4 fsub     FCA93028   1     SFL       fp5=fp9,fp6,fcr
  161| 0014A8 lfdux    7DBA34EE   1     LFDU      fp13,gr26=v2(gr26,gr6,0)
  162| 0014AC fmul     FCDC02F2   1     MFL       fp6=fp28,fp11,fcr
  162| 0014B0 fmr      FFC02890   2     LRFL      fp30=fp5
  163| 0014B4 fmul     FCE507F2   2     MFL       fp7=fp5,fp31,fcr
  161| 0014B8 lfdux    7CBA34EE   1     LFDU      fp5,gr26=v2(gr26,gr6,0)
  163| 0014BC fsub     FD0D4828   1     SFL       fp8=fp13,fp9,fcr
  162| 0014C0 fmul     FD3E07F2   2     MFL       fp9=fp30,fp31,fcr
  163| 0014C4 fmadd    FD7C3AFA   2     FMA       fp11=fp7,fp28,fp11,fcr
  164| 0014C8 fmul     FCC601F2   2     MFL       fp6=fp6,fp7,fcr
  161| 0014CC lfdux    7CFA34EE   1     LFDU      fp7,gr26=v2(gr26,gr6,0)
  163| 0014D0 fsub     FF856828   1     SFL       fp28=fp5,fp13,fcr
  163| 0014D4 fmul     FF0802B2   2     MFL       fp24=fp8,fp10,fcr
  162| 0014D8 fmr      FFA04090   2     LRFL      fp29=fp8
  163| 0014DC qvfcpsgn 110B1010   1     CPYSFL    fp8=fp2,fp11
  164| 0014E0 fabs     FD605A10   1     ABSFL     fp11=fp11
  162| 0014E4 fmul     FDBD02B2   2     MFL       fp13=fp29,fp10,fcr
  163| 0014E8 fsub     FF272828   2     SFL       fp25=fp7,fp5,fcr
  163| 0014EC fmul     FF5C0332   2     MFL       fp26=fp28,fp12,fcr
  163| 0014F0 fmadd    FFFEC7FA   2     FMA       fp31=fp24,fp30,fp31,fcr
  164| 0014F4 fsub     FFCE5828   2     SFL       fp30=fp14,fp11,fcr
  162| 0014F8 fmr      FF60E090   2     LRFL      fp27=fp28
  164| 0014FC fmul     FD290632   2     MFL       fp9=fp9,fp24,fcr
  163| 001500 fmul     FF390132   2     MFL       fp25=fp25,fp4,fcr
  163| 001504 fmadd    FFBDD2BA   2     FMA       fp29=fp26,fp29,fp10,fcr
  163| 001508 qvfcpsgn 115F1010   1     CPYSFL    fp10=fp2,fp31
  164| 00150C fabs     FFE0FA10   1     ABSFL     fp31=fp31
  164| 001510 fsel     FD7E5BAE   2     FSEL      fp11=fp30,fp11,fp14
  164| 001514 fsub     FFCEF828   2     SFL       fp30=fp14,fp31,fcr
  163| 001518 fmadd    FF7BCB3A   2     FMA       fp27=fp25,fp27,fp12,fcr
  163| 00151C qvfcpsgn 119D1010   1     CPYSFL    fp12=fp2,fp29
  164| 001520 fabs     FFA0EA10   1     ABSFL     fp29=fp29
  162| 001524 fmr      FF80D090   2     LRFL      fp28=fp26
  164| 001528 fmul     FDAD06B2   2     MFL       fp13=fp13,fp26,fcr
  164| 00152C fsel     FFFEFBAE   2     FSEL      fp31=fp30,fp31,fp14
  163| 001530 qvfcpsgn 13DB1010   1     CPYSFL    fp30=fp2,fp27
  164| 001534 fabs     FF60DA10   1     ABSFL     fp27=fp27
  164| 001538 fsub     FEEEE828   2     SFL       fp23=fp14,fp29,fcr
  164| 00153C qvfre    13005830   1     QVFRE     fp24=fp11
  164| 001540 fsub     FF4ED828   1     SFL       fp26=fp14,fp27,fcr
  164| 001544 qvfre    12A0F830   1     QVFRE     fp21=fp31
  164| 001548 fmul     FE7C0672   1     MFL       fp19=fp28,fp25,fcr
  164| 00154C fneg     FF806850   2     COMPFL    fp28=fp13
  164| 001550 fsel     FFB7EBAE   2     FSEL      fp29=fp23,fp29,fp14
  164| 001554 fmsub    FEEB1638   2     FMS       fp23=fp2,fp11,fp24,fcr
  164| 001558 fsel     FF7ADBAE   2     FSEL      fp27=fp26,fp27,fp14
  164| 00155C fmsub    FE9F1578   2     FMS       fp20=fp2,fp31,fp21,fcr
  164| 001560 fsel     FDBC68EE   2     FSEL      fp13=fp28,fp13,fp3
  164| 001564 fneg     FE409850   2     COMPFL    fp18=fp19
  164| 001568 qvfre    1340E830   1     QVFRE     fp26=fp29
  164| 00156C fnmsub   FF18C5FC   1     FNMS      fp24=fp24,fp24,fp23,fcr
  164| 001570 qvfre    12E0D830   1     QVFRE     fp23=fp27
  164| 001574 fnmsub   FEB5AD3C   1     FNMS      fp21=fp21,fp21,fp20,fcr
  164| 001578 fneg     FF204850   2     COMPFL    fp25=fp9
  164| 00157C fneg     FE803050   2     COMPFL    fp20=fp6
  164| 001580 fmsub    FEDD16B8   2     FMS       fp22=fp2,fp29,fp26,fcr
  164| 001584 fsel     FE7298EE   2     FSEL      fp19=fp18,fp19,fp3
  164| 001588 fmsub    FE3B15F8   2     FMS       fp17=fp2,fp27,fp23,fcr
  164| 00158C fmsub    FE4B1638   2     FMS       fp18=fp2,fp11,fp24,fcr
  164| 001590 fsel     FD3948EE   2     FSEL      fp9=fp25,fp9,fp3
  164| 001594 fsel     FF9430EE   2     FSEL      fp28=fp20,fp6,fp3
  164| 001598 fnmsub   FF5AD5BC   2     FNMS      fp26=fp26,fp26,fp22,fcr
  164| 00159C fmsub    FEDF1578   2     FMS       fp22=fp2,fp31,fp21,fcr
  164| 0015A0 fnmsub   FEF7BC7C   2     FNMS      fp23=fp23,fp23,fp17,fcr
  164| 0015A4 fmul     FD8D0332   2     MFL       fp12=fp13,fp12,fcr
  164| 0015A8 fnmsub   FF38C4BC   2     FNMS      fp25=fp24,fp24,fp18,fcr
  164| 0015AC fmul     FF1307B2   2     MFL       fp24=fp19,fp30,fcr
  164| 0015B0 fmsub    FE9D16B8   2     FMS       fp20=fp2,fp29,fp26,fcr
  164| 0015B4 fnmsub   FCD5ADBC   2     FNMS      fp6=fp21,fp21,fp22,fcr
  164| 0015B8 fmsub    FDBB15F8   2     FMS       fp13=fp2,fp27,fp23,fcr
  164| 0015BC fmul     FD2902B2   2     MFL       fp9=fp9,fp10,fcr
  164| 0015C0 fmul     FF9C0232   2     MFL       fp28=fp28,fp8,fcr
  164| 0015C4 fnmsub   FEDAD53C   2     FNMS      fp22=fp26,fp26,fp20,fcr
  164| 0015C8 fnmsub   FF57BB7C   2     FNMS      fp26=fp23,fp23,fp13,fcr
    0| 0015CC bc       42400184   1     BCF       ctr=CL.597,taken=0%(0,100)
    0| 0015D0 fmr      FDE07090   1     LRFL      fp15=fp14
    0|                              CL.598:
  164| 0015D4 fmul     FEF806B2   1     MFL       fp23=fp24,fp26,fcr
  164| 0015D8 fmul     FEAC05B2   2     MFL       fp21=fp12,fp22,fcr
  164| 0015DC fmul     FE8901B2   2     MFL       fp20=fp9,fp6,fcr
  161| 0015E0 lfdux    7D1A34EE   1     LFDU      fp8,gr26=v2(gr26,gr6,0)
  164| 0015E4 fmul     FDBC0672   1     MFL       fp13=fp28,fp25,fcr
  161| 0015E8 lfd      C9590010   1     LFL       fp10=dx3bi(gr25,16)
  164| 0015EC fmsub    FF7BC5F8   1     FMS       fp27=fp24,fp27,fp23,fcr
  164| 0015F0 fmsub    FFBD6578   2     FMS       fp29=fp12,fp29,fp21,fcr
  164| 0015F4 fmsub    FFFF4D38   2     FMS       fp31=fp9,fp31,fp20,fcr
  161| 0015F8 lfd      C9990018   1     LFL       fp12=dx3bi(gr25,24)
  161| 0015FC lfdux    7D3A34EE   1     LFDU      fp9,gr26=v2(gr26,gr6,0)
  164| 001600 fmsub    FD6BE378   1     FMS       fp11=fp28,fp11,fp13,fcr
  164| 001604 fnmsub   FF9ABEFC   2     FNMS      fp28=fp23,fp26,fp27,fcr
  164| 001608 fnmsub   FF76AF7C   2     FNMS      fp27=fp21,fp22,fp29,fcr
  164| 00160C fnmsub   FFE6A7FC   2     FNMS      fp31=fp20,fp6,fp31,fcr
  161| 001610 lfd      CAB90008   1     LFL       fp21=dx3bi(gr25,8)
  162| 001614 fsub     FCC72828   1     SFL       fp6=fp7,fp5,fcr
  161| 001618 lfdux    7CBA34EE   1     LFDU      fp5,gr26=v2(gr26,gr6,0)
  163| 00161C fsub     FFA83828   1     SFL       fp29=fp8,fp7,fcr
  162| 001620 fmr      FE40E890   2     LRFL      fp18=fp29
  164| 001624 fnmsub   FD796AFC   2     FNMS      fp11=fp13,fp25,fp11,fcr
  164| 001628 stfdu    DF9B0020   2     STFDU     gr27,dq[](gr27,32)=fp28
  162| 00162C fmul     FF860132   1     MFL       fp28=fp6,fp4,fcr
  163| 001630 fsub     FF294028   2     SFL       fp25=fp9,fp8,fcr
  161| 001634 lfdux    7CFA34EE   1     LFDU      fp7,gr26=v2(gr26,gr6,0)
  163| 001638 fsub     FDA54828   1     SFL       fp13=fp5,fp9,fcr
  163| 00163C fmul     FF5D0572   2     MFL       fp26=fp29,fp21,fcr
  164| 001640 stfd     DB7BFFF8   1     STFL      dq[](gr27,-8)=fp27
  163| 001644 fmul     FE7902B2   1     MFL       fp19=fp25,fp10,fcr
  162| 001648 fmr      FF006890   2     LRFL      fp24=fp13
  163| 00164C fsub     FD272828   2     SFL       fp9=fp7,fp5,fcr
  163| 001650 fmadd    FD06D13A   2     FMA       fp8=fp26,fp6,fp4,fcr
  161| 001654 lfdu     CC990020   1     LFDU      fp4,gr25=dx3bi(gr25,32)
  163| 001658 fmul     FEED0332   1     MFL       fp23=fp13,fp12,fcr
  163| 00165C fmadd    FCD29D7A   2     FMA       fp6=fp19,fp18,fp21,fcr
  164| 001660 stfd     DBFBFFF0   1     STFL      dq[](gr27,-16)=fp31
  164| 001664 stfd     D97BFFE8   1     STFL      dq[](gr27,-24)=fp11
  164| 001668 fabs     FD604210   1     ABSFL     fp11=fp8
  163| 00166C qvfcpsgn 11081010   1     CPYSFL    fp8=fp2,fp8
  163| 001670 fmul     FDA90132   1     MFL       fp13=fp9,fp4,fcr
  163| 001674 fmadd    FD39BABA   2     FMA       fp9=fp23,fp25,fp10,fcr
  164| 001678 fabs     FFE03210   2     ABSFL     fp31=fp6
  164| 00167C fsub     FF6F5828   2     SFL       fp27=fp15,fp11,fcr
  164| 001680 fsub     FECFF828   2     SFL       fp22=fp15,fp31,fcr
  163| 001684 fmadd    FD586B3A   2     FMA       fp10=fp13,fp24,fp12,fcr
  164| 001688 fabs     FFA04A10   2     ABSFL     fp29=fp9
  162| 00168C fmul     FEB20572   2     MFL       fp21=fp18,fp21,fcr
  164| 001690 fsub     FF2FE828   2     SFL       fp25=fp15,fp29,fcr
  164| 001694 fsel     FFF6FBEE   2     FSEL      fp31=fp22,fp31,fp15
  164| 001698 fsel     FD7B5BEE   2     FSEL      fp11=fp27,fp11,fp15
  164| 00169C fabs     FF605210   2     ABSFL     fp27=fp10
  162| 0016A0 fmul     FE580332   2     MFL       fp18=fp24,fp12,fcr
  164| 0016A4 fsub     FECFD828   2     SFL       fp22=fp15,fp27,fcr
  164| 0016A8 fsel     FFB9EBEE   2     FSEL      fp29=fp25,fp29,fp15
  164| 0016AC qvfre    1320F830   1     QVFRE     fp25=fp31
  164| 0016B0 qvfre    13005830   1     QVFRE     fp24=fp11
  164| 0016B4 fmul     FD9305F2   1     MFL       fp12=fp19,fp23,fcr
  164| 0016B8 fmul     FDB20372   2     MFL       fp13=fp18,fp13,fcr
  164| 0016BC fsel     FF76DBEE   2     FSEL      fp27=fp22,fp27,fp15
  164| 0016C0 qvfre    1280E830   1     QVFRE     fp20=fp29
  164| 0016C4 fmsub    FEDF1678   1     FMS       fp22=fp2,fp31,fp25,fcr
  164| 0016C8 fmsub    FEEB1638   2     FMS       fp23=fp2,fp11,fp24,fcr
  164| 0016CC fmul     FFD504F2   2     MFL       fp30=fp21,fp19,fcr
  164| 0016D0 fmul     FF9C06B2   2     MFL       fp28=fp28,fp26,fcr
  164| 0016D4 qvfre    1340D830   1     QVFRE     fp26=fp27
  164| 0016D8 fmsub    FE7D1538   1     FMS       fp19=fp2,fp29,fp20,fcr
  164| 0016DC fnmsub   FF39CDBC   2     FNMS      fp25=fp25,fp25,fp22,fcr
  164| 0016E0 fnmsub   FF18C5FC   2     FNMS      fp24=fp24,fp24,fp23,fcr
  164| 0016E4 fneg     FEE06850   2     COMPFL    fp23=fp13
  164| 0016E8 fneg     FEC06050   2     COMPFL    fp22=fp12
  164| 0016EC fmsub    FEBB16B8   2     FMS       fp21=fp2,fp27,fp26,fcr
  164| 0016F0 fnmsub   FE94A4FC   2     FNMS      fp20=fp20,fp20,fp19,fcr
  164| 0016F4 fneg     FE60F050   2     COMPFL    fp19=fp30
  164| 0016F8 fneg     FE40E050   2     COMPFL    fp18=fp28
  164| 0016FC fmsub    FE3F1678   2     FMS       fp17=fp2,fp31,fp25,fcr
  164| 001700 fmsub    FE0B1638   2     FMS       fp16=fp2,fp11,fp24,fcr
  164| 001704 fnmsub   FF5AD57C   2     FNMS      fp26=fp26,fp26,fp21,fcr
  164| 001708 fmsub    FEBD1538   2     FMS       fp21=fp2,fp29,fp20,fcr
  164| 00170C fsel     FDB768EE   2     FSEL      fp13=fp23,fp13,fp3
  164| 001710 fsel     FD9660EE   2     FSEL      fp12=fp22,fp12,fp3
  164| 001714 fsel     FFD3F0EE   2     FSEL      fp30=fp19,fp30,fp3
  164| 001718 fsel     FF92E0EE   2     FSEL      fp28=fp18,fp28,fp3
  164| 00171C fmsub    FEFB16B8   2     FMS       fp23=fp2,fp27,fp26,fcr
  163| 001720 qvfcpsgn 114A1010   1     CPYSFL    fp10=fp2,fp10
  163| 001724 qvfcpsgn 11291010   1     CPYSFL    fp9=fp2,fp9
  163| 001728 qvfcpsgn 12661010   1     CPYSFL    fp19=fp2,fp6
  164| 00172C fnmsub   FED4A57C   1     FNMS      fp22=fp20,fp20,fp21,fcr
  164| 001730 fnmsub   FCD9CC7C   2     FNMS      fp6=fp25,fp25,fp17,fcr
  164| 001734 fnmsub   FF5AD5FC   2     FNMS      fp26=fp26,fp26,fp23,fcr
  164| 001738 fnmsub   FF38C43C   2     FNMS      fp25=fp24,fp24,fp16,fcr
  164| 00173C fmul     FF0D02B2   2     MFL       fp24=fp13,fp10,fcr
  164| 001740 fmul     FD8C0272   2     MFL       fp12=fp12,fp9,fcr
  164| 001744 fmul     FD3E04F2   2     MFL       fp9=fp30,fp19,fcr
  164| 001748 fmul     FF9C0232   2     MFL       fp28=fp28,fp8,fcr
    0| 00174C bc       4200FE88   1     BCT       ctr=CL.598,taken=100%(100,0)
    0|                              CL.597:
  164| 001750 fmul     FC9806B2   1     MFL       fp4=fp24,fp26,fcr
  164| 001754 fmul     FCAC05B2   2     MFL       fp5=fp12,fp22,fcr
  164| 001758 fmul     FCE901B2   2     MFL       fp7=fp9,fp6,fcr
  164| 00175C fmul     FD1C0672   2     MFL       fp8=fp28,fp25,fcr
  164| 001760 fmsub    FD5BC138   2     FMS       fp10=fp24,fp27,fp4,fcr
  164| 001764 fmsub    FD9D6178   2     FMS       fp12=fp12,fp29,fp5,fcr
  164| 001768 fmsub    FD3F49F8   2     FMS       fp9=fp9,fp31,fp7,fcr
  164| 00176C fmsub    FD6BE238   2     FMS       fp11=fp28,fp11,fp8,fcr
  164| 001770 fnmsub   FC9A22BC   2     FNMS      fp4=fp4,fp26,fp10,fcr
  164| 001774 fnmsub   FCB62B3C   2     FNMS      fp5=fp5,fp22,fp12,fcr
  164| 001778 fnmsub   FCC63A7C   2     FNMS      fp6=fp7,fp6,fp9,fcr
  164| 00177C fnmsub   FCF942FC   2     FNMS      fp7=fp8,fp25,fp11,fcr
  164| 001780 stfdu    DC9B0020   2     STFDU     gr27,dq[](gr27,32)=fp4
  164| 001784 stfd     D8BBFFF8   1     STFL      dq[](gr27,-8)=fp5
  164| 001788 stfd     D8DBFFF0   1     STFL      dq[](gr27,-16)=fp6
  164| 00178C stfd     D8FBFFE8   1     STFL      dq[](gr27,-24)=fp7
  167|                              CL.73:
  177| 001790 ld       E8E10230   1     L8        gr7=#SPILL58(gr1,560)
  177| 001794 cmpdi    2D270000   1     C8        cr2=gr7,0
  177| 001798 bc       408903C0   1     BF        CL.75,cr2,0x2/gt,taken=50%(0,0)
  180| 00179C ld       EB4101E8   1     L8        gr26=#SPILL39(gr1,488)
  180| 0017A0 ld       EB2101F0   1     L8        gr25=#SPILL24(gr1,496)
  177| 0017A4 ld       EB0101F8   1     L8        gr24=#SPILL70(gr1,504)
  177| 0017A8 ld       EAE10140   1     L8        gr23=#SPILL0(gr1,320)
  177| 0017AC ld       EAC10130   1     L8        gr22=#SPILL3(gr1,304)
  177| 0017B0 ld       EAA10138   1     L8        gr21=#SPILL32(gr1,312)
  186| 0017B4 ld       EA810148   1     L8        gr20=#SPILL10(gr1,328)
  180| 0017B8 ld       EA610150   1     L8        gr19=#SPILL29(gr1,336)
  180| 0017BC lfdx     7CDACCAE   1     LFL       fp6=g32ai(gr26,gr25,0)
  177| 0017C0 lfd      CBD80000   1     LFL       fp30=dx3a(gr24,0)
  177| 0017C4 add      7F0ABA14   1     A         gr24=gr10,gr23
  177| 0017C8 add      7F35B214   1     A         gr25=gr21,gr22
  180| 0017CC ld       EB6100D0   1     L8        gr27=#SPILL56(gr1,208)
  177| 0017D0 ld       EAA100C0   1     L8        gr21=#SPILL28(gr1,192)
  177| 0017D4 ld       EAC10200   1     L8        gr22=#SPILL27(gr1,512)
  180| 0017D8 mulld    7F40C1D2   1     M         gr26=gr0,gr24
  186| 0017DC mulld    7EF4C9D2   1     M         gr23=gr20,gr25
  180| 0017E0 ld       EA810160   1     L8        gr20=#SPILL64(gr1,352)
  180| 0017E4 lfd      C8BB0000   1     LFL       fp5=g31bi(gr27,0)
  180| 0017E8 mulld    7F73C9D2   1     M         gr27=gr19,gr25
  177| 0017EC mulld    7E75C1D2   1     M         gr19=gr21,gr24
    0| 0017F0 fmul     FCA00172   1     MFL       fp5=fp0,fp5,fcr
  180| 0017F4 add      7F14D214   1     A         gr24=gr20,gr26
  177| 0017F8 mulld    7F36C9D2   1     M         gr25=gr22,gr25
    0| 0017FC fmul     FCA501B2   1     MFL       fp5=fp5,fp6,fcr
  180| 001800 add      7F7BC214   1     A         gr27=gr27,gr24
  180| 001804 ld       EAC10208   1     L8        gr22=#SPILL77(gr1,520)
  177| 001808 ld       EB010210   1     L8        gr24=#SPILL71(gr1,528)
  186| 00180C ld       EAA10158   1     L8        gr21=#SPILL54(gr1,344)
    0| 001810 ld       E8E101E0   1     L8        gr7=#SPILL62(gr1,480)
  177| 001814 lfdx     7C8964AE   1     LFL       fp4=dq[](gr9,gr12,0)
  177| 001818 lfd      C8DD0000   1     LFL       fp6=v2(gr29,0)
  180| 00181C add      7F56D214   1     A         gr26=gr22,gr26
  177| 001820 add      7E98CA14   1     A         gr20=gr24,gr25
  186| 001824 ld       EAC10218   1     L8        gr22=#SPILL7(gr1,536)
  186| 001828 ld       EB010190   1     L8        gr24=#SPILL5(gr1,400)
  186| 00182C add      7EF5BA14   1     A         gr23=gr21,gr23
    0| 001830 mtspr    7CE903A6   1     LCTR      ctr=gr7
    0| 001834 ld       E8E10228   1     L8        gr7=#SPILL60(gr1,552)
  177| 001838 add      7F296214   1     A         gr25=gr9,gr12
  177| 00183C add      7E93A214   1     A         gr20=gr19,gr20
  186| 001840 lfdx     7CF6C4AE   1     LFL       fp7=atwidj2[](gr22,gr24,0)
  186| 001844 ld       EAC10098   1     L8        gr22=#SPILL81(gr1,152)
  186| 001848 ld       EB010220   1     L8        gr24=#SPILL52(gr1,544)
    0| 00184C cmpdi    2D270000   1     C8        cr2=gr7,0
  177| 001850 ld       EA6101F8   1     L8        gr19=#SPILL70(gr1,504)
  186| 001854 add      7EF6BA14   1     A         gr23=gr22,gr23
  186| 001858 ld       EAC100B0   1     L8        gr22=#SPILL84(gr1,176)
  186| 00185C lfdx     7D185CAE   1     LFL       fp8=atwid2[](gr24,gr11,0)
  186| 001860 add      7F0C9214   1     A         gr24=gr12,gr18
  186| 001864 add      7ED6AA14   1     A         gr22=gr22,gr21
  180| 001868 ld       EAA10170   1     L8        gr21=#SPILL68(gr1,368)
    0| 00186C bc       418A0080   1     BT        CL.570,cr2,0x4/eq,taken=50%(0,0)
  180| 001870 lfdux    7D3A1CEE   1     LFDU      fp9,gr26=v3(gr26,gr3,0)
  180| 001874 lfdux    7D5B1CEE   1     LFDU      fp10,gr27=v3(gr27,gr3,0)
  177| 001878 lfdu     CD930008   1     LFDU      fp12,gr19=dx3a(gr19,8)
  186| 00187C lfdux    7FB624EE   1     LFDU      fp29,gr22=mflx[](gr22,gr4,0)
  180| 001880 lfdu     CD750008   1     LFDU      fp11,gr21=vg3(gr21,8)
  186| 001884 lfdux    7F9724EE   1     LFDU      fp28,gr23=mflx[](gr23,gr4,0)
  177| 001888 lfdu     CDB90008   1     LFDU      fp13,gr25=dq[](gr25,8)
  177| 00188C lfdux    7FF434EE   1     LFDU      fp31,gr20=v2(gr20,gr6,0)
  180| 001890 fadd     FD29502A   1     AFL       fp9=fp9,fp10,fcr
    0| 001894 ld       E8E101E0   1     L8        gr7=#SPILL62(gr1,480)
  186| 001898 fadd     FD5DE02A   1     AFL       fp10=fp29,fp28,fcr
  180| 00189C fmsub    FD295878   2     FMS       fp9=fp11,fp9,fp1,fcr
    0| 0018A0 cmpdi    2D270000   1     C8        cr2=gr7,0
  180| 0018A4 fmul     FD690172   1     MFL       fp11=fp9,fp5,fcr
  182| 0018A8 fmadd    FFA9617A   2     FMA       fp29=fp12,fp9,fp5,fcr
  182| 0018AC fnmsub   FD29F17C   2     FNMS      fp9=fp30,fp9,fp5,fcr
  186| 0018B0 fmr      FFC06090   2     LRFL      fp30=fp12
  181| 0018B4 qvfcpsgn 116B0810   1     CPYSFL    fp11=fp1,fp11
  182| 0018B8 fsub     FD815828   1     SFL       fp12=fp1,fp11,fcr
  182| 0018BC fnmsub   FFBDFB7C   2     FNMS      fp29=fp31,fp29,fp13,fcr
  182| 0018C0 fadd     FD6B082A   2     AFL       fp11=fp11,fp1,fcr
  182| 0018C4 fmadd    FD29313A   2     FMA       fp9=fp6,fp9,fp4,fcr
  186| 0018C8 fmr      FCC0F890   2     LRFL      fp6=fp31
  186| 0018CC fmr      FC806890   2     LRFL      fp4=fp13
  182| 0018D0 fmul     FD8C0772   2     MFL       fp12=fp12,fp29,fcr
  182| 0018D4 fmadd    FD2B627A   2     FMA       fp9=fp12,fp11,fp9,fcr
  186| 0018D8 fmul     FD2A0272   2     MFL       fp9=fp10,fp9,fcr
  186| 0018DC fmul     FD290232   2     MFL       fp9=fp9,fp8,fcr
  186| 0018E0 fmul     FD2901F2   2     MFL       fp9=fp9,fp7,fcr
  186| 0018E4 stfdu    DD380008   2     STFDU     gr24,sflx[](gr24,8)=fp9
    0| 0018E8 bc       418A0270   1     BT        CL.75,cr2,0x4/eq,taken=20%(20,80)
    0|                              CL.570:
  180| 0018EC lfdux    7DBA1CEE   1     LFDU      fp13,gr26=v3(gr26,gr3,0)
  180| 0018F0 lfdux    7FFB1CEE   1     LFDU      fp31,gr27=v3(gr27,gr3,0)
  180| 0018F4 lfd      CB550008   1     LFL       fp26=vg3(gr21,8)
  180| 0018F8 lfdu     CD350010   1     LFDU      fp9,gr21=vg3(gr21,16)
  177| 0018FC lfd      C9530008   1     LFL       fp10=dx3a(gr19,8)
  186| 001900 lfdux    7D7624EE   1     LFDU      fp11,gr22=mflx[](gr22,gr4,0)
  186| 001904 lfdux    7D9724EE   1     LFDU      fp12,gr23=mflx[](gr23,gr4,0)
  180| 001908 lfdux    7FBA1CEE   1     LFDU      fp29,gr26=v3(gr26,gr3,0)
  180| 00190C fadd     FF8DF82A   1     AFL       fp28=fp13,fp31,fcr
  180| 001910 lfdux    7F7B1CEE   1     LFDU      fp27,gr27=v3(gr27,gr3,0)
  177| 001914 lfd      C9B90008   1     LFL       fp13=dq[](gr25,8)
  177| 001918 lfdux    7FF434EE   1     LFDU      fp31,gr20=v2(gr20,gr6,0)
  180| 00191C fmsub    FF9CD078   1     FMS       fp28=fp26,fp28,fp1,fcr
  180| 001920 fadd     FF3DD82A   2     AFL       fp25=fp29,fp27,fcr
  182| 001924 fnmsub   FF5CF17C   2     FNMS      fp26=fp30,fp28,fp5,fcr
    0| 001928 bc       424001A4   1     BCF       ctr=CL.599,taken=0%(0,100)
  180| 00192C fmsub    FF394878   1     FMS       fp25=fp9,fp25,fp1,fcr
  177| 001930 lfdu     CFD30010   2     LFDU      fp30,gr19=dx3a(gr19,16)
  180| 001934 fmul     FF1C0172   1     MFL       fp24=fp28,fp5,fcr
  186| 001938 lfdux    7FB624EE   1     LFDU      fp29,gr22=mflx[](gr22,gr4,0)
  182| 00193C fmadd    FEFC517A   1     FMA       fp23=fp10,fp28,fp5,fcr
  180| 001940 lfdux    7F9A1CEE   1     LFDU      fp28,gr26=v3(gr26,gr3,0)
  180| 001944 fmul     FD390172   1     MFL       fp9=fp25,fp5,fcr
  180| 001948 lfdux    7F7B1CEE   1     LFDU      fp27,gr27=v3(gr27,gr3,0)
  182| 00194C fmadd    FF5A313A   1     FMA       fp26=fp6,fp26,fp4,fcr
  181| 001950 qvfcpsgn 13180810   1     CPYSFL    fp24=fp1,fp24
  182| 001954 fmadd    FED9F17A   1     FMA       fp22=fp30,fp25,fp5,fcr
  177| 001958 lfdu     CC990010   1     LFDU      fp4,gr25=dq[](gr25,16)
  182| 00195C fnmsub   FE57FB7C   1     FNMS      fp18=fp31,fp23,fp13,fcr
  177| 001960 lfdux    7CD434EE   1     LFDU      fp6,gr20=v2(gr20,gr6,0)
  182| 001964 fsub     FE01C028   1     SFL       fp16=fp1,fp24,fcr
  181| 001968 qvfcpsgn 11290810   1     CPYSFL    fp9=fp1,fp9
  182| 00196C fnmsub   FE39517C   1     FNMS      fp17=fp10,fp25,fp5,fcr
  186| 001970 lfdux    7F3724EE   1     LFDU      fp25,gr23=mflx[](gr23,gr4,0)
  182| 001974 fadd     FF18082A   1     AFL       fp24=fp24,fp1,fcr
  180| 001978 lfd      CAF50008   1     LFL       fp23=vg3(gr21,8)
  182| 00197C fnmsub   FED6313C   1     FNMS      fp22=fp6,fp22,fp4,fcr
  180| 001980 lfdux    7EBA1CEE   1     LFDU      fp21,gr26=v3(gr26,gr3,0)
  182| 001984 fsub     FE814828   1     SFL       fp20=fp1,fp9,fcr
  180| 001988 lfdux    7E7B1CEE   1     LFDU      fp19,gr27=v3(gr27,gr3,0)
  182| 00198C fmul     FE5004B2   1     MFL       fp18=fp16,fp18,fcr
  177| 001990 lfd      C9530008   2     LFL       fp10=dx3a(gr19,8)
  182| 001994 fmadd    FDF1FB7A   1     FMA       fp15=fp31,fp17,fp13,fcr
  177| 001998 lfd      C9B90008   1     LFL       fp13=dq[](gr25,8)
  182| 00199C fadd     FE29082A   1     AFL       fp17=fp9,fp1,fcr
  180| 0019A0 lfdu     CD350010   1     LFDU      fp9,gr21=vg3(gr21,16)
  186| 0019A4 fadd     FE0B602A   1     AFL       fp16=fp11,fp12,fcr
  186| 0019A8 lfdux    7D7624EE   1     LFDU      fp11,gr22=mflx[](gr22,gr4,0)
  182| 0019AC fmul     FED405B2   1     MFL       fp22=fp20,fp22,fcr
  186| 0019B0 lfdux    7D9724EE   1     LFDU      fp12,gr23=mflx[](gr23,gr4,0)
  182| 0019B4 fmadd    FF5896BA   1     FMA       fp26=fp18,fp24,fp26,fcr
  177| 0019B8 lfdux    7FF434EE   1     LFDU      fp31,gr20=v2(gr20,gr6,0)
  180| 0019BC fadd     FF9CD82A   1     AFL       fp28=fp28,fp27,fcr
  186| 0019C0 fadd     FFBDC82A   2     AFL       fp29=fp29,fp25,fcr
  182| 0019C4 fmadd    FF71B3FA   2     FMA       fp27=fp22,fp17,fp15,fcr
  180| 0019C8 fadd     FF35982A   2     AFL       fp25=fp21,fp19,fcr
  186| 0019CC fmul     FF5006B2   2     MFL       fp26=fp16,fp26,fcr
  180| 0019D0 fmsub    FF9CB878   2     FMS       fp28=fp23,fp28,fp1,fcr
  186| 0019D4 fmul     FFBD06F2   2     MFL       fp29=fp29,fp27,fcr
  186| 0019D8 fmul     FF7A0232   2     MFL       fp27=fp26,fp8,fcr
  182| 0019DC fnmsub   FF5CF17C   2     FNMS      fp26=fp30,fp28,fp5,fcr
  186| 0019E0 fmul     FF1D0232   2     MFL       fp24=fp29,fp8,fcr
  186| 0019E4 fmul     FFDB01F2   2     MFL       fp30=fp27,fp7,fcr
    0| 0019E8 bc       424000D8   1     BCF       ctr=CL.600,taken=0%(0,100)
    0| 0019EC ori      60210000   1     XNOP      
    0| 0019F0 ori      60210000   1     XNOP      
    0|                              CL.601:
  180| 0019F4 lfd      CBB50008   1     LFL       fp29=vg3(gr21,8)
  186| 0019F8 lfdux    7F7624EE   1     LFDU      fp27,gr22=mflx[](gr22,gr4,0)
  180| 0019FC fmsub    FD394878   1     FMS       fp9=fp9,fp25,fp1,fcr
  180| 001A00 fmul     FF3C0172   2     MFL       fp25=fp28,fp5,fcr
  186| 001A04 fmul     FF1801F2   2     MFL       fp24=fp24,fp7,fcr
  177| 001A08 lfdu     CEF30010   2     LFDU      fp23,gr19=dx3a(gr19,16)
  180| 001A0C lfdux    7EDA1CEE   1     LFDU      fp22,gr26=v3(gr26,gr3,0)
  182| 001A10 fmadd    FEBC517A   1     FMA       fp21=fp10,fp28,fp5,fcr
  182| 001A14 fnmsub   FD49517C   2     FNMS      fp10=fp10,fp9,fp5,fcr
  182| 001A18 fmadd    FF5A313A   2     FMA       fp26=fp6,fp26,fp4,fcr
  177| 001A1C lfdu     CC990010   1     LFDU      fp4,gr25=dq[](gr25,16)
  177| 001A20 lfdux    7CD434EE   1     LFDU      fp6,gr20=v2(gr20,gr6,0)
  182| 001A24 fmadd    FF89B97A   1     FMA       fp28=fp23,fp9,fp5,fcr
  182| 001A28 fnmsub   FEB5FB7C   2     FNMS      fp21=fp31,fp21,fp13,fcr
  180| 001A2C lfdux    7E9B1CEE   1     LFDU      fp20,gr27=v3(gr27,gr3,0)
  180| 001A30 fmul     FD290172   1     MFL       fp9=fp9,fp5,fcr
  181| 001A34 qvfcpsgn 13390810   1     CPYSFL    fp25=fp1,fp25
  182| 001A38 fsub     FE61C828   1     SFL       fp19=fp1,fp25,fcr
  182| 001A3C fnmsub   FE5C313C   2     FNMS      fp18=fp6,fp28,fp4,fcr
  182| 001A40 fmadd    FD4AFB7A   2     FMA       fp10=fp31,fp10,fp13,fcr
  182| 001A44 fadd     FDB9082A   2     AFL       fp13=fp25,fp1,fcr
  180| 001A48 fadd     FFF6A02A   2     AFL       fp31=fp22,fp20,fcr
  181| 001A4C qvfcpsgn 11290810   1     CPYSFL    fp9=fp1,fp9
  182| 001A50 fsub     FF214828   1     SFL       fp25=fp1,fp9,fcr
  182| 001A54 fadd     FD29082A   2     AFL       fp9=fp9,fp1,fcr
  182| 001A58 fmul     FEB30572   2     MFL       fp21=fp19,fp21,fcr
  186| 001A5C lfdux    7ED724EE   1     LFDU      fp22,gr23=mflx[](gr23,gr4,0)
  180| 001A60 fmsub    FF9FE878   1     FMS       fp28=fp29,fp31,fp1,fcr
  186| 001A64 fadd     FD8B602A   2     AFL       fp12=fp11,fp12,fcr
  182| 001A68 fmul     FD7904B2   2     MFL       fp11=fp25,fp18,fcr
  186| 001A6C stfdu    DF180010   2     STFDU     gr24,sflx[](gr24,16)=fp24
  182| 001A70 fmadd    FDADAEBA   1     FMA       fp13=fp21,fp13,fp26,fcr
  186| 001A74 stfd     DBD8FFF8   1     STFL      sflx[](gr24,-8)=fp30
  182| 001A78 fnmsub   FF5CB97C   1     FNMS      fp26=fp23,fp28,fp5,fcr
  186| 001A7C fadd     FFFBB02A   2     AFL       fp31=fp27,fp22,fcr
  182| 001A80 fmadd    FD295ABA   2     FMA       fp9=fp11,fp9,fp10,fcr
  186| 001A84 lfdux    7D7624EE   1     LFDU      fp11,gr22=mflx[](gr22,gr4,0)
  186| 001A88 fmul     FD4C0372   1     MFL       fp10=fp12,fp13,fcr
  180| 001A8C lfdux    7FBA1CEE   1     LFDU      fp29,gr26=v3(gr26,gr3,0)
  180| 001A90 lfdux    7F7B1CEE   1     LFDU      fp27,gr27=v3(gr27,gr3,0)
  186| 001A94 lfdux    7D9724EE   1     LFDU      fp12,gr23=mflx[](gr23,gr4,0)
  186| 001A98 fmul     FFFF0272   1     MFL       fp31=fp31,fp9,fcr
  177| 001A9C lfd      C9B90008   1     LFL       fp13=dq[](gr25,8)
  186| 001AA0 fmul     FFCA0232   1     MFL       fp30=fp10,fp8,fcr
  177| 001AA4 lfd      C9530008   2     LFL       fp10=dx3a(gr19,8)
  180| 001AA8 lfdu     CD350010   1     LFDU      fp9,gr21=vg3(gr21,16)
  180| 001AAC fadd     FF3DD82A   1     AFL       fp25=fp29,fp27,fcr
  186| 001AB0 fmul     FF1F0232   2     MFL       fp24=fp31,fp8,fcr
  177| 001AB4 lfdux    7FF434EE   1     LFDU      fp31,gr20=v2(gr20,gr6,0)
  186| 001AB8 fmul     FFDE01F2   1     MFL       fp30=fp30,fp7,fcr
    0| 001ABC bc       4200FF38   1     BCT       ctr=CL.601,taken=100%(100,0)
    0|                              CL.600:
  186| 001AC0 stfd     DBD80008   1     STFL      sflx[](gr24,8)=fp30
  186| 001AC4 fmul     FFD801F2   1     MFL       fp30=fp24,fp7,fcr
  186| 001AC8 stfdu    DFD80010   2     STFDU     gr24,sflx[](gr24,16)=fp30
    0|                              CL.599:
  180| 001ACC fmsub    FD394878   1     FMS       fp9=fp9,fp25,fp1,fcr
  177| 001AD0 lfdu     CFD30010   2     LFDU      fp30,gr19=dx3a(gr19,16)
  180| 001AD4 fmul     FFBC0172   1     MFL       fp29=fp28,fp5,fcr
  177| 001AD8 lfdu     CF790010   1     LFDU      fp27,gr25=dq[](gr25,16)
  182| 001ADC fmadd    FF9C517A   1     FMA       fp28=fp10,fp28,fp5,fcr
  177| 001AE0 lfdux    7F3434EE   1     LFDU      fp25,gr20=v2(gr20,gr6,0)
  180| 001AE4 fmul     FF090172   1     MFL       fp24=fp9,fp5,fcr
  186| 001AE8 lfdux    7EF624EE   1     LFDU      fp23,gr22=mflx[](gr22,gr4,0)
  182| 001AEC fmadd    FFC9F17A   1     FMA       fp30=fp30,fp9,fp5,fcr
  181| 001AF0 qvfcpsgn 13BD0810   1     CPYSFL    fp29=fp1,fp29
  182| 001AF4 fnmsub   FCA9517C   1     FNMS      fp5=fp10,fp9,fp5,fcr
  186| 001AF8 lfdux    7D3724EE   1     LFDU      fp9,gr23=mflx[](gr23,gr4,0)
  182| 001AFC fnmsub   FD5CFB7C   1     FNMS      fp10=fp31,fp28,fp13,fcr
  181| 001B00 qvfcpsgn 13980810   1     CPYSFL    fp28=fp1,fp24
  182| 001B04 fnmsub   FFDECEFC   1     FNMS      fp30=fp25,fp30,fp27,fcr
  182| 001B08 fsub     FF61E028   2     SFL       fp27=fp1,fp28,fcr
  182| 001B0C fsub     FF21E828   2     SFL       fp25=fp1,fp29,fcr
  182| 001B10 fmadd    FCA5FB7A   2     FMA       fp5=fp31,fp5,fp13,fcr
  182| 001B14 fadd     FDBC082A   2     AFL       fp13=fp28,fp1,fcr
  182| 001B18 fmadd    FC9A313A   2     FMA       fp4=fp6,fp26,fp4,fcr
  182| 001B1C fadd     FCDD082A   2     AFL       fp6=fp29,fp1,fcr
  182| 001B20 fmul     FFFB07B2   2     MFL       fp31=fp27,fp30,fcr
  182| 001B24 fmul     FD5902B2   2     MFL       fp10=fp25,fp10,fcr
  186| 001B28 fadd     FD37482A   2     AFL       fp9=fp23,fp9,fcr
  186| 001B2C fadd     FD6B602A   2     AFL       fp11=fp11,fp12,fcr
  182| 001B30 fmadd    FCADF97A   2     FMA       fp5=fp31,fp13,fp5,fcr
  182| 001B34 fmadd    FC86513A   2     FMA       fp4=fp10,fp6,fp4,fcr
  186| 001B38 fmul     FCA90172   2     MFL       fp5=fp9,fp5,fcr
  186| 001B3C fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  186| 001B40 fmul     FCA50232   2     MFL       fp5=fp5,fp8,fcr
  186| 001B44 fmul     FC840232   2     MFL       fp4=fp4,fp8,fcr
  186| 001B48 fmul     FCA501F2   2     MFL       fp5=fp5,fp7,fcr
  186| 001B4C fmul     FC8401F2   2     MFL       fp4=fp4,fp7,fcr
  186| 001B50 stfdu    DCB80010   2     STFDU     gr24,sflx[](gr24,16)=fp5
  186| 001B54 stfd     D898FFF8   1     STFL      sflx[](gr24,-8)=fp4
  188|                              CL.75:
  190| 001B58 ld       E8E10118   1     L8        gr7=#SPILL59(gr1,280)
  190| 001B5C cmpdi    2D270000   1     C8        cr2=gr7,0
  190| 001B60 bc       40890120   1     BF        CL.77,cr2,0x2/gt,taken=50%(0,0)
    0| 001B64 bc       41860D20   1     BT        CL.196,cr1,0x4/eq,taken=50%(0,0)
    0| 001B68 ld       EAE101C0   1     L8        gr23=#SPILL63(gr1,448)
    0| 001B6C ld       EB2101C8   1     L8        gr25=#SPILL67(gr1,456)
    0| 001B70 or       7DDB7378   1     LR        gr27=gr14
  192| 001B74 ld       EB0101D8   1     L8        gr24=#SPILL75(gr1,472)
    0| 001B78 add      7F52BA14   1     A         gr26=gr18,gr23
    0| 001B7C bc       419E002C   1     BT        CL.386,cr7,0x4/eq,taken=50%(0,0)
    0| 001B80 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 001B84 lfdu     CCB90008   1     LFDU      fp5,gr25=dvl3a(gr25,8)
    0| 001B88 lfd      C8DA0000   1     LFL       fp6=sflx[](gr26,0)
    0| 001B8C lfdu     CCFA0008   1     LFDU      fp7,gr26=sflx[](gr26,8)
  192| 001B90 lfdu     CD180008   1     LFDU      fp8,gr24=dvl3ani(gr24,8)
    0| 001B94 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
    0| 001B98 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  192| 001B9C fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  192| 001BA0 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 001BA4 bc       419600DC   1     BT        CL.77,cr5,0x4/eq,taken=50%(0,0)
    0|                              CL.386:
    0| 001BA8 mtspr    7DE903A6   1     LCTR      ctr=gr15
    0| 001BAC bc       418E004C   1     BT        CL.572,cr3,0x4/eq,taken=50%(0,0)
    0| 001BB0 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 001BB4 lfd      C8B90008   1     LFL       fp5=dvl3a(gr25,8)
    0| 001BB8 lfd      C8DA0008   1     LFL       fp6=sflx[](gr26,8)
    0| 001BBC lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
  192| 001BC0 lfd      C9180008   1     LFL       fp8=dvl3ani(gr24,8)
    0| 001BC4 lfdu     CD390010   1     LFDU      fp9,gr25=dvl3a(gr25,16)
    0| 001BC8 lfdu     CD5A0010   1     LFDU      fp10,gr26=sflx[](gr26,16)
  192| 001BCC lfdu     CD780010   1     LFDU      fp11,gr24=dvl3ani(gr24,16)
    0| 001BD0 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
    0| 001BD4 fadd     FC87202A   2     AFL       fp4=fp7,fp4,fcr
  192| 001BD8 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  192| 001BDC stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 001BE0 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 001BE4 fmsub    FC845278   1     FMS       fp4=fp10,fp4,fp9,fcr
    0| 001BE8 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  192| 001BEC fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  192| 001BF0 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 001BF4 bc       4192008C   1     BT        CL.77,cr4,0x4/eq,taken=20%(20,80)
    0|                              CL.572:
    0| 001BF8 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s2[](gr27,gr4,0)
    0| 001BFC lfd      C8D90008   1     LFL       fp6=dvl3a(gr25,8)
    0| 001C00 lfd      C89A0008   1     LFL       fp4=sflx[](gr26,8)
    0| 001C04 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
    0| 001C08 fmsub    FCA521B8   1     FMS       fp5=fp4-fp6,fcr
  192| 001C0C lfd      C8D80008   1     LFL       fp6=dvl3ani(gr24,8)
    0| 001C10 fadd     FCA7282A   1     AFL       fp5=fp7,fp5,fcr
  192| 001C14 fmul     FCA60172   2     MFL       fp5=fp6,fp5,fcr
    0| 001C18 lfd      C8D90010   1     LFL       fp6=dvl3a(gr25,16)
    0| 001C1C lfd      C8FA0010   1     LFL       fp7=sflx[](gr26,16)
  192| 001C20 stfd     D8BB0000   1     STFL      s2[](gr27,0)=fp5
    0| 001C24 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s2[](gr27,gr4,0)
    0| 001C28 fmsub    FCA539B8   1     FMS       fp5=fp7,fp5,fp6,fcr
  192| 001C2C lfd      C8D80010   1     LFL       fp6=dvl3ani(gr24,16)
    0| 001C30 fadd     FC84282A   1     AFL       fp4=fp4,fp5,fcr
  192| 001C34 fmul     FC860132   2     MFL       fp4=fp6,fp4,fcr
    0| 001C38 lfd      C8B90018   1     LFL       fp5=dvl3a(gr25,24)
    0| 001C3C lfd      C8DA0018   1     LFL       fp6=sflx[](gr26,24)
  192| 001C40 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 001C44 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 001C48 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
  192| 001C4C lfd      C8B80018   1     LFL       fp5=dvl3ani(gr24,24)
    0| 001C50 fadd     FC87202A   1     AFL       fp4=fp7,fp4,fcr
  192| 001C54 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
    0| 001C58 lfdu     CCB90020   1     LFDU      fp5,gr25=dvl3a(gr25,32)
    0| 001C5C lfdu     CCFA0020   1     LFDU      fp7,gr26=sflx[](gr26,32)
  192| 001C60 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 001C64 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 001C68 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
  192| 001C6C lfdu     CCB80020   1     LFDU      fp5,gr24=dvl3ani(gr24,32)
    0| 001C70 fadd     FC86202A   1     AFL       fp4=fp6,fp4,fcr
  192| 001C74 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
  192| 001C78 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 001C7C bc       4200FF7C   1     BCT       ctr=CL.572,taken=100%(100,0)
  198|                              CL.77:
  209| 001C80 bc       409903B0   1     BF        CL.79,cr6,0x2/gt,taken=50%(0,0)
  209| 001C84 ld       EB2101B8   1     L8        gr25=#SPILL76(gr1,440)
  209| 001C88 ld       E8E100F0   1     L8        gr7=#SPILL88(gr1,240)
  212| 001C8C ld       EB0101A0   1     L8        gr24=#SPILL69(gr1,416)
    0| 001C90 cmpdi    2D300000   1     C8        cr2=gr16,0
  209| 001C94 lfd      C8DC0000   1     LFL       fp6=v3(gr28,0)
  209| 001C98 or       7F9AE378   1     LR        gr26=gr28
  209| 001C9C lfd      C9790000   1     LFL       fp11=dx3ai(gr25,0)
  209| 001CA0 lfd      C8870000   1     LFL       fp4=v3(gr7,0)
  212| 001CA4 add      7F69C214   1     A         gr27=gr9,gr24
    0| 001CA8 bc       418A0080   1     BT        CL.422,cr2,0x4/eq,taken=50%(0,0)
    0| 001CAC mtspr    7E0903A6   1     LCTR      ctr=gr16
  209|                              CL.421:
  209| 001CB0 lfdux    7CBA1CEE   1     LFDU      fp5,gr26=v3(gr26,gr3,0)
  210| 001CB4 fsub     FCE62028   1     SFL       fp7=fp6,fp4,fcr
  209| 001CB8 lfdu     CD190008   1     LFDU      fp8,gr25=dx3ai(gr25,8)
  212| 001CBC fmr      FC803090   1     LRFL      fp4=fp6
  211| 001CC0 fsub     FD253028   2     SFL       fp9=fp5,fp6,fcr
  212| 001CC4 fmr      FCC02890   2     LRFL      fp6=fp5
  210| 001CC8 fmul     FD4702F2   2     MFL       fp10=fp7,fp11,fcr
  211| 001CCC fmul     FCA90232   2     MFL       fp5=fp9,fp8,fcr
  211| 001CD0 fmadd    FCE72AFA   2     FMA       fp7=fp5,fp7,fp11,fcr
  212| 001CD4 fmul     FCAA0172   2     MFL       fp5=fp10,fp5,fcr
  212| 001CD8 fmr      FD604090   2     LRFL      fp11=fp8
  211| 001CDC qvfcpsgn 11071010   1     CPYSFL    fp8=fp2,fp7
  212| 001CE0 fabs     FCE03A10   1     ABSFL     fp7=fp7
  212| 001CE4 fneg     FD202850   2     COMPFL    fp9=fp5
  212| 001CE8 fsub     FD4E3828   2     SFL       fp10=fp14,fp7,fcr
  212| 001CEC fsel     FCA928EE   2     FSEL      fp5=fp9,fp5,fp3
  212| 001CF0 fsel     FCEA3BAE   2     FSEL      fp7=fp10,fp7,fp14
  212| 001CF4 fmul     FD250232   2     MFL       fp9=fp5,fp8,fcr
  212| 001CF8 qvfre    10A03830   1     QVFRE     fp5=fp7
  212| 001CFC fmsub    FD071178   1     FMS       fp8=fp2,fp7,fp5,fcr
  212| 001D00 fnmsub   FCA52A3C   2     FNMS      fp5=fp5,fp5,fp8,fcr
  212| 001D04 fmsub    FD071178   2     FMS       fp8=fp2,fp7,fp5,fcr
  212| 001D08 fnmsub   FCA52A3C   2     FNMS      fp5=fp5,fp5,fp8,fcr
  212| 001D0C fmul     FD090172   2     MFL       fp8=fp9,fp5,fcr
  212| 001D10 fmsub    FCE74A38   2     FMS       fp7=fp9,fp7,fp8,fcr
  212| 001D14 fnmsub   FCA541FC   2     FNMS      fp5=fp8,fp5,fp7,fcr
  212| 001D18 stfdu    DCBB0008   2     STFDU     gr27,dq[](gr27,8)=fp5
  215| 001D1C bc       4200FF94   1     BCT       ctr=CL.421,taken=100%(100,0)
    0| 001D20 cmpdi    2D310000   1     C8        cr2=gr17,0
    0| 001D24 bc       418A030C   1     BT        CL.79,cr2,0x4/eq,taken=20%(20,80)
    0|                              CL.422:
  209| 001D28 lfdux    7D3A1CEE   1     LFDU      fp9,gr26=v3(gr26,gr3,0)
  210| 001D2C fsub     FF862028   1     SFL       fp28=fp6,fp4,fcr
  209| 001D30 lfd      CBF90008   1     LFL       fp31=dx3ai(gr25,8)
  209| 001D34 lfd      C9590010   1     LFL       fp10=dx3ai(gr25,16)
  209| 001D38 lfd      C9990018   1     LFL       fp12=dx3ai(gr25,24)
  209| 001D3C lfdu     CC990020   1     LFDU      fp4,gr25=dx3ai(gr25,32)
    0| 001D40 mtspr    7E2903A6   1     LCTR      ctr=gr17
  211| 001D44 fsub     FCA93028   1     SFL       fp5=fp9,fp6,fcr
  209| 001D48 lfdux    7DBA1CEE   1     LFDU      fp13,gr26=v3(gr26,gr3,0)
  210| 001D4C fmul     FCDC02F2   1     MFL       fp6=fp28,fp11,fcr
  210| 001D50 fmr      FFC02890   2     LRFL      fp30=fp5
  211| 001D54 fmul     FCE507F2   2     MFL       fp7=fp5,fp31,fcr
  209| 001D58 lfdux    7CBA1CEE   1     LFDU      fp5,gr26=v3(gr26,gr3,0)
  211| 001D5C fsub     FD0D4828   1     SFL       fp8=fp13,fp9,fcr
  210| 001D60 fmul     FD3E07F2   2     MFL       fp9=fp30,fp31,fcr
  211| 001D64 fmadd    FD7C3AFA   2     FMA       fp11=fp7,fp28,fp11,fcr
  212| 001D68 fmul     FCC601F2   2     MFL       fp6=fp6,fp7,fcr
  209| 001D6C lfdux    7CFA1CEE   1     LFDU      fp7,gr26=v3(gr26,gr3,0)
  211| 001D70 fsub     FF856828   1     SFL       fp28=fp5,fp13,fcr
  211| 001D74 fmul     FF0802B2   2     MFL       fp24=fp8,fp10,fcr
  210| 001D78 fmr      FFA04090   2     LRFL      fp29=fp8
  211| 001D7C qvfcpsgn 110B1010   1     CPYSFL    fp8=fp2,fp11
  212| 001D80 fabs     FD605A10   1     ABSFL     fp11=fp11
  210| 001D84 fmul     FDBD02B2   2     MFL       fp13=fp29,fp10,fcr
  211| 001D88 fsub     FF272828   2     SFL       fp25=fp7,fp5,fcr
  211| 001D8C fmul     FF5C0332   2     MFL       fp26=fp28,fp12,fcr
  211| 001D90 fmadd    FFFEC7FA   2     FMA       fp31=fp24,fp30,fp31,fcr
  212| 001D94 fsub     FFCE5828   2     SFL       fp30=fp14,fp11,fcr
  210| 001D98 fmr      FF60E090   2     LRFL      fp27=fp28
  212| 001D9C fmul     FD290632   2     MFL       fp9=fp9,fp24,fcr
  211| 001DA0 fmul     FF390132   2     MFL       fp25=fp25,fp4,fcr
  211| 001DA4 fmadd    FFBDD2BA   2     FMA       fp29=fp26,fp29,fp10,fcr
  211| 001DA8 qvfcpsgn 115F1010   1     CPYSFL    fp10=fp2,fp31
  212| 001DAC fabs     FFE0FA10   1     ABSFL     fp31=fp31
  212| 001DB0 fsel     FD7E5BAE   2     FSEL      fp11=fp30,fp11,fp14
  212| 001DB4 fsub     FFCEF828   2     SFL       fp30=fp14,fp31,fcr
  211| 001DB8 fmadd    FF7BCB3A   2     FMA       fp27=fp25,fp27,fp12,fcr
  211| 001DBC qvfcpsgn 119D1010   1     CPYSFL    fp12=fp2,fp29
  212| 001DC0 fabs     FFA0EA10   1     ABSFL     fp29=fp29
  210| 001DC4 fmr      FF80D090   2     LRFL      fp28=fp26
  212| 001DC8 fmul     FDAD06B2   2     MFL       fp13=fp13,fp26,fcr
  212| 001DCC fsel     FFFEFBAE   2     FSEL      fp31=fp30,fp31,fp14
  211| 001DD0 qvfcpsgn 13DB1010   1     CPYSFL    fp30=fp2,fp27
  212| 001DD4 fabs     FF60DA10   1     ABSFL     fp27=fp27
  212| 001DD8 fsub     FEEEE828   2     SFL       fp23=fp14,fp29,fcr
  212| 001DDC qvfre    13005830   1     QVFRE     fp24=fp11
  212| 001DE0 fsub     FF4ED828   1     SFL       fp26=fp14,fp27,fcr
  212| 001DE4 qvfre    12A0F830   1     QVFRE     fp21=fp31
  212| 001DE8 fmul     FE7C0672   1     MFL       fp19=fp28,fp25,fcr
  212| 001DEC fneg     FF806850   2     COMPFL    fp28=fp13
  212| 001DF0 fsel     FFB7EBAE   2     FSEL      fp29=fp23,fp29,fp14
  212| 001DF4 fmsub    FEEB1638   2     FMS       fp23=fp2,fp11,fp24,fcr
  212| 001DF8 fsel     FF7ADBAE   2     FSEL      fp27=fp26,fp27,fp14
  212| 001DFC fmsub    FE9F1578   2     FMS       fp20=fp2,fp31,fp21,fcr
  212| 001E00 fsel     FDBC68EE   2     FSEL      fp13=fp28,fp13,fp3
  212| 001E04 fneg     FE409850   2     COMPFL    fp18=fp19
  212| 001E08 qvfre    1340E830   1     QVFRE     fp26=fp29
  212| 001E0C fnmsub   FF18C5FC   1     FNMS      fp24=fp24,fp24,fp23,fcr
  212| 001E10 qvfre    12E0D830   1     QVFRE     fp23=fp27
  212| 001E14 fnmsub   FEB5AD3C   1     FNMS      fp21=fp21,fp21,fp20,fcr
  212| 001E18 fneg     FF204850   2     COMPFL    fp25=fp9
  212| 001E1C fneg     FE803050   2     COMPFL    fp20=fp6
  212| 001E20 fmsub    FEDD16B8   2     FMS       fp22=fp2,fp29,fp26,fcr
  212| 001E24 fsel     FE7298EE   2     FSEL      fp19=fp18,fp19,fp3
  212| 001E28 fmsub    FE3B15F8   2     FMS       fp17=fp2,fp27,fp23,fcr
  212| 001E2C fmsub    FE4B1638   2     FMS       fp18=fp2,fp11,fp24,fcr
  212| 001E30 fsel     FD3948EE   2     FSEL      fp9=fp25,fp9,fp3
  212| 001E34 fsel     FF9430EE   2     FSEL      fp28=fp20,fp6,fp3
  212| 001E38 fnmsub   FF5AD5BC   2     FNMS      fp26=fp26,fp26,fp22,fcr
  212| 001E3C fmsub    FEDF1578   2     FMS       fp22=fp2,fp31,fp21,fcr
  212| 001E40 fnmsub   FEF7BC7C   2     FNMS      fp23=fp23,fp23,fp17,fcr
  212| 001E44 fmul     FD8D0332   2     MFL       fp12=fp13,fp12,fcr
  212| 001E48 fnmsub   FF38C4BC   2     FNMS      fp25=fp24,fp24,fp18,fcr
  212| 001E4C fmul     FF1307B2   2     MFL       fp24=fp19,fp30,fcr
  212| 001E50 fmsub    FE9D16B8   2     FMS       fp20=fp2,fp29,fp26,fcr
  212| 001E54 fnmsub   FCD5ADBC   2     FNMS      fp6=fp21,fp21,fp22,fcr
  212| 001E58 fmsub    FDBB15F8   2     FMS       fp13=fp2,fp27,fp23,fcr
  212| 001E5C fmul     FD2902B2   2     MFL       fp9=fp9,fp10,fcr
  212| 001E60 fmul     FF9C0232   2     MFL       fp28=fp28,fp8,fcr
  212| 001E64 fnmsub   FEDAD53C   2     FNMS      fp22=fp26,fp26,fp20,fcr
  212| 001E68 fnmsub   FF57BB7C   2     FNMS      fp26=fp23,fp23,fp13,fcr
    0| 001E6C bc       42400184   1     BCF       ctr=CL.604,taken=0%(0,100)
    0| 001E70 fmr      FDE07090   1     LRFL      fp15=fp14
    0|                              CL.605:
  212| 001E74 fmul     FEF806B2   1     MFL       fp23=fp24,fp26,fcr
  212| 001E78 fmul     FEAC05B2   2     MFL       fp21=fp12,fp22,fcr
  212| 001E7C fmul     FE8901B2   2     MFL       fp20=fp9,fp6,fcr
  209| 001E80 lfdux    7D1A1CEE   1     LFDU      fp8,gr26=v3(gr26,gr3,0)
  212| 001E84 fmul     FDBC0672   1     MFL       fp13=fp28,fp25,fcr
  209| 001E88 lfd      C9590010   1     LFL       fp10=dx3ai(gr25,16)
  212| 001E8C fmsub    FF7BC5F8   1     FMS       fp27=fp24,fp27,fp23,fcr
  212| 001E90 fmsub    FFBD6578   2     FMS       fp29=fp12,fp29,fp21,fcr
  212| 001E94 fmsub    FFFF4D38   2     FMS       fp31=fp9,fp31,fp20,fcr
  209| 001E98 lfd      C9990018   1     LFL       fp12=dx3ai(gr25,24)
  209| 001E9C lfdux    7D3A1CEE   1     LFDU      fp9,gr26=v3(gr26,gr3,0)
  212| 001EA0 fmsub    FD6BE378   1     FMS       fp11=fp28,fp11,fp13,fcr
  212| 001EA4 fnmsub   FF9ABEFC   2     FNMS      fp28=fp23,fp26,fp27,fcr
  212| 001EA8 fnmsub   FF76AF7C   2     FNMS      fp27=fp21,fp22,fp29,fcr
  212| 001EAC fnmsub   FFE6A7FC   2     FNMS      fp31=fp20,fp6,fp31,fcr
  209| 001EB0 lfd      CAB90008   1     LFL       fp21=dx3ai(gr25,8)
  210| 001EB4 fsub     FCC72828   1     SFL       fp6=fp7,fp5,fcr
  209| 001EB8 lfdux    7CBA1CEE   1     LFDU      fp5,gr26=v3(gr26,gr3,0)
  211| 001EBC fsub     FFA83828   1     SFL       fp29=fp8,fp7,fcr
  210| 001EC0 fmr      FE40E890   2     LRFL      fp18=fp29
  212| 001EC4 fnmsub   FD796AFC   2     FNMS      fp11=fp13,fp25,fp11,fcr
  212| 001EC8 stfdu    DF9B0020   2     STFDU     gr27,dq[](gr27,32)=fp28
  210| 001ECC fmul     FF860132   1     MFL       fp28=fp6,fp4,fcr
  211| 001ED0 fsub     FF294028   2     SFL       fp25=fp9,fp8,fcr
  209| 001ED4 lfdux    7CFA1CEE   1     LFDU      fp7,gr26=v3(gr26,gr3,0)
  211| 001ED8 fsub     FDA54828   1     SFL       fp13=fp5,fp9,fcr
  211| 001EDC fmul     FF5D0572   2     MFL       fp26=fp29,fp21,fcr
  212| 001EE0 stfd     DB7BFFF8   1     STFL      dq[](gr27,-8)=fp27
  211| 001EE4 fmul     FE7902B2   1     MFL       fp19=fp25,fp10,fcr
  210| 001EE8 fmr      FF006890   2     LRFL      fp24=fp13
  211| 001EEC fsub     FD272828   2     SFL       fp9=fp7,fp5,fcr
  211| 001EF0 fmadd    FD06D13A   2     FMA       fp8=fp26,fp6,fp4,fcr
  209| 001EF4 lfdu     CC990020   1     LFDU      fp4,gr25=dx3ai(gr25,32)
  211| 001EF8 fmul     FEED0332   1     MFL       fp23=fp13,fp12,fcr
  211| 001EFC fmadd    FCD29D7A   2     FMA       fp6=fp19,fp18,fp21,fcr
  212| 001F00 stfd     DBFBFFF0   1     STFL      dq[](gr27,-16)=fp31
  212| 001F04 stfd     D97BFFE8   1     STFL      dq[](gr27,-24)=fp11
  212| 001F08 fabs     FD604210   1     ABSFL     fp11=fp8
  211| 001F0C qvfcpsgn 11081010   1     CPYSFL    fp8=fp2,fp8
  211| 001F10 fmul     FDA90132   1     MFL       fp13=fp9,fp4,fcr
  211| 001F14 fmadd    FD39BABA   2     FMA       fp9=fp23,fp25,fp10,fcr
  212| 001F18 fabs     FFE03210   2     ABSFL     fp31=fp6
  212| 001F1C fsub     FF6F5828   2     SFL       fp27=fp15,fp11,fcr
  212| 001F20 fsub     FECFF828   2     SFL       fp22=fp15,fp31,fcr
  211| 001F24 fmadd    FD586B3A   2     FMA       fp10=fp13,fp24,fp12,fcr
  212| 001F28 fabs     FFA04A10   2     ABSFL     fp29=fp9
  210| 001F2C fmul     FEB20572   2     MFL       fp21=fp18,fp21,fcr
  212| 001F30 fsub     FF2FE828   2     SFL       fp25=fp15,fp29,fcr
  212| 001F34 fsel     FFF6FBEE   2     FSEL      fp31=fp22,fp31,fp15
  212| 001F38 fsel     FD7B5BEE   2     FSEL      fp11=fp27,fp11,fp15
  212| 001F3C fabs     FF605210   2     ABSFL     fp27=fp10
  210| 001F40 fmul     FE580332   2     MFL       fp18=fp24,fp12,fcr
  212| 001F44 fsub     FECFD828   2     SFL       fp22=fp15,fp27,fcr
  212| 001F48 fsel     FFB9EBEE   2     FSEL      fp29=fp25,fp29,fp15
  212| 001F4C qvfre    1320F830   1     QVFRE     fp25=fp31
  212| 001F50 qvfre    13005830   1     QVFRE     fp24=fp11
  212| 001F54 fmul     FD9305F2   1     MFL       fp12=fp19,fp23,fcr
  212| 001F58 fmul     FDB20372   2     MFL       fp13=fp18,fp13,fcr
  212| 001F5C fsel     FF76DBEE   2     FSEL      fp27=fp22,fp27,fp15
  212| 001F60 qvfre    1280E830   1     QVFRE     fp20=fp29
  212| 001F64 fmsub    FEDF1678   1     FMS       fp22=fp2,fp31,fp25,fcr
  212| 001F68 fmsub    FEEB1638   2     FMS       fp23=fp2,fp11,fp24,fcr
  212| 001F6C fmul     FFD504F2   2     MFL       fp30=fp21,fp19,fcr
  212| 001F70 fmul     FF9C06B2   2     MFL       fp28=fp28,fp26,fcr
  212| 001F74 qvfre    1340D830   1     QVFRE     fp26=fp27
  212| 001F78 fmsub    FE7D1538   1     FMS       fp19=fp2,fp29,fp20,fcr
  212| 001F7C fnmsub   FF39CDBC   2     FNMS      fp25=fp25,fp25,fp22,fcr
  212| 001F80 fnmsub   FF18C5FC   2     FNMS      fp24=fp24,fp24,fp23,fcr
  212| 001F84 fneg     FEE06850   2     COMPFL    fp23=fp13
  212| 001F88 fneg     FEC06050   2     COMPFL    fp22=fp12
  212| 001F8C fmsub    FEBB16B8   2     FMS       fp21=fp2,fp27,fp26,fcr
  212| 001F90 fnmsub   FE94A4FC   2     FNMS      fp20=fp20,fp20,fp19,fcr
  212| 001F94 fneg     FE60F050   2     COMPFL    fp19=fp30
  212| 001F98 fneg     FE40E050   2     COMPFL    fp18=fp28
  212| 001F9C fmsub    FE3F1678   2     FMS       fp17=fp2,fp31,fp25,fcr
  212| 001FA0 fmsub    FE0B1638   2     FMS       fp16=fp2,fp11,fp24,fcr
  212| 001FA4 fnmsub   FF5AD57C   2     FNMS      fp26=fp26,fp26,fp21,fcr
  212| 001FA8 fmsub    FEBD1538   2     FMS       fp21=fp2,fp29,fp20,fcr
  212| 001FAC fsel     FDB768EE   2     FSEL      fp13=fp23,fp13,fp3
  212| 001FB0 fsel     FD9660EE   2     FSEL      fp12=fp22,fp12,fp3
  212| 001FB4 fsel     FFD3F0EE   2     FSEL      fp30=fp19,fp30,fp3
  212| 001FB8 fsel     FF92E0EE   2     FSEL      fp28=fp18,fp28,fp3
  212| 001FBC fmsub    FEFB16B8   2     FMS       fp23=fp2,fp27,fp26,fcr
  211| 001FC0 qvfcpsgn 114A1010   1     CPYSFL    fp10=fp2,fp10
  211| 001FC4 qvfcpsgn 11291010   1     CPYSFL    fp9=fp2,fp9
  211| 001FC8 qvfcpsgn 12661010   1     CPYSFL    fp19=fp2,fp6
  212| 001FCC fnmsub   FED4A57C   1     FNMS      fp22=fp20,fp20,fp21,fcr
  212| 001FD0 fnmsub   FCD9CC7C   2     FNMS      fp6=fp25,fp25,fp17,fcr
  212| 001FD4 fnmsub   FF5AD5FC   2     FNMS      fp26=fp26,fp26,fp23,fcr
  212| 001FD8 fnmsub   FF38C43C   2     FNMS      fp25=fp24,fp24,fp16,fcr
  212| 001FDC fmul     FF0D02B2   2     MFL       fp24=fp13,fp10,fcr
  212| 001FE0 fmul     FD8C0272   2     MFL       fp12=fp12,fp9,fcr
  212| 001FE4 fmul     FD3E04F2   2     MFL       fp9=fp30,fp19,fcr
  212| 001FE8 fmul     FF9C0232   2     MFL       fp28=fp28,fp8,fcr
    0| 001FEC bc       4200FE88   1     BCT       ctr=CL.605,taken=100%(100,0)
    0|                              CL.604:
  212| 001FF0 fmul     FC9806B2   1     MFL       fp4=fp24,fp26,fcr
  212| 001FF4 fmul     FCAC05B2   2     MFL       fp5=fp12,fp22,fcr
  212| 001FF8 fmul     FCE901B2   2     MFL       fp7=fp9,fp6,fcr
  212| 001FFC fmul     FD1C0672   2     MFL       fp8=fp28,fp25,fcr
  212| 002000 fmsub    FD5BC138   2     FMS       fp10=fp24,fp27,fp4,fcr
  212| 002004 fmsub    FD9D6178   2     FMS       fp12=fp12,fp29,fp5,fcr
  212| 002008 fmsub    FD3F49F8   2     FMS       fp9=fp9,fp31,fp7,fcr
  212| 00200C fmsub    FD6BE238   2     FMS       fp11=fp28,fp11,fp8,fcr
  212| 002010 fnmsub   FC9A22BC   2     FNMS      fp4=fp4,fp26,fp10,fcr
  212| 002014 fnmsub   FCB62B3C   2     FNMS      fp5=fp5,fp22,fp12,fcr
  212| 002018 fnmsub   FCC63A7C   2     FNMS      fp6=fp7,fp6,fp9,fcr
  212| 00201C fnmsub   FCF942FC   2     FNMS      fp7=fp8,fp25,fp11,fcr
  212| 002020 stfdu    DC9B0020   2     STFDU     gr27,dq[](gr27,32)=fp4
  212| 002024 stfd     D8BBFFF8   1     STFL      dq[](gr27,-8)=fp5
  212| 002028 stfd     D8DBFFF0   1     STFL      dq[](gr27,-16)=fp6
  212| 00202C stfd     D8FBFFE8   1     STFL      dq[](gr27,-24)=fp7
  215|                              CL.79:
  225| 002030 ld       E8E101B0   1     L8        gr7=#SPILL57(gr1,432)
  225| 002034 cmpdi    2D270000   1     C8        cr2=gr7,0
  225| 002038 bc       408903C8   1     BF        CL.81,cr2,0x2/gt,taken=50%(0,0)
  225| 00203C ld       EAA10130   1     L8        gr21=#SPILL3(gr1,304)
  225| 002040 ld       EA810138   1     L8        gr20=#SPILL32(gr1,312)
  225| 002044 ld       EA610140   1     L8        gr19=#SPILL0(gr1,320)
  225| 002048 ld       EB010148   1     L8        gr24=#SPILL10(gr1,328)
  225| 00204C ld       EAE10150   1     L8        gr23=#SPILL29(gr1,336)
  225| 002050 ld       EAC10158   1     L8        gr22=#SPILL54(gr1,344)
  225| 002054 lfdx     7F8964AE   1     LFL       fp28=dq[](gr9,gr12,0)
  225| 002058 add      7F34AA14   1     A         gr25=gr20,gr21
  225| 00205C add      7F6A9A14   1     A         gr27=gr10,gr19
  225| 002060 mulld    7F58C9D2   1     M         gr26=gr24,gr25
  225| 002064 mulld    7F00D9D2   1     M         gr24=gr0,gr27
  225| 002068 mulld    7F37C9D2   1     M         gr25=gr23,gr25
  225| 00206C ld       EAE10160   1     L8        gr23=#SPILL64(gr1,352)
  225| 002070 rldicr   7B7B1F24   1     SLL8      gr27=gr27,3
  225| 002074 add      7F56D214   1     A         gr26=gr22,gr26
  225| 002078 lfdx     7FD6FCAE   1     LFL       fp30=mflx[](gr22,gr31,0)
  228| 00207C ld       EAC10178   1     L8        gr22=#SPILL23(gr1,376)
  225| 002080 lfd      CA7C0000   1     LFL       fp19=v3(gr28,0)
  225| 002084 add      7EF7C214   1     A         gr23=gr23,gr24
  225| 002088 add      7F1ADA14   1     A         gr24=gr26,gr27
  225| 00208C ld       EB410168   1     L8        gr26=#SPILL74(gr1,360)
  225| 002090 add      7F39BA14   1     A         gr25=gr25,gr23
  225| 002094 ld       EAE101A8   1     L8        gr23=#SPILL80(gr1,424)
  225| 002098 add      7F696214   1     A         gr27=gr9,gr12
  225| 00209C lfd      CA5A0000   1     LFL       fp18=dx3b(gr26,0)
  225| 0020A0 ld       EB410170   1     L8        gr26=#SPILL68(gr1,368)
  225| 0020A4 add      7F17C214   1     A         gr24=gr23,gr24
  225| 0020A8 ld       EAE10170   1     L8        gr23=#SPILL68(gr1,368)
  225| 0020AC lfd      C91A0000   1     LFL       fp8=vg3(gr26,0)
  228| 0020B0 ld       EB410180   1     L8        gr26=#SPILL40(gr1,384)
  228| 0020B4 lfdx     7C96D4AE   1     LFL       fp4=g32bi(gr22,gr26,0)
  228| 0020B8 ld       EB4100D0   1     L8        gr26=#SPILL56(gr1,208)
  234| 0020BC ld       EAC10188   1     L8        gr22=#SPILL8(gr1,392)
  228| 0020C0 lfd      C8BA0000   1     LFL       fp5=g31bi(gr26,0)
  234| 0020C4 ld       EB410190   1     L8        gr26=#SPILL5(gr1,400)
  234| 0020C8 lfdx     7CD6D4AE   1     LFL       fp6=atwidj3[](gr22,gr26,0)
  234| 0020CC ld       EB410198   1     L8        gr26=#SPILL53(gr1,408)
  234| 0020D0 ld       EAC101A0   1     L8        gr22=#SPILL69(gr1,416)
  234| 0020D4 lfdx     7CFA5CAE   1     LFL       fp7=atwid3[](gr26,gr11,0)
  234| 0020D8 add      7F52B214   1     A         gr26=gr18,gr22
  225| 0020DC ld       EAC10168   1     L8        gr22=#SPILL74(gr1,360)
    0| 0020E0 bc       4182009C   1     BT        CL.425,cr0,0x4/eq,taken=50%(0,0)
    0| 0020E4 ld       E8E10128   1     L8        gr7=#SPILL90(gr1,296)
    0| 0020E8 mtspr    7CE903A6   1     LCTR      ctr=gr7
    0| 0020EC ori      60210000   1     XNOP      
  225|                              CL.424:
  225| 0020F0 lfdux    7D391CEE   1     LFDU      fp9,gr25=v3(gr25,gr3,0)
  228| 0020F4 fsub     FD134028   1     SFL       fp8=fp19,fp8,fcr
  225| 0020F8 lfdu     CDB70008   1     LFDU      fp13,gr23=vg3(gr23,8)
  225| 0020FC lfdu     CD560008   1     LFDU      fp10,gr22=dx3b(gr22,8)
  225| 002100 lfdux    7FB824EE   1     LFDU      fp29,gr24=mflx[](gr24,gr4,0)
  225| 002104 lfdu     CD7B0008   1     LFDU      fp11,gr27=dq[](gr27,8)
  228| 002108 fadd     FFE8482A   1     AFL       fp31=fp8,fp9,fcr
  234| 00210C fmr      FD006890   2     LRFL      fp8=fp13
  234| 002110 fadd     FD9EE82A   2     AFL       fp12=fp30,fp29,fcr
  234| 002114 fmr      FFC0E890   2     LRFL      fp30=fp29
  228| 002118 fsub     FDBF6828   2     SFL       fp13=fp31,fp13,fcr
  228| 00211C fmul     FDAD0072   2     MFL       fp13=fp13,fp1,fcr
  228| 002120 fmul     FDA00372   2     MFL       fp13=fp0,fp13,fcr
  228| 002124 fmul     FDA50372   2     MFL       fp13=fp5,fp13,fcr
  228| 002128 fmul     FFE40372   2     MFL       fp31=fp4,fp13,fcr
  230| 00212C fmadd    FFA4537A   2     FMA       fp29=fp10,fp4,fp13,fcr
  230| 002130 fnmsub   FDA4937C   2     FNMS      fp13=fp18,fp4,fp13,fcr
  234| 002134 fmr      FE405090   2     LRFL      fp18=fp10
  229| 002138 qvfcpsgn 115F0810   1     CPYSFL    fp10=fp1,fp31
  230| 00213C fsub     FFE15028   1     SFL       fp31=fp1,fp10,fcr
  230| 002140 fnmsub   FFBD4AFC   2     FNMS      fp29=fp9,fp29,fp11,fcr
  230| 002144 fadd     FD4A082A   2     AFL       fp10=fp10,fp1,fcr
  230| 002148 fmadd    FDAD9F3A   2     FMA       fp13=fp19,fp13,fp28,fcr
  234| 00214C fmr      FE604890   2     LRFL      fp19=fp9
  234| 002150 fmr      FF805890   2     LRFL      fp28=fp11
  230| 002154 fmul     FD3F0772   2     MFL       fp9=fp31,fp29,fcr
  230| 002158 fmadd    FD2A4B7A   2     FMA       fp9=fp9,fp10,fp13,fcr
  234| 00215C fmul     FD2C0272   2     MFL       fp9=fp12,fp9,fcr
  234| 002160 fmul     FD2901F2   2     MFL       fp9=fp9,fp7,fcr
  234| 002164 fmul     FD2901B2   2     MFL       fp9=fp9,fp6,fcr
  234| 002168 stfdu    DD3A0008   2     STFDU     gr26,sflx[](gr26,8)=fp9
  236| 00216C bc       4200FF84   1     BCT       ctr=CL.424,taken=100%(100,0)
    0| 002170 ld       E8E10120   1     L8        gr7=#SPILL61(gr1,288)
    0| 002174 cmpdi    2D270000   1     C8        cr2=gr7,0
    0| 002178 bc       418A0288   1     BT        CL.81,cr2,0x4/eq,taken=20%(20,80)
    0|                              CL.425:
  225| 00217C lfdux    7F591CEE   1     LFDU      fp26,gr25=v3(gr25,gr3,0)
  228| 002180 fsub     FD334028   1     SFL       fp9=fp19,fp8,fcr
  225| 002184 lfd      C9B70008   1     LFL       fp13=vg3(gr23,8)
  225| 002188 lfd      CB170010   1     LFL       fp24=vg3(gr23,16)
  225| 00218C lfdu     CF370018   1     LFDU      fp25,gr23=vg3(gr23,24)
  225| 002190 lfd      CA960008   1     LFL       fp20=dx3b(gr22,8)
  225| 002194 lfdu     CD160018   1     LFDU      fp8,gr22=dx3b(gr22,24)
  228| 002198 fadd     FD69D02A   1     AFL       fp11=fp9,fp26,fcr
  225| 00219C lfdux    7D391CEE   1     LFDU      fp9,gr25=v3(gr25,gr3,0)
  228| 0021A0 fsub     FD9A6828   1     SFL       fp12=fp26,fp13,fcr
  225| 0021A4 lfd      CADB0008   1     LFL       fp22=dq[](gr27,8)
  225| 0021A8 lfdux    7FB824EE   1     LFDU      fp29,gr24=mflx[](gr24,gr4,0)
  225| 0021AC lfdu     CD5B0018   1     LFDU      fp10,gr27=dq[](gr27,24)
  228| 0021B0 fsub     FFEB6828   1     SFL       fp31=fp11,fp13,fcr
  225| 0021B4 lfd      C976FFF8   1     LFL       fp11=dx3b(gr22,-8)
  228| 0021B8 fadd     FEAC482A   1     AFL       fp21=fp12,fp9,fcr
  225| 0021BC lfdux    7D991CEE   1     LFDU      fp12,gr25=v3(gr25,gr3,0)
  228| 0021C0 fsub     FF69C028   1     SFL       fp27=fp9,fp24,fcr
    0| 0021C4 ld       E8E10120   1     L8        gr7=#SPILL61(gr1,288)
  228| 0021C8 fmul     FEFF0072   1     MFL       fp23=fp31,fp1,fcr
  225| 0021CC lfdux    7DB824EE   1     LFDU      fp13,gr24=mflx[](gr24,gr4,0)
  228| 0021D0 fsub     FF15C028   1     SFL       fp24=fp21,fp24,fcr
  225| 0021D4 lfd      CBFBFFF8   1     LFL       fp31=dq[](gr27,-8)
  228| 0021D8 fadd     FF7B602A   1     AFL       fp27=fp27,fp12,fcr
    0| 0021DC mtspr    7CE903A6   1     LCTR      ctr=gr7
  228| 0021E0 fmul     FEE005F2   1     MFL       fp23=fp0,fp23,fcr
  234| 0021E4 fadd     FFDEE82A   2     AFL       fp30=fp30,fp29,fcr
  228| 0021E8 fmul     FF180072   2     MFL       fp24=fp24,fp1,fcr
  234| 0021EC fadd     FFBD682A   2     AFL       fp29=fp29,fp13,fcr
  228| 0021F0 fsub     FF7BC828   2     SFL       fp27=fp27,fp25,fcr
  228| 0021F4 fmul     FEA505F2   2     MFL       fp21=fp5,fp23,fcr
  228| 0021F8 fmul     FEE00632   2     MFL       fp23=fp0,fp24,fcr
  228| 0021FC fmul     FF1B0072   2     MFL       fp24=fp27,fp1,fcr
  230| 002200 fnmsub   FE44957C   2     FNMS      fp18=fp18,fp4,fp21,fcr
  228| 002204 fmul     FF640572   2     MFL       fp27=fp4,fp21,fcr
  228| 002208 fmul     FEE505F2   2     MFL       fp23=fp5,fp23,fcr
  230| 00220C fmadd    FEA4A57A   2     FMA       fp21=fp20,fp4,fp21,fcr
  228| 002210 fmul     FF000632   2     MFL       fp24=fp0,fp24,fcr
  230| 002214 fmadd    FF929F3A   2     FMA       fp28=fp19,fp18,fp28,fcr
  229| 002218 qvfcpsgn 137B0810   1     CPYSFL    fp27=fp1,fp27
  230| 00221C fmadd    FE645DFA   1     FMA       fp19=fp11,fp4,fp23,fcr
  230| 002220 fnmsub   FE44A5FC   2     FNMS      fp18=fp20,fp4,fp23,fcr
  230| 002224 fnmsub   FEB5D5BC   2     FNMS      fp21=fp26,fp21,fp22,fcr
  228| 002228 fmul     FEE405F2   2     MFL       fp23=fp4,fp23,fcr
  230| 00222C fsub     FE81D828   2     SFL       fp20=fp1,fp27,fcr
  230| 002230 fadd     FF7B082A   2     AFL       fp27=fp27,fp1,fcr
  230| 002234 fnmsub   FE734FFC   2     FNMS      fp19=fp9,fp19,fp31,fcr
  230| 002238 fmadd    FF52D5BA   2     FMA       fp26=fp26,fp18,fp22,fcr
    0| 00223C bc       42400144   1     BCF       ctr=CL.606,taken=0%(0,100)
    0| 002240 ori      60210000   1     XNOP      
    0|                              CL.607:
  228| 002244 fsub     FF2CC828   1     SFL       fp25=fp12,fp25,fcr
  229| 002248 qvfcpsgn 12F70810   1     CPYSFL    fp23=fp1,fp23
  230| 00224C fsub     FE41B828   1     SFL       fp18=fp1,fp23,fcr
  228| 002250 fmul     FF050632   2     MFL       fp24=fp5,fp24,fcr
  230| 002254 fadd     FEF7082A   2     AFL       fp23=fp23,fp1,fcr
  230| 002258 fmul     FED40572   2     MFL       fp22=fp20,fp21,fcr
  225| 00225C lfd      CAB70010   1     LFL       fp21=vg3(gr23,16)
  225| 002260 lfd      CA970008   1     LFL       fp20=vg3(gr23,8)
  230| 002264 fmul     FE7204F2   1     MFL       fp19=fp18,fp19,fcr
  230| 002268 fmadd    FE44463A   2     FMA       fp18=fp8,fp4,fp24,fcr
  230| 00226C fnmsub   FD645E3C   2     FNMS      fp11=fp11,fp4,fp24,fcr
  228| 002270 fmul     FF040632   2     MFL       fp24=fp4,fp24,fcr
  230| 002274 fmadd    FF9BB73A   2     FMA       fp28=fp22,fp27,fp28,fcr
  225| 002278 lfdux    7F7824EE   1     LFDU      fp27,gr24=mflx[](gr24,gr4,0)
  225| 00227C lfdux    7ED91CEE   1     LFDU      fp22,gr25=v3(gr25,gr3,0)
  230| 002280 fnmsub   FE5262BC   1     FNMS      fp18=fp12,fp18,fp10,fcr
  230| 002284 fmadd    FD6B4FFA   2     FMA       fp11=fp9,fp11,fp31,fcr
  229| 002288 qvfcpsgn 11380810   1     CPYSFL    fp9=fp1,fp24
  230| 00228C fsub     FF014828   1     SFL       fp24=fp1,fp9,fcr
  230| 002290 fadd     FFE9082A   2     AFL       fp31=fp9,fp1,fcr
  230| 002294 fmadd    FF579EBA   2     FMA       fp26=fp19,fp23,fp26,fcr
  228| 002298 fadd     FF39B02A   2     AFL       fp25=fp25,fp22,fcr
  225| 00229C lfdux    7D391CEE   1     LFDU      fp9,gr25=v3(gr25,gr3,0)
  234| 0022A0 fmul     FF9E0732   1     MFL       fp28=fp30,fp28,fcr
  230| 0022A4 fmul     FF1804B2   2     MFL       fp24=fp24,fp18,fcr
  234| 0022A8 fmul     FFBD06B2   2     MFL       fp29=fp29,fp26,fcr
  228| 0022AC fsub     FF59A028   2     SFL       fp26=fp25,fp20,fcr
  234| 0022B0 fadd     FDADD82A   2     AFL       fp13=fp13,fp27,fcr
  228| 0022B4 fsub     FFC9A828   2     SFL       fp30=fp9,fp21,fcr
  230| 0022B8 fmadd    FD7FC2FA   2     FMA       fp11=fp24,fp31,fp11,fcr
  234| 0022BC fmul     FFFC01F2   2     MFL       fp31=fp28,fp7,fcr
  234| 0022C0 fmul     FFBD01F2   2     MFL       fp29=fp29,fp7,fcr
  228| 0022C4 fmul     FF9A0072   2     MFL       fp28=fp26,fp1,fcr
  234| 0022C8 fmul     FD6D02F2   2     MFL       fp11=fp13,fp11,fcr
  234| 0022CC fmul     FDBF01B2   2     MFL       fp13=fp31,fp6,fcr
  234| 0022D0 fmul     FFFD01B2   2     MFL       fp31=fp29,fp6,fcr
  228| 0022D4 fmul     FFA00732   2     MFL       fp29=fp0,fp28,fcr
  228| 0022D8 fsub     FF96A028   2     SFL       fp28=fp22,fp20,fcr
  225| 0022DC lfd      CAF60008   1     LFL       fp23=dx3b(gr22,8)
  234| 0022E0 fmul     FD6B01F2   1     MFL       fp11=fp11,fp7,fcr
  234| 0022E4 stfd     D9BA0008   1     STFL      sflx[](gr26,8)=fp13
  228| 0022E8 fmul     FE850772   1     MFL       fp20=fp5,fp29,fcr
  228| 0022EC fadd     FDBC482A   2     AFL       fp13=fp28,fp9,fcr
  234| 0022F0 stfd     DBFA0010   1     STFL      sflx[](gr26,16)=fp31
  234| 0022F4 fmul     FFEB01B2   1     MFL       fp31=fp11,fp6,fcr
  225| 0022F8 lfd      CB5B0008   1     LFL       fp26=dq[](gr27,8)
  230| 0022FC fnmsub   FD64453C   1     FNMS      fp11=fp8,fp4,fp20,fcr
  228| 002300 fsub     FFADA828   2     SFL       fp29=fp13,fp21,fcr
  225| 002304 lfdu     CD160018   1     LFDU      fp8,gr22=dx3b(gr22,24)
  230| 002308 fmadd    FDA4BD3A   1     FMA       fp13=fp23,fp4,fp20,fcr
  234| 00230C stfdu    DFFA0018   2     STFDU     gr26,sflx[](gr26,24)=fp31
  225| 002310 lfdux    7FF824EE   1     LFDU      fp31,gr24=mflx[](gr24,gr4,0)
  230| 002314 fmadd    FF8B62BA   1     FMA       fp28=fp12,fp11,fp10,fcr
  225| 002318 lfdux    7D991CEE   1     LFDU      fp12,gr25=v3(gr25,gr3,0)
  228| 00231C fmul     FD7D0072   1     MFL       fp11=fp29,fp1,fcr
  225| 002320 lfdu     CD5B0018   1     LFDU      fp10,gr27=dq[](gr27,24)
  230| 002324 fnmsub   FEADB6BC   1     FNMS      fp21=fp22,fp13,fp26,fcr
  225| 002328 lfdux    7DB824EE   1     LFDU      fp13,gr24=mflx[](gr24,gr4,0)
  225| 00232C lfdu     CF370018   1     LFDU      fp25,gr23=vg3(gr23,24)
  228| 002330 fadd     FF1E602A   1     AFL       fp24=fp30,fp12,fcr
  228| 002334 fmul     FFA002F2   2     MFL       fp29=fp0,fp11,fcr
  234| 002338 fadd     FFDBF82A   2     AFL       fp30=fp27,fp31,fcr
  225| 00233C lfd      C976FFF8   1     LFL       fp11=dx3b(gr22,-8)
  228| 002340 fmul     FF640532   1     MFL       fp27=fp4,fp20,fcr
  228| 002344 fsub     FF18C828   2     SFL       fp24=fp24,fp25,fcr
  228| 002348 fmul     FE850772   2     MFL       fp20=fp5,fp29,fcr
  234| 00234C fadd     FFBF682A   2     AFL       fp29=fp31,fp13,fcr
  225| 002350 lfd      CBFBFFF8   1     LFL       fp31=dq[](gr27,-8)
  229| 002354 qvfcpsgn 137B0810   1     CPYSFL    fp27=fp1,fp27
  228| 002358 fmul     FF180072   1     MFL       fp24=fp24,fp1,fcr
  230| 00235C fmadd    FE645D3A   2     FMA       fp19=fp11,fp4,fp20,fcr
  230| 002360 fnmsub   FE44BD3C   2     FNMS      fp18=fp23,fp4,fp20,fcr
  228| 002364 fmul     FEE40532   2     MFL       fp23=fp4,fp20,fcr
  230| 002368 fsub     FE81D828   2     SFL       fp20=fp1,fp27,fcr
  230| 00236C fadd     FF7B082A   2     AFL       fp27=fp27,fp1,fcr
  228| 002370 fmul     FF000632   2     MFL       fp24=fp0,fp24,fcr
  230| 002374 fnmsub   FE734FFC   2     FNMS      fp19=fp9,fp19,fp31,fcr
  230| 002378 fmadd    FF52B6BA   2     FMA       fp26=fp22,fp18,fp26,fcr
    0| 00237C bc       4200FEC8   1     BCT       ctr=CL.607,taken=100%(100,0)
    0|                              CL.606:
  228| 002380 fmul     FCA50632   1     MFL       fp5=fp5,fp24,fcr
  229| 002384 qvfcpsgn 13370810   1     CPYSFL    fp25=fp1,fp23
  230| 002388 fmul     FED40572   1     MFL       fp22=fp20,fp21,fcr
  225| 00238C lfdux    7EF824EE   1     LFDU      fp23,gr24=mflx[](gr24,gr4,0)
  230| 002390 fsub     FF01C828   1     SFL       fp24=fp1,fp25,fcr
  230| 002394 fadd     FF39082A   2     AFL       fp25=fp25,fp1,fcr
  228| 002398 fmul     FEA40172   2     MFL       fp21=fp4,fp5,fcr
  230| 00239C fmadd    FD04417A   2     FMA       fp8=fp8,fp4,fp5,fcr
  230| 0023A0 fnmsub   FC84597C   2     FNMS      fp4=fp11,fp4,fp5,fcr
  234| 0023A4 fadd     FD6DB82A   2     AFL       fp11=fp13,fp23,fcr
  230| 0023A8 fmadd    FDBBB73A   2     FMA       fp13=fp22,fp27,fp28,fcr
  229| 0023AC qvfcpsgn 13950810   1     CPYSFL    fp28=fp1,fp21
  230| 0023B0 fnmsub   FD0862BC   1     FNMS      fp8=fp12,fp8,fp10,fcr
  230| 0023B4 fsub     FD41E028   2     SFL       fp10=fp1,fp28,fcr
  230| 0023B8 fmul     FCB804F2   2     MFL       fp5=fp24,fp19,fcr
  230| 0023BC fmadd    FC844FFA   2     FMA       fp4=fp9,fp4,fp31,fcr
  230| 0023C0 fadd     FD3C082A   2     AFL       fp9=fp28,fp1,fcr
  234| 0023C4 fmul     FD9E0372   2     MFL       fp12=fp30,fp13,fcr
  230| 0023C8 fmul     FD0A0232   2     MFL       fp8=fp10,fp8,fcr
  230| 0023CC fmadd    FCB92EBA   2     FMA       fp5=fp5,fp25,fp26,fcr
  234| 0023D0 fmul     FD4C01F2   2     MFL       fp10=fp12,fp7,fcr
  230| 0023D4 fmadd    FC89413A   2     FMA       fp4=fp8,fp9,fp4,fcr
  234| 0023D8 fmul     FCBD0172   2     MFL       fp5=fp29,fp5,fcr
  234| 0023DC fmul     FD0A01B2   2     MFL       fp8=fp10,fp6,fcr
  234| 0023E0 fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  234| 0023E4 fmul     FCA501F2   2     MFL       fp5=fp5,fp7,fcr
  234| 0023E8 stfd     D91A0008   1     STFL      sflx[](gr26,8)=fp8
  234| 0023EC fmul     FC8401F2   1     MFL       fp4=fp4,fp7,fcr
  234| 0023F0 fmul     FCA501B2   2     MFL       fp5=fp5,fp6,fcr
  234| 0023F4 fmul     FC8401B2   2     MFL       fp4=fp4,fp6,fcr
  234| 0023F8 stfd     D8BA0010   1     STFL      sflx[](gr26,16)=fp5
  234| 0023FC stfdu    DC9A0018   1     STFDU     gr26,sflx[](gr26,24)=fp4
  236|                              CL.81:
  238| 002400 ld       E8E10118   1     L8        gr7=#SPILL59(gr1,280)
  238| 002404 cmpdi    2D270000   1     C8        cr2=gr7,0
  238| 002408 bc       40890134   1     BF        CL.83,cr2,0x2/gt,taken=50%(0,0)
    0| 00240C bc       41860354   1     BT        CL.200,cr1,0x4/eq,taken=50%(0,0)
    0| 002410 ld       EAE100F8   1     L8        gr23=#SPILL55(gr1,248)
    0| 002414 ld       EB210100   1     L8        gr25=#SPILL72(gr1,256)
    0| 002418 add      7F4C9214   1     A         gr26=gr12,gr18
  240| 00241C ld       EB010110   1     L8        gr24=#SPILL79(gr1,272)
    0| 002420 add      7F77FA14   1     A         gr27=gr23,gr31
    0| 002424 bc       419E002C   1     BT        CL.388,cr7,0x4/eq,taken=50%(0,0)
    0| 002428 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 00242C lfdu     CCB90008   1     LFDU      fp5,gr25=dvl3b(gr25,8)
    0| 002430 lfd      C8DA0000   1     LFL       fp6=sflx[](gr26,0)
    0| 002434 lfdu     CCFA0008   1     LFDU      fp7,gr26=sflx[](gr26,8)
  240| 002438 lfdu     CD180008   1     LFDU      fp8,gr24=dvl3bni(gr24,8)
    0| 00243C fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
    0| 002440 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  240| 002444 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  240| 002448 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 00244C bc       419600F0   1     BT        CL.83,cr5,0x4/eq,taken=50%(0,0)
    0|                              CL.388:
    0| 002450 mtspr    7DE903A6   1     LCTR      ctr=gr15
    0| 002454 bc       418E0054   1     BT        CL.580,cr3,0x4/eq,taken=50%(0,0)
    0| 002458 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 00245C lfd      C8B90008   1     LFL       fp5=dvl3b(gr25,8)
    0| 002460 lfd      C8DA0008   1     LFL       fp6=sflx[](gr26,8)
    0| 002464 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
  240| 002468 lfd      C9180008   1     LFL       fp8=dvl3bni(gr24,8)
    0| 00246C lfdu     CD390010   1     LFDU      fp9,gr25=dvl3b(gr25,16)
    0| 002470 lfdu     CD5A0010   1     LFDU      fp10,gr26=sflx[](gr26,16)
  240| 002474 lfdu     CD780010   1     LFDU      fp11,gr24=dvl3bni(gr24,16)
    0| 002478 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
    0| 00247C fadd     FC87202A   2     AFL       fp4=fp7,fp4,fcr
  240| 002480 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  240| 002484 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 002488 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 00248C fmsub    FC845278   1     FMS       fp4=fp10,fp4,fp9,fcr
    0| 002490 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  240| 002494 fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  240| 002498 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 00249C bc       419200A0   1     BT        CL.83,cr4,0x4/eq,taken=20%(20,80)
    0| 0024A0 ori      60210000   1     XNOP      
    0| 0024A4 ori      60210000   1     XNOP      
    0|                              CL.580:
    0| 0024A8 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s3[](gr27,gr4,0)
    0| 0024AC lfd      C8D90008   1     LFL       fp6=dvl3b(gr25,8)
    0| 0024B0 lfd      C89A0008   1     LFL       fp4=sflx[](gr26,8)
    0| 0024B4 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
    0| 0024B8 fmsub    FCA521B8   1     FMS       fp5=fp4-fp6,fcr
  240| 0024BC lfd      C8D80008   1     LFL       fp6=dvl3bni(gr24,8)
    0| 0024C0 fadd     FCA7282A   1     AFL       fp5=fp7,fp5,fcr
  240| 0024C4 fmul     FCA60172   2     MFL       fp5=fp6,fp5,fcr
    0| 0024C8 lfd      C8D90010   1     LFL       fp6=dvl3b(gr25,16)
    0| 0024CC lfd      C8FA0010   1     LFL       fp7=sflx[](gr26,16)
  240| 0024D0 stfd     D8BB0000   1     STFL      s3[](gr27,0)=fp5
    0| 0024D4 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s3[](gr27,gr4,0)
    0| 0024D8 fmsub    FCA539B8   1     FMS       fp5=fp7,fp5,fp6,fcr
  240| 0024DC lfd      C8D80010   1     LFL       fp6=dvl3bni(gr24,16)
    0| 0024E0 fadd     FC84282A   1     AFL       fp4=fp4,fp5,fcr
  240| 0024E4 fmul     FC860132   2     MFL       fp4=fp6,fp4,fcr
    0| 0024E8 lfd      C8B90018   1     LFL       fp5=dvl3b(gr25,24)
    0| 0024EC lfd      C8DA0018   1     LFL       fp6=sflx[](gr26,24)
  240| 0024F0 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 0024F4 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 0024F8 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
  240| 0024FC lfd      C8B80018   1     LFL       fp5=dvl3bni(gr24,24)
    0| 002500 fadd     FC87202A   1     AFL       fp4=fp7,fp4,fcr
  240| 002504 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
    0| 002508 lfdu     CCB90020   1     LFDU      fp5,gr25=dvl3b(gr25,32)
    0| 00250C lfdu     CCFA0020   1     LFDU      fp7,gr26=sflx[](gr26,32)
  240| 002510 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 002514 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 002518 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
  240| 00251C lfdu     CCB80020   1     LFDU      fp5,gr24=dvl3bni(gr24,32)
    0| 002520 fadd     FC86202A   1     AFL       fp4=fp6,fp4,fcr
  240| 002524 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
  240| 002528 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 00252C bc       4200FF7C   1     BCT       ctr=CL.580,taken=100%(100,0)
    0| 002530 ori      60210000   1     XNOP      
    0| 002534 ori      60210000   1     XNOP      
    0| 002538 ori      60210000   1     XNOP      
  246|                              CL.83:
    0| 00253C ld       EAE100B8   1     L8        gr23=#SPILL26(gr1,184)
    0| 002540 ld       EA6100D8   1     L8        gr19=#SPILL86(gr1,216)
  247| 002544 ld       E8E10090   1     L8        gr7=#SPILL1(gr1,144)
    0| 002548 ld       EAC100C0   1     L8        gr22=#SPILL28(gr1,192)
  247| 00254C addi     394A0001   1     AI        gr10=gr10,1
    0| 002550 ld       EB610098   1     L8        gr27=#SPILL81(gr1,152)
    0| 002554 add      7FD7F214   1     A         gr30=gr23,gr30
    0| 002558 add      7E73BA14   1     A         gr19=gr19,gr23
    0| 00255C ld       EAE100E8   1     L8        gr23=#SPILL87(gr1,232)
    0| 002560 std      FA6100D8   1     ST8       #SPILL86(gr1,216)=gr19
  247| 002564 cmpld    7D2A3840   1     CL8       cr2=gr10,gr7
    0| 002568 ld       EB4100A0   1     L8        gr26=#SPILL82(gr1,160)
    0| 00256C ld       EB2100A8   1     L8        gr25=#SPILL83(gr1,168)
    0| 002570 ld       EB0100B0   1     L8        gr24=#SPILL84(gr1,176)
    0| 002574 add      7FB6EA14   1     A         gr29=gr22,gr29
    0| 002578 ld       EAA100C8   1     L8        gr21=#SPILL85(gr1,200)
    0| 00257C ld       EA8100D0   1     L8        gr20=#SPILL56(gr1,208)
    0| 002580 ld       E8E100E0   1     L8        gr7=#SPILL89(gr1,224)
    0| 002584 add      7EF6BA14   1     A         gr23=gr22,gr23
    0| 002588 ld       EAC100F0   1     L8        gr22=#SPILL88(gr1,240)
    0| 00258C std      FAE100E8   1     ST8       #SPILL87(gr1,232)=gr23
    0| 002590 addi     3B7B0008   1     AI        gr27=gr27,8
    0| 002594 add      7F40D214   1     A         gr26=gr0,gr26
    0| 002598 std      FB610098   1     ST8       #SPILL81(gr1,152)=gr27
    0| 00259C std      FB4100A0   1     ST8       #SPILL82(gr1,160)=gr26
    0| 0025A0 addi     3B390008   1     AI        gr25=gr25,8
    0| 0025A4 addi     3B180008   1     AI        gr24=gr24,8
    0| 0025A8 std      FB2100A8   1     ST8       #SPILL83(gr1,168)=gr25
    0| 0025AC std      FB0100B0   1     ST8       #SPILL84(gr1,176)=gr24
    0| 0025B0 addi     3AB50008   1     AI        gr21=gr21,8
    0| 0025B4 addi     3A940008   1     AI        gr20=gr20,8
    0| 0025B8 std      FAA100C8   1     ST8       #SPILL85(gr1,200)=gr21
    0| 0025BC std      FA8100D0   1     ST8       #SPILL56(gr1,208)=gr20
    0| 0025C0 addi     38E70008   1     AI        gr7=gr7,8
    0| 0025C4 add      7EC0B214   1     A         gr22=gr0,gr22
    0| 0025C8 std      F8E100E0   1     ST8       #SPILL89(gr1,224)=gr7
    0| 0025CC addi     3BFF0008   1     AI        gr31=gr31,8
    0| 0025D0 std      FAC100F0   1     ST8       #SPILL88(gr1,240)=gr22
    0| 0025D4 addi     396B0008   1     AI        gr11=gr11,8
    0| 0025D8 add      7F80E214   1     A         gr28=gr0,gr28
    0| 0025DC addi     39CE0008   1     AI        gr14=gr14,8
  247| 0025E0 bc       4188E544   1     BT        CL.66,cr2,0x8/llt,taken=80%(80,20)
  247| 0025E4 ld       E8E10260   1     L8        gr7=#SPILL91(gr1,608)
  247|                              CL.65:
  248| 0025E8 ld       E9410138   1     L8        gr10=#SPILL32(gr1,312)
    0| 0025EC ld       E9610150   1     L8        gr11=#SPILL29(gr1,336)
    0| 0025F0 ld       E9810268   1     L8        gr12=#SPILL45(gr1,616)
  248| 0025F4 ld       EBE10270   1     L8        gr31=#SPILL4(gr1,624)
    0| 0025F8 ld       EBC10278   1     L8        gr30=#SPILL49(gr1,632)
    0| 0025FC ld       EBA10280   1     L8        gr29=#SPILL47(gr1,640)
    0| 002600 ld       EB810200   1     L8        gr28=#SPILL27(gr1,512)
    0| 002604 ld       EB610288   1     L8        gr27=#SPILL48(gr1,648)
    0| 002608 ld       EB410290   1     L8        gr26=#SPILL46(gr1,656)
    0| 00260C ld       EB210240   1     L8        gr25=#SPILL25(gr1,576)
    0| 002610 ld       EB010298   1     L8        gr24=#SPILL51(gr1,664)
    0| 002614 ld       EAE102A0   1     L8        gr23=#SPILL93(gr1,672)
    0| 002618 ld       EAC10148   1     L8        gr22=#SPILL10(gr1,328)
    0| 00261C ld       EAA102A8   1     L8        gr21=#SPILL41(gr1,680)
    0| 002620 ld       EA8102B0   1     L8        gr20=#SPILL43(gr1,688)
    0| 002624 ld       EA6102B8   1     L8        gr19=#SPILL44(gr1,696)
    0| 002628 ld       EA2102C0   1     L8        gr17=#SPILL42(gr1,704)
    0| 00262C ld       EA010190   1     L8        gr16=#SPILL5(gr1,400)
    0| 002630 ld       E9E101E8   1     L8        gr15=#SPILL39(gr1,488)
    0| 002634 ld       E9C10180   1     L8        gr14=#SPILL40(gr1,384)
  248| 002638 addi     394A0001   1     AI        gr10=gr10,1
    0| 00263C add      7D8B6214   1     A         gr12=gr11,gr12
  248| 002640 std      F9410138   1     ST8       #SPILL32(gr1,312)=gr10
    0| 002644 std      F9810268   1     ST8       #SPILL45(gr1,616)=gr12
  248| 002648 cmpld    7C2AF840   1     CL8       cr0=gr10,gr31
    0| 00264C add      7FCBF214   1     A         gr30=gr11,gr30
    0| 002650 add      7FABEA14   1     A         gr29=gr11,gr29
    0| 002654 std      FBC10278   1     ST8       #SPILL49(gr1,632)=gr30
    0| 002658 std      FBA10280   1     ST8       #SPILL47(gr1,640)=gr29
    0| 00265C add      7F7BE214   1     A         gr27=gr27,gr28
    0| 002660 add      7F5AE214   1     A         gr26=gr26,gr28
    0| 002664 std      FB610288   1     ST8       #SPILL48(gr1,648)=gr27
    0| 002668 std      FB410290   1     ST8       #SPILL46(gr1,656)=gr26
    0| 00266C add      7F18CA14   1     A         gr24=gr24,gr25
    0| 002670 add      7EF7CA14   1     A         gr23=gr23,gr25
    0| 002674 std      FB010298   1     ST8       #SPILL51(gr1,664)=gr24
    0| 002678 std      FAE102A0   1     ST8       #SPILL93(gr1,672)=gr23
    0| 00267C add      7EB5B214   1     A         gr21=gr21,gr22
    0| 002680 add      7E94B214   1     A         gr20=gr20,gr22
    0| 002684 std      FAA102A8   1     ST8       #SPILL41(gr1,680)=gr21
    0| 002688 std      FA8102B0   1     ST8       #SPILL43(gr1,688)=gr20
    0| 00268C add      7E73B214   1     A         gr19=gr19,gr22
    0| 002690 add      7E31B214   1     A         gr17=gr17,gr22
    0| 002694 std      FA6102B8   1     ST8       #SPILL44(gr1,696)=gr19
    0| 002698 std      FA2102C0   1     ST8       #SPILL42(gr1,704)=gr17
    0| 00269C addi     3A100008   1     AI        gr16=gr16,8
    0| 0026A0 addi     39EF0008   1     AI        gr15=gr15,8
    0| 0026A4 std      FA010190   1     ST8       #SPILL5(gr1,400)=gr16
    0| 0026A8 std      F9E101E8   1     ST8       #SPILL39(gr1,488)=gr15
    0| 0026AC addi     39CE0008   1     AI        gr14=gr14,8
    0| 0026B0 std      F9C10180   1     ST8       #SPILL40(gr1,384)=gr14
  248| 0026B4 bc       4180E1F0   1     BT        CL.64,cr0,0x8/llt,taken=80%(80,20)
  251|                              CL.107:
  251| 0026B8 lwa      E98104AA   1     L4A       gr12=#stack(gr1,1192)
  251| 0026BC ld       E9C10380   1     L8        gr14=#stack(gr1,896)
  251| 0026C0 ld       E9E10388   1     L8        gr15=#stack(gr1,904)
  251| 0026C4 ld       EA010390   1     L8        gr16=#stack(gr1,912)
  251| 0026C8 ld       EA210398   1     L8        gr17=#stack(gr1,920)
  251| 0026CC ld       EA4103A0   1     L8        gr18=#stack(gr1,928)
  251| 0026D0 ld       EA6103A8   1     L8        gr19=#stack(gr1,936)
  251| 0026D4 ld       EA8103B0   1     L8        gr20=#stack(gr1,944)
  251| 0026D8 ld       EAA103B8   1     L8        gr21=#stack(gr1,952)
  251| 0026DC ld       EAC103C0   1     L8        gr22=#stack(gr1,960)
  251| 0026E0 ld       EAE103C8   1     L8        gr23=#stack(gr1,968)
  251| 0026E4 ld       EB0103D0   1     L8        gr24=#stack(gr1,976)
  251| 0026E8 ld       EB2103D8   1     L8        gr25=#stack(gr1,984)
  251| 0026EC ld       EB4103E0   1     L8        gr26=#stack(gr1,992)
  251| 0026F0 ld       EB6103E8   1     L8        gr27=#stack(gr1,1000)
  251| 0026F4 ld       EB8103F0   1     L8        gr28=#stack(gr1,1008)
  251| 0026F8 ld       EBA103F8   1     L8        gr29=#stack(gr1,1016)
  251| 0026FC ld       EBC10400   1     L8        gr30=#stack(gr1,1024)
  251| 002700 ld       EBE10408   1     L8        gr31=#stack(gr1,1032)
  251| 002704 mtcrf    7D820120   1     MTCRF     cr2=gr12
  251| 002708 mtcrf    7D810120   1     MTCRF     cr3=gr12
  251| 00270C mtcrf    7D808120   1     MTCRF     cr4=gr12
  251| 002710 lfd      CBE10498   1     LFL       fp31=#stack(gr1,1176)
  251| 002714 lfd      CBC10490   1     LFL       fp30=#stack(gr1,1168)
  251| 002718 lfd      CBA10488   1     LFL       fp29=#stack(gr1,1160)
  251| 00271C lfd      CB810480   1     LFL       fp28=#stack(gr1,1152)
  251| 002720 lfd      CB610478   1     LFL       fp27=#stack(gr1,1144)
  251| 002724 lfd      CB410470   1     LFL       fp26=#stack(gr1,1136)
  251| 002728 lfd      CB210468   1     LFL       fp25=#stack(gr1,1128)
  251| 00272C lfd      CB010460   1     LFL       fp24=#stack(gr1,1120)
  251| 002730 lfd      CAE10458   1     LFL       fp23=#stack(gr1,1112)
  251| 002734 lfd      CAC10450   1     LFL       fp22=#stack(gr1,1104)
  251| 002738 lfd      CAA10448   1     LFL       fp21=#stack(gr1,1096)
  251| 00273C lfd      CA810440   1     LFL       fp20=#stack(gr1,1088)
  251| 002740 lfd      CA610438   1     LFL       fp19=#stack(gr1,1080)
  251| 002744 lfd      CA410430   1     LFL       fp18=#stack(gr1,1072)
  251| 002748 lfd      CA210428   1     LFL       fp17=#stack(gr1,1064)
  251| 00274C lfd      CA010420   1     LFL       fp16=#stack(gr1,1056)
  251| 002750 lfd      C9E10418   1     LFL       fp15=#stack(gr1,1048)
  251| 002754 lfd      C9C10410   1     LFL       fp14=#stack(gr1,1040)
  251| 002758 addi     382104A0   1     AI        gr1=gr1,1184
  251| 00275C bclr     4E800020   1     BA        lr
    0|                              CL.200:
    0| 002760 ld       EAE100F8   1     L8        gr23=#SPILL55(gr1,248)
    0| 002764 ld       EB210100   1     L8        gr25=#SPILL72(gr1,256)
    0| 002768 add      7F4C9214   1     A         gr26=gr12,gr18
  243| 00276C ld       EB010108   1     L8        gr24=#SPILL78(gr1,264)
    0| 002770 add      7F77FA14   1     A         gr27=gr23,gr31
    0| 002774 bc       419E002C   1     BT        CL.389,cr7,0x4/eq,taken=50%(0,0)
    0| 002778 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 00277C lfdu     CCB90008   1     LFDU      fp5,gr25=dvl3b(gr25,8)
    0| 002780 lfd      C8DA0000   1     LFL       fp6=sflx[](gr26,0)
    0| 002784 lfdu     CCFA0008   1     LFDU      fp7,gr26=sflx[](gr26,8)
  243| 002788 lfdu     CD180008   1     LFDU      fp8,gr24=dvl3bi(gr24,8)
    0| 00278C fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
    0| 002790 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  243| 002794 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  243| 002798 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 00279C bc       4196FDA0   1     BT        CL.83,cr5,0x4/eq,taken=50%(0,0)
    0|                              CL.389:
    0| 0027A0 mtspr    7DE903A6   1     LCTR      ctr=gr15
    0| 0027A4 bc       418E0054   1     BT        CL.582,cr3,0x4/eq,taken=50%(0,0)
    0| 0027A8 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 0027AC lfd      C8B90008   1     LFL       fp5=dvl3b(gr25,8)
    0| 0027B0 lfd      C8DA0008   1     LFL       fp6=sflx[](gr26,8)
    0| 0027B4 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
  243| 0027B8 lfd      C9180008   1     LFL       fp8=dvl3bi(gr24,8)
    0| 0027BC lfdu     CD390010   1     LFDU      fp9,gr25=dvl3b(gr25,16)
    0| 0027C0 lfdu     CD5A0010   1     LFDU      fp10,gr26=sflx[](gr26,16)
  243| 0027C4 lfdu     CD780010   1     LFDU      fp11,gr24=dvl3bi(gr24,16)
    0| 0027C8 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
    0| 0027CC fadd     FC87202A   2     AFL       fp4=fp7,fp4,fcr
  243| 0027D0 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  243| 0027D4 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 0027D8 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 0027DC fmsub    FC845278   1     FMS       fp4=fp10,fp4,fp9,fcr
    0| 0027E0 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  243| 0027E4 fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  243| 0027E8 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 0027EC bc       4192FD50   1     BT        CL.83,cr4,0x4/eq,taken=20%(20,80)
    0| 0027F0 ori      60210000   1     XNOP      
    0| 0027F4 ori      60210000   1     XNOP      
    0|                              CL.582:
    0| 0027F8 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s3[](gr27,gr4,0)
    0| 0027FC lfd      C8D90008   1     LFL       fp6=dvl3b(gr25,8)
    0| 002800 lfd      C89A0008   1     LFL       fp4=sflx[](gr26,8)
    0| 002804 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
    0| 002808 fmsub    FCA521B8   1     FMS       fp5=fp4-fp6,fcr
  243| 00280C lfd      C8D80008   1     LFL       fp6=dvl3bi(gr24,8)
    0| 002810 fadd     FCA7282A   1     AFL       fp5=fp7,fp5,fcr
  243| 002814 fmul     FCA60172   2     MFL       fp5=fp6,fp5,fcr
    0| 002818 lfd      C8D90010   1     LFL       fp6=dvl3b(gr25,16)
    0| 00281C lfd      C8FA0010   1     LFL       fp7=sflx[](gr26,16)
  243| 002820 stfd     D8BB0000   1     STFL      s3[](gr27,0)=fp5
    0| 002824 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s3[](gr27,gr4,0)
    0| 002828 fmsub    FCA539B8   1     FMS       fp5=fp7,fp5,fp6,fcr
  243| 00282C lfd      C8D80010   1     LFL       fp6=dvl3bi(gr24,16)
    0| 002830 fadd     FC84282A   1     AFL       fp4=fp4,fp5,fcr
  243| 002834 fmul     FC860132   2     MFL       fp4=fp6,fp4,fcr
    0| 002838 lfd      C8B90018   1     LFL       fp5=dvl3b(gr25,24)
    0| 00283C lfd      C8DA0018   1     LFL       fp6=sflx[](gr26,24)
  243| 002840 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 002844 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 002848 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
  243| 00284C lfd      C8B80018   1     LFL       fp5=dvl3bi(gr24,24)
    0| 002850 fadd     FC87202A   1     AFL       fp4=fp7,fp4,fcr
  243| 002854 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
    0| 002858 lfdu     CCB90020   1     LFDU      fp5,gr25=dvl3b(gr25,32)
    0| 00285C lfdu     CCFA0020   1     LFDU      fp7,gr26=sflx[](gr26,32)
  243| 002860 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 002864 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s3[](gr27,gr4,0)
    0| 002868 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
  243| 00286C lfdu     CCB80020   1     LFDU      fp5,gr24=dvl3bi(gr24,32)
    0| 002870 fadd     FC86202A   1     AFL       fp4=fp6,fp4,fcr
  243| 002874 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
  243| 002878 stfd     D89B0000   1     STFL      s3[](gr27,0)=fp4
    0| 00287C bc       4200FF7C   1     BCT       ctr=CL.582,taken=100%(100,0)
    0| 002880 b        4BFFFCBC   1     B         CL.83,-1
    0|                              CL.196:
    0| 002884 ld       EAE101C0   1     L8        gr23=#SPILL63(gr1,448)
    0| 002888 ld       EB2101C8   1     L8        gr25=#SPILL67(gr1,456)
    0| 00288C or       7DDB7378   1     LR        gr27=gr14
  195| 002890 ld       EB0101D0   1     L8        gr24=#SPILL73(gr1,464)
    0| 002894 add      7F52BA14   1     A         gr26=gr18,gr23
    0| 002898 bc       419E002C   1     BT        CL.387,cr7,0x4/eq,taken=50%(0,0)
    0| 00289C lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 0028A0 lfdu     CCB90008   1     LFDU      fp5,gr25=dvl3a(gr25,8)
    0| 0028A4 lfd      C8DA0000   1     LFL       fp6=sflx[](gr26,0)
    0| 0028A8 lfdu     CCFA0008   1     LFDU      fp7,gr26=sflx[](gr26,8)
  195| 0028AC lfdu     CD180008   1     LFDU      fp8,gr24=dvl3ai(gr24,8)
    0| 0028B0 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
    0| 0028B4 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  195| 0028B8 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  195| 0028BC stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 0028C0 bc       4196F3C0   1     BT        CL.77,cr5,0x4/eq,taken=50%(0,0)
    0|                              CL.387:
    0| 0028C4 mtspr    7DE903A6   1     LCTR      ctr=gr15
    0| 0028C8 bc       418E0050   1     BT        CL.574,cr3,0x4/eq,taken=50%(0,0)
    0| 0028CC lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 0028D0 lfd      C8B90008   1     LFL       fp5=dvl3a(gr25,8)
    0| 0028D4 lfd      C8DA0008   1     LFL       fp6=sflx[](gr26,8)
    0| 0028D8 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
  195| 0028DC lfd      C9180008   1     LFL       fp8=dvl3ai(gr24,8)
    0| 0028E0 lfdu     CD390010   1     LFDU      fp9,gr25=dvl3a(gr25,16)
    0| 0028E4 lfdu     CD5A0010   1     LFDU      fp10,gr26=sflx[](gr26,16)
  195| 0028E8 lfdu     CD780010   1     LFDU      fp11,gr24=dvl3ai(gr24,16)
    0| 0028EC fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
    0| 0028F0 fadd     FC87202A   2     AFL       fp4=fp7,fp4,fcr
  195| 0028F4 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  195| 0028F8 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 0028FC lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 002900 fmsub    FC845278   1     FMS       fp4=fp10,fp4,fp9,fcr
    0| 002904 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  195| 002908 fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  195| 00290C stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 002910 bc       4192F370   1     BT        CL.77,cr4,0x4/eq,taken=20%(20,80)
    0| 002914 ori      60210000   1     XNOP      
    0|                              CL.574:
    0| 002918 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s2[](gr27,gr4,0)
    0| 00291C lfd      C8D90008   1     LFL       fp6=dvl3a(gr25,8)
    0| 002920 lfd      C89A0008   1     LFL       fp4=sflx[](gr26,8)
    0| 002924 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
    0| 002928 fmsub    FCA521B8   1     FMS       fp5=fp4-fp6,fcr
  195| 00292C lfd      C8D80008   1     LFL       fp6=dvl3ai(gr24,8)
    0| 002930 fadd     FCA7282A   1     AFL       fp5=fp7,fp5,fcr
  195| 002934 fmul     FCA60172   2     MFL       fp5=fp6,fp5,fcr
    0| 002938 lfd      C8D90010   1     LFL       fp6=dvl3a(gr25,16)
    0| 00293C lfd      C8FA0010   1     LFL       fp7=sflx[](gr26,16)
  195| 002940 stfd     D8BB0000   1     STFL      s2[](gr27,0)=fp5
    0| 002944 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s2[](gr27,gr4,0)
    0| 002948 fmsub    FCA539B8   1     FMS       fp5=fp7,fp5,fp6,fcr
  195| 00294C lfd      C8D80010   1     LFL       fp6=dvl3ai(gr24,16)
    0| 002950 fadd     FC84282A   1     AFL       fp4=fp4,fp5,fcr
  195| 002954 fmul     FC860132   2     MFL       fp4=fp6,fp4,fcr
    0| 002958 lfd      C8B90018   1     LFL       fp5=dvl3a(gr25,24)
    0| 00295C lfd      C8DA0018   1     LFL       fp6=sflx[](gr26,24)
  195| 002960 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 002964 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 002968 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
  195| 00296C lfd      C8B80018   1     LFL       fp5=dvl3ai(gr24,24)
    0| 002970 fadd     FC87202A   1     AFL       fp4=fp7,fp4,fcr
  195| 002974 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
    0| 002978 lfdu     CCB90020   1     LFDU      fp5,gr25=dvl3a(gr25,32)
    0| 00297C lfdu     CCFA0020   1     LFDU      fp7,gr26=sflx[](gr26,32)
  195| 002980 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 002984 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s2[](gr27,gr4,0)
    0| 002988 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
  195| 00298C lfdu     CCB80020   1     LFDU      fp5,gr24=dvl3ai(gr24,32)
    0| 002990 fadd     FC86202A   1     AFL       fp4=fp6,fp4,fcr
  195| 002994 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
  195| 002998 stfd     D89B0000   1     STFL      s2[](gr27,0)=fp4
    0| 00299C bc       4200FF7C   1     BCT       ctr=CL.574,taken=100%(100,0)
    0| 0029A0 b        4BFFF2E0   1     B         CL.77,-1
    0|                              CL.192:
    0| 0029A4 ld       EAE101C0   1     L8        gr23=#SPILL63(gr1,448)
    0| 0029A8 ld       EB6100C8   1     L8        gr27=#SPILL85(gr1,200)
    0| 0029AC ld       EB2101C8   1     L8        gr25=#SPILL67(gr1,456)
  147| 0029B0 ld       EB0101D0   1     L8        gr24=#SPILL73(gr1,464)
    0| 0029B4 add      7F52BA14   1     A         gr26=gr18,gr23
    0| 0029B8 bc       419E002C   1     BT        CL.385,cr7,0x4/eq,taken=50%(0,0)
    0| 0029BC lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 0029C0 lfdu     CCB90008   1     LFDU      fp5,gr25=dvl3a(gr25,8)
    0| 0029C4 lfd      C8DA0000   1     LFL       fp6=sflx[](gr26,0)
    0| 0029C8 lfdu     CCFA0008   1     LFDU      fp7,gr26=sflx[](gr26,8)
  147| 0029CC lfdu     CD180008   1     LFDU      fp8,gr24=dvl3ai(gr24,8)
    0| 0029D0 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
    0| 0029D4 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  147| 0029D8 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  147| 0029DC stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 0029E0 bc       4196EA00   1     BT        CL.71,cr5,0x4/eq,taken=50%(0,0)
    0|                              CL.385:
    0| 0029E4 mtspr    7DE903A6   1     LCTR      ctr=gr15
    0| 0029E8 bc       418E0050   1     BT        CL.566,cr3,0x4/eq,taken=50%(0,0)
    0| 0029EC lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 0029F0 lfd      C8B90008   1     LFL       fp5=dvl3a(gr25,8)
    0| 0029F4 lfd      C8DA0008   1     LFL       fp6=sflx[](gr26,8)
    0| 0029F8 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
  147| 0029FC lfd      C9180008   1     LFL       fp8=dvl3ai(gr24,8)
    0| 002A00 lfdu     CD390010   1     LFDU      fp9,gr25=dvl3a(gr25,16)
    0| 002A04 lfdu     CD5A0010   1     LFDU      fp10,gr26=sflx[](gr26,16)
  147| 002A08 lfdu     CD780010   1     LFDU      fp11,gr24=dvl3ai(gr24,16)
    0| 002A0C fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
    0| 002A10 fadd     FC87202A   2     AFL       fp4=fp7,fp4,fcr
  147| 002A14 fmul     FC880132   2     MFL       fp4=fp8,fp4,fcr
  147| 002A18 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 002A1C lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 002A20 fmsub    FC845278   1     FMS       fp4=fp10,fp4,fp9,fcr
    0| 002A24 fadd     FC86202A   2     AFL       fp4=fp6,fp4,fcr
  147| 002A28 fmul     FC8B0132   2     MFL       fp4=fp11,fp4,fcr
  147| 002A2C stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 002A30 bc       4192E9B0   1     BT        CL.71,cr4,0x4/eq,taken=20%(20,80)
    0| 002A34 ori      60210000   1     XNOP      
    0|                              CL.566:
    0| 002A38 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s1[](gr27,gr4,0)
    0| 002A3C lfd      C8D90008   1     LFL       fp6=dvl3a(gr25,8)
    0| 002A40 lfd      C89A0008   1     LFL       fp4=sflx[](gr26,8)
    0| 002A44 lfd      C8FA0000   1     LFL       fp7=sflx[](gr26,0)
    0| 002A48 fmsub    FCA521B8   1     FMS       fp5=fp4-fp6,fcr
  147| 002A4C lfd      C8D80008   1     LFL       fp6=dvl3ai(gr24,8)
    0| 002A50 fadd     FCA7282A   1     AFL       fp5=fp7,fp5,fcr
  147| 002A54 fmul     FCA60172   2     MFL       fp5=fp6,fp5,fcr
    0| 002A58 lfd      C8D90010   1     LFL       fp6=dvl3a(gr25,16)
    0| 002A5C lfd      C8FA0010   1     LFL       fp7=sflx[](gr26,16)
  147| 002A60 stfd     D8BB0000   1     STFL      s1[](gr27,0)=fp5
    0| 002A64 lfdux    7CBB24EE   1     LFDU      fp5,gr27=s1[](gr27,gr4,0)
    0| 002A68 fmsub    FCA539B8   1     FMS       fp5=fp7,fp5,fp6,fcr
  147| 002A6C lfd      C8D80010   1     LFL       fp6=dvl3ai(gr24,16)
    0| 002A70 fadd     FC84282A   1     AFL       fp4=fp4,fp5,fcr
  147| 002A74 fmul     FC860132   2     MFL       fp4=fp6,fp4,fcr
    0| 002A78 lfd      C8B90018   1     LFL       fp5=dvl3a(gr25,24)
    0| 002A7C lfd      C8DA0018   1     LFL       fp6=sflx[](gr26,24)
  147| 002A80 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 002A84 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 002A88 fmsub    FC843178   1     FMS       fp4=fp6,fp4,fp5,fcr
  147| 002A8C lfd      C8B80018   1     LFL       fp5=dvl3ai(gr24,24)
    0| 002A90 fadd     FC87202A   1     AFL       fp4=fp7,fp4,fcr
  147| 002A94 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
    0| 002A98 lfdu     CCB90020   1     LFDU      fp5,gr25=dvl3a(gr25,32)
    0| 002A9C lfdu     CCFA0020   1     LFDU      fp7,gr26=sflx[](gr26,32)
  147| 002AA0 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 002AA4 lfdux    7C9B24EE   1     LFDU      fp4,gr27=s1[](gr27,gr4,0)
    0| 002AA8 fmsub    FC843978   1     FMS       fp4=fp7,fp4,fp5,fcr
  147| 002AAC lfdu     CCB80020   1     LFDU      fp5,gr24=dvl3ai(gr24,32)
    0| 002AB0 fadd     FC86202A   1     AFL       fp4=fp6,fp4,fcr
  147| 002AB4 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
  147| 002AB8 stfd     D89B0000   1     STFL      s1[](gr27,0)=fp4
    0| 002ABC bc       4200FF7C   1     BCT       ctr=CL.566,taken=100%(100,0)
    0| 002AC0 b        4BFFE920   1     B         CL.71,-1
   93|                              CL.865:
  251| 002AC4 ld       E9C10380   1     L8        gr14=#stack(gr1,896)
  251| 002AC8 ld       E9E10388   1     L8        gr15=#stack(gr1,904)
  251| 002ACC ld       EA010390   1     L8        gr16=#stack(gr1,912)
  251| 002AD0 ld       EA210398   1     L8        gr17=#stack(gr1,920)
  251| 002AD4 ld       EA4103A0   1     L8        gr18=#stack(gr1,928)
  251| 002AD8 ld       EA6103A8   1     L8        gr19=#stack(gr1,936)
  251| 002ADC ld       EA8103B0   1     L8        gr20=#stack(gr1,944)
  251| 002AE0 ld       EAA103B8   1     L8        gr21=#stack(gr1,952)
  251| 002AE4 ld       EAC103C0   1     L8        gr22=#stack(gr1,960)
  251| 002AE8 ld       EAE103C8   1     L8        gr23=#stack(gr1,968)
  251| 002AEC ld       EB0103D0   1     L8        gr24=#stack(gr1,976)
  251| 002AF0 ld       EB2103D8   1     L8        gr25=#stack(gr1,984)
  251| 002AF4 ld       EB4103E0   1     L8        gr26=#stack(gr1,992)
  251| 002AF8 ld       EB6103E8   1     L8        gr27=#stack(gr1,1000)
  251| 002AFC ld       EB8103F0   1     L8        gr28=#stack(gr1,1008)
  251| 002B00 ld       EBA103F8   1     L8        gr29=#stack(gr1,1016)
  251| 002B04 ld       EBC10400   1     L8        gr30=#stack(gr1,1024)
  251| 002B08 ld       EBE10408   1     L8        gr31=#stack(gr1,1032)
  251| 002B0C addi     382104A0   1     AI        gr1=gr1,1184
  251| 002B10 bclr     4E800020   1     BA        lr
     |               Tag Table
     | 002B14        00000000 00012202 92120000 00002B14
     |               Instruction count         2757
     |               Straight-line exec time   3529
     |               Constant Area
     | 000000        3F000000 3F800000 00000000 49424D20 2B617F7D 4ED8C33E
     | 000018        55555555 55555556

 
 
>>>>> COMPILATION UNIT EPILOGUE SECTION <<<<<
 
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    momx3.f90                   07/08/15   15:48:18
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
 
    Source records read.......................................     259
1501-510  Compilation successful for file momx3.f90.
1501-543  Object file created.
