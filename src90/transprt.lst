IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- transprt.f90 07/08/15 15:48:38
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
 "transprt.f90", line 114.17: 1513-029 (W) The number of arguments to "advx1" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 115.17: 1513-029 (W) The number of arguments to "advx2" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 116.17: 1513-029 (W) The number of arguments to "advx3" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 134.17: 1513-029 (W) The number of arguments to "advx2" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 135.17: 1513-029 (W) The number of arguments to "advx1" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 136.17: 1513-029 (W) The number of arguments to "advx3" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 158.17: 1513-029 (W) The number of arguments to "advx2" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 159.17: 1513-029 (W) The number of arguments to "advx3" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 160.17: 1513-029 (W) The number of arguments to "advx1" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 182.17: 1513-029 (W) The number of arguments to "advx3" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 183.17: 1513-029 (W) The number of arguments to "advx2" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 184.17: 1513-029 (W) The number of arguments to "advx1" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 206.17: 1513-029 (W) The number of arguments to "advx3" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 207.17: 1513-029 (W) The number of arguments to "advx1" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 208.17: 1513-029 (W) The number of arguments to "advx2" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 230.17: 1513-029 (W) The number of arguments to "advx1" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 231.17: 1513-029 (W) The number of arguments to "advx3" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
 "transprt.f90", line 232.17: 1513-029 (W) The number of arguments to "advx2" differs from the number of arguments in a previous reference. You should use the OPTIONAL attribute and an explicit interface to define a procedure with optional arguments.
** transprt   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-534 (I) Loop (loop index 1) at transprt.f90 <line 80> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 2) at transprt.f90 <line 81> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 3) at transprt.f90 <line 82> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3da%addr  + d-w3da%rvo))->w3da[].rns0.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] = (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] *  5.0000000000000000E-001) * (((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long long) js + $$CIV2][($$CIV1 + (long long) is) - 1ll] + ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1]); with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at transprt.f90 <line 82> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dc%addr  + d-w3dc%rvo))->w3dc[].rns6.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] = (((((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns9.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] *  5.0000000000000000E-001) * (((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[($$CIV3 + (long long) ks) - 1ll][(long long) js + $$CIV2][(long long) is + $$CIV1] + ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1])) * ((double *)((char *)d-g31b%addr  + d-g31b%rvo))->g31b[].rns8.[(long long) is + $$CIV1]) * ((double *)((char *)d-g32b%addr  + d-g32b%rvo))->g32b[].rns7.[(long long) js + $$CIV2]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at transprt.f90 <line 82> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns3.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] = ((((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns5.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] *  5.0000000000000000E-001) * (((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][($$CIV2 + (long long) js) - 1ll][(long long) is + $$CIV1] + ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1])) * ((double *)((char *)d-g2b%addr  + d-g2b%rvo))->g2b[].rns4.[(long long) is + $$CIV1]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 3) at transprt.f90 <line 83> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*((long long) ks + $$CIV3) + (d-w3da%bounds%mult[].off1248)*((long long) js + $$CIV2) + (d-w3da%bounds%mult[].off1272)*((long long) is + $$CIV1)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 3) at transprt.f90 <line 83> was not SIMD vectorized because it contains operation in (((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns2.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] *  5.0000000000000000E-001) * (((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long long) js + $$CIV2][($$CIV1 + (long long) is) - 1ll] + ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1]) which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 3) at transprt.f90 <line 83> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*((long long) ks + $$CIV3) + (d-w3da%bounds%mult[].off1248)*((long long) js + $$CIV2) + (d-w3da%bounds%mult[].off1272)*((long long) is + $$CIV1)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at transprt.f90 <line 83> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at transprt.f90 <line 83> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*((long long) ks + $$CIV3) + (d-w3da%bounds%mult[].off1248)*((long long) js + $$CIV2) + (d-w3da%bounds%mult[].off1272)*((long long) is + $$CIV1)).
1586-536 (I) Loop (loop index 3) at transprt.f90 <line 86> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*((long long) ks + $$CIV3) + (d-w3dc%bounds%mult[].off1456)*((long long) js + $$CIV2) + (d-w3dc%bounds%mult[].off1480)*((long long) is + $$CIV1)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 3) at transprt.f90 <line 86> was not SIMD vectorized because it contains operation in (((((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns9.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] *  5.0000000000000000E-001) * (((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[($$CIV3 + (long long) ks) - 1ll][(long long) js + $$CIV2][(long long) is + $$CIV1] + ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1])) * ((double *)((char *)d-g31b%addr  + d-g31b%rvo))->g31b[].rns8.[(long long) is + $$CIV1]) * ((double *)((char *)d-g32b%addr  + d-g32b%rvo))->g32b[].rns7.[(long long) js + $$CIV2] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 3) at transprt.f90 <line 86> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*((long long) ks + $$CIV3) + (d-w3dc%bounds%mult[].off1456)*((long long) js + $$CIV2) + (d-w3dc%bounds%mult[].off1480)*((long long) is + $$CIV1)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at transprt.f90 <line 86> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at transprt.f90 <line 86> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*((long long) ks + $$CIV3) + (d-w3dc%bounds%mult[].off1456)*((long long) js + $$CIV2) + (d-w3dc%bounds%mult[].off1480)*((long long) is + $$CIV1)).
1586-536 (I) Loop (loop index 3) at transprt.f90 <line 84> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*((long long) ks + $$CIV3) + (d-w3db%bounds%mult[].off1352)*((long long) js + $$CIV2) + (d-w3db%bounds%mult[].off1376)*((long long) is + $$CIV1)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 3) at transprt.f90 <line 84> was not SIMD vectorized because it contains operation in ((((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns5.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1] *  5.0000000000000000E-001) * (((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][($$CIV2 + (long long) js) - 1ll][(long long) is + $$CIV1] + ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long long) js + $$CIV2][(long long) is + $$CIV1])) * ((double *)((char *)d-g2b%addr  + d-g2b%rvo))->g2b[].rns4.[(long long) is + $$CIV1] which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 3) at transprt.f90 <line 84> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*((long long) ks + $$CIV3) + (d-w3db%bounds%mult[].off1352)*((long long) js + $$CIV2) + (d-w3db%bounds%mult[].off1376)*((long long) is + $$CIV1)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at transprt.f90 <line 84> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at transprt.f90 <line 84> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*((long long) ks + $$CIV3) + (d-w3db%bounds%mult[].off1352)*((long long) js + $$CIV2) + (d-w3db%bounds%mult[].off1376)*((long long) is + $$CIV1)).
1586-534 (I) Loop (loop index 4) at transprt.f90 <line 246> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 5) at transprt.f90 <line 262> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 6) at transprt.f90 <line 263> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 7) at transprt.f90 <line 264> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dh%addr  + d-w3dh%rvo))->w3dh[].rns258.[2ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV6][(long long) is + $$CIV5] = ((double *)((char *)d-er%addr  + d-er%rvo))->er[].rns259.[2ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV6][(long long) is + $$CIV5]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 7) at transprt.f90 <line 264> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dh%addr  + d-w3dh%rvo))->w3dh[].rns258.[($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks][(long long) js + $$CIV6][(long long) is + $$CIV5] = ((double *)((char *)d-er%addr  + d-er%rvo))->er[].rns259.[($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks][(long long) js + $$CIV6][(long long) is + $$CIV5]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 7) at transprt.f90 <line 264> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dh%addr  + d-w3dh%rvo))->w3dh[].rns258.[3ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV6][(long long) is + $$CIV5] = ((double *)((char *)d-er%addr  + d-er%rvo))->er[].rns259.[3ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV6][(long long) is + $$CIV5]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 7) at transprt.f90 <line 264> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dh%addr  + d-w3dh%rvo))->w3dh[].rns258.[1ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV6][(long long) is + $$CIV5] = ((double *)((char *)d-er%addr  + d-er%rvo))->er[].rns259.[1ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV6][(long long) is + $$CIV5]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(2ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(2ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(2ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)).
1586-536 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)).
1586-536 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(3ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(3ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(3ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)).
1586-536 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(1ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(1ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 7) at transprt.f90 <line 265> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(1ll + (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)).
1586-550 (I) Loop (loop index 8) at transprt.f90 <line 270> was not SIMD vectorized because it is not profitable to vectorize.
1586-551 (I) Loop (loop index 8) at transprt.f90 <line 271> was not SIMD vectorized because it contains unsupported vector data types.
1586-550 (I) Loop (loop index 9) at transprt.f90 <line 246> was not SIMD vectorized because it is not profitable to vectorize.
1586-551 (I) Loop (loop index 9) at transprt.f90 <line 247> was not SIMD vectorized because it contains unsupported vector data types.
1586-551 (I) Loop (loop index 9) at transprt.f90 <line 247> was not SIMD vectorized because it contains unsupported vector data types.
1586-551 (I) Loop (loop index 9) at transprt.f90 <line 247> was not SIMD vectorized because it contains unsupported vector data types.
1586-534 (I) Loop (loop index 13) at transprt.f90 <line 262> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 14) at transprt.f90 <line 263> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 15) at transprt.f90 <line 264> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dh%addr  + d-w3dh%rvo))->w3dh[].rns258.[(long long) ks + $$CIV7][(long long) js + $$CIV6][(long long) is + $$CIV5] = ((double *)((char *)d-er%addr  + d-er%rvo))->er[].rns259.[(long long) ks + $$CIV7][(long long) js + $$CIV6][(long long) is + $$CIV5]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 15) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*((long long) ks + $$CIV7) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 15) at transprt.f90 <line 265> was not SIMD vectorized because it contains memory references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*((long long) ks + $$CIV7) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at transprt.f90 <line 265> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at transprt.f90 <line 265> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dh%addr  + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*((long long) ks + $$CIV7) + (d-w3dh%bounds%mult[].off2184)*((long long) js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) is + $$CIV5)).
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"5">. Total number of the innermost loops SIMD vectorized <"0">.


    11|         SUBROUTINE transprt ()
    65|           IF (.NOT.0 <> ((xhydro  .XOR.  1)  .AND.  1)) THEN
    67|             IF ((0 <> (xmhd  .AND.  1))) THEN
    71|               CALL ct()
    72|             ENDIF
    80|             IF ((1 + (int(ke) - int(ks)) > 0)) THEN
                      $$CIV3 = 0
       Id=1           DO $$CIV3 = $$CIV3, int((1 + (int(ke) - int(ks))))-1
    81|                 IF ((1 + (int(je) - int(js)) > 0)) THEN
                          $$CIV2 = 0
       Id=2               DO $$CIV2 = $$CIV2, int((1 + (int(je) - int(js))))&
                &             -1
    82|                     IF ((1 + (int(ie) - int(is)) > 0)) THEN
                              $$CIV1 = 0
                              $$PRC0 = d-d%addr%d(int(is) - 1,$$CIV2 + int(js),&
                &               $$CIV3 + int(ks))
       Id=3                   DO $$CIV1 = $$CIV1, int((1 + (int(ie) - int(is))&
                &                 ))-1
                                $$PRC1 = d-d%addr%d(int(is) + $$CIV1,$$CIV2 + &
                &                 int(js),$$CIV3 + int(ks))
    83|                         d-w3da%addr%w3da(int(is) + $$CIV1,int(js) + &
                &                 $$CIV2,int(ks) + $$CIV3) = (d-v1%addr%v1(int(is)&
                &                  + $$CIV1,int(js) + $$CIV2,int(ks) + $$CIV3) *  &
                &                 5.0000000000000000E-001) * ($$PRC0 + $$PRC1)
    84|                         d-w3db%addr%w3db(int(is) + $$CIV1,int(js) + &
                &                 $$CIV2,int(ks) + $$CIV3) = ((d-v2%addr%v2(int(&
                &                 is) + $$CIV1,int(js) + $$CIV2,int(ks) + $$CIV3) &
                &                 *  5.0000000000000000E-001) * (d-d%addr%d(int(&
                &                 is) + $$CIV1,($$CIV2 + int(js)) - 1,int(ks) + &
                &                 $$CIV3) + $$PRC1)) * d-g2b%addr%g2b(int(is) + &
                &                 $$CIV1)
    86|                         d-w3dc%addr%w3dc(int(is) + $$CIV1,int(js) + &
                &                 $$CIV2,int(ks) + $$CIV3) = (((d-v3%addr%v3(int(&
                &                 is) + $$CIV1,int(js) + $$CIV2,int(ks) + $$CIV3) &
                &                 *  5.0000000000000000E-001) * (d-d%addr%d(int(&
                &                 is) + $$CIV1,int(js) + $$CIV2,($$CIV3 + int(ks))&
                &                  - 1) + $$PRC1)) * d-g31b%addr%g31b(int(is) + &
                &                 $$CIV1)) * d-g32b%addr%g32b(int(js) + $$CIV2)
                                $$PRC0 = $$PRC1
    88|                       ENDDO
                            ENDIF
    89|                   ENDDO
                        ENDIF
    90|               ENDDO
                    ENDIF
    97|             nseq = 0
    98|             IF ((ix1x2x3 == 1)) THEN
   106|               IF ((lrad <> 0)) THEN
   107|                 CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,d-w3dg%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr,&
                &         d-er%addr,d-w3dh%addr,d-abun%addr,d-w4da%addr)
   109|                 CALL advx2(d-d%addr,d-w3dd%addr,d-w3dg%addr,d-w3de%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr,&
                &         d-w3dh%addr,d-er%addr,d-w4da%addr,d-abun%addr)
   111|                 CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,d-w3dg%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr,&
                &         d-er%addr,d-w3dh%addr,d-abun%addr,d-w4da%addr)
   113|               ELSE
   114|                 CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,d-w3dg%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr)
   115|                 CALL advx2(d-d%addr,d-w3dd%addr,d-w3dg%addr,d-w3de%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr)
   116|                 CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,d-w3dg%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr)
   117|               ENDIF
   119|               ix1x2x3 = 2
   120|             ELSE
   124|               lab_16
                      IF ((ix1x2x3 == 2)) THEN
   126|                 IF ((lrad <> 0)) THEN
   127|                   CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &           d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &           d-w4da%addr)
   129|                   CALL advx1(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &           d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &           d-abun%addr)
   131|                   CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &           d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &           d-w4da%addr)
   133|                 ELSE
   134|                   CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &           d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr)
   135|                   CALL advx1(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &           d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr)
   136|                   CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &           d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr)
   137|                 ENDIF
   139|                 ix1x2x3 = 3
   140|               ELSE
   144|                 lab_21
                        IF ((ix1x2x3 == 3)) THEN
   150|                   IF ((lrad <> 0)) THEN
   151|                     CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &             d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &             d-w4da%addr)
   153|                     CALL advx3(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &             d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &             d-abun%addr)
   155|                     CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &             d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &             d-w4da%addr)
   157|                   ELSE
   158|                     CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &             d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr)
   159|                     CALL advx3(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &             d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr)
   160|                     CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &             d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr)
   161|                   ENDIF
   163|                   ix1x2x3 = 4
   164|                 ELSE
   168|                   lab_25
                          IF ((ix1x2x3 == 4)) THEN
   174|                     IF ((lrad <> 0)) THEN
   175|                       CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   177|                       CALL advx2(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &               d-abun%addr)
   179|                       CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   181|                     ELSE
   182|                       CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   183|                       CALL advx2(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   184|                       CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   185|                     ENDIF
   187|                     ix1x2x3 = 5
   188|                   ELSE
   192|                     lab_29
                            IF (.NOT.(ix1x2x3 == 5)) GOTO lab_33
   198|                     IF ((lrad <> 0)) THEN
   199|                       CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   201|                       CALL advx1(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &               d-abun%addr)
   203|                       CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   205|                     ELSE
   206|                       CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   207|                       CALL advx1(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   208|                       CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   209|                     ENDIF
   211|                     ix1x2x3 = 6
   212|                     GOTO lab_19
   216|                     lab_33
   222|                     IF ((lrad <> 0)) THEN
   223|                       CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   225|                       CALL advx3(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &               d-abun%addr)
   227|                       CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   229|                     ELSE
   230|                       CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   231|                       CALL advx3(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   232|                       CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   233|                     ENDIF
   235|                     ix1x2x3 = 1
   241|                     lab_19
   246|                     IF (.FALSE.) GOTO lab_67
                            $$CIV9 = int(0)
       Id=4                 DO $$CIV9 = $$CIV9, 0
   246Id=4                       IF (.FALSE.) GOTO lab_78
                              $$LoopIV1 = 0
       Id=9                   DO $$LoopIV1 = $$LoopIV1, 5
   247|                         bvstat($$LoopIV1 + 1,int(int(($$CIV9 * 3))) + 3)&
                &                  = 0
                                bvstat($$LoopIV1 + 1,int(int(($$CIV9 * 3 + 1))) &
                &                 + 3) = 0
                                bvstat($$LoopIV1 + 1,int(int(($$CIV9 * 3 + 2))) &
                &                 + 3) = 0
   247|                       ENDDO
                              lab_78
   250|                     ENDDO
                            lab_67
   246|                   ELSE
   256|                     lab_2
   257|                     IF ((lrad <> 0)) THEN
   262|                       IF ((MOD((1 + (int(ke) - int(ks))), 4) > 0  .AND. &
                &                1 + (int(ke) - int(ks)) > 0)) THEN
                                $$CIV7 = 0
       Id=13                    DO $$CIV7 = $$CIV7, MOD((1 + (int(ke) - int(&
                &                   ks))), int(4))-1
   263|                           IF ((1 + (int(je) - int(js)) > 0)) THEN
                                    $$CIV6 = 0
       Id=14                        DO $$CIV6 = $$CIV6, int((1 + (int(je) - &
                &                       int(js))))-1
   264|                               IF ((1 + (int(ie) - int(is)) > 0)) THEN
                                        $$CIV5 = 0
       Id=15                            DO $$CIV5 = $$CIV5, int((1 + (int(ie) &
                &                           - int(is))))-1
   265|                                   d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,int(ks) + $$CIV7) = &
                &                           d-er%addr%er(int(is) + $$CIV5,int(js) &
                &                           + $$CIV6,int(ks) + $$CIV7)
   266|                                 ENDDO
                                      ENDIF
   267|                             ENDDO
                                  ENDIF
   268|                         ENDDO
                              ENDIF
   262|                       IF ((1 + (int(ke) - int(ks)) > 0  .AND.  1 + (int(&
                &               ke) - int(ks)) > MOD((1 + (int(ke) - int(ks))), 4)&
                &               )) THEN
                                $$CIVA = int(0)
       Id=5                     DO $$CIVA = $$CIVA, int(((int(ke) - (MOD((1 + &
                &                   (int(ke) - int(ks))), 4) + int(ks))) / 4 + 1))&
                &                   -1
   263|                           IF ((1 + (int(je) - int(js)) > 0)) THEN
                                    $$CIV6 = 0
       Id=6                         DO $$CIV6 = $$CIV6, int((1 + (int(je) - &
                &                       int(js))))-1
   264|                               IF ((1 + (int(ie) - int(is)) > 0)) THEN
                                        $$CIV5 = 0
       Id=7                             DO $$CIV5 = $$CIV5, int((1 + (int(ie) &
                &                           - int(is))))-1
   265|                                   d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,($$CIVA * 4 + MOD((1 + (&
                &                           int(ke) - int(ks))), 4)) + int(ks)) = &
                &                           d-er%addr%er(int(is) + $$CIV5,int(js) &
                &                           + $$CIV6,($$CIVA * 4 + MOD((1 + (int(&
                &                           ke) - int(ks))), 4)) + int(ks))
                                          d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,1 + (($$CIVA * 4 + MOD((&
                &                           1 + (int(ke) - int(ks))), 4)) + int(&
                &                           ks))) = d-er%addr%er(int(is) + $$CIV5,&
                &                           int(js) + $$CIV6,1 + (($$CIVA * 4 + &
                &                           MOD((1 + (int(ke) - int(ks))), 4)) + &
                &                           int(ks)))
                                          d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,2 + (($$CIVA * 4 + MOD((&
                &                           1 + (int(ke) - int(ks))), 4)) + int(&
                &                           ks))) = d-er%addr%er(int(is) + $$CIV5,&
                &                           int(js) + $$CIV6,2 + (($$CIVA * 4 + &
                &                           MOD((1 + (int(ke) - int(ks))), 4)) + &
                &                           int(ks)))
                                          d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,3 + (($$CIVA * 4 + MOD((&
                &                           1 + (int(ke) - int(ks))), 4)) + int(&
                &                           ks))) = d-er%addr%er(int(is) + $$CIV5,&
                &                           int(js) + $$CIV6,3 + (($$CIVA * 4 + &
                &                           MOD((1 + (int(ke) - int(ks))), 4)) + &
                &                           int(ks)))
   266|                                 ENDDO
                                      ENDIF
   267|                             ENDDO
                                  ENDIF
   268|                         ENDDO
                              ENDIF
   270|                       IF (.FALSE.) GOTO lab_75
                              $$CIV8 = 0
       Id=8                   DO $$CIV8 = $$CIV8, 5
   271|                         bvstat($$CIV8 + 1,6) = 0
   272|                       ENDDO
                              lab_75
   274|                       lab_44
   277|                       lab_77
                              RETURN
                            END SUBROUTINE transprt


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0            80             1    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            81             2    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*((long long) ks + 
                                          $$CIV3) + (d-w3da%bounds%mult[].off1248)*((long long) 
                                          js + $$CIV2) + (d-w3da%bounds%mult[].off1272)*((long 
                                          long) is + $$CIV1))  with non-vectorizable alignment.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-v1%addr  + 
                                          d-v1%rvo))->v1[].rns2.[(long long) ks + $$CIV3][(long 
                                          long) js + $$CIV2][(long long) is + $$CIV1] *  
                                          5.0000000000000000E-001) * (((double *)((char 
                                          *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + 
                                          $$CIV3][(long long) js + $$CIV2][($$CIV1 + (long 
                                          long) is) - 1ll] + ((double *)((char *)d-d%addr  + 
                                          d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long 
                                          long) js + $$CIV2][(long long) is + $$CIV1]) which is 
                                          not  suitable for SIMD vectorization.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*((long long) ks + 
                                          $$CIV3) + (d-w3da%bounds%mult[].off1248)*((long long) 
                                          js + $$CIV2) + (d-w3da%bounds%mult[].off1272)*((long 
                                          long) is + $$CIV1)) with  non-vectorizable strides.
         0            83                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            83                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3da%addr 
                                          + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*((long 
                                          long) ks + $$CIV3) + 
                                          (d-w3da%bounds%mult[].off1248)*((long long) js + 
                                          $$CIV2) + (d-w3da%bounds%mult[].off1272)*((long long) 
                                          is + $$CIV1)).
         0            84                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*((long long) ks + 
                                          $$CIV3) + (d-w3db%bounds%mult[].off1352)*((long long) 
                                          js + $$CIV2) + (d-w3db%bounds%mult[].off1376)*((long 
                                          long) is + $$CIV1))  with non-vectorizable alignment.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          operation in ((((double *)((char *)d-v2%addr  + 
                                          d-v2%rvo))->v2[].rns5.[(long long) ks + $$CIV3][(long 
                                          long) js + $$CIV2][(long long) is + $$CIV1] *  
                                          5.0000000000000000E-001) * (((double *)((char 
                                          *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + 
                                          $$CIV3][($$CIV2 + (long long) js) - 1ll][(long long) 
                                          is + $$CIV1] + ((double *)((char *)d-d%addr  + 
                                          d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long 
                                          long) js + $$CIV2][(long long) is + $$CIV1])) * 
                                          ((double *)((char *)d-g2b%addr  + 
                                          d-g2b%rvo))->g2b[].rns4.[(long long) is + $$CIV1] 
                                          which is not  suitable for SIMD vectorization.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*((long long) ks + 
                                          $$CIV3) + (d-w3db%bounds%mult[].off1352)*((long long) 
                                          js + $$CIV2) + (d-w3db%bounds%mult[].off1376)*((long 
                                          long) is + $$CIV1)) with  non-vectorizable strides.
         0            84                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            84                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*((long 
                                          long) ks + $$CIV3) + 
                                          (d-w3db%bounds%mult[].off1352)*((long long) js + 
                                          $$CIV2) + (d-w3db%bounds%mult[].off1376)*((long long) 
                                          is + $$CIV1)).
         0            86                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*((long long) ks + 
                                          $$CIV3) + (d-w3dc%bounds%mult[].off1456)*((long long) 
                                          js + $$CIV2) + (d-w3dc%bounds%mult[].off1480)*((long 
                                          long) is + $$CIV1))  with non-vectorizable alignment.
         0            86                  Loop was not SIMD vectorized because it contains 
                                          operation in (((((double *)((char *)d-v3%addr  + 
                                          d-v3%rvo))->v3[].rns9.[(long long) ks + $$CIV3][(long 
                                          long) js + $$CIV2][(long long) is + $$CIV1] *  
                                          5.0000000000000000E-001) * (((double *)((char 
                                          *)d-d%addr  + d-d%rvo))->d[].rns1.[($$CIV3 + (long 
                                          long) ks) - 1ll][(long long) js + $$CIV2][(long long) 
                                          is + $$CIV1] + ((double *)((char *)d-d%addr  + 
                                          d-d%rvo))->d[].rns1.[(long long) ks + $$CIV3][(long 
                                          long) js + $$CIV2][(long long) is + $$CIV1])) * 
                                          ((double *)((char *)d-g31b%addr  + 
                                          d-g31b%rvo))->g31b[].rns8.[(long long) is + $$CIV1]) 
                                          * ((double *)((char *)d-g32b%addr  + 
                                          d-g32b%rvo))->g32b[].rns7.[(long long) js + $$CIV2] 
                                          which is not  suitable for SIMD vectorization.
         0            86                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*((long long) ks + 
                                          $$CIV3) + (d-w3dc%bounds%mult[].off1456)*((long long) 
                                          js + $$CIV2) + (d-w3dc%bounds%mult[].off1480)*((long 
                                          long) is + $$CIV1)) with  non-vectorizable strides.
         0            86                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            86                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dc%addr 
                                          + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*((long 
                                          long) ks + $$CIV3) + 
                                          (d-w3dc%bounds%mult[].off1456)*((long long) js + 
                                          $$CIV2) + (d-w3dc%bounds%mult[].off1480)*((long long) 
                                          is + $$CIV1)).
         0           246             4    Loop interchanging applied to loop nest.
         0           246             4    Outer loop has been unrolled 3 time(s).
         0           246             4    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
                                     9    Loop has been rolled.
                                     9    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0           247                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.
         0           247                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.
         0           247                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.
         0           262            13    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           263            14    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*((long long) ks + 
                                          $$CIV7) + (d-w3dh%bounds%mult[].off2184)*((long long) 
                                          js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long 
                                          long) is + $$CIV5))  with non-vectorizable alignment.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*((long long) ks + 
                                          $$CIV7) + (d-w3dh%bounds%mult[].off2184)*((long long) 
                                          js + $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long 
                                          long) is + $$CIV5)) with  non-vectorizable strides.
         0           265                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dh%addr 
                                          + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*((long 
                                          long) ks + $$CIV7) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5)).
         0           262             5    Outer loop has been unrolled 4 time(s).
         0           262             5    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           263             6    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*(($$CIVA * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5))  with non-vectorizable alignment.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*(($$CIVA * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5)) with  non-vectorizable strides.
         0           265                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dh%addr 
                                          + d-w3dh%rvo + 
                                          (d-w3dh%bounds%mult[].off2160)*(($$CIVA * 4ll + (1ll 
                                          + ((long long) ke - (long long) ks)) % 4ll) + (long 
                                          long) ks) + (d-w3dh%bounds%mult[].off2184)*((long 
                                          long) js + $$CIV6) + 
                                          (d-w3dh%bounds%mult[].off2208)*((long long) is + 
                                          $$CIV5)).
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*(1ll + (($$CIVA * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5))  with non-vectorizable alignment.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*(1ll + (($$CIVA * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5)) with  non-vectorizable strides.
         0           265                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dh%addr 
                                          + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(1ll + 
                                          (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) 
                                          ks)) % 4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5)).
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*(2ll + (($$CIVA * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5))  with non-vectorizable alignment.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*(2ll + (($$CIVA * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5)) with  non-vectorizable strides.
         0           265                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dh%addr 
                                          + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(2ll + 
                                          (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) 
                                          ks)) % 4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5)).
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*(3ll + (($$CIVA * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5))  with non-vectorizable alignment.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dh%addr  + d-w3dh%rvo 
                                          + (d-w3dh%bounds%mult[].off2160)*(3ll + (($$CIVA * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5)) with  non-vectorizable strides.
         0           265                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           265                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dh%addr 
                                          + d-w3dh%rvo + (d-w3dh%bounds%mult[].off2160)*(3ll + 
                                          (($$CIVA * 4ll + (1ll + ((long long) ke - (long long) 
                                          ks)) % 4ll) + (long long) ks)) + 
                                          (d-w3dh%bounds%mult[].off2184)*((long long) js + 
                                          $$CIV6) + (d-w3dh%bounds%mult[].off2208)*((long long) 
                                          is + $$CIV5)).
         0           270             8    Loop was not SIMD vectorized because it is not 
                                          profitable to vectorize.
         0           271                  Loop was not SIMD vectorized because it contains 
                                          unsupported vector data types.


    11|         SUBROUTINE transprt ()
    65|           IF (.NOT.0 <> ((xhydro  .XOR.  1)  .AND.  1)) THEN
    67|             IF ((0 <> (xmhd  .AND.  1))) THEN
    71|               CALL ct()
    72|             ENDIF
    80|             IF ((1 + (int(ke) - int(ks)) > 0)) THEN
                      $$CIV3 = 0
       Id=1           DO $$CIV3 = $$CIV3, int((1 + (int(ke) - int(ks))))-1
    81|                 IF ((1 + (int(je) - int(js)) > 0)) THEN
                          $$CIV2 = 0
       Id=2               DO $$CIV2 = $$CIV2, int((1 + (int(je) - int(js))))&
                &             -1
    82|                     IF ((1 + (int(ie) - int(is)) > 0)) THEN
                              $$CIV1 = 0
                              $$PRC0 = d-d%addr%d(int(is) - 1,$$CIV2 + int(js),&
                &               $$CIV3 + int(ks))
                              $$ICM0 = int(js) + $$CIV2
                              $$ICM1 = int(ks) + $$CIV3
    86|                       $$ICM2 = d-g32b%addr%g32b(int(js) + $$CIV2)
    82|Id=3                   DO $$CIV1 = $$CIV1, int((1 + (int(ie) - int(is))&
                &                 ))-1
                                $$PRC1 = d-d%addr%d(int(is) + $$CIV1,$$ICM0,&
                &                 $$ICM1)
    83|                         d-w3da%addr%w3da(int(is) + $$CIV1,$$ICM0,$$ICM1)&
                &                  = (d-v1%addr%v1(int(is) + $$CIV1,$$ICM0,$$ICM1)&
                &                  *  5.0000000000000000E-001) * ($$PRC0 + $$PRC1)&
                &                 
    84|                         d-w3db%addr%w3db(int(is) + $$CIV1,$$ICM0,$$ICM1)&
                &                  = ((d-v2%addr%v2(int(is) + $$CIV1,$$ICM0,&
                &                 $$ICM1) *  5.0000000000000000E-001) * (&
                &                 d-d%addr%d(int(is) + $$CIV1,($$CIV2 + int(js)) &
                &                 - 1,$$ICM1) + $$PRC1)) * d-g2b%addr%g2b(int(is) &
                &                 + $$CIV1)
    86|                         d-w3dc%addr%w3dc(int(is) + $$CIV1,$$ICM0,$$ICM1)&
                &                  = (((d-v3%addr%v3(int(is) + $$CIV1,$$ICM0,&
                &                 $$ICM1) *  5.0000000000000000E-001) * (&
                &                 d-d%addr%d(int(is) + $$CIV1,$$ICM0,($$CIV3 + &
                &                 int(ks)) - 1) + $$PRC1)) * d-g31b%addr%g31b(int(&
                &                 is) + $$CIV1)) * $$ICM2
                                $$PRC0 = $$PRC1
    88|                       ENDDO
                            ENDIF
    89|                   ENDDO
                        ENDIF
    90|               ENDDO
                    ENDIF
    97|             nseq = 0
    98|             IF ((ix1x2x3 == 1)) THEN
   106|               IF ((lrad <> 0)) THEN
   107|                 CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,d-w3dg%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr,&
                &         d-er%addr,d-w3dh%addr,d-abun%addr,d-w4da%addr)
   109|                 CALL advx2(d-d%addr,d-w3dd%addr,d-w3dg%addr,d-w3de%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr,&
                &         d-w3dh%addr,d-er%addr,d-w4da%addr,d-abun%addr)
   111|                 CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,d-w3dg%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr,&
                &         d-er%addr,d-w3dh%addr,d-abun%addr,d-w4da%addr)
   113|               ELSE
   114|                 CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,d-w3dg%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr)
   115|                 CALL advx2(d-d%addr,d-w3dd%addr,d-w3dg%addr,d-w3de%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr)
   116|                 CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,d-w3dg%addr,&
                &         d-w3df%addr,d-w3da%addr,d-w3db%addr,d-w3dc%addr)
   117|               ENDIF
   119|               ix1x2x3 = 2
   120|             ELSE
   124|               lab_16
                      IF ((ix1x2x3 == 2)) THEN
   126|                 IF ((lrad <> 0)) THEN
   127|                   CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &           d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &           d-w4da%addr)
   129|                   CALL advx1(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &           d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &           d-abun%addr)
   131|                   CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &           d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &           d-w4da%addr)
   133|                 ELSE
   134|                   CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &           d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr)
   135|                   CALL advx1(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &           d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr)
   136|                   CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &           d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &           d-w3dc%addr)
   137|                 ENDIF
   139|                 ix1x2x3 = 3
   140|               ELSE
   144|                 lab_21
                        IF ((ix1x2x3 == 3)) THEN
   150|                   IF ((lrad <> 0)) THEN
   151|                     CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &             d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &             d-w4da%addr)
   153|                     CALL advx3(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &             d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &             d-abun%addr)
   155|                     CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &             d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &             d-w4da%addr)
   157|                   ELSE
   158|                     CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &             d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr)
   159|                     CALL advx3(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &             d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr)
   160|                     CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &             d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &             d-w3dc%addr)
   161|                   ENDIF
   163|                   ix1x2x3 = 4
   164|                 ELSE
   168|                   lab_25
                          IF ((ix1x2x3 == 4)) THEN
   174|                     IF ((lrad <> 0)) THEN
   175|                       CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   177|                       CALL advx2(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &               d-abun%addr)
   179|                       CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   181|                     ELSE
   182|                       CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   183|                       CALL advx2(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   184|                       CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   185|                     ENDIF
   187|                     ix1x2x3 = 5
   188|                   ELSE
   192|                     lab_29
                            IF (.NOT.(ix1x2x3 == 5)) GOTO lab_33
   198|                     IF ((lrad <> 0)) THEN
   199|                       CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   201|                       CALL advx1(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &               d-abun%addr)
   203|                       CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   205|                     ELSE
   206|                       CALL advx3(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   207|                       CALL advx1(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   208|                       CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   209|                     ENDIF
   211|                     ix1x2x3 = 6
   212|                     GOTO lab_19
   216|                     lab_33
   222|                     IF ((lrad <> 0)) THEN
   223|                       CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   225|                       CALL advx3(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-w3dh%addr,d-er%addr,d-w4da%addr,&
                &               d-abun%addr)
   227|                       CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr,d-er%addr,d-w3dh%addr,d-abun%addr,&
                &               d-w4da%addr)
   229|                     ELSE
   230|                       CALL advx1(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   231|                       CALL advx3(d-d%addr,d-w3dd%addr,d-w3dg%addr,&
                &               d-w3de%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   232|                       CALL advx2(d-w3dd%addr,d-d%addr,d-w3de%addr,&
                &               d-w3dg%addr,d-w3df%addr,d-w3da%addr,d-w3db%addr,&
                &               d-w3dc%addr)
   233|                     ENDIF
   235|                     ix1x2x3 = 1
   241|                     lab_19
   246|                     IF (.FALSE.) GOTO lab_67
                            $$CIV9 = int(0)
       Id=4                 DO $$CIV9 = $$CIV9, 0
   246Id=4                       IF (.FALSE.) GOTO lab_78
                              $$LoopIV1 = 0
       Id=9                   DO $$LoopIV1 = $$LoopIV1, 5
   247|                         bvstat($$LoopIV1 + 1,int(int(($$CIV9 * 3))) + 3)&
                &                  = 0
                                bvstat($$LoopIV1 + 1,int(int(($$CIV9 * 3 + 1))) &
                &                 + 3) = 0
                                bvstat($$LoopIV1 + 1,int(int(($$CIV9 * 3 + 2))) &
                &                 + 3) = 0
   247|                       ENDDO
                              lab_78
   250|                     ENDDO
                            lab_67
   246|                   ELSE
   256|                     lab_2
   257|                     IF ((lrad <> 0)) THEN
   262|                       IF ((MOD((1 + (int(ke) - int(ks))), 4) > 0  .AND. &
                &                1 + (int(ke) - int(ks)) > 0)) THEN
                                $$CIV7 = 0
       Id=13                    DO $$CIV7 = $$CIV7, MOD((1 + (int(ke) - int(&
                &                   ks))), int(4))-1
   263|                           IF ((1 + (int(je) - int(js)) > 0)) THEN
                                    $$CIV6 = 0
       Id=14                        DO $$CIV6 = $$CIV6, int((1 + (int(je) - &
                &                       int(js))))-1
   264|                               IF ((1 + (int(ie) - int(is)) > 0)) THEN
                                        $$CIV5 = 0
       Id=15                            DO $$CIV5 = $$CIV5, int((1 + (int(ie) &
                &                           - int(is))))-1
   265|                                   d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,int(ks) + $$CIV7) = &
                &                           d-er%addr%er(int(is) + $$CIV5,int(js) &
                &                           + $$CIV6,int(ks) + $$CIV7)
   266|                                 ENDDO
                                      ENDIF
   267|                             ENDDO
                                  ENDIF
   268|                         ENDDO
                              ENDIF
   262|                       IF ((1 + (int(ke) - int(ks)) > 0  .AND.  1 + (int(&
                &               ke) - int(ks)) > MOD((1 + (int(ke) - int(ks))), 4)&
                &               )) THEN
                                $$CIVA = int(0)
       Id=5                     DO $$CIVA = $$CIVA, int(((int(ke) - (MOD((1 + &
                &                   (int(ke) - int(ks))), 4) + int(ks))) / 4 + 1))&
                &                   -1
   263|                           IF ((1 + (int(je) - int(js)) > 0)) THEN
                                    $$CIV6 = 0
       Id=6                         DO $$CIV6 = $$CIV6, int((1 + (int(je) - &
                &                       int(js))))-1
   264|                               IF ((1 + (int(ie) - int(is)) > 0)) THEN
                                        $$CIV5 = 0
       Id=7                             DO $$CIV5 = $$CIV5, int((1 + (int(ie) &
                &                           - int(is))))-1
   265|                                   d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,($$CIVA * 4 + MOD((1 + (&
                &                           int(ke) - int(ks))), 4)) + int(ks)) = &
                &                           d-er%addr%er(int(is) + $$CIV5,int(js) &
                &                           + $$CIV6,($$CIVA * 4 + MOD((1 + (int(&
                &                           ke) - int(ks))), 4)) + int(ks))
                                          d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,1 + (($$CIVA * 4 + MOD((&
                &                           1 + (int(ke) - int(ks))), 4)) + int(&
                &                           ks))) = d-er%addr%er(int(is) + $$CIV5,&
                &                           int(js) + $$CIV6,1 + (($$CIVA * 4 + &
                &                           MOD((1 + (int(ke) - int(ks))), 4)) + &
                &                           int(ks)))
                                          d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,2 + (($$CIVA * 4 + MOD((&
                &                           1 + (int(ke) - int(ks))), 4)) + int(&
                &                           ks))) = d-er%addr%er(int(is) + $$CIV5,&
                &                           int(js) + $$CIV6,2 + (($$CIVA * 4 + &
                &                           MOD((1 + (int(ke) - int(ks))), 4)) + &
                &                           int(ks)))
                                          d-w3dh%addr%w3dh(int(is) + $$CIV5,int(&
                &                           js) + $$CIV6,3 + (($$CIVA * 4 + MOD((&
                &                           1 + (int(ke) - int(ks))), 4)) + int(&
                &                           ks))) = d-er%addr%er(int(is) + $$CIV5,&
                &                           int(js) + $$CIV6,3 + (($$CIVA * 4 + &
                &                           MOD((1 + (int(ke) - int(ks))), 4)) + &
                &                           int(ks)))
   266|                                 ENDDO
                                      ENDIF
   267|                             ENDDO
                                  ENDIF
   268|                         ENDDO
                              ENDIF
   270|                       IF (.FALSE.) GOTO lab_75
                              $$CIV8 = 0
       Id=8                   DO $$CIV8 = $$CIV8, 5
   271|                         bvstat($$CIV8 + 1,6) = 0
   272|                       ENDDO
                              lab_75
   274|                       lab_44
   277|                       lab_77
                              RETURN
                            END SUBROUTINE transprt

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   ssus ssss ssss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ss--  ---- ---- -sss ssss
 CCR's set/used:   ss-- -sss
     | 000000                           PDEF     transprt
   11|                                  PROC      
    0| 000000 stfd     DBE1FFF8   1     STFL      #stack(gr1,-8)=fp31
    0| 000004 stfd     DBC1FFF0   1     STFL      #stack(gr1,-16)=fp30
    0| 000008 stfd     DBA1FFE8   1     STFL      #stack(gr1,-24)=fp29
    0| 00000C stfd     DB81FFE0   1     STFL      #stack(gr1,-32)=fp28
    0| 000010 stfd     DB61FFD8   1     STFL      #stack(gr1,-40)=fp27
    0| 000014 stfd     DB41FFD0   1     STFL      #stack(gr1,-48)=fp26
    0| 000018 stfd     DB21FFC8   1     STFL      #stack(gr1,-56)=fp25
    0| 00001C std      FBE1FFC0   1     ST8       #stack(gr1,-64)=gr31
    0| 000020 std      FBC1FFB8   1     ST8       #stack(gr1,-72)=gr30
    0| 000024 std      FBA1FFB0   1     ST8       #stack(gr1,-80)=gr29
    0| 000028 std      FB81FFA8   1     ST8       #stack(gr1,-88)=gr28
    0| 00002C std      FB61FFA0   1     ST8       #stack(gr1,-96)=gr27
    0| 000030 std      FB41FF98   1     ST8       #stack(gr1,-104)=gr26
    0| 000034 std      FB21FF90   1     ST8       #stack(gr1,-112)=gr25
    0| 000038 std      FB01FF88   1     ST8       #stack(gr1,-120)=gr24
    0| 00003C std      FAE1FF80   1     ST8       #stack(gr1,-128)=gr23
    0| 000040 std      FAC1FF78   1     ST8       #stack(gr1,-136)=gr22
    0| 000044 std      FAA1FF70   1     ST8       #stack(gr1,-144)=gr21
    0| 000048 std      FA81FF68   1     ST8       #stack(gr1,-152)=gr20
    0| 00004C std      FA61FF60   1     ST8       #stack(gr1,-160)=gr19
    0| 000050 std      FA41FF58   1     ST8       #stack(gr1,-168)=gr18
    0| 000054 std      FA21FF50   1     ST8       #stack(gr1,-176)=gr17
    0| 000058 std      FA01FF48   1     ST8       #stack(gr1,-184)=gr16
    0| 00005C std      F9E1FF40   1     ST8       #stack(gr1,-192)=gr15
    0| 000060 std      F9C1FF38   1     ST8       #stack(gr1,-200)=gr14
    0| 000064 mfspr    7C0802A6   1     LFLR      gr0=lr
    0| 000068 std      F8010010   1     ST8       #stack(gr1,16)=gr0
    0| 00006C stdu     F821FD01   1     ST8U      gr1,#stack(gr1,-768)=gr1
   65| 000070 ld       E8620000   1     L8        gr3=.&&N&&config(gr2,0)
   65| 000074 lwz      80030028   1     L4Z       gr0=<s177:d40:l4>(gr3,40)
   65| 000078 andi.    70000001   1     RN4_R     gr0,cr0=gr0,0,0x1
   65| 00007C bc       41820E88   1     BT        CL.2,cr0,0x4/eq,taken=50%(0,0)
   67| 000080 lwz      80030038   1     L4Z       gr0=<s177:d56:l4>(gr3,56)
   67| 000084 andi.    70000001   1     RN4_R     gr0,cr0=gr0,0,0x1
   67| 000088 bc       4182000C   1     BT        CL.3,cr0,0x4/eq,taken=60%(60,40)
   71| 00008C bl       48000001   1     CALL      ct,0,#ProcAlias",ct",fcr",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   71| 000090 ori      60000000   1
   72|                              CL.3:
   80| 000094 ld       EBA20000   1     L8        gr29=.&&N&&grid(gr2,0)
    0| 000098 ld       E8A20000   1     L8        gr5=.&&N&field(gr2,0)
    0| 00009C ld       E8C20000   1     L8        gr6=.&&N&scratch(gr2,0)
   80| 0000A0 lwa      E81D0016   1     L4A       gr0=<s183:d20:l4>(gr29,20)
   80| 0000A4 lwa      E97D0012   1     L4A       gr11=<s183:d16:l4>(gr29,16)
    0| 0000A8 ld       E8850000   1     L8        gr4=<s39:d0:l8>(gr5,0)
    0| 0000AC ld       E9060498   1     L8        gr8=<s95:d1176:l8>(gr6,1176)
    0| 0000B0 ld       E9260500   1     L8        gr9=<s95:d1280:l8>(gr6,1280)
    0| 0000B4 ld       E9460568   1     L8        gr10=<s95:d1384:l8>(gr6,1384)
   80| 0000B8 std      F96100A8   1     ST8       #SPILL0(gr1,168)=gr11
   80| 0000BC subf     7C6B0050   1     S         gr3=gr0,gr11
   80| 0000C0 addic.   35830001   1     AI_R      gr12,cr0=gr3,1,ca"
   80| 0000C4 std      F98100B0   1     ST8       #SPILL1(gr1,176)=gr12
   80| 0000C8 bc       408105BC   1     BF        CL.61,cr0,0x2/gt,taken=50%(0,0)
   82| 0000CC std      F88100D0   1     ST8       #SPILL5(gr1,208)=gr4
   82| 0000D0 lwa      E81D0002   1     L4A       gr0=<s183:d0:l4>(gr29,0)
   82| 0000D4 ld       E8650060   1     L8        gr3=<s39:d96:l8>(gr5,96)
   81| 0000D8 lwa      EB9D000A   1     L4A       gr28=<s183:d8:l4>(gr29,8)
   83| 0000DC or       7CAF2B78   1     LR        gr15=gr5
   83| 0000E0 ld       EA020000   1     L8        gr16=.&&N&scratch(gr2,0)
   82| 0000E4 ld       EAEF0018   1     L8        gr23=<s39:d24:l8>(gr15,24)
   84| 0000E8 ld       E8CF0268   1     L8        gr6=<s39:d616:l8>(gr15,616)
    0| 0000EC mulld    7EC019D2   1     M         gr22=gr0,gr3
   81| 0000F0 std      FB8100B8   1     ST8       #SPILL2(gr1,184)=gr28
   83| 0000F4 ld       E97004F8   1     L8        gr11=<s95:d1272:l8>(gr16,1272)
    0| 0000F8 add      7EA4BA14   1     A         gr21=gr4,gr23
    0| 0000FC subf     7EC3B050   1     S         gr22=gr22,gr3
   83| 000100 ld       EB6F01A0   1     L8        gr27=<s39:d416:l8>(gr15,416)
   84| 000104 ld       EB4F0208   1     L8        gr26=<s39:d520:l8>(gr15,520)
   81| 000108 lwa      EB3D000E   1     L4A       gr25=<s183:d12:l4>(gr29,12)
   83| 00010C ld       EB0F01B8   1     L8        gr24=<s39:d440:l8>(gr15,440)
    0| 000110 add      7E95B214   1     A         gr20=gr21,gr22
   84| 000114 ld       EACF0220   1     L8        gr22=<s39:d544:l8>(gr15,544)
   82| 000118 lwa      E9DD0006   1     L4A       gr14=<s183:d4:l4>(gr29,4)
   81| 00011C ld       EBA100B8   1     L8        gr29=#SPILL2(gr1,184)
    0| 000120 std      FA8100C0   1     ST8       #SPILL3(gr1,192)=gr20
   84| 000124 ld       EBC20000   1     L8        gr30=.&&N&grid(gr2,0)
   83| 000128 ld       EAF004B0   1     L8        gr23=<s95:d1200:l8>(gr16,1200)
   83| 00012C add      7E38DA14   1     A         gr17=gr24,gr27
   84| 000130 add      7F76D214   1     A         gr27=gr22,gr26
   81| 000134 subf     7F5DC850   1     S         gr26=gr25,gr29
   84| 000138 mulld    7F2031D2   1     M         gr25=gr0,gr6
   83| 00013C mulld    7EA059D2   1     M         gr21=gr0,gr11
   86| 000140 ld       EB9E0CB0   1     L8        gr28=<s10:d3248:l8>(gr30,3248)
   83| 000144 add      7F08BA14   1     A         gr24=gr8,gr23
   81| 000148 addic.   36FA0001   1     AI_R      gr23,cr0=gr26,1,ca"
   84| 00014C ld       E9900560   1     L8        gr12=<s95:d1376:l8>(gr16,1376)
   81| 000150 std      FAE100C8   1     ST8       #SPILL4(gr1,200)=gr23
   86| 000154 ld       EBF005C8   1     L8        gr31=<s95:d1480:l8>(gr16,1480)
   84| 000158 add      7E19DA14   1     A         gr16=gr25,gr27
   86| 00015C ld       EB5E0B98   1     L8        gr26=<s10:d2968:l8>(gr30,2968)
   84| 000160 ld       EAFE0B78   1     L8        gr23=<s10:d2936:l8>(gr30,2936)
   86| 000164 ld       EB3E0CC8   1     L8        gr25=<s10:d3272:l8>(gr30,3272)
   86| 000168 ld       E8EF02D0   1     L8        gr7=<s39:d720:l8>(gr15,720)
   86| 00016C ld       EA4F0270   1     L8        gr18=<s39:d624:l8>(gr15,624)
   83| 000170 add      7DF5C214   1     A         gr15=gr21,gr24
   84| 000174 rldicr   78181F24   1     SLL8      gr24=gr0,3
   86| 000178 addi     3B9CFFF8   1     AI        gr28=gr28,-8
   84| 00017C addi     3B78FFF8   1     AI        gr27=gr24,-8
   84| 000180 ld       EABE0B60   1     L8        gr21=<s10:d2912:l8>(gr30,2912)
   86| 000184 ld       EADE0BB0   1     L8        gr22=<s10:d2992:l8>(gr30,2992)
   84| 000188 ld       EBC20000   1     L8        gr30=.&&N&scratch(gr2,0)
   86| 00018C add      7F5ADA14   1     A         gr26=gr26,gr27
   84| 000190 add      7F77DA14   1     A         gr27=gr23,gr27
   86| 000194 add      7EF9E214   1     A         gr23=gr25,gr28
   86| 000198 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
   83| 00019C ld       E8A50200   1     L8        gr5=<s39:d512:l8>(gr5,512)
   84| 0001A0 ld       EB1E0518   1     L8        gr24=<s95:d1304:l8>(gr30,1304)
   86| 0001A4 mulld    7FA0F9D2   1     M         gr29=gr0,gr31
   86| 0001A8 ld       EBDC0288   1     L8        gr30=<s39:d648:l8>(gr28,648)
   86| 0001AC ld       EB820000   1     L8        gr28=.&&N&scratch(gr2,0)
   86| 0001B0 mulld    7E6039D2   1     M         gr19=gr0,gr7
   86| 0001B4 ld       EB3C0580   1     L8        gr25=<s95:d1408:l8>(gr28,1408)
   84| 0001B8 add      7F89C214   1     A         gr28=gr9,gr24
   82| 0001BC ld       EB020000   1     L8        gr24=.&&N&field(gr2,0)
   86| 0001C0 add      7FD2F214   1     A         gr30=gr18,gr30
   82| 0001C4 ld       EA420000   1     L8        gr18=.&&N&field(gr2,0)
   84| 0001C8 mulld    7E8061D2   1     M         gr20=gr0,gr12
   86| 0001CC add      7F2ACA14   1     A         gr25=gr10,gr25
   82| 0001D0 ld       E8980030   1     L8        gr4=<s39:d48:l8>(gr24,48)
   86| 0001D4 add      7F39EA14   1     A         gr25=gr25,gr29
   83| 0001D8 mulld    7FA029D2   1     M         gr29=gr0,gr5
   82| 0001DC std      F88100D8   1     ST8       #SPILL6(gr1,216)=gr4
   86| 0001E0 add      7F13F214   1     A         gr24=gr19,gr30
   83| 0001E4 add      7FBD8A14   1     A         gr29=gr29,gr17
   83| 0001E8 ld       EA3201D0   1     L8        gr17=<s39:d464:l8>(gr18,464)
   83| 0001EC ld       EA7201E8   1     L8        gr19=<s39:d488:l8>(gr18,488)
   84| 0001F0 add      7F94E214   1     A         gr28=gr20,gr28
   80| 0001F4 addi     3A800000   1     LI        gr20=0
   84| 0001F8 ld       E8920238   1     L8        gr4=<s39:d568:l8>(gr18,568)
   80| 0001FC std      FA8100E0   1     ST8       #SPILL7(gr1,224)=gr20
   83| 000200 std      FA2100E8   1     ST8       #SPILL8(gr1,232)=gr17
   83| 000204 std      FA6100F0   1     ST8       #SPILL9(gr1,240)=gr19
   84| 000208 ld       EA920250   1     L8        gr20=<s39:d592:l8>(gr18,592)
   86| 00020C ld       EA3202A0   1     L8        gr17=<s39:d672:l8>(gr18,672)
   84| 000210 std      F88100F8   1     ST8       #SPILL10(gr1,248)=gr4
   86| 000214 ld       EA7202B8   1     L8        gr19=<s39:d696:l8>(gr18,696)
   82| 000218 ld       EBD20048   1     L8        gr30=<s39:d72:l8>(gr18,72)
   84| 00021C std      FA810100   1     ST8       #SPILL11(gr1,256)=gr20
   86| 000220 std      FA210108   1     ST8       #SPILL12(gr1,264)=gr17
   86| 000224 std      FA610110   1     ST8       #SPILL13(gr1,272)=gr19
   83| 000228 ld       EA420000   1     L8        gr18=.&&N&scratch(gr2,0)
   83| 00022C ld       E89204C8   1     L8        gr4=<s95:d1224:l8>(gr18,1224)
   83| 000230 ld       EA9204E0   1     L8        gr20=<s95:d1248:l8>(gr18,1248)
   84| 000234 ld       EA320530   1     L8        gr17=<s95:d1328:l8>(gr18,1328)
   84| 000238 ld       EA720548   1     L8        gr19=<s95:d1352:l8>(gr18,1352)
   83| 00023C std      F8810118   1     ST8       #SPILL14(gr1,280)=gr4
   83| 000240 std      FA810120   1     ST8       #SPILL15(gr1,288)=gr20
   86| 000244 ld       E8920598   1     L8        gr4=<s95:d1432:l8>(gr18,1432)
   86| 000248 ld       EA9205B0   1     L8        gr20=<s95:d1456:l8>(gr18,1456)
   84| 00024C std      FA210128   1     ST8       #SPILL16(gr1,296)=gr17
   84| 000250 std      FA610130   1     ST8       #SPILL17(gr1,304)=gr19
   86| 000254 std      F8810138   1     ST8       #SPILL18(gr1,312)=gr4
   86| 000258 std      FA810140   1     ST8       #SPILL19(gr1,320)=gr20
    0| 00025C ld       E88100D0   1     L8        gr4=#SPILL5(gr1,208)
    0| 000260 bc       40810424   1     BF        CL.61,cr0,0x2/gt,taken=20%(20,80)
   84| 000264 add      7EB5DA14   1     A         gr21=gr21,gr27
   86| 000268 add      7F76D214   1     A         gr27=gr22,gr26
   83| 00026C subf     7F4B7850   1     S         gr26=gr15,gr11
   84| 000270 subf     7DE68050   1     S         gr15=gr16,gr6
    0| 000274 std      F88101A8   1     ST8       #SPILL32(gr1,424)=gr4
   84| 000278 subf     7E0CE050   1     S         gr16=gr28,gr12
   86| 00027C subf     7F87C050   1     S         gr28=gr24,gr7
   83| 000280 std      FB410160   1     ST8       #SPILL23(gr1,352)=gr26
   86| 000284 std      FB810178   1     ST8       #SPILL26(gr1,376)=gr28
    0| 000288 ld       EB4100A8   1     L8        gr26=#SPILL0(gr1,168)
    0| 00028C ld       EB8100D8   1     L8        gr28=#SPILL6(gr1,216)
   86| 000290 subf     7F1FC850   1     S         gr24=gr25,gr31
   86| 000294 ld       EB2100B8   1     L8        gr25=#SPILL2(gr1,184)
   86| 000298 std      FB610150   1     ST8       #SPILL21(gr1,336)=gr27
    0| 00029C subfic   23600001   1     SFI       gr27=1,gr0,ca"
   84| 0002A0 std      F9E10168   1     ST8       #SPILL24(gr1,360)=gr15
   83| 0002A4 subf     7EC5E850   1     S         gr22=gr29,gr5
    0| 0002A8 add      7FAEDA14   1     A         gr29=gr14,gr27
   86| 0002AC rldicr   7B3B1F24   1     SLL8      gr27=gr25,3
    0| 0002B0 mulld    7F9AE1D2   1     M         gr28=gr26,gr28
   86| 0002B4 add      7EF7DA14   1     A         gr23=gr23,gr27
   84| 0002B8 std      FAA10148   1     ST8       #SPILL20(gr1,328)=gr21
    0| 0002BC ld       EB4100C0   1     L8        gr26=#SPILL3(gr1,192)
    0| 0002C0 ld       EB6100D8   1     L8        gr27=#SPILL6(gr1,216)
   83| 0002C4 std      FAC10158   1     ST8       #SPILL22(gr1,344)=gr22
   84| 0002C8 std      FA010170   1     ST8       #SPILL25(gr1,368)=gr16
   86| 0002CC std      FB010180   1     ST8       #SPILL27(gr1,384)=gr24
   86| 0002D0 std      FAE10188   1     ST8       #SPILL28(gr1,392)=gr23
    0| 0002D4 subf     7F7BD050   1     S         gr27=gr26,gr27
    0| 0002D8 subf     7F407050   1     S         gr26=gr14,gr0
    0| 0002DC add      7C1BE214   1     A         gr0=gr27,gr28
    0| 0002E0 addic.   377A0001   1     AI_R      gr27,cr0=gr26,1,ca"
    0| 0002E4 rldicl   7BAEF842   1     SRL8      gr14=gr29,1
    0| 0002E8 mcrf     4C800000   1     LRCR      cr1=cr0
    0| 0002EC andi.    73BD0001   1     RN4_R     gr29,cr0=gr29,0,0x1
    0| 0002F0 ld       EBA100C0   1     L8        gr29=#SPILL3(gr1,192)
    0| 0002F4 mulld    7F79F1D2   1     M         gr27=gr25,gr30
    0| 0002F8 subf     7FBEE850   1     S         gr29=gr29,gr30
    0| 0002FC std      F9C10190   1     ST8       #SPILL29(gr1,400)=gr14
    0| 000300 ld       EB420000   1     L8        gr26=.+CONSTANT_AREA(gr2,0)
    0| 000304 add      7F7BEA14   1     A         gr27=gr27,gr29
    0| 000308 cmpdi    2FAE0000   1     C8        cr7=gr14,0
    0| 00030C std      FB610198   1     ST8       #SPILL30(gr1,408)=gr27
    0| 000310 add      7FBBE214   1     A         gr29=gr27,gr28
    0| 000314 std      FBA101A0   1     ST8       #SPILL31(gr1,416)=gr29
    0| 000318 lfs      C01A0000   1     LFS       fp0=+CONSTANT_AREA(gr26,0)
   80|                              CL.62:
   81| 00031C addi     3BA00000   1     LI        gr29=0
    0| 000320 bc       40850334   1     BF        CL.63,cr1,0x2/gt,taken=20%(20,80)
    0| 000324 ld       EB4100A8   1     L8        gr26=#SPILL0(gr1,168)
    0| 000328 ld       EB2100E0   1     L8        gr25=#SPILL7(gr1,224)
    0| 00032C ld       EB010138   1     L8        gr24=#SPILL18(gr1,312)
    0| 000330 ld       EA0100F8   1     L8        gr16=#SPILL10(gr1,248)
    0| 000334 ld       EAC10180   1     L8        gr22=#SPILL27(gr1,384)
    0| 000338 ld       EAE100D8   1     L8        gr23=#SPILL6(gr1,216)
    0| 00033C ld       EA810108   1     L8        gr20=#SPILL12(gr1,264)
    0| 000340 add      7F99D214   1     A         gr28=gr25,gr26
    0| 000344 ld       EA410128   1     L8        gr18=#SPILL16(gr1,296)
    0| 000348 mulld    7F78E1D2   1     M         gr27=gr24,gr28
    0| 00034C mulld    7DD7E1D2   1     M         gr14=gr23,gr28
    0| 000350 add      7EB6DA14   1     A         gr21=gr22,gr27
    0| 000354 mulld    7F70E1D2   1     M         gr27=gr16,gr28
    0| 000358 std      FAA101B0   1     ST8       #SPILL33(gr1,432)=gr21
    0| 00035C std      FB6101C8   1     ST8       #SPILL36(gr1,456)=gr27
    0| 000360 ld       EB610118   1     L8        gr27=#SPILL14(gr1,280)
    0| 000364 mulld    7E74E1D2   1     M         gr19=gr20,gr28
    0| 000368 mulld    7E1BE1D2   1     M         gr16=gr27,gr28
    0| 00036C std      FA6101B8   1     ST8       #SPILL34(gr1,440)=gr19
    0| 000370 std      FA0101D0   1     ST8       #SPILL37(gr1,464)=gr16
    0| 000374 ld       EB6100E8   1     L8        gr27=#SPILL8(gr1,232)
    0| 000378 mulld    7E32E1D2   1     M         gr17=gr18,gr28
    0| 00037C mulld    7F9BE1D2   1     M         gr28=gr27,gr28
    0| 000380 std      FA2101C0   1     ST8       #SPILL35(gr1,448)=gr17
    0| 000384 std      FB8101D8   1     ST8       #SPILL38(gr1,472)=gr28
    0| 000388 ld       E9E10198   1     L8        gr15=#SPILL30(gr1,408)
   86| 00038C ld       EB810188   1     L8        gr28=#SPILL28(gr1,392)
   82| 000390 ld       EB6101A0   1     L8        gr27=#SPILL31(gr1,416)
   81|                              CL.64:
   82| 000394 ld       EB2100B8   1     L8        gr25=#SPILL2(gr1,184)
   86| 000398 ld       EAC10110   1     L8        gr22=#SPILL13(gr1,272)
   84| 00039C ld       EA210100   1     L8        gr17=#SPILL11(gr1,256)
   83| 0003A0 ld       EA0100F0   1     L8        gr16=#SPILL9(gr1,240)
   86| 0003A4 ld       EA810178   1     L8        gr20=#SPILL26(gr1,376)
   82| 0003A8 ld       EAA100C0   1     L8        gr21=#SPILL3(gr1,192)
   82| 0003AC add      7E59EA14   1     A         gr18=gr25,gr29
   86| 0003B0 ld       EA6101B8   1     L8        gr19=#SPILL34(gr1,440)
   86| 0003B4 mulld    7EF2B1D2   1     M         gr23=gr18,gr22
   84| 0003B8 mulld    7ED191D2   1     M         gr22=gr17,gr18
   84| 0003BC ld       EA210130   1     L8        gr17=#SPILL17(gr1,304)
   86| 0003C0 mulld    7F12F1D2   1     M         gr24=gr18,gr30
   86| 0003C4 add      7EF7A214   1     A         gr23=gr23,gr20
   83| 0003C8 mulld    7E9091D2   1     M         gr20=gr16,gr18
   83| 0003CC ld       EA010120   1     L8        gr16=#SPILL15(gr1,288)
   82| 0003D0 add      7F35C214   1     A         gr25=gr21,gr24
   84| 0003D4 ld       EAA10168   1     L8        gr21=#SPILL24(gr1,360)
   86| 0003D8 add      7EF3BA14   1     A         gr23=gr19,gr23
   84| 0003DC mulld    7E7191D2   1     M         gr19=gr17,gr18
   86| 0003E0 ld       EA210140   1     L8        gr17=#SPILL19(gr1,320)
   84| 0003E4 add      7ED6AA14   1     A         gr22=gr22,gr21
   83| 0003E8 mulld    7EB091D2   1     M         gr21=gr16,gr18
   83| 0003EC ld       EA010158   1     L8        gr16=#SPILL22(gr1,344)
   86| 0003F0 mulld    7E5191D2   1     M         gr18=gr17,gr18
   83| 0003F4 add      7E948214   1     A         gr20=gr20,gr16
   84| 0003F8 ld       EA010170   1     L8        gr16=#SPILL25(gr1,368)
   86| 0003FC ld       E88101B0   1     L8        gr4=#SPILL33(gr1,432)
    0| 000400 ld       EB410190   1     L8        gr26=#SPILL29(gr1,400)
   82| 000404 add      7F2ECA14   1     A         gr25=gr14,gr25
   86| 000408 add      7F180214   1     A         gr24=gr24,gr0
   82| 00040C lfdux    7C5BF4EE   1     LFDU      fp2,gr27=d(gr27,gr30,0)
   84| 000410 add      7E309A14   1     A         gr17=gr16,gr19
   83| 000414 ld       EA610160   1     L8        gr19=#SPILL23(gr1,352)
   86| 000418 add      7E522214   1     A         gr18=gr18,gr4
   84| 00041C ld       E88101C0   1     L8        gr4=#SPILL35(gr1,448)
   86| 000420 lfdu     CC3C0008   1     LFDU      fp1,gr28=g32b(gr28,8)
    0| 000424 mtspr    7F4903A6   1     LCTR      ctr=gr26
   84| 000428 add      7F4E7A14   1     A         gr26=gr14,gr15
   83| 00042C add      7E13AA14   1     A         gr16=gr19,gr21
   84| 000430 ld       EAA101C8   1     L8        gr21=#SPILL36(gr1,456)
   83| 000434 ld       EA6101D8   1     L8        gr19=#SPILL38(gr1,472)
   84| 000438 add      7E248A14   1     A         gr17=gr4,gr17
   83| 00043C ld       E88101D0   1     L8        gr4=#SPILL37(gr1,464)
   84| 000440 add      7ED5B214   1     A         gr22=gr21,gr22
   86| 000444 ld       EAA10150   1     L8        gr21=#SPILL21(gr1,336)
   83| 000448 add      7E93A214   1     A         gr20=gr19,gr20
   84| 00044C ld       EA610148   1     L8        gr19=#SPILL20(gr1,328)
   83| 000450 add      7E048214   1     A         gr16=gr4,gr16
    0| 000454 bc       41820068   1     BT        CL.315,cr0,0x4/eq,taken=50%(0,0)
   82| 000458 lfdux    7C791CEE   1     LFDU      fp3,gr25=d(gr25,gr3,0)
   86| 00045C lfdux    7C973CEE   1     LFDU      fp4,gr23=v3(gr23,gr7,0)
   86| 000460 lfdux    7CB81CEE   1     LFDU      fp5,gr24=d(gr24,gr3,0)
   84| 000464 lfdux    7CD634EE   1     LFDU      fp6,gr22=v2(gr22,gr6,0)
   84| 000468 lfdux    7CFA1CEE   1     LFDU      fp7,gr26=d(gr26,gr3,0)
   86| 00046C lfdu     CD150008   1     LFDU      fp8,gr21=g31b(gr21,8)
   83| 000470 lfdux    7D342CEE   1     LFDU      fp9,gr20=v1(gr20,gr5,0)
   83| 000474 fadd     FD42182A   1     AFL       fp10=fp2,fp3,fcr
   84| 000478 lfdu     CD730008   2     LFDU      fp11,gr19=g2b(gr19,8)
   86| 00047C fmul     FC840032   1     MFL       fp4=fp4,fp0,fcr
   86| 000480 fadd     FCA3282A   2     AFL       fp5=fp3,fp5,fcr
   84| 000484 fmul     FCC60032   2     MFL       fp6=fp6,fp0,fcr
   84| 000488 fadd     FCE3382A   2     AFL       fp7=fp3,fp7,fcr
   86| 00048C fmr      FC401890   2     LRFL      fp2=fp3
   83| 000490 fmul     FD290032   2     MFL       fp9=fp9,fp0,fcr
   86| 000494 fmul     FC640172   2     MFL       fp3=fp4,fp5,fcr
   84| 000498 fmul     FC8601F2   2     MFL       fp4=fp6,fp7,fcr
   83| 00049C fmul     FCA902B2   2     MFL       fp5=fp9,fp10,fcr
   86| 0004A0 fmul     FC630232   2     MFL       fp3=fp3,fp8,fcr
   84| 0004A4 fmul     FC8402F2   2     MFL       fp4=fp4,fp11,fcr
   83| 0004A8 stfdux   7CB05DEE   2     STFDU     gr16,w3da(gr16,gr11,0)=fp5
   86| 0004AC fmul     FC630072   1     MFL       fp3=fp3,fp1,fcr
   84| 0004B0 stfdux   7C9165EE   2     STFDU     gr17,w3db(gr17,gr12,0)=fp4
   86| 0004B4 stfdux   7C72FDEE   1     STFDU     gr18,w3dc(gr18,gr31,0)=fp3
    0| 0004B8 bc       419E0188   1     BT        CL.277,cr7,0x4/eq,taken=20%(20,80)
    0|                              CL.315:
   82| 0004BC lfdux    7D391CEE   1     LFDU      fp9,gr25=d(gr25,gr3,0)
   86| 0004C0 lfdux    7C981CEE   1     LFDU      fp4,gr24=d(gr24,gr3,0)
   86| 0004C4 lfdux    7CB73CEE   1     LFDU      fp5,gr23=v3(gr23,gr7,0)
   84| 0004C8 lfdux    7C7A1CEE   1     LFDU      fp3,gr26=d(gr26,gr3,0)
   84| 0004CC lfdux    7D5634EE   1     LFDU      fp10,gr22=v2(gr22,gr6,0)
   86| 0004D0 lfdu     CCD50010   1     LFDU      fp6,gr21=g31b(gr21,16)
   83| 0004D4 lfdux    7D942CEE   1     LFDU      fp12,gr20=v1(gr20,gr5,0)
   83| 0004D8 fadd     FD62482A   1     AFL       fp11=fp2,fp9,fcr
   82| 0004DC lfdux    7C591CEE   1     LFDU      fp2,gr25=d(gr25,gr3,0)
   86| 0004E0 fadd     FC89202A   1     AFL       fp4=fp9,fp4,fcr
   86| 0004E4 lfdux    7CF81CEE   1     LFDU      fp7,gr24=d(gr24,gr3,0)
   84| 0004E8 fadd     FFE9182A   1     AFL       fp31=fp9,fp3,fcr
   86| 0004EC lfdux    7D173CEE   1     LFDU      fp8,gr23=v3(gr23,gr7,0)
   86| 0004F0 fmul     FCA50032   1     MFL       fp5=fp5,fp0,fcr
   84| 0004F4 lfdux    7FDA1CEE   1     LFDU      fp30,gr26=d(gr26,gr3,0)
   84| 0004F8 fmul     FD4A0032   1     MFL       fp10=fp10,fp0,fcr
   84| 0004FC lfdux    7C7634EE   1     LFDU      fp3,gr22=v2(gr22,gr6,0)
   86| 000500 fadd     FDA2382A   1     AFL       fp13=fp2,fp7,fcr
   86| 000504 lfd      C8F5FFF8   1     LFL       fp7=g31b(gr21,-8)
   86| 000508 fmul     FF880032   1     MFL       fp28=fp8,fp0,fcr
   83| 00050C lfdux    7D142CEE   1     LFDU      fp8,gr20=v1(gr20,gr5,0)
   86| 000510 fmul     FFA50132   1     MFL       fp29=fp5,fp4,fcr
   84| 000514 lfdu     CC930010   2     LFDU      fp4,gr19=g2b(gr19,16)
   84| 000518 fmul     FCA30032   1     MFL       fp5=fp3,fp0,fcr
   84| 00051C lfd      C873FFF8   2     LFL       fp3=g2b(gr19,-8)
   84| 000520 fadd     FFC2F02A   1     AFL       fp30=fp2,fp30,fcr
   86| 000524 fmul     FDBC0372   2     MFL       fp13=fp28,fp13,fcr
   83| 000528 fmul     FD8C0032   2     MFL       fp12=fp12,fp0,fcr
   86| 00052C fmul     FCFD01F2   2     MFL       fp7=fp29,fp7,fcr
   83| 000530 fmul     FD080032   2     MFL       fp8=fp8,fp0,fcr
   83| 000534 fadd     FD29102A   2     AFL       fp9=fp9,fp2,fcr
   84| 000538 fmul     FCA507B2   2     MFL       fp5=fp5,fp30,fcr
   84| 00053C fmul     FD4A07F2   2     MFL       fp10=fp10,fp31,fcr
   86| 000540 fmul     FCCD01B2   2     MFL       fp6=fp13,fp6,fcr
   83| 000544 fmul     FD8C02F2   2     MFL       fp12=fp12,fp11,fcr
   86| 000548 fmul     FCE70072   2     MFL       fp7=fp7,fp1,fcr
   83| 00054C fmul     FFC80272   2     MFL       fp30=fp8,fp9,fcr
   84| 000550 fmul     FC850132   2     MFL       fp4=fp5,fp4,fcr
    0| 000554 bc       424000CC   1     BCF       ctr=CL.328,taken=0%(0,100)
    0| 000558 ori      60210000   1     XNOP      
    0| 00055C ori      60210000   1     XNOP      
    0| 000560 ori      60210000   1     XNOP      
    0|                              CL.329:
   84| 000564 lfdu     CCB30010   1     LFDU      fp5,gr19=g2b(gr19,16)
   84| 000568 fmul     FD0A00F2   1     MFL       fp8=fp10,fp3,fcr
   83| 00056C stfdux   7D905DEE   2     STFDU     gr16,w3da(gr16,gr11,0)=fp12
   84| 000570 lfd      C873FFF8   1     LFL       fp3=g2b(gr19,-8)
   86| 000574 fmul     FCC60072   1     MFL       fp6=fp6,fp1,fcr
   86| 000578 stfdux   7CF2FDEE   2     STFDU     gr18,w3dc(gr18,gr31,0)=fp7
   84| 00057C stfdux   7D1165EE   1     STFDU     gr17,w3db(gr17,gr12,0)=fp8
   86| 000580 lfdu     CCF50010   1     LFDU      fp7,gr21=g31b(gr21,16)
   86| 000584 lfd      C915FFF8   1     LFL       fp8=g31b(gr21,-8)
   83| 000588 lfdux    7D342CEE   1     LFDU      fp9,gr20=v1(gr20,gr5,0)
   84| 00058C lfdux    7D5A1CEE   1     LFDU      fp10,gr26=d(gr26,gr3,0)
   82| 000590 lfdux    7D791CEE   1     LFDU      fp11,gr25=d(gr25,gr3,0)
   86| 000594 lfdux    7FB81CEE   1     LFDU      fp29,gr24=d(gr24,gr3,0)
   86| 000598 lfdux    7D973CEE   1     LFDU      fp12,gr23=v3(gr23,gr7,0)
   84| 00059C lfdux    7DB634EE   1     LFDU      fp13,gr22=v2(gr22,gr6,0)
   83| 0005A0 stfdux   7FD05DEE   1     STFDU     gr16,w3da(gr16,gr11,0)=fp30
   83| 0005A4 lfdux    7FF42CEE   1     LFDU      fp31,gr20=v1(gr20,gr5,0)
   83| 0005A8 fadd     FFC2582A   1     AFL       fp30=fp2,fp11,fcr
   86| 0005AC fadd     FFABE82A   2     AFL       fp29=fp11,fp29,fcr
   84| 0005B0 lfdux    7F9A1CEE   1     LFDU      fp28,gr26=d(gr26,gr3,0)
   82| 0005B4 lfdux    7C591CEE   1     LFDU      fp2,gr25=d(gr25,gr3,0)
   86| 0005B8 lfdux    7F781CEE   1     LFDU      fp27,gr24=d(gr24,gr3,0)
   84| 0005BC lfdux    7F5634EE   1     LFDU      fp26,gr22=v2(gr22,gr6,0)
   86| 0005C0 lfdux    7F373CEE   1     LFDU      fp25,gr23=v3(gr23,gr7,0)
   86| 0005C4 fmul     FD8C0032   1     MFL       fp12=fp12,fp0,fcr
   84| 0005C8 stfdux   7C9165EE   2     STFDU     gr17,w3db(gr17,gr12,0)=fp4
   86| 0005CC stfdux   7CD2FDEE   1     STFDU     gr18,w3dc(gr18,gr31,0)=fp6
   83| 0005D0 fmul     FC890032   1     MFL       fp4=fp9,fp0,fcr
   83| 0005D4 fmul     FCDF0032   2     MFL       fp6=fp31,fp0,fcr
   84| 0005D8 fmul     FD3A0032   2     MFL       fp9=fp26,fp0,fcr
   84| 0005DC fadd     FFE2E02A   2     AFL       fp31=fp2,fp28,fcr
   86| 0005E0 fadd     FF82D82A   2     AFL       fp28=fp2,fp27,fcr
   86| 0005E4 fmul     FF790032   2     MFL       fp27=fp25,fp0,fcr
   86| 0005E8 fmul     FD8C0772   2     MFL       fp12=fp12,fp29,fcr
   84| 0005EC fmul     FDAD0032   2     MFL       fp13=fp13,fp0,fcr
   84| 0005F0 fadd     FD4B502A   2     AFL       fp10=fp11,fp10,fcr
   84| 0005F4 fmul     FD2907F2   2     MFL       fp9=fp9,fp31,fcr
   83| 0005F8 fadd     FD6B102A   2     AFL       fp11=fp11,fp2,fcr
   86| 0005FC fmul     FFFB0732   2     MFL       fp31=fp27,fp28,fcr
   86| 000600 fmul     FD0C0232   2     MFL       fp8=fp12,fp8,fcr
   83| 000604 fmul     FD8407B2   2     MFL       fp12=fp4,fp30,fcr
   84| 000608 fmul     FD4D02B2   2     MFL       fp10=fp13,fp10,fcr
   84| 00060C fmul     FC890172   2     MFL       fp4=fp9,fp5,fcr
   83| 000610 fmul     FFC602F2   2     MFL       fp30=fp6,fp11,fcr
   86| 000614 fmul     FCDF01F2   2     MFL       fp6=fp31,fp7,fcr
   86| 000618 fmul     FCE80072   2     MFL       fp7=fp8,fp1,fcr
    0| 00061C bc       4200FF48   1     BCT       ctr=CL.329,taken=100%(100,0)
    0|                              CL.328:
   86| 000620 fmul     FC260072   1     MFL       fp1=fp6,fp1,fcr
   83| 000624 stfdux   7D905DEE   2     STFDU     gr16,w3da(gr16,gr11,0)=fp12
   84| 000628 fmul     FC4A00F2   1     MFL       fp2=fp10,fp3,fcr
   86| 00062C stfdux   7CF2FDEE   2     STFDU     gr18,w3dc(gr18,gr31,0)=fp7
   83| 000630 stfdux   7FD05DEE   1     STFDU     gr16,w3da(gr16,gr11,0)=fp30
   86| 000634 stfdux   7C32FDEE   1     STFDU     gr18,w3dc(gr18,gr31,0)=fp1
   84| 000638 stfdux   7C5165EE   1     STFDU     gr17,w3db(gr17,gr12,0)=fp2
   84| 00063C stfdux   7C9165EE   1     STFDU     gr17,w3db(gr17,gr12,0)=fp4
    0|                              CL.277:
   89| 000640 ld       E88100C8   1     L8        gr4=#SPILL4(gr1,200)
   89| 000644 addi     3BBD0001   1     AI        gr29=gr29,1
    0| 000648 add      7DEFF214   1     A         gr15=gr15,gr30
   89| 00064C cmpld    7F3D2040   1     CL8       cr6=gr29,gr4
   89| 000650 bc       4198FD44   1     BT        CL.64,cr6,0x8/llt,taken=80%(80,20)
   89|                              CL.63:
   90| 000654 ld       E88100E0   1     L8        gr4=#SPILL7(gr1,224)
    0| 000658 ld       EBA100D8   1     L8        gr29=#SPILL6(gr1,216)
   90| 00065C ld       EB8100B0   1     L8        gr28=#SPILL1(gr1,176)
    0| 000660 ld       EB6101A0   1     L8        gr27=#SPILL31(gr1,416)
   90| 000664 addi     38840001   1     AI        gr4=gr4,1
    0| 000668 add      7C00EA14   1     A         gr0=gr0,gr29
   90| 00066C std      F88100E0   1     ST8       #SPILL7(gr1,224)=gr4
   90| 000670 cmpld    7F24E040   1     CL8       cr6=gr4,gr28
    0| 000674 add      7F7BEA14   1     A         gr27=gr27,gr29
    0| 000678 std      FB6101A0   1     ST8       #SPILL31(gr1,416)=gr27
   90| 00067C bc       4198FCA0   1     BT        CL.62,cr6,0x8/llt,taken=80%(80,20)
   90| 000680 ld       E88101A8   1     L8        gr4=#SPILL32(gr1,424)
   90|                              CL.61:
   97| 000684 ld       EBE20000   1     L8        gr31=.&&N&&root(gr2,0)
    0| 000688 ld       E9820000   1     L8        gr12=.&&N&&config(gr2,0)
    0| 00068C ld       EBC20000   1     L8        gr30=.&&N&scratch(gr2,0)
   97| 000690 addi     3BA00000   1     LI        gr29=0
   97| 000694 stw      93BF01FC   1     ST4Z      <s201:d508:l4>(gr31,508)=gr29
    0| 000698 lwz      800C0018   1     L4Z       gr0=<s177:d24:l4>(gr12,24)
   98| 00069C lwz      817F01E0   1     L4Z       gr11=<s201:d480:l4>(gr31,480)
    0| 0006A0 ld       E87E05D0   1     L8        gr3=<s95:d1488:l8>(gr30,1488)
    0| 0006A4 ld       E8BE0638   1     L8        gr5=<s95:d1592:l8>(gr30,1592)
    0| 0006A8 ld       E8DE0708   1     L8        gr6=<s95:d1800:l8>(gr30,1800)
    0| 0006AC ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
    0| 0006B0 cmpdi    2CA00000   1     C8        cr1=gr0,0
   98| 0006B4 cmpwi    2C0B0001   1     C4        cr0=gr11,1
   98| 0006B8 bc       4082023C   1     BF        CL.16,cr0,0x4/eq,taken=50%(0,0)
  106| 0006BC bc       418601D8   1     BT        CL.17,cr1,0x4/eq,taken=50%(0,0)
  107| 0006C0 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  107| 0006C4 ld       E97E0840   1     L8        gr11=<s95:d2112:l8>(gr30,2112)
  107| 0006C8 or       7FCEF378   1     LR        gr14=gr30
  107| 0006CC ld       EBDE08A8   1     L8        gr30=<s95:d2216:l8>(gr30,2216)
  107| 0006D0 ld       E81C0410   1     L8        gr0=<s39:d1040:l8>(gr28,1040)
  107| 0006D4 std      F9610078   1     ST8       #MX_TEMP1(gr1,120)=gr11
  107| 0006D8 ld       E99C0820   1     L8        gr12=<s39:d2080:l8>(gr28,2080)
  107| 0006DC std      FBC10088   1     ST8       #MX_TEMP1(gr1,136)=gr30
  107| 0006E0 std      F8010070   1     ST8       #MX_TEMP1(gr1,112)=gr0
  107| 0006E4 std      F9810080   1     ST8       #MX_TEMP1(gr1,128)=gr12
  107| 0006E8 bl       48000001   1     CALL      advx1,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  107| 0006EC ori      60000000   1
  109| 0006F0 ld       E8AE0840   1     L8        gr5=<s95:d2112:l8>(gr14,2112)
  109| 0006F4 ld       E8DC0410   1     L8        gr6=<s39:d1040:l8>(gr28,1040)
  109| 0006F8 ld       E8EE08A8   1     L8        gr7=<s95:d2216:l8>(gr14,2216)
  109| 0006FC ld       E81C0820   1     L8        gr0=<s39:d2080:l8>(gr28,2080)
  109| 000700 ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  109| 000704 ld       E88E05D0   1     L8        gr4=<s95:d1488:l8>(gr14,1488)
  109| 000708 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  109| 00070C std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  109| 000710 std      F8E10080   1     ST8       #MX_TEMP1(gr1,128)=gr7
  109| 000714 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  109| 000718 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  109| 00071C ld       E8AE0708   1     L8        gr5=<s95:d1800:l8>(gr14,1800)
  109| 000720 ld       E8CE0638   1     L8        gr6=<s95:d1592:l8>(gr14,1592)
  109| 000724 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  109| 000728 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  109| 00072C ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  109| 000730 bl       48000001   1     CALL      advx2,12,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,w3dh",er",w4da",abun",advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  109| 000734 ori      60000000   1
  111| 000738 ld       E8BC0410   1     L8        gr5=<s39:d1040:l8>(gr28,1040)
  111| 00073C ld       E8CE0840   1     L8        gr6=<s95:d2112:l8>(gr14,2112)
  111| 000740 ld       E8FC0820   1     L8        gr7=<s39:d2080:l8>(gr28,2080)
  111| 000744 ld       E80E08A8   1     L8        gr0=<s95:d2216:l8>(gr14,2216)
  111| 000748 ld       E86E05D0   1     L8        gr3=<s95:d1488:l8>(gr14,1488)
  111| 00074C ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  111| 000750 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  111| 000754 std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  111| 000758 std      F8E10080   1     ST8       #MX_TEMP1(gr1,128)=gr7
  111| 00075C ld       E8AE0638   1     L8        gr5=<s95:d1592:l8>(gr14,1592)
  111| 000760 ld       E8CE0708   1     L8        gr6=<s95:d1800:l8>(gr14,1800)
  111| 000764 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  111| 000768 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  111| 00076C ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  111| 000770 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  111| 000774 ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  111| 000778 bl       48000001   1     CALL      advx3,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  111| 00077C ori      60000000   1
  117|                              CL.18:
  119| 000780 addi     38000002   1     LI        gr0=2
  119| 000784 stw      901F01E0   1     ST4Z      <s201:d480:l4>(gr31,480)=gr0
  241|                              CL.19:
    0| 000788 ld       E8820000   1     L8        gr4=.&&N&&bndry(gr2,0)
  246| 00078C addi     38600000   1     LI        gr3=0
  247| 000790 addi     38E00000   1     LI        gr7=0
  247| 000794 addi     38040324   1     AI        gr0=gr4,804
    0| 000798 ori      60210000   1     XNOP      
    0| 00079C ori      60210000   1     XNOP      
    0| 0007A0 ori      60210000   1     XNOP      
  246|                              CL.68:
  247| 0007A4 rldicr   78641764   1     SLL8      gr4=gr3,2
  247| 0007A8 subf     7C832050   1     S         gr4=gr4,gr3
  250| 0007AC addi     38630001   1     AI        gr3=gr3,1
  247| 0007B0 addi     38A40001   1     AI        gr5=gr4,1
  247| 0007B4 addi     38C40002   1     AI        gr6=gr4,2
  247| 0007B8 rldic    78842EC8   1     RN8       gr4=gr4,5,0x1FFFFFFFE0
  247| 0007BC rldic    78A52EC8   1     RN8       gr5=gr5,5,0x1FFFFFFFE0
  247| 0007C0 rldic    78C62EC8   1     RN8       gr6=gr6,5,0x1FFFFFFFE0
  247| 0007C4 add      7C802214   1     A         gr4=gr0,gr4
  247| 0007C8 add      7CA02A14   1     A         gr5=gr0,gr5
  247| 0007CC stw      90E40004   1     ST4Z      bvstat[](gr4,4)=gr7
  247| 0007D0 stw      90E50004   1     ST4Z      bvstat[](gr5,4)=gr7
  247| 0007D4 add      7CC03214   1     A         gr6=gr0,gr6
  250| 0007D8 cmpldi   28230001   1     CL8       cr0=gr3,1
  247| 0007DC stw      90E60004   1     ST4Z      bvstat[](gr6,4)=gr7
  247| 0007E0 stw      90E40008   1     ST4Z      bvstat[](gr4,8)=gr7
  247| 0007E4 stw      90E50008   1     ST4Z      bvstat[](gr5,8)=gr7
  247| 0007E8 stw      90E60008   1     ST4Z      bvstat[](gr6,8)=gr7
  247| 0007EC stw      90E4000C   1     ST4Z      bvstat[](gr4,12)=gr7
  247| 0007F0 stw      90E5000C   1     ST4Z      bvstat[](gr5,12)=gr7
  247| 0007F4 stw      90E6000C   1     ST4Z      bvstat[](gr6,12)=gr7
  247| 0007F8 stw      90E40010   1     ST4Z      bvstat[](gr4,16)=gr7
  247| 0007FC stw      90E50010   1     ST4Z      bvstat[](gr5,16)=gr7
  247| 000800 stw      90E60010   1     ST4Z      bvstat[](gr6,16)=gr7
  247| 000804 stw      90E40014   1     ST4Z      bvstat[](gr4,20)=gr7
  247| 000808 stw      90E50014   1     ST4Z      bvstat[](gr5,20)=gr7
  247| 00080C stw      90E60014   1     ST4Z      bvstat[](gr6,20)=gr7
  247| 000810 stwu     94E40018   1     ST4U      gr4,bvstat[](gr4,24)=gr7
  247| 000814 stwu     94E50018   1     ST4U      gr5,bvstat[](gr5,24)=gr7
  247| 000818 stwu     94E60018   1     ST4U      gr6,bvstat[](gr6,24)=gr7
  250| 00081C bc       4180FF88   1     BT        CL.68,cr0,0x8/llt,taken=80%(80,20)
  277| 000820 ld       E9810310   1     L8        gr12=#stack(gr1,784)
  277| 000824 lfd      CBE102F8   1     LFL       fp31=#stack(gr1,760)
  277| 000828 lfd      CBC102F0   1     LFL       fp30=#stack(gr1,752)
  277| 00082C lfd      CBA102E8   1     LFL       fp29=#stack(gr1,744)
  277| 000830 lfd      CB8102E0   1     LFL       fp28=#stack(gr1,736)
  277| 000834 lfd      CB6102D8   1     LFL       fp27=#stack(gr1,728)
  277| 000838 lfd      CB4102D0   1     LFL       fp26=#stack(gr1,720)
  277| 00083C lfd      CB2102C8   1     LFL       fp25=#stack(gr1,712)
  277| 000840 addi     38210300   1     AI        gr1=gr1,768
  277| 000844 mtspr    7D8803A6   1     LLR       lr=gr12
  277| 000848 ld       E9C1FF38   1     L8        gr14=#stack(gr1,-200)
  277| 00084C ld       E9E1FF40   1     L8        gr15=#stack(gr1,-192)
  277| 000850 ld       EA01FF48   1     L8        gr16=#stack(gr1,-184)
  277| 000854 ld       EA21FF50   1     L8        gr17=#stack(gr1,-176)
  277| 000858 ld       EA41FF58   1     L8        gr18=#stack(gr1,-168)
  277| 00085C ld       EA61FF60   1     L8        gr19=#stack(gr1,-160)
  277| 000860 ld       EA81FF68   1     L8        gr20=#stack(gr1,-152)
  277| 000864 ld       EAA1FF70   1     L8        gr21=#stack(gr1,-144)
  277| 000868 ld       EAC1FF78   1     L8        gr22=#stack(gr1,-136)
  277| 00086C ld       EAE1FF80   1     L8        gr23=#stack(gr1,-128)
  277| 000870 ld       EB01FF88   1     L8        gr24=#stack(gr1,-120)
  277| 000874 ld       EB21FF90   1     L8        gr25=#stack(gr1,-112)
  277| 000878 ld       EB41FF98   1     L8        gr26=#stack(gr1,-104)
  277| 00087C ld       EB61FFA0   1     L8        gr27=#stack(gr1,-96)
  277| 000880 ld       EB81FFA8   1     L8        gr28=#stack(gr1,-88)
  277| 000884 ld       EBA1FFB0   1     L8        gr29=#stack(gr1,-80)
  277| 000888 ld       EBC1FFB8   1     L8        gr30=#stack(gr1,-72)
  277| 00088C ld       EBE1FFC0   1     L8        gr31=#stack(gr1,-64)
  277| 000890 bclr     4E800020   1     BA        lr
  113|                              CL.17:
  114| 000894 bl       48000001   1     CALL      advx1,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  114| 000898 ori      60000000   1
  115| 00089C ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  115| 0008A0 ld       E89E05D0   1     L8        gr4=<s95:d1488:l8>(gr30,1488)
  115| 0008A4 ld       E8BE0708   1     L8        gr5=<s95:d1800:l8>(gr30,1800)
  115| 0008A8 ld       E8DE0638   1     L8        gr6=<s95:d1592:l8>(gr30,1592)
  115| 0008AC ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  115| 0008B0 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  115| 0008B4 ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  115| 0008B8 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  115| 0008BC ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  115| 0008C0 bl       48000001   1     CALL      advx2,8,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  115| 0008C4 ori      60000000   1
  116| 0008C8 ld       E87E05D0   1     L8        gr3=<s95:d1488:l8>(gr30,1488)
  116| 0008CC ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  116| 0008D0 ld       E8BE0638   1     L8        gr5=<s95:d1592:l8>(gr30,1592)
  116| 0008D4 ld       E8DE0708   1     L8        gr6=<s95:d1800:l8>(gr30,1800)
  116| 0008D8 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  116| 0008DC ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  116| 0008E0 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  116| 0008E4 ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  116| 0008E8 bl       48000001   1     CALL      advx3,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  116| 0008EC ori      60000000   1
    0| 0008F0 b        4BFFFE90   1     B         CL.18,-1
  124|                              CL.16:
  124| 0008F4 cmpwi    2C0B0002   1     C4        cr0=gr11,2
  124| 0008F8 bc       40820134   1     BF        CL.21,cr0,0x4/eq,taken=50%(0,0)
  126| 0008FC bc       418600C8   1     BT        CL.22,cr1,0x4/eq,taken=50%(0,0)
  127| 000900 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  127| 000904 ld       E97E0840   1     L8        gr11=<s95:d2112:l8>(gr30,2112)
  127| 000908 or       7FCEF378   1     LR        gr14=gr30
  127| 00090C ld       EBDE08A8   1     L8        gr30=<s95:d2216:l8>(gr30,2216)
  127| 000910 ld       E81C0410   1     L8        gr0=<s39:d1040:l8>(gr28,1040)
  127| 000914 std      F9610078   1     ST8       #MX_TEMP1(gr1,120)=gr11
  127| 000918 ld       E99C0820   1     L8        gr12=<s39:d2080:l8>(gr28,2080)
  127| 00091C std      FBC10088   1     ST8       #MX_TEMP1(gr1,136)=gr30
  127| 000920 std      F8010070   1     ST8       #MX_TEMP1(gr1,112)=gr0
  127| 000924 std      F9810080   1     ST8       #MX_TEMP1(gr1,128)=gr12
  127| 000928 bl       48000001   1     CALL      advx2,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  127| 00092C ori      60000000   1
  129| 000930 ld       E8AE0840   1     L8        gr5=<s95:d2112:l8>(gr14,2112)
  129| 000934 ld       E8DC0410   1     L8        gr6=<s39:d1040:l8>(gr28,1040)
  129| 000938 ld       E90E08A8   1     L8        gr8=<s95:d2216:l8>(gr14,2216)
  129| 00093C ld       E81C0820   1     L8        gr0=<s39:d2080:l8>(gr28,2080)
  129| 000940 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  129| 000944 ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  129| 000948 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  129| 00094C std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  129| 000950 ld       E8AE0708   1     L8        gr5=<s95:d1800:l8>(gr14,1800)
  129| 000954 ld       E8CE0638   1     L8        gr6=<s95:d1592:l8>(gr14,1592)
  129| 000958 std      F9010080   1     ST8       #MX_TEMP1(gr1,128)=gr8
  129| 00095C ld       E88E05D0   1     L8        gr4=<s95:d1488:l8>(gr14,1488)
  129| 000960 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  129| 000964 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  129| 000968 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  129| 00096C ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  129| 000970 bl       48000001   1     CALL      advx1,12,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,w3dh",er",w4da",abun",advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  129| 000974 ori      60000000   1
  131| 000978 ld       E8BC0410   1     L8        gr5=<s39:d1040:l8>(gr28,1040)
  131| 00097C ld       E8CE0840   1     L8        gr6=<s95:d2112:l8>(gr14,2112)
  131| 000980 ld       E8FC0820   1     L8        gr7=<s39:d2080:l8>(gr28,2080)
  131| 000984 ld       E80E08A8   1     L8        gr0=<s95:d2216:l8>(gr14,2216)
  131| 000988 ld       E86E05D0   1     L8        gr3=<s95:d1488:l8>(gr14,1488)
  131| 00098C ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  131| 000990 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  131| 000994 std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  131| 000998 ld       E8AE0638   1     L8        gr5=<s95:d1592:l8>(gr14,1592)
  131| 00099C std      F8E10080   1     ST8       #MX_TEMP1(gr1,128)=gr7
  131| 0009A0 ld       E8CE0708   1     L8        gr6=<s95:d1800:l8>(gr14,1800)
  131| 0009A4 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  131| 0009A8 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  131| 0009AC std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  131| 0009B0 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  131| 0009B4 ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  131| 0009B8 bl       48000001   1     CALL      advx3,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  131| 0009BC ori      60000000   1
    0| 0009C0 b        48000060   1     B         CL.23,-1
  133|                              CL.22:
  134| 0009C4 bl       48000001   1     CALL      advx2,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  134| 0009C8 ori      60000000   1
  135| 0009CC ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  135| 0009D0 ld       E89E05D0   1     L8        gr4=<s95:d1488:l8>(gr30,1488)
  135| 0009D4 ld       E8BE0708   1     L8        gr5=<s95:d1800:l8>(gr30,1800)
  135| 0009D8 ld       E8DE0638   1     L8        gr6=<s95:d1592:l8>(gr30,1592)
  135| 0009DC ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  135| 0009E0 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  135| 0009E4 ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  135| 0009E8 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  135| 0009EC ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  135| 0009F0 bl       48000001   1     CALL      advx1,8,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  135| 0009F4 ori      60000000   1
  136| 0009F8 ld       E87E05D0   1     L8        gr3=<s95:d1488:l8>(gr30,1488)
  136| 0009FC ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  136| 000A00 ld       E8BE0638   1     L8        gr5=<s95:d1592:l8>(gr30,1592)
  136| 000A04 ld       E8DE0708   1     L8        gr6=<s95:d1800:l8>(gr30,1800)
  136| 000A08 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  136| 000A0C ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  136| 000A10 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  136| 000A14 ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  136| 000A18 bl       48000001   1     CALL      advx3,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  136| 000A1C ori      60000000   1
  137|                              CL.23:
  139| 000A20 addi     38000003   1     LI        gr0=3
  139| 000A24 stw      901F01E0   1     ST4Z      <s201:d480:l4>(gr31,480)=gr0
  140| 000A28 b        4BFFFD60   1     B         CL.19,-1
  144|                              CL.21:
  144| 000A2C cmpwi    2C0B0003   1     C4        cr0=gr11,3
  144| 000A30 bc       40820134   1     BF        CL.25,cr0,0x4/eq,taken=50%(0,0)
  150| 000A34 bc       418600C8   1     BT        CL.26,cr1,0x4/eq,taken=50%(0,0)
  151| 000A38 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  151| 000A3C ld       E97E0840   1     L8        gr11=<s95:d2112:l8>(gr30,2112)
  151| 000A40 or       7FCEF378   1     LR        gr14=gr30
  151| 000A44 ld       EBDE08A8   1     L8        gr30=<s95:d2216:l8>(gr30,2216)
  151| 000A48 ld       E81C0410   1     L8        gr0=<s39:d1040:l8>(gr28,1040)
  151| 000A4C std      F9610078   1     ST8       #MX_TEMP1(gr1,120)=gr11
  151| 000A50 ld       E99C0820   1     L8        gr12=<s39:d2080:l8>(gr28,2080)
  151| 000A54 std      FBC10088   1     ST8       #MX_TEMP1(gr1,136)=gr30
  151| 000A58 std      F8010070   1     ST8       #MX_TEMP1(gr1,112)=gr0
  151| 000A5C std      F9810080   1     ST8       #MX_TEMP1(gr1,128)=gr12
  151| 000A60 bl       48000001   1     CALL      advx2,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  151| 000A64 ori      60000000   1
  153| 000A68 ld       E8AE0840   1     L8        gr5=<s95:d2112:l8>(gr14,2112)
  153| 000A6C ld       E8DC0410   1     L8        gr6=<s39:d1040:l8>(gr28,1040)
  153| 000A70 ld       E90E08A8   1     L8        gr8=<s95:d2216:l8>(gr14,2216)
  153| 000A74 ld       E81C0820   1     L8        gr0=<s39:d2080:l8>(gr28,2080)
  153| 000A78 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  153| 000A7C ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  153| 000A80 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  153| 000A84 std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  153| 000A88 ld       E8AE0708   1     L8        gr5=<s95:d1800:l8>(gr14,1800)
  153| 000A8C ld       E8CE0638   1     L8        gr6=<s95:d1592:l8>(gr14,1592)
  153| 000A90 std      F9010080   1     ST8       #MX_TEMP1(gr1,128)=gr8
  153| 000A94 ld       E88E05D0   1     L8        gr4=<s95:d1488:l8>(gr14,1488)
  153| 000A98 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  153| 000A9C ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  153| 000AA0 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  153| 000AA4 ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  153| 000AA8 bl       48000001   1     CALL      advx3,12,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,w3dh",er",w4da",abun",advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  153| 000AAC ori      60000000   1
  155| 000AB0 ld       E8BC0410   1     L8        gr5=<s39:d1040:l8>(gr28,1040)
  155| 000AB4 ld       E8CE0840   1     L8        gr6=<s95:d2112:l8>(gr14,2112)
  155| 000AB8 ld       E8FC0820   1     L8        gr7=<s39:d2080:l8>(gr28,2080)
  155| 000ABC ld       E80E08A8   1     L8        gr0=<s95:d2216:l8>(gr14,2216)
  155| 000AC0 ld       E86E05D0   1     L8        gr3=<s95:d1488:l8>(gr14,1488)
  155| 000AC4 ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  155| 000AC8 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  155| 000ACC std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  155| 000AD0 ld       E8AE0638   1     L8        gr5=<s95:d1592:l8>(gr14,1592)
  155| 000AD4 std      F8E10080   1     ST8       #MX_TEMP1(gr1,128)=gr7
  155| 000AD8 ld       E8CE0708   1     L8        gr6=<s95:d1800:l8>(gr14,1800)
  155| 000ADC ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  155| 000AE0 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  155| 000AE4 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  155| 000AE8 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  155| 000AEC ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  155| 000AF0 bl       48000001   1     CALL      advx1,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  155| 000AF4 ori      60000000   1
    0| 000AF8 b        48000060   1     B         CL.27,-1
  157|                              CL.26:
  158| 000AFC bl       48000001   1     CALL      advx2,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  158| 000B00 ori      60000000   1
  159| 000B04 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  159| 000B08 ld       E89E05D0   1     L8        gr4=<s95:d1488:l8>(gr30,1488)
  159| 000B0C ld       E8BE0708   1     L8        gr5=<s95:d1800:l8>(gr30,1800)
  159| 000B10 ld       E8DE0638   1     L8        gr6=<s95:d1592:l8>(gr30,1592)
  159| 000B14 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  159| 000B18 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  159| 000B1C ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  159| 000B20 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  159| 000B24 ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  159| 000B28 bl       48000001   1     CALL      advx3,8,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  159| 000B2C ori      60000000   1
  160| 000B30 ld       E87E05D0   1     L8        gr3=<s95:d1488:l8>(gr30,1488)
  160| 000B34 ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  160| 000B38 ld       E8BE0638   1     L8        gr5=<s95:d1592:l8>(gr30,1592)
  160| 000B3C ld       E8DE0708   1     L8        gr6=<s95:d1800:l8>(gr30,1800)
  160| 000B40 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  160| 000B44 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  160| 000B48 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  160| 000B4C ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  160| 000B50 bl       48000001   1     CALL      advx1,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  160| 000B54 ori      60000000   1
  161|                              CL.27:
  163| 000B58 addi     38000004   1     LI        gr0=4
  163| 000B5C stw      901F01E0   1     ST4Z      <s201:d480:l4>(gr31,480)=gr0
  164| 000B60 b        4BFFFC28   1     B         CL.19,-1
  168|                              CL.25:
  168| 000B64 cmpwi    2C0B0004   1     C4        cr0=gr11,4
  168| 000B68 bc       40820134   1     BF        CL.29,cr0,0x4/eq,taken=50%(0,0)
  174| 000B6C bc       418600C8   1     BT        CL.30,cr1,0x4/eq,taken=50%(0,0)
  175| 000B70 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  175| 000B74 ld       E97E0840   1     L8        gr11=<s95:d2112:l8>(gr30,2112)
  175| 000B78 or       7FCEF378   1     LR        gr14=gr30
  175| 000B7C ld       EBDE08A8   1     L8        gr30=<s95:d2216:l8>(gr30,2216)
  175| 000B80 ld       E81C0410   1     L8        gr0=<s39:d1040:l8>(gr28,1040)
  175| 000B84 std      F9610078   1     ST8       #MX_TEMP1(gr1,120)=gr11
  175| 000B88 ld       E99C0820   1     L8        gr12=<s39:d2080:l8>(gr28,2080)
  175| 000B8C std      FBC10088   1     ST8       #MX_TEMP1(gr1,136)=gr30
  175| 000B90 std      F8010070   1     ST8       #MX_TEMP1(gr1,112)=gr0
  175| 000B94 std      F9810080   1     ST8       #MX_TEMP1(gr1,128)=gr12
  175| 000B98 bl       48000001   1     CALL      advx3,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  175| 000B9C ori      60000000   1
  177| 000BA0 ld       E8AE0840   1     L8        gr5=<s95:d2112:l8>(gr14,2112)
  177| 000BA4 ld       E8DC0410   1     L8        gr6=<s39:d1040:l8>(gr28,1040)
  177| 000BA8 ld       E90E08A8   1     L8        gr8=<s95:d2216:l8>(gr14,2216)
  177| 000BAC ld       E81C0820   1     L8        gr0=<s39:d2080:l8>(gr28,2080)
  177| 000BB0 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  177| 000BB4 ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  177| 000BB8 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  177| 000BBC std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  177| 000BC0 ld       E8AE0708   1     L8        gr5=<s95:d1800:l8>(gr14,1800)
  177| 000BC4 ld       E8CE0638   1     L8        gr6=<s95:d1592:l8>(gr14,1592)
  177| 000BC8 std      F9010080   1     ST8       #MX_TEMP1(gr1,128)=gr8
  177| 000BCC ld       E88E05D0   1     L8        gr4=<s95:d1488:l8>(gr14,1488)
  177| 000BD0 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  177| 000BD4 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  177| 000BD8 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  177| 000BDC ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  177| 000BE0 bl       48000001   1     CALL      advx2,12,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,w3dh",er",w4da",abun",advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  177| 000BE4 ori      60000000   1
  179| 000BE8 ld       E8BC0410   1     L8        gr5=<s39:d1040:l8>(gr28,1040)
  179| 000BEC ld       E8CE0840   1     L8        gr6=<s95:d2112:l8>(gr14,2112)
  179| 000BF0 ld       E8FC0820   1     L8        gr7=<s39:d2080:l8>(gr28,2080)
  179| 000BF4 ld       E80E08A8   1     L8        gr0=<s95:d2216:l8>(gr14,2216)
  179| 000BF8 ld       E86E05D0   1     L8        gr3=<s95:d1488:l8>(gr14,1488)
  179| 000BFC ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  179| 000C00 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  179| 000C04 std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  179| 000C08 ld       E8AE0638   1     L8        gr5=<s95:d1592:l8>(gr14,1592)
  179| 000C0C std      F8E10080   1     ST8       #MX_TEMP1(gr1,128)=gr7
  179| 000C10 ld       E8CE0708   1     L8        gr6=<s95:d1800:l8>(gr14,1800)
  179| 000C14 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  179| 000C18 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  179| 000C1C std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  179| 000C20 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  179| 000C24 ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  179| 000C28 bl       48000001   1     CALL      advx1,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  179| 000C2C ori      60000000   1
    0| 000C30 b        48000060   1     B         CL.31,-1
  181|                              CL.30:
  182| 000C34 bl       48000001   1     CALL      advx3,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  182| 000C38 ori      60000000   1
  183| 000C3C ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  183| 000C40 ld       E89E05D0   1     L8        gr4=<s95:d1488:l8>(gr30,1488)
  183| 000C44 ld       E8BE0708   1     L8        gr5=<s95:d1800:l8>(gr30,1800)
  183| 000C48 ld       E8DE0638   1     L8        gr6=<s95:d1592:l8>(gr30,1592)
  183| 000C4C ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  183| 000C50 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  183| 000C54 ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  183| 000C58 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  183| 000C5C ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  183| 000C60 bl       48000001   1     CALL      advx2,8,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  183| 000C64 ori      60000000   1
  184| 000C68 ld       E87E05D0   1     L8        gr3=<s95:d1488:l8>(gr30,1488)
  184| 000C6C ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  184| 000C70 ld       E8BE0638   1     L8        gr5=<s95:d1592:l8>(gr30,1592)
  184| 000C74 ld       E8DE0708   1     L8        gr6=<s95:d1800:l8>(gr30,1800)
  184| 000C78 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  184| 000C7C ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  184| 000C80 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  184| 000C84 ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  184| 000C88 bl       48000001   1     CALL      advx1,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  184| 000C8C ori      60000000   1
  185|                              CL.31:
  187| 000C90 addi     38000005   1     LI        gr0=5
  187| 000C94 stw      901F01E0   1     ST4Z      <s201:d480:l4>(gr31,480)=gr0
  188| 000C98 b        4BFFFAF0   1     B         CL.19,-1
  192|                              CL.29:
  192| 000C9C cmpwi    2C0B0005   1     C4        cr0=gr11,5
  192| 000CA0 bc       40820134   1     BF        CL.33,cr0,0x4/eq,taken=50%(0,0)
  198| 000CA4 bc       418600C8   1     BT        CL.34,cr1,0x4/eq,taken=50%(0,0)
  199| 000CA8 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  199| 000CAC ld       E97E0840   1     L8        gr11=<s95:d2112:l8>(gr30,2112)
  199| 000CB0 or       7FCEF378   1     LR        gr14=gr30
  199| 000CB4 ld       EBDE08A8   1     L8        gr30=<s95:d2216:l8>(gr30,2216)
  199| 000CB8 ld       E81C0410   1     L8        gr0=<s39:d1040:l8>(gr28,1040)
  199| 000CBC std      F9610078   1     ST8       #MX_TEMP1(gr1,120)=gr11
  199| 000CC0 ld       E99C0820   1     L8        gr12=<s39:d2080:l8>(gr28,2080)
  199| 000CC4 std      FBC10088   1     ST8       #MX_TEMP1(gr1,136)=gr30
  199| 000CC8 std      F8010070   1     ST8       #MX_TEMP1(gr1,112)=gr0
  199| 000CCC std      F9810080   1     ST8       #MX_TEMP1(gr1,128)=gr12
  199| 000CD0 bl       48000001   1     CALL      advx3,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  199| 000CD4 ori      60000000   1
  201| 000CD8 ld       E8AE0840   1     L8        gr5=<s95:d2112:l8>(gr14,2112)
  201| 000CDC ld       E8DC0410   1     L8        gr6=<s39:d1040:l8>(gr28,1040)
  201| 000CE0 ld       E90E08A8   1     L8        gr8=<s95:d2216:l8>(gr14,2216)
  201| 000CE4 ld       E81C0820   1     L8        gr0=<s39:d2080:l8>(gr28,2080)
  201| 000CE8 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  201| 000CEC ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  201| 000CF0 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  201| 000CF4 std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  201| 000CF8 ld       E8AE0708   1     L8        gr5=<s95:d1800:l8>(gr14,1800)
  201| 000CFC ld       E8CE0638   1     L8        gr6=<s95:d1592:l8>(gr14,1592)
  201| 000D00 std      F9010080   1     ST8       #MX_TEMP1(gr1,128)=gr8
  201| 000D04 ld       E88E05D0   1     L8        gr4=<s95:d1488:l8>(gr14,1488)
  201| 000D08 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  201| 000D0C ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  201| 000D10 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  201| 000D14 ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  201| 000D18 bl       48000001   1     CALL      advx1,12,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,w3dh",er",w4da",abun",advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  201| 000D1C ori      60000000   1
  203| 000D20 ld       E8BC0410   1     L8        gr5=<s39:d1040:l8>(gr28,1040)
  203| 000D24 ld       E8CE0840   1     L8        gr6=<s95:d2112:l8>(gr14,2112)
  203| 000D28 ld       E8FC0820   1     L8        gr7=<s39:d2080:l8>(gr28,2080)
  203| 000D2C ld       E80E08A8   1     L8        gr0=<s95:d2216:l8>(gr14,2216)
  203| 000D30 ld       E86E05D0   1     L8        gr3=<s95:d1488:l8>(gr14,1488)
  203| 000D34 ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  203| 000D38 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  203| 000D3C std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  203| 000D40 ld       E8AE0638   1     L8        gr5=<s95:d1592:l8>(gr14,1592)
  203| 000D44 std      F8E10080   1     ST8       #MX_TEMP1(gr1,128)=gr7
  203| 000D48 ld       E8CE0708   1     L8        gr6=<s95:d1800:l8>(gr14,1800)
  203| 000D4C ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  203| 000D50 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  203| 000D54 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  203| 000D58 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  203| 000D5C ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  203| 000D60 bl       48000001   1     CALL      advx2,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  203| 000D64 ori      60000000   1
    0| 000D68 b        48000060   1     B         CL.35,-1
  205|                              CL.34:
  206| 000D6C bl       48000001   1     CALL      advx3,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  206| 000D70 ori      60000000   1
  207| 000D74 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  207| 000D78 ld       E89E05D0   1     L8        gr4=<s95:d1488:l8>(gr30,1488)
  207| 000D7C ld       E8BE0708   1     L8        gr5=<s95:d1800:l8>(gr30,1800)
  207| 000D80 ld       E8DE0638   1     L8        gr6=<s95:d1592:l8>(gr30,1592)
  207| 000D84 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  207| 000D88 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  207| 000D8C ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  207| 000D90 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  207| 000D94 ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  207| 000D98 bl       48000001   1     CALL      advx1,8,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  207| 000D9C ori      60000000   1
  208| 000DA0 ld       E87E05D0   1     L8        gr3=<s95:d1488:l8>(gr30,1488)
  208| 000DA4 ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  208| 000DA8 ld       E8BE0638   1     L8        gr5=<s95:d1592:l8>(gr30,1592)
  208| 000DAC ld       E8DE0708   1     L8        gr6=<s95:d1800:l8>(gr30,1800)
  208| 000DB0 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  208| 000DB4 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  208| 000DB8 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  208| 000DBC ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  208| 000DC0 bl       48000001   1     CALL      advx2,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  208| 000DC4 ori      60000000   1
  209|                              CL.35:
  211| 000DC8 addi     38000006   1     LI        gr0=6
  211| 000DCC stw      901F01E0   1     ST4Z      <s201:d480:l4>(gr31,480)=gr0
  212| 000DD0 b        4BFFF9B8   1     B         CL.19,-1
  216|                              CL.33:
  222| 000DD4 bc       418600C8   1     BT        CL.37,cr1,0x4/eq,taken=50%(0,0)
  223| 000DD8 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  223| 000DDC ld       E97E0840   1     L8        gr11=<s95:d2112:l8>(gr30,2112)
  223| 000DE0 or       7FCEF378   1     LR        gr14=gr30
  223| 000DE4 ld       EBDE08A8   1     L8        gr30=<s95:d2216:l8>(gr30,2216)
  223| 000DE8 ld       E81C0410   1     L8        gr0=<s39:d1040:l8>(gr28,1040)
  223| 000DEC std      F9610078   1     ST8       #MX_TEMP1(gr1,120)=gr11
  223| 000DF0 ld       E99C0820   1     L8        gr12=<s39:d2080:l8>(gr28,2080)
  223| 000DF4 std      FBC10088   1     ST8       #MX_TEMP1(gr1,136)=gr30
  223| 000DF8 std      F8010070   1     ST8       #MX_TEMP1(gr1,112)=gr0
  223| 000DFC std      F9810080   1     ST8       #MX_TEMP1(gr1,128)=gr12
  223| 000E00 bl       48000001   1     CALL      advx1,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  223| 000E04 ori      60000000   1
  225| 000E08 ld       E8AE0840   1     L8        gr5=<s95:d2112:l8>(gr14,2112)
  225| 000E0C ld       E8DC0410   1     L8        gr6=<s39:d1040:l8>(gr28,1040)
  225| 000E10 ld       E90E08A8   1     L8        gr8=<s95:d2216:l8>(gr14,2216)
  225| 000E14 ld       E81C0820   1     L8        gr0=<s39:d2080:l8>(gr28,2080)
  225| 000E18 ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  225| 000E1C ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  225| 000E20 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  225| 000E24 std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  225| 000E28 ld       E8AE0708   1     L8        gr5=<s95:d1800:l8>(gr14,1800)
  225| 000E2C ld       E8CE0638   1     L8        gr6=<s95:d1592:l8>(gr14,1592)
  225| 000E30 ld       E88E05D0   1     L8        gr4=<s95:d1488:l8>(gr14,1488)
  225| 000E34 std      F9010080   1     ST8       #MX_TEMP1(gr1,128)=gr8
  225| 000E38 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  225| 000E3C ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  225| 000E40 ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  225| 000E44 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  225| 000E48 bl       48000001   1     CALL      advx3,12,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,w3dh",er",w4da",abun",advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  225| 000E4C ori      60000000   1
  227| 000E50 ld       E8BC0410   1     L8        gr5=<s39:d1040:l8>(gr28,1040)
  227| 000E54 ld       E8CE0840   1     L8        gr6=<s95:d2112:l8>(gr14,2112)
  227| 000E58 ld       E8FC0820   1     L8        gr7=<s39:d2080:l8>(gr28,2080)
  227| 000E5C ld       E80E08A8   1     L8        gr0=<s95:d2216:l8>(gr14,2216)
  227| 000E60 ld       E86E05D0   1     L8        gr3=<s95:d1488:l8>(gr14,1488)
  227| 000E64 ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  227| 000E68 std      F8A10070   1     ST8       #MX_TEMP1(gr1,112)=gr5
  227| 000E6C std      F8C10078   1     ST8       #MX_TEMP1(gr1,120)=gr6
  227| 000E70 ld       E8AE0638   1     L8        gr5=<s95:d1592:l8>(gr14,1592)
  227| 000E74 ld       E8CE0708   1     L8        gr6=<s95:d1800:l8>(gr14,1800)
  227| 000E78 std      F8E10080   1     ST8       #MX_TEMP1(gr1,128)=gr7
  227| 000E7C ld       E8EE06A0   1     L8        gr7=<s95:d1696:l8>(gr14,1696)
  227| 000E80 ld       E90E0498   1     L8        gr8=<s95:d1176:l8>(gr14,1176)
  227| 000E84 ld       E92E0500   1     L8        gr9=<s95:d1280:l8>(gr14,1280)
  227| 000E88 std      F8010088   1     ST8       #MX_TEMP1(gr1,136)=gr0
  227| 000E8C ld       E94E0568   1     L8        gr10=<s95:d1384:l8>(gr14,1384)
  227| 000E90 bl       48000001   1     CALL      advx2,12,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,er",w3dh",abun",w4da",advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  227| 000E94 ori      60000000   1
    0| 000E98 b        48000060   1     B         CL.38,-1
  229|                              CL.37:
  230| 000E9C bl       48000001   1     CALL      advx1,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  230| 000EA0 ori      60000000   1
  231| 000EA4 ld       EB820000   1     L8        gr28=.&&N&field(gr2,0)
  231| 000EA8 ld       E89E05D0   1     L8        gr4=<s95:d1488:l8>(gr30,1488)
  231| 000EAC ld       E8BE0708   1     L8        gr5=<s95:d1800:l8>(gr30,1800)
  231| 000EB0 ld       E8DE0638   1     L8        gr6=<s95:d1592:l8>(gr30,1592)
  231| 000EB4 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  231| 000EB8 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  231| 000EBC ld       E87C0000   1     L8        gr3=<s39:d0:l8>(gr28,0)
  231| 000EC0 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  231| 000EC4 ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  231| 000EC8 bl       48000001   1     CALL      advx3,8,d",gr3,w3dd",gr4,w3dg",gr5,w3de",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  231| 000ECC ori      60000000   1
  232| 000ED0 ld       E87E05D0   1     L8        gr3=<s95:d1488:l8>(gr30,1488)
  232| 000ED4 ld       E89C0000   1     L8        gr4=<s39:d0:l8>(gr28,0)
  232| 000ED8 ld       E8BE0638   1     L8        gr5=<s95:d1592:l8>(gr30,1592)
  232| 000EDC ld       E8DE0708   1     L8        gr6=<s95:d1800:l8>(gr30,1800)
  232| 000EE0 ld       E8FE06A0   1     L8        gr7=<s95:d1696:l8>(gr30,1696)
  232| 000EE4 ld       E91E0498   1     L8        gr8=<s95:d1176:l8>(gr30,1176)
  232| 000EE8 ld       E93E0500   1     L8        gr9=<s95:d1280:l8>(gr30,1280)
  232| 000EEC ld       E95E0568   1     L8        gr10=<s95:d1384:l8>(gr30,1384)
  232| 000EF0 bl       48000001   1     CALL      advx2,8,w3dd",gr3,d",gr4,w3de",gr5,w3dg",gr6,w3df",gr7,w3da",gr8,w3db",gr9,w3dc",gr10,advx2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  232| 000EF4 ori      60000000   1
  233|                              CL.38:
  235| 000EF8 addi     38000001   1     LI        gr0=1
  235| 000EFC stw      901F01E0   1     ST4Z      <s201:d480:l4>(gr31,480)=gr0
    0| 000F00 b        4BFFF888   1     B         CL.19,-1
  256|                              CL.2:
  257| 000F04 lwz      80030018   1     L4Z       gr0=<s177:d24:l4>(gr3,24)
  257| 000F08 cmpdi    2C200000   1     C8        cr0=gr0,0
  257| 000F0C bc       41820428   1     BT        CL.432,cr0,0x4/eq,taken=30%(30,70)
  262| 000F10 ld       E8A20000   1     L8        gr5=.&&N&&grid(gr2,0)
    0| 000F14 addi     38800000   1     LI        gr4=0
  262| 000F18 lwa      E8050016   1     L4A       gr0=<s183:d20:l4>(gr5,20)
  262| 000F1C lwa      E8C50012   1     L4A       gr6=<s183:d16:l4>(gr5,16)
  262| 000F20 subf     7C660050   1     S         gr3=gr0,gr6
  262| 000F24 addi     38030001   1     AI        gr0=gr3,1
  262| 000F28 sradi    7C031674   1     SRA8CA    gr3,ca=gr0,2
  262| 000F2C cmpdi    2F200000   1     C8        cr6=gr0,0
  262| 000F30 addze    7C630194   1     ADDE      gr3,ca=gr3,0,ca
  262| 000F34 rldicr   78631764   1     SLL8      gr3=gr3,2
  262| 000F38 subf     7CE30051   1     S_R       gr7,cr0=gr0,gr3
  262| 000F3C crand    4C390A02   1     CR_N      cr0=cr[60],0x2/gt,0x2/gt,0x2/gt,cr0
  262| 000F40 bc       4081010C   1     BF        CL.91,cr0,0x2/gt,taken=50%(0,0)
  265| 000F44 ld       EBA20000   1     L8        gr29=.&&N&field(gr2,0)
  265| 000F48 ld       EB820000   1     L8        gr28=.&&N&scratch(gr2,0)
  263| 000F4C lwa      EAA5000A   1     L4A       gr21=<s183:d8:l4>(gr5,8)
  263| 000F50 lwa      EB65000E   1     L4A       gr27=<s183:d12:l4>(gr5,12)
  264| 000F54 lwa      E9450002   1     L4A       gr10=<s183:d0:l4>(gr5,0)
  264| 000F58 lwa      EB450006   1     L4A       gr26=<s183:d4:l4>(gr5,4)
  265| 000F5C ld       E97D0440   1     L8        gr11=<s39:d1088:l8>(gr29,1088)
  265| 000F60 ld       E99D0458   1     L8        gr12=<s39:d1112:l8>(gr29,1112)
  265| 000F64 ld       E91D0470   1     L8        gr8=<s39:d1136:l8>(gr29,1136)
  265| 000F68 ld       EBFC0870   1     L8        gr31=<s95:d2160:l8>(gr28,2160)
  265| 000F6C ld       EBDC0888   1     L8        gr30=<s95:d2184:l8>(gr28,2184)
  265| 000F70 ld       E93C08A0   1     L8        gr9=<s95:d2208:l8>(gr28,2208)
  265| 000F74 ld       EA7D0410   1     L8        gr19=<s39:d1040:l8>(gr29,1040)
  265| 000F78 ld       EA5C0840   1     L8        gr18=<s95:d2112:l8>(gr28,2112)
  263| 000F7C subf     7F75D850   1     S         gr27=gr27,gr21
  265| 000F80 ld       EBBD0428   1     L8        gr29=<s39:d1064:l8>(gr29,1064)
  265| 000F84 ld       EB9C0858   1     L8        gr28=<s95:d2136:l8>(gr28,2136)
  263| 000F88 addic.   377B0001   1     AI_R      gr27,cr0=gr27,1,ca"
    0| 000F8C bc       40810394   1     BF        CL.217,cr0,0x2/gt,taken=50%(0,0)
    0| 000F90 mulld    7F2951D2   1     M         gr25=gr9,gr10
    0| 000F94 mulld    7F06F9D2   1     M         gr24=gr6,gr31
    0| 000F98 mulld    7EF5F1D2   1     M         gr23=gr21,gr30
    0| 000F9C mulld    7EC659D2   1     M         gr22=gr6,gr11
    0| 000FA0 mulld    7EB561D2   1     M         gr21=gr21,gr12
    0| 000FA4 mulld    7E8851D2   1     M         gr20=gr8,gr10
    0| 000FA8 subf     7E499050   1     S         gr18=gr18,gr9
    0| 000FAC subf     7E689850   1     S         gr19=gr19,gr8
    0| 000FB0 add      7F9C9214   1     A         gr28=gr28,gr18
    0| 000FB4 add      7FBD9A14   1     A         gr29=gr29,gr19
    0| 000FB8 subfic   226A0001   1     SFI       gr19=1,gr10,ca"
    0| 000FBC add      7F38CA14   1     A         gr25=gr24,gr25
    0| 000FC0 add      7F97E214   1     A         gr28=gr23,gr28
    0| 000FC4 add      7F15B214   1     A         gr24=gr21,gr22
    0| 000FC8 add      7FB4EA14   1     A         gr29=gr20,gr29
    0| 000FCC subf     7D4AD050   1     S         gr10=gr26,gr10
    0| 000FD0 add      7F5A9A14   1     A         gr26=gr26,gr19
    0| 000FD4 add      7F99E214   1     A         gr28=gr25,gr28
    0| 000FD8 add      7FB8EA14   1     A         gr29=gr24,gr29
    0| 000FDC addic.   354A0001   1     AI_R      gr10,cr0=gr10,1,ca"
  262|                              CL.86:
  263| 000FE0 addi     39400000   1     LI        gr10=0
    0| 000FE4 bc       40810054   1     BF        CL.90,cr0,0x2/gt,taken=20%(20,80)
    0| 000FE8 or       7FB7EB78   1     LR        gr23=gr29
    0| 000FEC or       7F96E378   1     LR        gr22=gr28
  263|                              CL.87:
  265| 000FF0 or       7EF9BB78   1     LR        gr25=gr23
    0| 000FF4 mtspr    7F4903A6   1     LCTR      ctr=gr26
  265| 000FF8 lfdux    7C1944EE   1     LFDU      fp0,gr25=er(gr25,gr8,0)
  265| 000FFC or       7ED8B378   1     LR        gr24=gr22
    0| 001000 bc       42400020   1     BCF       ctr=CL.330,taken=0%(0,100)
    0| 001004 ori      60210000   1     XNOP      
    0| 001008 ori      60210000   1     XNOP      
    0| 00100C ori      60210000   1     XNOP      
    0|                              CL.331:
  265| 001010 lfdux    7C3944EE   1     LFDU      fp1,gr25=er(gr25,gr8,0)
  265| 001014 stfdux   7C184DEE   1     STFDU     gr24,w3dh(gr24,gr9,0)=fp0
    0| 001018 fmr      FC000890   1     LRFL      fp0=fp1
    0| 00101C bc       4200FFF4   1     BCT       ctr=CL.331,taken=100%(100,0)
    0|                              CL.330:
  267| 001020 addi     394A0001   1     AI        gr10=gr10,1
  265| 001024 stfdux   7C184DEE   1     STFDU     gr24,w3dh(gr24,gr9,0)=fp0
  267| 001028 cmpld    7CAAD840   1     CL8       cr1=gr10,gr27
    0| 00102C add      7EECBA14   1     A         gr23=gr12,gr23
    0| 001030 add      7ED6F214   1     A         gr22=gr22,gr30
  267| 001034 bc       4184FFBC   1     BT        CL.87,cr1,0x8/llt,taken=80%(80,20)
  267|                              CL.90:
  268| 001038 addi     38840001   1     AI        gr4=gr4,1
    0| 00103C add      7FABEA14   1     A         gr29=gr11,gr29
  268| 001040 cmpd     7CA72000   1     C8        cr1=gr7,gr4
    0| 001044 add      7F9CFA14   1     A         gr28=gr28,gr31
  268| 001048 bc       4185FF98   1     BT        CL.86,cr1,0x2/gt,taken=80%(80,20)
  268|                              CL.91:
  262| 00104C cmpd     7CA03800   1     C8        cr1=gr0,gr7
  262| 001050 crand    4C392A02   1     CR_N      cr0=cr[61],0x2/gt,0x2/gt,0x2/gt,cr0
  262| 001054 bc       40810258   1     BF        CL.69,cr0,0x2/gt,taken=50%(0,0)
  265| 001058 ld       E9620000   1     L8        gr11=.&&N&field(gr2,0)
  265| 00105C ld       E9820000   1     L8        gr12=.&&N&scratch(gr2,0)
  263| 001060 lwa      EB45000A   1     L4A       gr26=<s183:d8:l4>(gr5,8)
  263| 001064 lwa      EBE5000E   1     L4A       gr31=<s183:d12:l4>(gr5,12)
  264| 001068 lwa      E9450002   1     L4A       gr10=<s183:d0:l4>(gr5,0)
  268| 00106C addi     3AC3FFFF   1     AI        gr22=gr3,-1
  265| 001070 ld       E90B0440   1     L8        gr8=<s39:d1088:l8>(gr11,1088)
  265| 001074 ld       E80B0458   1     L8        gr0=<s39:d1112:l8>(gr11,1112)
  265| 001078 ld       E86B0470   1     L8        gr3=<s39:d1136:l8>(gr11,1136)
  265| 00107C ld       E92C0870   1     L8        gr9=<s95:d2160:l8>(gr12,2160)
  265| 001080 ld       EBCC0888   1     L8        gr30=<s95:d2184:l8>(gr12,2184)
  265| 001084 ld       E88C08A0   1     L8        gr4=<s95:d2208:l8>(gr12,2208)
  265| 001088 ld       EAEB0410   1     L8        gr23=<s39:d1040:l8>(gr11,1040)
  265| 00108C ld       EAAC0840   1     L8        gr21=<s95:d2112:l8>(gr12,2112)
  263| 001090 subf     7FFAF850   1     S         gr31=gr31,gr26
  265| 001094 ld       E96B0428   1     L8        gr11=<s39:d1064:l8>(gr11,1064)
  265| 001098 ld       EB0C0858   1     L8        gr24=<s95:d2136:l8>(gr12,2136)
    0| 00109C mulld    7D8451D2   1     M         gr12=gr4,gr10
  263| 0010A0 addic.   37BF0001   1     AI_R      gr29,cr0=gr31,1,ca"
    0| 0010A4 mulld    7FE649D2   1     M         gr31=gr6,gr9
    0| 0010A8 mulld    7F9AF1D2   1     M         gr28=gr26,gr30
    0| 0010AC mulld    7F6641D2   1     M         gr27=gr6,gr8
    0| 0010B0 mulld    7F5A01D2   1     M         gr26=gr26,gr0
    0| 0010B4 mulld    7F2351D2   1     M         gr25=gr3,gr10
    0| 0010B8 subf     7EA4A850   1     S         gr21=gr21,gr4
    0| 0010BC subf     7EE3B850   1     S         gr23=gr23,gr3
  264| 0010C0 lwa      E8C50006   1     L4A       gr6=<s183:d4:l4>(gr5,4)
    0| 0010C4 add      7F18AA14   1     A         gr24=gr24,gr21
    0| 0010C8 add      7EEBBA14   1     A         gr23=gr11,gr23
  268| 0010CC sradi    7ED61674   1     SRA8CA    gr22,ca=gr22,2
    0| 0010D0 mulld    7D6749D2   1     M         gr11=gr7,gr9
    0| 0010D4 mulld    7CE741D2   1     M         gr7=gr7,gr8
    0| 0010D8 add      7D8CFA14   1     A         gr12=gr12,gr31
    0| 0010DC add      7FF8E214   1     A         gr31=gr24,gr28
    0| 0010E0 add      7F9ADA14   1     A         gr28=gr26,gr27
    0| 0010E4 add      7F77CA14   1     A         gr27=gr23,gr25
    0| 0010E8 rldicr   79341764   1     SLL8      gr20=gr9,2
    0| 0010EC rldicr   79131764   1     SLL8      gr19=gr8,2
    0| 0010F0 std      FA8101E0   1     ST8       #SPILL39(gr1,480)=gr20
    0| 0010F4 std      FA6101E8   1     ST8       #SPILL40(gr1,488)=gr19
  262| 0010F8 addi     3A400000   1     LI        gr18=0
  268| 0010FC addze    7CB60194   1     ADDE      gr5,ca=gr22,0,ca
  262| 001100 std      FA4101F0   1     ST8       #SPILL41(gr1,496)=gr18
    0| 001104 add      7D8CFA14   1     A         gr12=gr12,gr31
    0| 001108 add      7F7BE214   1     A         gr27=gr27,gr28
    0| 00110C subf     7FEA3050   1     S         gr31=gr6,gr10
    0| 001110 bc       4081019C   1     BF        CL.69,cr0,0x2/gt,taken=20%(20,80)
    0| 001114 subfic   214A0001   1     SFI       gr10=1,gr10,ca"
    0| 001118 add      7F8B6214   1     A         gr28=gr11,gr12
    0| 00111C add      7CC65214   1     A         gr6=gr6,gr10
    0| 001120 subf     7D89A050   1     S         gr12=gr20,gr9
    0| 001124 add      7F67DA14   1     A         gr27=gr7,gr27
    0| 001128 rldicr   792B0FA4   1     SLL8      gr11=gr9,1
    0| 00112C rldicr   790A0FA4   1     SLL8      gr10=gr8,1
    0| 001130 subf     7CE89850   1     S         gr7=gr19,gr8
    0| 001134 addic.   37FF0001   1     AI_R      gr31,cr0=gr31,1,ca"
    0| 001138 rldicl   78DAF842   1     SRL8      gr26=gr6,1
    0| 00113C add      7EA9E214   1     A         gr21=gr9,gr28
    0| 001140 add      7D2CE214   1     A         gr9=gr12,gr28
    0| 001144 std      FAA101F8   1     ST8       #SPILL42(gr1,504)=gr21
    0| 001148 std      F9210200   1     ST8       #SPILL43(gr1,512)=gr9
    0| 00114C add      7EC8DA14   1     A         gr22=gr8,gr27
    0| 001150 addi     39050001   1     AI        gr8=gr5,1
    0| 001154 add      7F2BE214   1     A         gr25=gr11,gr28
    0| 001158 std      F9010208   1     ST8       #SPILL44(gr1,520)=gr8
    0| 00115C add      7F0ADA14   1     A         gr24=gr10,gr27
    0| 001160 add      7EE7DA14   1     A         gr23=gr7,gr27
    0| 001164 mcrf     4C800000   1     LRCR      cr1=cr0
    0| 001168 andi.    70C50001   1     RN4_R     gr5,cr0=gr6,0,0x1
    0| 00116C cmpdi    2FBA0000   1     C8        cr7=gr26,0
  262|                              CL.70:
  263| 001170 addi     38A00000   1     LI        gr5=0
    0| 001174 bc       408500E8   1     BF        CL.71,cr1,0x2/gt,taken=20%(20,80)
    0| 001178 or       7F75DB78   1     LR        gr21=gr27
    0| 00117C or       7EF4BB78   1     LR        gr20=gr23
    0| 001180 or       7ED3B378   1     LR        gr19=gr22
    0| 001184 or       7F12C378   1     LR        gr18=gr24
    0| 001188 or       7F91E378   1     LR        gr17=gr28
    0| 00118C ld       EA010200   1     L8        gr16=#SPILL43(gr1,512)
    0| 001190 or       7F2FCB78   1     LR        gr15=gr25
    0| 001194 ld       E9C101F8   1     L8        gr14=#SPILL42(gr1,504)
  263|                              CL.72:
  265| 001198 or       7EA6AB78   1     LR        gr6=gr21
  265| 00119C or       7E679B78   1     LR        gr7=gr19
  265| 0011A0 or       7E489378   1     LR        gr8=gr18
  265| 0011A4 or       7E89A378   1     LR        gr9=gr20
  265| 0011A8 or       7E2A8B78   1     LR        gr10=gr17
  265| 0011AC or       7DCB7378   1     LR        gr11=gr14
  265| 0011B0 or       7DEC7B78   1     LR        gr12=gr15
  265| 0011B4 or       7E1F8378   1     LR        gr31=gr16
    0| 0011B8 mtspr    7F4903A6   1     LCTR      ctr=gr26
    0| 0011BC bc       41820030   1     BT        CL.324,cr0,0x4/eq,taken=50%(0,0)
  265| 0011C0 lfdux    7C061CEE   1     LFDU      fp0,gr6=er(gr6,gr3,0)
  265| 0011C4 lfdux    7C271CEE   1     LFDU      fp1,gr7=er(gr7,gr3,0)
  265| 0011C8 lfdux    7C481CEE   1     LFDU      fp2,gr8=er(gr8,gr3,0)
  265| 0011CC lfdux    7C691CEE   1     LFDU      fp3,gr9=er(gr9,gr3,0)
  265| 0011D0 stfdux   7C0A25EE   1     STFDU     gr10,w3dh(gr10,gr4,0)=fp0
  265| 0011D4 stfdux   7C2B25EE   1     STFDU     gr11,w3dh(gr11,gr4,0)=fp1
  265| 0011D8 stfdux   7C4C25EE   1     STFDU     gr12,w3dh(gr12,gr4,0)=fp2
  265| 0011DC stfdux   7C7F25EE   1     STFDU     gr31,w3dh(gr31,gr4,0)=fp3
    0| 0011E0 bc       419E0050   1     BT        CL.283,cr7,0x4/eq,taken=20%(20,80)
    0| 0011E4 ori      60210000   1     XNOP      
    0| 0011E8 ori      60210000   1     XNOP      
    0|                              CL.324:
  265| 0011EC lfdux    7C061CEE   1     LFDU      fp0,gr6=er(gr6,gr3,0)
  265| 0011F0 lfdux    7C271CEE   1     LFDU      fp1,gr7=er(gr7,gr3,0)
  265| 0011F4 lfdux    7C481CEE   1     LFDU      fp2,gr8=er(gr8,gr3,0)
  265| 0011F8 lfdux    7C691CEE   1     LFDU      fp3,gr9=er(gr9,gr3,0)
  265| 0011FC lfdux    7C861CEE   1     LFDU      fp4,gr6=er(gr6,gr3,0)
  265| 001200 lfdux    7CA71CEE   1     LFDU      fp5,gr7=er(gr7,gr3,0)
  265| 001204 lfdux    7CC81CEE   1     LFDU      fp6,gr8=er(gr8,gr3,0)
  265| 001208 lfdux    7CE91CEE   1     LFDU      fp7,gr9=er(gr9,gr3,0)
  265| 00120C stfdux   7C0A25EE   1     STFDU     gr10,w3dh(gr10,gr4,0)=fp0
  265| 001210 stfdux   7C2B25EE   1     STFDU     gr11,w3dh(gr11,gr4,0)=fp1
  265| 001214 stfdux   7C4C25EE   1     STFDU     gr12,w3dh(gr12,gr4,0)=fp2
  265| 001218 stfdux   7C7F25EE   1     STFDU     gr31,w3dh(gr31,gr4,0)=fp3
  265| 00121C stfdux   7C8A25EE   1     STFDU     gr10,w3dh(gr10,gr4,0)=fp4
  265| 001220 stfdux   7CAB25EE   1     STFDU     gr11,w3dh(gr11,gr4,0)=fp5
  265| 001224 stfdux   7CCC25EE   1     STFDU     gr12,w3dh(gr12,gr4,0)=fp6
  265| 001228 stfdux   7CFF25EE   1     STFDU     gr31,w3dh(gr31,gr4,0)=fp7
    0| 00122C bc       4200FFC0   1     BCT       ctr=CL.324,taken=100%(100,0)
    0|                              CL.283:
  267| 001230 addi     38A50001   1     AI        gr5=gr5,1
    0| 001234 add      7EA0AA14   1     A         gr21=gr0,gr21
  267| 001238 cmpld    7F25E840   1     CL8       cr6=gr5,gr29
    0| 00123C add      7E80A214   1     A         gr20=gr0,gr20
    0| 001240 add      7E609A14   1     A         gr19=gr0,gr19
    0| 001244 add      7E409214   1     A         gr18=gr0,gr18
    0| 001248 add      7E31F214   1     A         gr17=gr17,gr30
    0| 00124C add      7E10F214   1     A         gr16=gr16,gr30
    0| 001250 add      7DEFF214   1     A         gr15=gr15,gr30
    0| 001254 add      7DCEF214   1     A         gr14=gr14,gr30
  267| 001258 bc       4198FF40   1     BT        CL.72,cr6,0x8/llt,taken=80%(80,20)
  267|                              CL.71:
  268| 00125C ld       E8A101F0   1     L8        gr5=#SPILL41(gr1,496)
    0| 001260 ld       E8C101E0   1     L8        gr6=#SPILL39(gr1,480)
    0| 001264 ld       E8E101F8   1     L8        gr7=#SPILL42(gr1,504)
  268| 001268 ld       E9010208   1     L8        gr8=#SPILL44(gr1,520)
    0| 00126C ld       E9210200   1     L8        gr9=#SPILL43(gr1,512)
    0| 001270 ld       E94101E8   1     L8        gr10=#SPILL40(gr1,488)
  268| 001274 addi     38A50001   1     AI        gr5=gr5,1
    0| 001278 add      7F26CA14   1     A         gr25=gr6,gr25
  268| 00127C std      F8A101F0   1     ST8       #SPILL41(gr1,496)=gr5
    0| 001280 add      7CE63A14   1     A         gr7=gr6,gr7
  268| 001284 cmpld    7F254040   1     CL8       cr6=gr5,gr8
    0| 001288 add      7D264A14   1     A         gr9=gr6,gr9
    0| 00128C std      F8E101F8   1     ST8       #SPILL42(gr1,504)=gr7
    0| 001290 std      F9210200   1     ST8       #SPILL43(gr1,512)=gr9
    0| 001294 add      7F86E214   1     A         gr28=gr6,gr28
    0| 001298 add      7F0AC214   1     A         gr24=gr10,gr24
    0| 00129C add      7EEABA14   1     A         gr23=gr10,gr23
    0| 0012A0 add      7ECAB214   1     A         gr22=gr10,gr22
    0| 0012A4 add      7F6ADA14   1     A         gr27=gr10,gr27
  268| 0012A8 bc       4198FEC8   1     BT        CL.70,cr6,0x8/llt,taken=80%(80,20)
  268|                              CL.69:
    0| 0012AC ld       E8620000   1     L8        gr3=.&&N&&bndry(gr2,0)
  271| 0012B0 addi     38000000   1     LI        gr0=0
  277| 0012B4 ld       E9C10238   1     L8        gr14=#stack(gr1,568)
  277| 0012B8 ld       E9E10240   1     L8        gr15=#stack(gr1,576)
  277| 0012BC ld       EA010248   1     L8        gr16=#stack(gr1,584)
  277| 0012C0 ld       EA210250   1     L8        gr17=#stack(gr1,592)
  271| 0012C4 stw      90030388   1     ST4Z      bvstat[](gr3,904)=gr0
  271| 0012C8 stw      9003038C   1     ST4Z      bvstat[](gr3,908)=gr0
  271| 0012CC stw      90030390   1     ST4Z      bvstat[](gr3,912)=gr0
  271| 0012D0 stw      90030394   1     ST4Z      bvstat[](gr3,916)=gr0
  271| 0012D4 stw      90030398   1     ST4Z      bvstat[](gr3,920)=gr0
  271| 0012D8 addi     38630384   1     AI        gr3=gr3,900
  277| 0012DC ld       EA410258   1     L8        gr18=#stack(gr1,600)
  277| 0012E0 ld       EA610260   1     L8        gr19=#stack(gr1,608)
  277| 0012E4 ld       EA810268   1     L8        gr20=#stack(gr1,616)
  277| 0012E8 ld       EAA10270   1     L8        gr21=#stack(gr1,624)
  277| 0012EC ld       EAC10278   1     L8        gr22=#stack(gr1,632)
  277| 0012F0 ld       EAE10280   1     L8        gr23=#stack(gr1,640)
  277| 0012F4 ld       EB010288   1     L8        gr24=#stack(gr1,648)
  277| 0012F8 ld       EB210290   1     L8        gr25=#stack(gr1,656)
  277| 0012FC ld       EB410298   1     L8        gr26=#stack(gr1,664)
  277| 001300 ld       EB6102A0   1     L8        gr27=#stack(gr1,672)
  277| 001304 ld       EB8102A8   1     L8        gr28=#stack(gr1,680)
  277| 001308 ld       EBA102B0   1     L8        gr29=#stack(gr1,688)
  277| 00130C ld       EBC102B8   1     L8        gr30=#stack(gr1,696)
  277| 001310 ld       EBE102C0   1     L8        gr31=#stack(gr1,704)
  277| 001314 addi     38210300   1     AI        gr1=gr1,768
  271| 001318 stwu     94030018   1     ST4U      gr3,bvstat[](gr3,24)=gr0
  277| 00131C bclr     4E800020   1     BA        lr
  267|                              CL.217:
    0| 001320 mtspr    7CE903A6   1     LCTR      ctr=gr7
  267|                              CL.184:
  268| 001324 addi     38840001   1     AI        gr4=gr4,1
  268| 001328 cmpd     7CA43800   1     C8        cr1=gr4,gr7
  268| 00132C bc       4104FFF8   1     BCTT      ctr=CL.184,cr1,0x1/lt,taken=80%(80,20)
    0| 001330 b        4BFFFD1C   1     B         CL.91,-1
  257|                              CL.432:
  277| 001334 addi     38210300   1     AI        gr1=gr1,768
  277| 001338 bclr     4E800020   1     BA        lr
     |               Tag Table
     | 00133C        00000000 00012201 87120000 0000133C
     |               Instruction count         1231
     |               Straight-line exec time   1282
     |               Constant Area
     | 000000        3F000000

 
 
>>>>> COMPILATION UNIT EPILOGUE SECTION <<<<<
 
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
   18           0         0           0         18            0
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    transprt.f90                07/08/15   15:48:38
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
   18           0         0           0         18            0
 
 
    Source records read.......................................     284
1501-510  Compilation successful for file transprt.f90.
1501-543  Object file created.
