IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- noh.f90 07/08/15 15:48:51
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** noh   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-534 (I) Loop (loop index 1) at noh.f90 <line 61> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 2) at noh.f90 <line 62> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-e%addr  + d-e%rvo))->e[].rns2.[($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks][(long long) js + $$CIV1][(long long) is + $$CIV0] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-e%addr  + d-e%rvo))->e[].rns2.[3ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV1][(long long) is + $$CIV0] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-e%addr  + d-e%rvo))->e[].rns2.[1ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV1][(long long) is + $$CIV0] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks][(long long) js + $$CIV1][(long long) is + $$CIV0] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[3ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV1][(long long) is + $$CIV0] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[1ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV1][(long long) is + $$CIV0] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[2ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV1][(long long) is + $$CIV0] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-e%addr  + d-e%rvo))->e[].rns2.[2ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)][(long long) js + $$CIV1][(long long) is + $$CIV0] = p0 / gamm1; with non-vectorizable strides.
1586-536 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)).
1586-536 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(3ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(3ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(3ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)).
1586-536 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(1ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(1ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(1ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)).
1586-536 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)).
1586-536 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(3ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(3ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(3ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)).
1586-536 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(1ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(1ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(1ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)).
1586-536 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(2ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(2ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at noh.f90 <line 64> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*(2ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)).
1586-536 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(2ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(2ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at noh.f90 <line 65> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*(2ll + (($$CIVC * 4ll + (1ll + ((long long) ke - (long long) ks)) % 4ll) + (long long) ks)) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)).
1586-534 (I) Loop (loop index 4) at noh.f90 <line 70> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 5) at noh.f90 <line 71> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 6) at noh.f90 <line 72> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 6) at noh.f90 <line 72> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 7) at noh.f90 <line 91> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-doib%addr  + d-doib%rvo))->doib[].rns9.[1ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2oib%addr  + d-v2oib%rvo))->v2oib[].rns7.[2ll][$$CIV7 + 1ll][$$CIV6 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-eoib%addr  + d-eoib%rvo))->eoib[].rns10.[1ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1oib%addr  + d-v1oib%rvo))->v1oib[].rns6.[1ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = v0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3oib%addr  + d-v3oib%rvo))->v3oib[].rns8.[2ll][$$CIV7 + 1ll][$$CIV6 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2oib%addr  + d-v2oib%rvo))->v2oib[].rns7.[1ll][$$CIV7 + 1ll][$$CIV6 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-doib%addr  + d-doib%rvo))->doib[].rns9.[2ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3oib%addr  + d-v3oib%rvo))->v3oib[].rns8.[1ll][$$CIV7 + 1ll][$$CIV6 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-eoib%addr  + d-eoib%rvo))->eoib[].rns10.[2ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 92> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1oib%addr  + d-v1oib%rvo))->v1oib[].rns6.[2ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = v0; with non-vectorizable strides.
1586-536 (I) Loop (loop index 8) at noh.f90 <line 99> was not SIMD vectorized because it contains memory references ((char *)d-doib%addr  + d-doib%rvo + (d-doib%bounds%mult[].off2552)*(1ll) + (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 99> was not SIMD vectorized because it contains memory references ((char *)d-doib%addr  + d-doib%rvo + (d-doib%bounds%mult[].off2552)*(1ll) + (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 99> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 99> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-doib%addr  + d-doib%rvo + (d-doib%bounds%mult[].off2552)*(1ll) + (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 96> was not SIMD vectorized because it contains memory references ((char *)d-v2oib%addr  + d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(2ll) + (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 96> was not SIMD vectorized because it contains memory references ((char *)d-v2oib%addr  + d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(2ll) + (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 96> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 96> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2oib%addr  + d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(2ll) + (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 101> was not SIMD vectorized because it contains memory references ((char *)d-eoib%addr  + d-eoib%rvo + (d-eoib%bounds%mult[].off3176)*(1ll) + (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 101> was not SIMD vectorized because it contains memory references ((char *)d-eoib%addr  + d-eoib%rvo + (d-eoib%bounds%mult[].off3176)*(1ll) + (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 101> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 101> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-eoib%addr  + d-eoib%rvo + (d-eoib%bounds%mult[].off3176)*(1ll) + (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 93> was not SIMD vectorized because it contains memory references ((char *)d-v1oib%addr  + d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(1ll) + (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 93> was not SIMD vectorized because it contains memory references ((char *)d-v1oib%addr  + d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(1ll) + (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 93> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 93> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1oib%addr  + d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(1ll) + (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 98> was not SIMD vectorized because it contains memory references ((char *)d-v3oib%addr  + d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(2ll) + (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 98> was not SIMD vectorized because it contains memory references ((char *)d-v3oib%addr  + d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(2ll) + (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 98> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 98> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3oib%addr  + d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(2ll) + (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 95> was not SIMD vectorized because it contains memory references ((char *)d-v2oib%addr  + d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(1ll) + (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 95> was not SIMD vectorized because it contains memory references ((char *)d-v2oib%addr  + d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(1ll) + (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 95> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 95> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2oib%addr  + d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(1ll) + (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 100> was not SIMD vectorized because it contains memory references ((char *)d-doib%addr  + d-doib%rvo + (d-doib%bounds%mult[].off2552)*(2ll) + (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 100> was not SIMD vectorized because it contains memory references ((char *)d-doib%addr  + d-doib%rvo + (d-doib%bounds%mult[].off2552)*(2ll) + (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 100> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 100> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-doib%addr  + d-doib%rvo + (d-doib%bounds%mult[].off2552)*(2ll) + (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 97> was not SIMD vectorized because it contains memory references ((char *)d-v3oib%addr  + d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(1ll) + (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 97> was not SIMD vectorized because it contains memory references ((char *)d-v3oib%addr  + d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(1ll) + (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 97> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 97> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3oib%addr  + d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(1ll) + (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-eoib%addr  + d-eoib%rvo + (d-eoib%bounds%mult[].off3176)*(2ll) + (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-eoib%addr  + d-eoib%rvo + (d-eoib%bounds%mult[].off3176)*(2ll) + (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 102> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 102> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-eoib%addr  + d-eoib%rvo + (d-eoib%bounds%mult[].off3176)*(2ll) + (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 8) at noh.f90 <line 94> was not SIMD vectorized because it contains memory references ((char *)d-v1oib%addr  + d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(2ll) + (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 8) at noh.f90 <line 94> was not SIMD vectorized because it contains memory references ((char *)d-v1oib%addr  + d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(2ll) + (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 8) at noh.f90 <line 94> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 8) at noh.f90 <line 94> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1oib%addr  + d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(2ll) + (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)).
1586-534 (I) Loop (loop index 9) at noh.f90 <line 106> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dojb%addr  + d-dojb%rvo))->dojb[].rns14.[1ll][$$CIV9 + 1ll][$$CIV8 + 1ll] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-eojb%addr  + d-eojb%rvo))->eojb[].rns15.[2ll][$$CIV9 + 1ll][$$CIV8 + 1ll] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2ojb%addr  + d-v2ojb%rvo))->v2ojb[].rns11.[2ll][$$CIV9 + 1ll][$$CIV8 + 1ll] = v0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3ojb%addr  + d-v3ojb%rvo))->v3ojb[].rns13.[1ll][$$CIV9 + 1ll][$$CIV8 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dojb%addr  + d-dojb%rvo))->dojb[].rns14.[2ll][$$CIV9 + 1ll][$$CIV8 + 1ll] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1ojb%addr  + d-v1ojb%rvo))->v1ojb[].rns12.[1ll][$$CIV9 + 1ll][$$CIV8 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3ojb%addr  + d-v3ojb%rvo))->v3ojb[].rns13.[2ll][$$CIV9 + 1ll][$$CIV8 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2ojb%addr  + d-v2ojb%rvo))->v2ojb[].rns11.[1ll][$$CIV9 + 1ll][$$CIV8 + 1ll] = v0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-eojb%addr  + d-eojb%rvo))->eojb[].rns15.[1ll][$$CIV9 + 1ll][$$CIV8 + 1ll] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 107> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1ojb%addr  + d-v1ojb%rvo))->v1ojb[].rns12.[2ll][$$CIV9 + 1ll][$$CIV8 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-536 (I) Loop (loop index 10) at noh.f90 <line 114> was not SIMD vectorized because it contains memory references ((char *)d-dojb%addr  + d-dojb%rvo + (d-dojb%bounds%mult[].off2760)*(1ll) + (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 114> was not SIMD vectorized because it contains memory references ((char *)d-dojb%addr  + d-dojb%rvo + (d-dojb%bounds%mult[].off2760)*(1ll) + (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 114> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 114> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-dojb%addr  + d-dojb%rvo + (d-dojb%bounds%mult[].off2760)*(1ll) + (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 117> was not SIMD vectorized because it contains memory references ((char *)d-eojb%addr  + d-eojb%rvo + (d-eojb%bounds%mult[].off3384)*(2ll) + (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 117> was not SIMD vectorized because it contains memory references ((char *)d-eojb%addr  + d-eojb%rvo + (d-eojb%bounds%mult[].off3384)*(2ll) + (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 117> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 117> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-eojb%addr  + d-eojb%rvo + (d-eojb%bounds%mult[].off3384)*(2ll) + (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 109> was not SIMD vectorized because it contains memory references ((char *)d-v2ojb%addr  + d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(2ll) + (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 109> was not SIMD vectorized because it contains memory references ((char *)d-v2ojb%addr  + d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(2ll) + (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 109> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 109> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2ojb%addr  + d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(2ll) + (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 112> was not SIMD vectorized because it contains memory references ((char *)d-v3ojb%addr  + d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(1ll) + (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 112> was not SIMD vectorized because it contains memory references ((char *)d-v3ojb%addr  + d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(1ll) + (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 112> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 112> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3ojb%addr  + d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(1ll) + (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 115> was not SIMD vectorized because it contains memory references ((char *)d-dojb%addr  + d-dojb%rvo + (d-dojb%bounds%mult[].off2760)*(2ll) + (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 115> was not SIMD vectorized because it contains memory references ((char *)d-dojb%addr  + d-dojb%rvo + (d-dojb%bounds%mult[].off2760)*(2ll) + (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 115> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 115> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-dojb%addr  + d-dojb%rvo + (d-dojb%bounds%mult[].off2760)*(2ll) + (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 110> was not SIMD vectorized because it contains memory references ((char *)d-v1ojb%addr  + d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(1ll) + (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 110> was not SIMD vectorized because it contains memory references ((char *)d-v1ojb%addr  + d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(1ll) + (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 110> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 110> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1ojb%addr  + d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(1ll) + (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 113> was not SIMD vectorized because it contains memory references ((char *)d-v3ojb%addr  + d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(2ll) + (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 113> was not SIMD vectorized because it contains memory references ((char *)d-v3ojb%addr  + d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(2ll) + (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 113> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 113> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3ojb%addr  + d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(2ll) + (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 108> was not SIMD vectorized because it contains memory references ((char *)d-v2ojb%addr  + d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(1ll) + (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 108> was not SIMD vectorized because it contains memory references ((char *)d-v2ojb%addr  + d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(1ll) + (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 108> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 108> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2ojb%addr  + d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(1ll) + (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 116> was not SIMD vectorized because it contains memory references ((char *)d-eojb%addr  + d-eojb%rvo + (d-eojb%bounds%mult[].off3384)*(1ll) + (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 116> was not SIMD vectorized because it contains memory references ((char *)d-eojb%addr  + d-eojb%rvo + (d-eojb%bounds%mult[].off3384)*(1ll) + (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 116> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 116> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-eojb%addr  + d-eojb%rvo + (d-eojb%bounds%mult[].off3384)*(1ll) + (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)).
1586-536 (I) Loop (loop index 10) at noh.f90 <line 111> was not SIMD vectorized because it contains memory references ((char *)d-v1ojb%addr  + d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(2ll) + (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 10) at noh.f90 <line 111> was not SIMD vectorized because it contains memory references ((char *)d-v1ojb%addr  + d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(2ll) + (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 10) at noh.f90 <line 111> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 10) at noh.f90 <line 111> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1ojb%addr  + d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(2ll) + (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)).
1586-534 (I) Loop (loop index 11) at noh.f90 <line 121> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1okb%addr  + d-v1okb%rvo))->v1okb[].rns17.[1ll][$$CIVB + 1ll][$$CIVA + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2okb%addr  + d-v2okb%rvo))->v2okb[].rns18.[2ll][$$CIVB + 1ll][$$CIVA + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3okb%addr  + d-v3okb%rvo))->v3okb[].rns16.[1ll][$$CIVB + 1ll][$$CIVA + 1ll] = v0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-eokb%addr  + d-eokb%rvo))->eokb[].rns20.[1ll][$$CIVB + 1ll][$$CIVA + 1ll] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1okb%addr  + d-v1okb%rvo))->v1okb[].rns17.[2ll][$$CIVB + 1ll][$$CIVA + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dokb%addr  + d-dokb%rvo))->dokb[].rns19.[1ll][$$CIVB + 1ll][$$CIVA + 1ll] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3okb%addr  + d-v3okb%rvo))->v3okb[].rns16.[2ll][$$CIVB + 1ll][$$CIVA + 1ll] = v0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2okb%addr  + d-v2okb%rvo))->v2okb[].rns18.[1ll][$$CIVB + 1ll][$$CIVA + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-dokb%addr  + d-dokb%rvo))->dokb[].rns19.[2ll][$$CIVB + 1ll][$$CIVA + 1ll] = d0; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 122> was not SIMD vectorized because it contains memory references ((double *)((char *)d-eokb%addr  + d-eokb%rvo))->eokb[].rns20.[2ll][$$CIVB + 1ll][$$CIVA + 1ll] = p0 / gamm1; with non-vectorizable strides.
1586-536 (I) Loop (loop index 12) at noh.f90 <line 125> was not SIMD vectorized because it contains memory references ((char *)d-v1okb%addr  + d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(1ll) + (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 125> was not SIMD vectorized because it contains memory references ((char *)d-v1okb%addr  + d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(1ll) + (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 125> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 125> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1okb%addr  + d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(1ll) + (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 128> was not SIMD vectorized because it contains memory references ((char *)d-v2okb%addr  + d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(2ll) + (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 128> was not SIMD vectorized because it contains memory references ((char *)d-v2okb%addr  + d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(2ll) + (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 128> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 128> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2okb%addr  + d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(2ll) + (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 123> was not SIMD vectorized because it contains memory references ((char *)d-v3okb%addr  + d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(1ll) + (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 123> was not SIMD vectorized because it contains memory references ((char *)d-v3okb%addr  + d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(1ll) + (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 123> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 123> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3okb%addr  + d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(1ll) + (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 131> was not SIMD vectorized because it contains memory references ((char *)d-eokb%addr  + d-eokb%rvo + (d-eokb%bounds%mult[].off3592)*(1ll) + (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 131> was not SIMD vectorized because it contains memory references ((char *)d-eokb%addr  + d-eokb%rvo + (d-eokb%bounds%mult[].off3592)*(1ll) + (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 131> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 131> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-eokb%addr  + d-eokb%rvo + (d-eokb%bounds%mult[].off3592)*(1ll) + (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 126> was not SIMD vectorized because it contains memory references ((char *)d-v1okb%addr  + d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(2ll) + (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 126> was not SIMD vectorized because it contains memory references ((char *)d-v1okb%addr  + d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(2ll) + (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 126> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 126> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1okb%addr  + d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(2ll) + (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 129> was not SIMD vectorized because it contains memory references ((char *)d-dokb%addr  + d-dokb%rvo + (d-dokb%bounds%mult[].off2968)*(1ll) + (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 129> was not SIMD vectorized because it contains memory references ((char *)d-dokb%addr  + d-dokb%rvo + (d-dokb%bounds%mult[].off2968)*(1ll) + (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 129> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 129> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-dokb%addr  + d-dokb%rvo + (d-dokb%bounds%mult[].off2968)*(1ll) + (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 124> was not SIMD vectorized because it contains memory references ((char *)d-v3okb%addr  + d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(2ll) + (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 124> was not SIMD vectorized because it contains memory references ((char *)d-v3okb%addr  + d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(2ll) + (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 124> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 124> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3okb%addr  + d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(2ll) + (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 127> was not SIMD vectorized because it contains memory references ((char *)d-v2okb%addr  + d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(1ll) + (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 127> was not SIMD vectorized because it contains memory references ((char *)d-v2okb%addr  + d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(1ll) + (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 127> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 127> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2okb%addr  + d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(1ll) + (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 130> was not SIMD vectorized because it contains memory references ((char *)d-dokb%addr  + d-dokb%rvo + (d-dokb%bounds%mult[].off2968)*(2ll) + (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 130> was not SIMD vectorized because it contains memory references ((char *)d-dokb%addr  + d-dokb%rvo + (d-dokb%bounds%mult[].off2968)*(2ll) + (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 130> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 130> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-dokb%addr  + d-dokb%rvo + (d-dokb%bounds%mult[].off2968)*(2ll) + (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)).
1586-536 (I) Loop (loop index 12) at noh.f90 <line 132> was not SIMD vectorized because it contains memory references ((char *)d-eokb%addr  + d-eokb%rvo + (d-eokb%bounds%mult[].off3592)*(2ll) + (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at noh.f90 <line 132> was not SIMD vectorized because it contains memory references ((char *)d-eokb%addr  + d-eokb%rvo + (d-eokb%bounds%mult[].off3592)*(2ll) + (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at noh.f90 <line 132> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at noh.f90 <line 132> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-eokb%addr  + d-eokb%rvo + (d-eokb%bounds%mult[].off3592)*(2ll) + (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)).
1586-534 (I) Loop (loop index 16) at noh.f90 <line 70> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 17) at noh.f90 <line 71> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 18) at noh.f90 <line 72> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 18) at noh.f90 <line 72> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 22) at noh.f90 <line 61> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 23) at noh.f90 <line 62> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 24) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-e%addr  + d-e%rvo))->e[].rns2.[(long long) ks + $$CIV2][(long long) js + $$CIV1][(long long) is + $$CIV0] = p0 / gamm1; with non-vectorizable strides.
1586-540 (I) Loop (loop index 24) at noh.f90 <line 63> was not SIMD vectorized because it contains memory references ((double *)((char *)d-d%addr  + d-d%rvo))->d[].rns1.[(long long) ks + $$CIV2][(long long) js + $$CIV1][(long long) is + $$CIV0] = d0; with non-vectorizable strides.
1586-536 (I) Loop (loop index 24) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*((long long) ks + $$CIV2) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 24) at noh.f90 <line 65> was not SIMD vectorized because it contains memory references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*((long long) ks + $$CIV2) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 24) at noh.f90 <line 65> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 24) at noh.f90 <line 65> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-e%addr  + d-e%rvo + (d-e%bounds%mult[].off152)*((long long) ks + $$CIV2) + (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)).
1586-536 (I) Loop (loop index 24) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*((long long) ks + $$CIV2) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 24) at noh.f90 <line 64> was not SIMD vectorized because it contains memory references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*((long long) ks + $$CIV2) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 24) at noh.f90 <line 64> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 24) at noh.f90 <line 64> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-d%addr  + d-d%rvo + (d-d%bounds%mult[].off48)*((long long) ks + $$CIV2) + (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)).
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"7">. Total number of the innermost loops SIMD vectorized <"0">.


    11|         SUBROUTINE noh ()
    36|           d0 =  1.0000000000000000E+000
    37|           p0 =  9.9999999999999995E-007
    38|           v0 = -1.0000000000000000E+000
    40|           IF ((myid == 0)) THEN
    11|             |pgen%nlitems%type.off32 = 4
                    |pgen%nlitems%kind.off40 = 
                    |pgen%nlitems%size.off48 = 
                    |pgen%nlitems%name_addr.off56 = "pgenp0d0v0idirectInoh.f90" &
                &     + 4
                    |pgen%nlitems%name_len.off64 = 2
                    |pgen%nlitems%item_addr.off72 = loc(p0)
                    |pgen%nlitems%type.off80 = 4
                    |pgen%nlitems%kind.off88 = 
                    |pgen%nlitems%size.off96 = 
                    |pgen%nlitems%name_addr.off104 = &
                &     "pgenp0d0v0idirectInoh.f90" + 6
                    |pgen%nlitems%name_len.off112 = 2
                    |pgen%nlitems%item_addr.off120 = loc(d0)
                    |pgen%nlitems%type.off128 = 4
                    |pgen%nlitems%kind.off136 = 
                    |pgen%nlitems%size.off144 = 
                    |pgen%nlitems%name_addr.off152 = &
                &     "pgenp0d0v0idirectInoh.f90" + 8
                    |pgen%nlitems%name_len.off160 = 2
                    |pgen%nlitems%item_addr.off168 = loc(v0)
                    |pgen%version = 129
                    |pgen%name_addr = "pgenp0d0v0idirectInoh.f90"
                    |pgen%name_len = 4
                    |pgen%num_of_items = 4
                    |pgen%nlitems%type.off176 = 0
                    |pgen%nlitems%kind.off184 = 
                    |pgen%nlitems%size.off192 = 
                    |pgen%nlitems%name_addr.off200 = &
                &     "pgenp0d0v0idirectInoh.f90" + 10
                    |pgen%nlitems%name_len.off208 = 7
                    |pgen%nlitems%item_addr.off216 = loc(idirect)
    41|             |pgen%name_flags = 0
                    #2 = _xlfBeginIO(1,2,#1,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#2))
    42|             |pgen%name_flags = 0
                    #4 = _xlfBeginIO(2,258,#3,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#4))
    43|             buf_in[].off1744 = d0
    44|             buf_in[].off1752 = p0
    45|             buf_in[].off1760 = v0
    46|             ibuf_in[].off144 = idirect
    47|           ENDIF
    48|           T_2 = 3
                  T_3 = 1275070495
                  T_4 = 0
                  CALL mpi_bcast(buf_in,T_2,T_3,T_4,comm3d,ierr)
    50|           T_5 = 1
                  T_6 = 1275069467
                  T_7 = 0
                  CALL mpi_bcast(ibuf_in,T_5,T_6,T_7,comm3d,ierr)
    52|           IF ((myid <> 0)) THEN
    53|             d0 = buf_in[].off1744
    54|             p0 = buf_in[].off1752
    55|             v0 = buf_in[].off1760
    56|             idirect = ibuf_in[].off144
    57|           ENDIF
    61|           IF ((MOD((1 + (int(ke) - int(ks))), 4) > 0  .AND.  1 + (int(&
                &   ke) - int(ks)) > 0)) THEN
                    $$CIV2 = 0
       Id=22        DO $$CIV2 = $$CIV2, MOD((1 + (int(ke) - int(ks))), int(4))&
                &       -1
    62|               IF ((1 + (int(je) - int(js)) > 0)) THEN
                        $$CIV1 = 0
       Id=23            DO $$CIV1 = $$CIV1, int((1 + (int(je) - int(js))))-1
    63|                   IF ((1 + (int(ie) - int(is)) > 0)) THEN
                            $$CIV0 = 0
       Id=24                DO $$CIV0 = $$CIV0, int((1 + (int(ie) - int(is))))&
                &               -1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,int(&
                &               ks) + $$CIV2) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,int(&
                &               ks) + $$CIV2) = p0 / gamm1
    66|                     ENDDO
                          ENDIF
    67|                 ENDDO
                      ENDIF
    68|             ENDDO
                  ENDIF
    61|           IF ((1 + (int(ke) - int(ks)) > 0  .AND.  1 + (int(ke) - int(&
                &   ks)) > MOD((1 + (int(ke) - int(ks))), 4))) THEN
                    $$CIVC = int(0)
       Id=1         DO $$CIVC = $$CIVC, int(((int(ke) - (MOD((1 + (int(ke) - &
                &       int(ks))), 4) + int(ks))) / 4 + 1))-1
    62|               IF ((1 + (int(je) - int(js)) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int((1 + (int(je) - int(js))))-1
    63|                   IF ((1 + (int(ie) - int(is)) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int((1 + (int(ie) - int(is))))&
                &               -1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,(&
                &               $$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) + &
                &               int(ks)) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,(&
                &               $$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) + &
                &               int(ks)) = p0 / gamm1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,1 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,1 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = p0 / gamm1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,2 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,2 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = p0 / gamm1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,3 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,3 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = p0 / gamm1
    66|                     ENDDO
                          ENDIF
    67|                 ENDDO
                      ENDIF
    68|             ENDDO
                  ENDIF
    70|           IF ((MOD(int(kn), 4) > 0  .AND.  int(kn) > 0)) THEN
                    $$CIV5 = 0
       Id=16        DO $$CIV5 = $$CIV5, MOD(int(kn), int(4))-1
    71|               IF ((int(jn) > 0)) THEN
                        $$CIV4 = 0
       Id=17            DO $$CIV4 = $$CIV4, int(int(jn))-1
    72|                   IF ((int(in) > 0)) THEN
                            $$CIV3 = 0
       Id=18                DO $$CIV3 = $$CIV3, int(int(in))-1
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_97
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    77|                       GOTO lab_100
                              lab_97
                              IF (.NOT.(idirect == 2)) GOTO lab_98
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    81|                       GOTO lab_99
                              lab_98
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    85|                       lab_99
                              lab_100
    86|                     ENDDO
                          ENDIF
    87|                 ENDDO
                      ENDIF
    88|             ENDDO
                  ENDIF
    70|           IF ((int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 4))) THEN
                    $$CIVD = int(0)
       Id=4         DO $$CIVD = $$CIVD, int((((int(kn) - MOD(int(kn), 4)) - 1)&
                &        / 4 + 1))-1
    71|               IF ((int(jn) > 0)) THEN
                        $$CIV4 = 0
       Id=5             DO $$CIV4 = $$CIV4, int(int(jn))-1
    72|                   IF ((int(in) > 0)) THEN
                            $$CIV3 = 0
       Id=6                 DO $$CIV3 = $$CIV3, int(int(in))-1
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_18
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    77|                       GOTO lab_19
                              lab_18
                              IF (.NOT.(idirect == 2)) GOTO lab_20
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    81|                       GOTO lab_21
                              lab_20
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    85|                       lab_21
                              lab_19
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_104
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    77|                       GOTO lab_107
                              lab_104
                              IF (.NOT.(idirect == 2)) GOTO lab_105
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    81|                       GOTO lab_106
                              lab_105
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    85|                       lab_106
                              lab_107
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_108
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    77|                       GOTO lab_111
                              lab_108
                              IF (.NOT.(idirect == 2)) GOTO lab_109
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    81|                       GOTO lab_110
                              lab_109
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    85|                       lab_110
                              lab_111
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_112
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    77|                       GOTO lab_115
                              lab_112
                              IF (.NOT.(idirect == 2)) GOTO lab_113
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    81|                       GOTO lab_114
                              lab_113
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    85|                       lab_114
                              lab_115
    86|                     ENDDO
                          ENDIF
    87|                 ENDDO
                      ENDIF
    88|             ENDDO
                  ENDIF
    90|           IF ((idirect == 1)) THEN
    91|             IF ((int(kn) > 0)) THEN
                      $$CIV7 = 0
       Id=7           DO $$CIV7 = $$CIV7, int(int(kn))-1
    92|                 IF ((int(jn) > 0)) THEN
                          $$CIV6 = 0
       Id=8               DO $$CIV6 = $$CIV6, int(int(jn))-1
    93|                     d-v1oib%addr%v1oib($$CIV6 + 1,$$CIV7 + 1,1) = v0
    94|                     d-v1oib%addr%v1oib($$CIV6 + 1,$$CIV7 + 1,2) = v0
    95|                     d-v2oib%addr%v2oib($$CIV6 + 1,$$CIV7 + 1,1) =  &
                &             0.0000000000000000E+000
    96|                     d-v2oib%addr%v2oib($$CIV6 + 1,$$CIV7 + 1,2) =  &
                &             0.0000000000000000E+000
    97|                     d-v3oib%addr%v3oib($$CIV6 + 1,$$CIV7 + 1,1) =  &
                &             0.0000000000000000E+000
    98|                     d-v3oib%addr%v3oib($$CIV6 + 1,$$CIV7 + 1,2) =  &
                &             0.0000000000000000E+000
    99|                     d-doib%addr%doib($$CIV6 + 1,$$CIV7 + 1,1) = d0
   100|                     d-doib%addr%doib($$CIV6 + 1,$$CIV7 + 1,2) = d0
   101|                     d-eoib%addr%eoib($$CIV6 + 1,$$CIV7 + 1,1) = p0 / &
                &             gamm1
   102|                     d-eoib%addr%eoib($$CIV6 + 1,$$CIV7 + 1,2) = p0 / &
                &             gamm1
   103|                   ENDDO
                        ENDIF
   104|               ENDDO
                    ENDIF
   105|           ELSE
                    lab_31
                    IF ((idirect == 2)) THEN
   106|               IF ((int(kn) > 0)) THEN
                        $$CIV9 = 0
       Id=9             DO $$CIV9 = $$CIV9, int(int(kn))-1
   107|                   IF ((int(in) > 0)) THEN
                            $$CIV8 = 0
       Id=10                DO $$CIV8 = $$CIV8, int(int(in))-1
   108|                       d-v2ojb%addr%v2ojb($$CIV8 + 1,$$CIV9 + 1,1) = v0
   109|                       d-v2ojb%addr%v2ojb($$CIV8 + 1,$$CIV9 + 1,2) = v0
   110|                       d-v1ojb%addr%v1ojb($$CIV8 + 1,$$CIV9 + 1,1) =  &
                &               0.0000000000000000E+000
   111|                       d-v1ojb%addr%v1ojb($$CIV8 + 1,$$CIV9 + 1,2) =  &
                &               0.0000000000000000E+000
   112|                       d-v3ojb%addr%v3ojb($$CIV8 + 1,$$CIV9 + 1,1) =  &
                &               0.0000000000000000E+000
   113|                       d-v3ojb%addr%v3ojb($$CIV8 + 1,$$CIV9 + 1,2) =  &
                &               0.0000000000000000E+000
   114|                       d-dojb%addr%dojb($$CIV8 + 1,$$CIV9 + 1,1) = d0
   115|                       d-dojb%addr%dojb($$CIV8 + 1,$$CIV9 + 1,2) = d0
   116|                       d-eojb%addr%eojb($$CIV8 + 1,$$CIV9 + 1,1) = p0 / &
                &               gamm1
   117|                       d-eojb%addr%eojb($$CIV8 + 1,$$CIV9 + 1,2) = p0 / &
                &               gamm1
   118|                     ENDDO
                          ENDIF
   119|                 ENDDO
                      ENDIF
   120|             ELSE
                      lab_41
   121|               IF (.NOT.(int(jn) > 0)) GOTO lab_79
                      $$CIVB = 0
       Id=11          DO $$CIVB = $$CIVB, int(int(jn))-1
   122|                 IF ((int(jn) > 0)) THEN
                          $$CIVA = 0
       Id=12              DO $$CIVA = $$CIVA, int(int(jn))-1
   123|                     d-v3okb%addr%v3okb($$CIVA + 1,$$CIVB + 1,1) = v0
   124|                     d-v3okb%addr%v3okb($$CIVA + 1,$$CIVB + 1,2) = v0
   125|                     d-v1okb%addr%v1okb($$CIVA + 1,$$CIVB + 1,1) =  &
                &             0.0000000000000000E+000
   126|                     d-v1okb%addr%v1okb($$CIVA + 1,$$CIVB + 1,2) =  &
                &             0.0000000000000000E+000
   127|                     d-v2okb%addr%v2okb($$CIVA + 1,$$CIVB + 1,1) =  &
                &             0.0000000000000000E+000
   128|                     d-v2okb%addr%v2okb($$CIVA + 1,$$CIVB + 1,2) =  &
                &             0.0000000000000000E+000
   129|                     d-dokb%addr%dokb($$CIVA + 1,$$CIVB + 1,1) = d0
   130|                     d-dokb%addr%dokb($$CIVA + 1,$$CIVB + 1,2) = d0
   131|                     d-eokb%addr%eokb($$CIVA + 1,$$CIVB + 1,1) = p0 / &
                &             gamm1
   132|                     d-eokb%addr%eokb($$CIVA + 1,$$CIVB + 1,2) = p0 / &
                &             gamm1
   133|                   ENDDO
                        ENDIF
   134|               ENDDO
                      lab_79
   138|               lab_83
                      RETURN
                    END SUBROUTINE noh


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0            61            22    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            62            23    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*((long long) ks + $$CIV2) + 
                                          (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + 
                                          (d-d%bounds%mult[].off96)*((long long) is + $$CIV0))  
                                          with non-vectorizable alignment.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*((long long) ks + $$CIV2) + 
                                          (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + 
                                          (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)) 
                                          with  non-vectorizable strides.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-d%addr  + 
                                          d-d%rvo + (d-d%bounds%mult[].off48)*((long long) ks + 
                                          $$CIV2) + (d-d%bounds%mult[].off72)*((long long) js + 
                                          $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is + 
                                          $$CIV0)).
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*((long long) ks + $$CIV2) 
                                          + (d-e%bounds%mult[].off176)*((long long) js + 
                                          $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is 
                                          + $$CIV0))  with non-vectorizable alignment.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*((long long) ks + $$CIV2) 
                                          + (d-e%bounds%mult[].off176)*((long long) js + 
                                          $$CIV1) + (d-e%bounds%mult[].off200)*((long long) is 
                                          + $$CIV0)) with  non-vectorizable strides.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-e%addr  + 
                                          d-e%rvo + (d-e%bounds%mult[].off152)*((long long) ks 
                                          + $$CIV2) + (d-e%bounds%mult[].off176)*((long long) 
                                          js + $$CIV1) + (d-e%bounds%mult[].off200)*((long 
                                          long) is + $$CIV0)).
         0            61             1    Outer loop has been unrolled 4 time(s).
         0            61             1    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            62             2    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*(($$CIVC * 4ll + (1ll + 
                                          ((long long) ke - (long long) ks)) % 4ll) + (long 
                                          long) ks) + (d-d%bounds%mult[].off72)*((long long) js 
                                          + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is 
                                          + $$CIV0))  with non-vectorizable alignment.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*(($$CIVC * 4ll + (1ll + 
                                          ((long long) ke - (long long) ks)) % 4ll) + (long 
                                          long) ks) + (d-d%bounds%mult[].off72)*((long long) js 
                                          + $$CIV1) + (d-d%bounds%mult[].off96)*((long long) is 
                                          + $$CIV0)) with  non-vectorizable strides.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-d%addr  + 
                                          d-d%rvo + (d-d%bounds%mult[].off48)*(($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks) + (d-d%bounds%mult[].off72)*((long 
                                          long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long 
                                          long) is + $$CIV0)).
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*(($$CIVC * 4ll + (1ll + 
                                          ((long long) ke - (long long) ks)) % 4ll) + (long 
                                          long) ks) + (d-e%bounds%mult[].off176)*((long long) 
                                          js + $$CIV1) + (d-e%bounds%mult[].off200)*((long 
                                          long) is + $$CIV0))  with non-vectorizable alignment.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*(($$CIVC * 4ll + (1ll + 
                                          ((long long) ke - (long long) ks)) % 4ll) + (long 
                                          long) ks) + (d-e%bounds%mult[].off176)*((long long) 
                                          js + $$CIV1) + (d-e%bounds%mult[].off200)*((long 
                                          long) is + $$CIV0)) with  non-vectorizable strides.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-e%addr  + 
                                          d-e%rvo + (d-e%bounds%mult[].off152)*(($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks) + (d-e%bounds%mult[].off176)*((long 
                                          long) js + $$CIV1) + 
                                          (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)).
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*(1ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-d%bounds%mult[].off72)*((long 
                                          long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long 
                                          long) is + $$CIV0))  with non-vectorizable alignment.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*(1ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-d%bounds%mult[].off72)*((long 
                                          long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long 
                                          long) is + $$CIV0)) with  non-vectorizable strides.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-d%addr  + 
                                          d-d%rvo + (d-d%bounds%mult[].off48)*(1ll + (($$CIVC * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + 
                                          (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)).
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*(1ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-e%bounds%mult[].off176)*((long 
                                          long) js + $$CIV1) + 
                                          (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) 
                                          with non-vectorizable alignment.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*(1ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-e%bounds%mult[].off176)*((long 
                                          long) js + $$CIV1) + 
                                          (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) 
                                          with  non-vectorizable strides.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-e%addr  + 
                                          d-e%rvo + (d-e%bounds%mult[].off152)*(1ll + (($$CIVC 
                                          * 4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) 
                                          + (d-e%bounds%mult[].off200)*((long long) is + 
                                          $$CIV0)).
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*(2ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-d%bounds%mult[].off72)*((long 
                                          long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long 
                                          long) is + $$CIV0))  with non-vectorizable alignment.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*(2ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-d%bounds%mult[].off72)*((long 
                                          long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long 
                                          long) is + $$CIV0)) with  non-vectorizable strides.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-d%addr  + 
                                          d-d%rvo + (d-d%bounds%mult[].off48)*(2ll + (($$CIVC * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + 
                                          (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)).
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*(2ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-e%bounds%mult[].off176)*((long 
                                          long) js + $$CIV1) + 
                                          (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) 
                                          with non-vectorizable alignment.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*(2ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-e%bounds%mult[].off176)*((long 
                                          long) js + $$CIV1) + 
                                          (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) 
                                          with  non-vectorizable strides.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-e%addr  + 
                                          d-e%rvo + (d-e%bounds%mult[].off152)*(2ll + (($$CIVC 
                                          * 4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) 
                                          + (d-e%bounds%mult[].off200)*((long long) is + 
                                          $$CIV0)).
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*(3ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-d%bounds%mult[].off72)*((long 
                                          long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long 
                                          long) is + $$CIV0))  with non-vectorizable alignment.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-d%addr  + d-d%rvo + 
                                          (d-d%bounds%mult[].off48)*(3ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-d%bounds%mult[].off72)*((long 
                                          long) js + $$CIV1) + (d-d%bounds%mult[].off96)*((long 
                                          long) is + $$CIV0)) with  non-vectorizable strides.
         0            64                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            64                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-d%addr  + 
                                          d-d%rvo + (d-d%bounds%mult[].off48)*(3ll + (($$CIVC * 
                                          4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-d%bounds%mult[].off72)*((long long) js + $$CIV1) + 
                                          (d-d%bounds%mult[].off96)*((long long) is + $$CIV0)).
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*(3ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-e%bounds%mult[].off176)*((long 
                                          long) js + $$CIV1) + 
                                          (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) 
                                          with non-vectorizable alignment.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-e%addr  + d-e%rvo + 
                                          (d-e%bounds%mult[].off152)*(3ll + (($$CIVC * 4ll + 
                                          (1ll + ((long long) ke - (long long) ks)) % 4ll) + 
                                          (long long) ks)) + (d-e%bounds%mult[].off176)*((long 
                                          long) js + $$CIV1) + 
                                          (d-e%bounds%mult[].off200)*((long long) is + $$CIV0)) 
                                          with  non-vectorizable strides.
         0            65                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            65                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-e%addr  + 
                                          d-e%rvo + (d-e%bounds%mult[].off152)*(3ll + (($$CIVC 
                                          * 4ll + (1ll + ((long long) ke - (long long) ks)) % 
                                          4ll) + (long long) ks)) + 
                                          (d-e%bounds%mult[].off176)*((long long) js + $$CIV1) 
                                          + (d-e%bounds%mult[].off200)*((long long) is + 
                                          $$CIV0)).
         0            70            16    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            71            17    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            72            18    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0            72            18    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0            70             4    Outer loop has been unrolled 4 time(s).
         0            70             4    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            71             5    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            72             6    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0            72             6    Loop was not SIMD vectorized because it contains 
                                          control flow.
         0            91             7    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            93                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1oib%addr  + 
                                          d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(1ll) + 
                                          (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + 
                                          (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0            93                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1oib%addr  + 
                                          d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(1ll) + 
                                          (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + 
                                          (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0            93                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            93                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v1oib%addr  + d-v1oib%rvo + 
                                          (d-v1oib%bounds%mult[].off3800)*(1ll) + 
                                          (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + 
                                          (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)).
         0            94                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1oib%addr  + 
                                          d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(2ll) + 
                                          (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + 
                                          (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0            94                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1oib%addr  + 
                                          d-v1oib%rvo + (d-v1oib%bounds%mult[].off3800)*(2ll) + 
                                          (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + 
                                          (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0            94                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            94                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v1oib%addr  + d-v1oib%rvo + 
                                          (d-v1oib%bounds%mult[].off3800)*(2ll) + 
                                          (d-v1oib%bounds%mult[].off3824)*($$CIV7 + 1ll) + 
                                          (d-v1oib%bounds%mult[].off3848)*($$CIV6 + 1ll)).
         0            95                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2oib%addr  + 
                                          d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(1ll) + 
                                          (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + 
                                          (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0            95                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2oib%addr  + 
                                          d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(1ll) + 
                                          (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + 
                                          (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0            95                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            95                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v2oib%addr  + d-v2oib%rvo + 
                                          (d-v2oib%bounds%mult[].off4424)*(1ll) + 
                                          (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + 
                                          (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)).
         0            96                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2oib%addr  + 
                                          d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(2ll) + 
                                          (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + 
                                          (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0            96                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2oib%addr  + 
                                          d-v2oib%rvo + (d-v2oib%bounds%mult[].off4424)*(2ll) + 
                                          (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + 
                                          (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0            96                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            96                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v2oib%addr  + d-v2oib%rvo + 
                                          (d-v2oib%bounds%mult[].off4424)*(2ll) + 
                                          (d-v2oib%bounds%mult[].off4448)*($$CIV7 + 1ll) + 
                                          (d-v2oib%bounds%mult[].off4472)*($$CIV6 + 1ll)).
         0            97                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3oib%addr  + 
                                          d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(1ll) + 
                                          (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + 
                                          (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0            97                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3oib%addr  + 
                                          d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(1ll) + 
                                          (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + 
                                          (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0            97                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            97                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v3oib%addr  + d-v3oib%rvo + 
                                          (d-v3oib%bounds%mult[].off5048)*(1ll) + 
                                          (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + 
                                          (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)).
         0            98                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3oib%addr  + 
                                          d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(2ll) + 
                                          (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + 
                                          (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0            98                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3oib%addr  + 
                                          d-v3oib%rvo + (d-v3oib%bounds%mult[].off5048)*(2ll) + 
                                          (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + 
                                          (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0            98                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            98                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v3oib%addr  + d-v3oib%rvo + 
                                          (d-v3oib%bounds%mult[].off5048)*(2ll) + 
                                          (d-v3oib%bounds%mult[].off5072)*($$CIV7 + 1ll) + 
                                          (d-v3oib%bounds%mult[].off5096)*($$CIV6 + 1ll)).
         0            99                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-doib%addr  + d-doib%rvo 
                                          + (d-doib%bounds%mult[].off2552)*(1ll) + 
                                          (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + 
                                          (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0            99                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-doib%addr  + d-doib%rvo 
                                          + (d-doib%bounds%mult[].off2552)*(1ll) + 
                                          (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + 
                                          (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0            99                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0            99                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-doib%addr 
                                          + d-doib%rvo + (d-doib%bounds%mult[].off2552)*(1ll) + 
                                          (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + 
                                          (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)).
         0           100                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-doib%addr  + d-doib%rvo 
                                          + (d-doib%bounds%mult[].off2552)*(2ll) + 
                                          (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + 
                                          (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0           100                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-doib%addr  + d-doib%rvo 
                                          + (d-doib%bounds%mult[].off2552)*(2ll) + 
                                          (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + 
                                          (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0           100                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           100                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-doib%addr 
                                          + d-doib%rvo + (d-doib%bounds%mult[].off2552)*(2ll) + 
                                          (d-doib%bounds%mult[].off2576)*($$CIV7 + 1ll) + 
                                          (d-doib%bounds%mult[].off2600)*($$CIV6 + 1ll)).
         0           101                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eoib%addr  + d-eoib%rvo 
                                          + (d-eoib%bounds%mult[].off3176)*(1ll) + 
                                          (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + 
                                          (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0           101                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eoib%addr  + d-eoib%rvo 
                                          + (d-eoib%bounds%mult[].off3176)*(1ll) + 
                                          (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + 
                                          (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0           101                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           101                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-eoib%addr 
                                          + d-eoib%rvo + (d-eoib%bounds%mult[].off3176)*(1ll) + 
                                          (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + 
                                          (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)).
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eoib%addr  + d-eoib%rvo 
                                          + (d-eoib%bounds%mult[].off3176)*(2ll) + 
                                          (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + 
                                          (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eoib%addr  + d-eoib%rvo 
                                          + (d-eoib%bounds%mult[].off3176)*(2ll) + 
                                          (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + 
                                          (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0           102                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-eoib%addr 
                                          + d-eoib%rvo + (d-eoib%bounds%mult[].off3176)*(2ll) + 
                                          (d-eoib%bounds%mult[].off3200)*($$CIV7 + 1ll) + 
                                          (d-eoib%bounds%mult[].off3224)*($$CIV6 + 1ll)).
         0           106             9    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           108                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2ojb%addr  + 
                                          d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(1ll) + 
                                          (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + 
                                          (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           108                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2ojb%addr  + 
                                          d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(1ll) + 
                                          (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + 
                                          (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           108                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           108                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v2ojb%addr  + d-v2ojb%rvo + 
                                          (d-v2ojb%bounds%mult[].off4632)*(1ll) + 
                                          (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + 
                                          (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)).
         0           109                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2ojb%addr  + 
                                          d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(2ll) + 
                                          (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + 
                                          (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           109                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2ojb%addr  + 
                                          d-v2ojb%rvo + (d-v2ojb%bounds%mult[].off4632)*(2ll) + 
                                          (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + 
                                          (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           109                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           109                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v2ojb%addr  + d-v2ojb%rvo + 
                                          (d-v2ojb%bounds%mult[].off4632)*(2ll) + 
                                          (d-v2ojb%bounds%mult[].off4656)*($$CIV9 + 1ll) + 
                                          (d-v2ojb%bounds%mult[].off4680)*($$CIV8 + 1ll)).
         0           110                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1ojb%addr  + 
                                          d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(1ll) + 
                                          (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + 
                                          (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           110                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1ojb%addr  + 
                                          d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(1ll) + 
                                          (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + 
                                          (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           110                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           110                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v1ojb%addr  + d-v1ojb%rvo + 
                                          (d-v1ojb%bounds%mult[].off4008)*(1ll) + 
                                          (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + 
                                          (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)).
         0           111                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1ojb%addr  + 
                                          d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(2ll) + 
                                          (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + 
                                          (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           111                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1ojb%addr  + 
                                          d-v1ojb%rvo + (d-v1ojb%bounds%mult[].off4008)*(2ll) + 
                                          (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + 
                                          (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           111                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           111                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v1ojb%addr  + d-v1ojb%rvo + 
                                          (d-v1ojb%bounds%mult[].off4008)*(2ll) + 
                                          (d-v1ojb%bounds%mult[].off4032)*($$CIV9 + 1ll) + 
                                          (d-v1ojb%bounds%mult[].off4056)*($$CIV8 + 1ll)).
         0           112                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3ojb%addr  + 
                                          d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(1ll) + 
                                          (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + 
                                          (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           112                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3ojb%addr  + 
                                          d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(1ll) + 
                                          (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + 
                                          (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           112                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           112                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v3ojb%addr  + d-v3ojb%rvo + 
                                          (d-v3ojb%bounds%mult[].off5256)*(1ll) + 
                                          (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + 
                                          (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)).
         0           113                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3ojb%addr  + 
                                          d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(2ll) + 
                                          (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + 
                                          (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           113                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3ojb%addr  + 
                                          d-v3ojb%rvo + (d-v3ojb%bounds%mult[].off5256)*(2ll) + 
                                          (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + 
                                          (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           113                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           113                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v3ojb%addr  + d-v3ojb%rvo + 
                                          (d-v3ojb%bounds%mult[].off5256)*(2ll) + 
                                          (d-v3ojb%bounds%mult[].off5280)*($$CIV9 + 1ll) + 
                                          (d-v3ojb%bounds%mult[].off5304)*($$CIV8 + 1ll)).
         0           114                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dojb%addr  + d-dojb%rvo 
                                          + (d-dojb%bounds%mult[].off2760)*(1ll) + 
                                          (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + 
                                          (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           114                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dojb%addr  + d-dojb%rvo 
                                          + (d-dojb%bounds%mult[].off2760)*(1ll) + 
                                          (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + 
                                          (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           114                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           114                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-dojb%addr 
                                          + d-dojb%rvo + (d-dojb%bounds%mult[].off2760)*(1ll) + 
                                          (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + 
                                          (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)).
         0           115                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dojb%addr  + d-dojb%rvo 
                                          + (d-dojb%bounds%mult[].off2760)*(2ll) + 
                                          (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + 
                                          (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           115                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dojb%addr  + d-dojb%rvo 
                                          + (d-dojb%bounds%mult[].off2760)*(2ll) + 
                                          (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + 
                                          (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           115                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           115                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-dojb%addr 
                                          + d-dojb%rvo + (d-dojb%bounds%mult[].off2760)*(2ll) + 
                                          (d-dojb%bounds%mult[].off2784)*($$CIV9 + 1ll) + 
                                          (d-dojb%bounds%mult[].off2808)*($$CIV8 + 1ll)).
         0           116                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eojb%addr  + d-eojb%rvo 
                                          + (d-eojb%bounds%mult[].off3384)*(1ll) + 
                                          (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + 
                                          (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           116                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eojb%addr  + d-eojb%rvo 
                                          + (d-eojb%bounds%mult[].off3384)*(1ll) + 
                                          (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + 
                                          (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           116                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           116                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-eojb%addr 
                                          + d-eojb%rvo + (d-eojb%bounds%mult[].off3384)*(1ll) + 
                                          (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + 
                                          (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)).
         0           117                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eojb%addr  + d-eojb%rvo 
                                          + (d-eojb%bounds%mult[].off3384)*(2ll) + 
                                          (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + 
                                          (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           117                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eojb%addr  + d-eojb%rvo 
                                          + (d-eojb%bounds%mult[].off3384)*(2ll) + 
                                          (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + 
                                          (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           117                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           117                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-eojb%addr 
                                          + d-eojb%rvo + (d-eojb%bounds%mult[].off3384)*(2ll) + 
                                          (d-eojb%bounds%mult[].off3408)*($$CIV9 + 1ll) + 
                                          (d-eojb%bounds%mult[].off3432)*($$CIV8 + 1ll)).
         0           121            11    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           123                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3okb%addr  + 
                                          d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(1ll) + 
                                          (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + 
                                          (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           123                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3okb%addr  + 
                                          d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(1ll) + 
                                          (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + 
                                          (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           123                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           123                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v3okb%addr  + d-v3okb%rvo + 
                                          (d-v3okb%bounds%mult[].off5464)*(1ll) + 
                                          (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + 
                                          (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)).
         0           124                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3okb%addr  + 
                                          d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(2ll) + 
                                          (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + 
                                          (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           124                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3okb%addr  + 
                                          d-v3okb%rvo + (d-v3okb%bounds%mult[].off5464)*(2ll) + 
                                          (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + 
                                          (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           124                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           124                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v3okb%addr  + d-v3okb%rvo + 
                                          (d-v3okb%bounds%mult[].off5464)*(2ll) + 
                                          (d-v3okb%bounds%mult[].off5488)*($$CIVB + 1ll) + 
                                          (d-v3okb%bounds%mult[].off5512)*($$CIVA + 1ll)).
         0           125                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1okb%addr  + 
                                          d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(1ll) + 
                                          (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + 
                                          (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           125                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1okb%addr  + 
                                          d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(1ll) + 
                                          (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + 
                                          (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           125                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           125                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v1okb%addr  + d-v1okb%rvo + 
                                          (d-v1okb%bounds%mult[].off4216)*(1ll) + 
                                          (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + 
                                          (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)).
         0           126                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1okb%addr  + 
                                          d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(2ll) + 
                                          (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + 
                                          (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           126                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1okb%addr  + 
                                          d-v1okb%rvo + (d-v1okb%bounds%mult[].off4216)*(2ll) + 
                                          (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + 
                                          (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           126                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           126                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v1okb%addr  + d-v1okb%rvo + 
                                          (d-v1okb%bounds%mult[].off4216)*(2ll) + 
                                          (d-v1okb%bounds%mult[].off4240)*($$CIVB + 1ll) + 
                                          (d-v1okb%bounds%mult[].off4264)*($$CIVA + 1ll)).
         0           127                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2okb%addr  + 
                                          d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(1ll) + 
                                          (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + 
                                          (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           127                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2okb%addr  + 
                                          d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(1ll) + 
                                          (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + 
                                          (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           127                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           127                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v2okb%addr  + d-v2okb%rvo + 
                                          (d-v2okb%bounds%mult[].off4840)*(1ll) + 
                                          (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + 
                                          (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)).
         0           128                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2okb%addr  + 
                                          d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(2ll) + 
                                          (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + 
                                          (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           128                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2okb%addr  + 
                                          d-v2okb%rvo + (d-v2okb%bounds%mult[].off4840)*(2ll) + 
                                          (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + 
                                          (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           128                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           128                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char 
                                          *)d-v2okb%addr  + d-v2okb%rvo + 
                                          (d-v2okb%bounds%mult[].off4840)*(2ll) + 
                                          (d-v2okb%bounds%mult[].off4864)*($$CIVB + 1ll) + 
                                          (d-v2okb%bounds%mult[].off4888)*($$CIVA + 1ll)).
         0           129                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dokb%addr  + d-dokb%rvo 
                                          + (d-dokb%bounds%mult[].off2968)*(1ll) + 
                                          (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + 
                                          (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           129                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dokb%addr  + d-dokb%rvo 
                                          + (d-dokb%bounds%mult[].off2968)*(1ll) + 
                                          (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + 
                                          (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           129                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           129                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-dokb%addr 
                                          + d-dokb%rvo + (d-dokb%bounds%mult[].off2968)*(1ll) + 
                                          (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + 
                                          (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)).
         0           130                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dokb%addr  + d-dokb%rvo 
                                          + (d-dokb%bounds%mult[].off2968)*(2ll) + 
                                          (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + 
                                          (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           130                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-dokb%addr  + d-dokb%rvo 
                                          + (d-dokb%bounds%mult[].off2968)*(2ll) + 
                                          (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + 
                                          (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           130                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           130                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-dokb%addr 
                                          + d-dokb%rvo + (d-dokb%bounds%mult[].off2968)*(2ll) + 
                                          (d-dokb%bounds%mult[].off2992)*($$CIVB + 1ll) + 
                                          (d-dokb%bounds%mult[].off3016)*($$CIVA + 1ll)).
         0           131                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eokb%addr  + d-eokb%rvo 
                                          + (d-eokb%bounds%mult[].off3592)*(1ll) + 
                                          (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + 
                                          (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           131                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eokb%addr  + d-eokb%rvo 
                                          + (d-eokb%bounds%mult[].off3592)*(1ll) + 
                                          (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + 
                                          (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           131                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           131                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-eokb%addr 
                                          + d-eokb%rvo + (d-eokb%bounds%mult[].off3592)*(1ll) + 
                                          (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + 
                                          (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)).
         0           132                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eokb%addr  + d-eokb%rvo 
                                          + (d-eokb%bounds%mult[].off3592)*(2ll) + 
                                          (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + 
                                          (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll))  with 
                                          non-vectorizable alignment.
         0           132                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-eokb%addr  + d-eokb%rvo 
                                          + (d-eokb%bounds%mult[].off3592)*(2ll) + 
                                          (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + 
                                          (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)) with  
                                          non-vectorizable strides.
         0           132                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           132                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-eokb%addr 
                                          + d-eokb%rvo + (d-eokb%bounds%mult[].off3592)*(2ll) + 
                                          (d-eokb%bounds%mult[].off3616)*($$CIVB + 1ll) + 
                                          (d-eokb%bounds%mult[].off3640)*($$CIVA + 1ll)).


    11|         SUBROUTINE noh ()
    36|           d0 =  1.0000000000000000E+000
    37|           p0 =  9.9999999999999995E-007
    38|           v0 = -1.0000000000000000E+000
    40|           IF ((myid == 0)) THEN
    11|             |pgen%nlitems%type.off32 = 4
                    |pgen%nlitems%kind.off40 = 
                    |pgen%nlitems%size.off48 = 
                    |pgen%nlitems%name_addr.off56 = "pgenp0d0v0idirectInoh.f90" &
                &     + 4
                    |pgen%nlitems%name_len.off64 = 2
                    |pgen%nlitems%item_addr.off72 = loc(p0)
                    |pgen%nlitems%type.off80 = 4
                    |pgen%nlitems%kind.off88 = 
                    |pgen%nlitems%size.off96 = 
                    |pgen%nlitems%name_addr.off104 = &
                &     "pgenp0d0v0idirectInoh.f90" + 6
                    |pgen%nlitems%name_len.off112 = 2
                    |pgen%nlitems%item_addr.off120 = loc(d0)
                    |pgen%nlitems%type.off128 = 4
                    |pgen%nlitems%kind.off136 = 
                    |pgen%nlitems%size.off144 = 
                    |pgen%nlitems%name_addr.off152 = &
                &     "pgenp0d0v0idirectInoh.f90" + 8
                    |pgen%nlitems%name_len.off160 = 2
                    |pgen%nlitems%item_addr.off168 = loc(v0)
                    |pgen%version = 129
                    |pgen%name_addr = "pgenp0d0v0idirectInoh.f90"
                    |pgen%name_len = 4
                    |pgen%num_of_items = 4
                    |pgen%nlitems%type.off176 = 0
                    |pgen%nlitems%kind.off184 = 
                    |pgen%nlitems%size.off192 = 
                    |pgen%nlitems%name_addr.off200 = &
                &     "pgenp0d0v0idirectInoh.f90" + 10
                    |pgen%nlitems%name_len.off208 = 7
                    |pgen%nlitems%item_addr.off216 = loc(idirect)
    41|             |pgen%name_flags = 0
                    #2 = _xlfBeginIO(1,2,#1,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#2))
    42|             |pgen%name_flags = 0
                    #4 = _xlfBeginIO(2,258,#3,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#4))
    43|             buf_in[].off1744 = d0
    44|             buf_in[].off1752 = p0
    45|             buf_in[].off1760 = v0
    46|             ibuf_in[].off144 = idirect
    47|           ENDIF
    48|           T_2 = 3
                  T_3 = 1275070495
                  T_4 = 0
                  CALL mpi_bcast(buf_in,T_2,T_3,T_4,comm3d,ierr)
    50|           T_5 = 1
                  T_6 = 1275069467
                  T_7 = 0
                  CALL mpi_bcast(ibuf_in,T_5,T_6,T_7,comm3d,ierr)
    52|           IF ((myid <> 0)) THEN
    53|             d0 = buf_in[].off1744
    54|             p0 = buf_in[].off1752
    55|             v0 = buf_in[].off1760
    56|             idirect = ibuf_in[].off144
    57|           ENDIF
    61|           IF ((MOD((1 + (int(ke) - int(ks))), 4) > 0  .AND.  1 + (int(&
                &   ke) - int(ks)) > 0)) THEN
                    $$CIV2 = 0
       Id=22        DO $$CIV2 = $$CIV2, MOD((1 + (int(ke) - int(ks))), int(4))&
                &       -1
    62|               IF ((1 + (int(je) - int(js)) > 0)) THEN
                        $$CIV1 = 0
       Id=23            DO $$CIV1 = $$CIV1, int((1 + (int(je) - int(js))))-1
    63|                   IF ((1 + (int(ie) - int(is)) > 0)) THEN
                            $$CIV0 = 0
       Id=24                DO $$CIV0 = $$CIV0, int((1 + (int(ie) - int(is))))&
                &               -1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,int(&
                &               ks) + $$CIV2) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,int(&
                &               ks) + $$CIV2) = p0 / gamm1
    66|                     ENDDO
                          ENDIF
    67|                 ENDDO
                      ENDIF
    68|             ENDDO
                  ENDIF
    61|           IF ((1 + (int(ke) - int(ks)) > 0  .AND.  1 + (int(ke) - int(&
                &   ks)) > MOD((1 + (int(ke) - int(ks))), 4))) THEN
                    $$CIVC = int(0)
       Id=1         DO $$CIVC = $$CIVC, int(((int(ke) - (MOD((1 + (int(ke) - &
                &       int(ks))), 4) + int(ks))) / 4 + 1))-1
    62|               IF ((1 + (int(je) - int(js)) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int((1 + (int(je) - int(js))))-1
    63|                   IF ((1 + (int(ie) - int(is)) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int((1 + (int(ie) - int(is))))&
                &               -1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,(&
                &               $$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) + &
                &               int(ks)) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,(&
                &               $$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) + &
                &               int(ks)) = p0 / gamm1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,1 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,1 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = p0 / gamm1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,2 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,2 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = p0 / gamm1
    64|                       d-d%addr%d(int(is) + $$CIV0,int(js) + $$CIV1,3 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = d0
    65|                       d-e%addr%e(int(is) + $$CIV0,int(js) + $$CIV1,3 + (&
                &               ($$CIVC * 4 + MOD((1 + (int(ke) - int(ks))), 4)) &
                &               + int(ks))) = p0 / gamm1
    66|                     ENDDO
                          ENDIF
    67|                 ENDDO
                      ENDIF
    68|             ENDDO
                  ENDIF
    70|           IF ((MOD(int(kn), 4) > 0  .AND.  int(kn) > 0)) THEN
                    $$CIV5 = 0
       Id=16        DO $$CIV5 = $$CIV5, MOD(int(kn), int(4))-1
    71|               IF ((int(jn) > 0)) THEN
                        $$CIV4 = 0
       Id=17            DO $$CIV4 = $$CIV4, int(int(jn))-1
    72|                   IF ((int(in) > 0)) THEN
                            $$CIV3 = 0
       Id=18                DO $$CIV3 = $$CIV3, int(int(in))-1
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_97
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    77|                       GOTO lab_100
                              lab_97
                              IF (.NOT.(idirect == 2)) GOTO lab_98
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    81|                       GOTO lab_99
                              lab_98
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) =  &
                &               0.0000000000000000E+000
    85|                       lab_99
                              lab_100
    86|                     ENDDO
                          ENDIF
    87|                 ENDDO
                      ENDIF
    88|             ENDDO
                  ENDIF
    70|           IF ((int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 4))) THEN
                    $$CIVD = int(0)
       Id=4         DO $$CIVD = $$CIVD, int((((int(kn) - MOD(int(kn), 4)) - 1)&
                &        / 4 + 1))-1
    71|               IF ((int(jn) > 0)) THEN
                        $$CIV4 = 0
       Id=5             DO $$CIV4 = $$CIV4, int(int(jn))-1
    72|                   IF ((int(in) > 0)) THEN
                            $$CIV3 = 0
       Id=6                 DO $$CIV3 = $$CIV3, int(int(in))-1
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_18
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    77|                       GOTO lab_19
                              lab_18
                              IF (.NOT.(idirect == 2)) GOTO lab_20
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    81|                       GOTO lab_21
                              lab_20
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,1 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    85|                       lab_21
                              lab_19
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_104
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    77|                       GOTO lab_107
                              lab_104
                              IF (.NOT.(idirect == 2)) GOTO lab_105
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    81|                       GOTO lab_106
                              lab_105
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,2 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    85|                       lab_106
                              lab_107
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_108
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    77|                       GOTO lab_111
                              lab_108
                              IF (.NOT.(idirect == 2)) GOTO lab_109
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    81|                       GOTO lab_110
                              lab_109
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,3 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    85|                       lab_110
                              lab_111
    73|                       IF (.NOT.(idirect == 1)) GOTO lab_112
    74|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    75|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    76|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    77|                       GOTO lab_115
                              lab_112
                              IF (.NOT.(idirect == 2)) GOTO lab_113
    78|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    79|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    80|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    81|                       GOTO lab_114
                              lab_113
    82|                       d-v3%addr%v3($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) = v0
    83|                       d-v1%addr%v1($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    84|                       d-v2%addr%v2($$CIV3 + 1,$$CIV4 + 1,4 + ($$CIVD * &
                &               4 + MOD(int(kn), 4))) =  0.0000000000000000E+000
    85|                       lab_114
                              lab_115
    86|                     ENDDO
                          ENDIF
    87|                 ENDDO
                      ENDIF
    88|             ENDDO
                  ENDIF
    90|           IF ((idirect == 1)) THEN
    91|             IF ((int(kn) > 0)) THEN
                      $$CIV7 = 0
       Id=7           DO $$CIV7 = $$CIV7, int(int(kn))-1
    92|                 IF ((int(jn) > 0)) THEN
                          $$CIV6 = 0
       Id=8               DO $$CIV6 = $$CIV6, int(int(jn))-1
    93|                     d-v1oib%addr%v1oib($$CIV6 + 1,$$CIV7 + 1,1) = v0
    94|                     d-v1oib%addr%v1oib($$CIV6 + 1,$$CIV7 + 1,2) = v0
    95|                     d-v2oib%addr%v2oib($$CIV6 + 1,$$CIV7 + 1,1) =  &
                &             0.0000000000000000E+000
    96|                     d-v2oib%addr%v2oib($$CIV6 + 1,$$CIV7 + 1,2) =  &
                &             0.0000000000000000E+000
    97|                     d-v3oib%addr%v3oib($$CIV6 + 1,$$CIV7 + 1,1) =  &
                &             0.0000000000000000E+000
    98|                     d-v3oib%addr%v3oib($$CIV6 + 1,$$CIV7 + 1,2) =  &
                &             0.0000000000000000E+000
    99|                     d-doib%addr%doib($$CIV6 + 1,$$CIV7 + 1,1) = d0
   100|                     d-doib%addr%doib($$CIV6 + 1,$$CIV7 + 1,2) = d0
   101|                     d-eoib%addr%eoib($$CIV6 + 1,$$CIV7 + 1,1) = p0 / &
                &             gamm1
   102|                     d-eoib%addr%eoib($$CIV6 + 1,$$CIV7 + 1,2) = p0 / &
                &             gamm1
   103|                   ENDDO
                        ENDIF
   104|               ENDDO
                    ENDIF
   105|           ELSE
                    lab_31
                    IF ((idirect == 2)) THEN
   106|               IF ((int(kn) > 0)) THEN
                        $$CIV9 = 0
       Id=9             DO $$CIV9 = $$CIV9, int(int(kn))-1
   107|                   IF ((int(in) > 0)) THEN
                            $$CIV8 = 0
       Id=10                DO $$CIV8 = $$CIV8, int(int(in))-1
   108|                       d-v2ojb%addr%v2ojb($$CIV8 + 1,$$CIV9 + 1,1) = v0
   109|                       d-v2ojb%addr%v2ojb($$CIV8 + 1,$$CIV9 + 1,2) = v0
   110|                       d-v1ojb%addr%v1ojb($$CIV8 + 1,$$CIV9 + 1,1) =  &
                &               0.0000000000000000E+000
   111|                       d-v1ojb%addr%v1ojb($$CIV8 + 1,$$CIV9 + 1,2) =  &
                &               0.0000000000000000E+000
   112|                       d-v3ojb%addr%v3ojb($$CIV8 + 1,$$CIV9 + 1,1) =  &
                &               0.0000000000000000E+000
   113|                       d-v3ojb%addr%v3ojb($$CIV8 + 1,$$CIV9 + 1,2) =  &
                &               0.0000000000000000E+000
   114|                       d-dojb%addr%dojb($$CIV8 + 1,$$CIV9 + 1,1) = d0
   115|                       d-dojb%addr%dojb($$CIV8 + 1,$$CIV9 + 1,2) = d0
   116|                       d-eojb%addr%eojb($$CIV8 + 1,$$CIV9 + 1,1) = p0 / &
                &               gamm1
   117|                       d-eojb%addr%eojb($$CIV8 + 1,$$CIV9 + 1,2) = p0 / &
                &               gamm1
   118|                     ENDDO
                          ENDIF
   119|                 ENDDO
                      ENDIF
   120|             ELSE
                      lab_41
   121|               IF (.NOT.(int(jn) > 0)) GOTO lab_79
                      $$CIVB = 0
       Id=11          DO $$CIVB = $$CIVB, int(int(jn))-1
   122|                 IF ((int(jn) > 0)) THEN
                          $$CIVA = 0
       Id=12              DO $$CIVA = $$CIVA, int(int(jn))-1
   123|                     d-v3okb%addr%v3okb($$CIVA + 1,$$CIVB + 1,1) = v0
   124|                     d-v3okb%addr%v3okb($$CIVA + 1,$$CIVB + 1,2) = v0
   125|                     d-v1okb%addr%v1okb($$CIVA + 1,$$CIVB + 1,1) =  &
                &             0.0000000000000000E+000
   126|                     d-v1okb%addr%v1okb($$CIVA + 1,$$CIVB + 1,2) =  &
                &             0.0000000000000000E+000
   127|                     d-v2okb%addr%v2okb($$CIVA + 1,$$CIVB + 1,1) =  &
                &             0.0000000000000000E+000
   128|                     d-v2okb%addr%v2okb($$CIVA + 1,$$CIVB + 1,2) =  &
                &             0.0000000000000000E+000
   129|                     d-dokb%addr%dokb($$CIVA + 1,$$CIVB + 1,1) = d0
   130|                     d-dokb%addr%dokb($$CIVA + 1,$$CIVB + 1,2) = d0
   131|                     d-eokb%addr%eokb($$CIVA + 1,$$CIVB + 1,1) = p0 / &
                &             gamm1
   132|                     d-eokb%addr%eokb($$CIVA + 1,$$CIVB + 1,2) = p0 / &
                &             gamm1
   133|                   ENDDO
                        ENDIF
   134|               ENDDO
                      lab_79
   138|               lab_83
                      RETURN
                    END SUBROUTINE noh

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   ssus ssss ssss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ss--  ---- ---- ---- -sss
 CCR's set/used:   ss-- ssss
     | 000000                           PDEF     noh
   11|                                  PROC      
    0| 000000 stfd     DBE1FFF8   1     STFL      #stack(gr1,-8)=fp31
    0| 000004 stfd     DBC1FFF0   1     STFL      #stack(gr1,-16)=fp30
    0| 000008 stfd     DBA1FFE8   1     STFL      #stack(gr1,-24)=fp29
    0| 00000C std      FBE1FFE0   1     ST8       #stack(gr1,-32)=gr31
    0| 000010 std      FBC1FFD8   1     ST8       #stack(gr1,-40)=gr30
    0| 000014 std      FBA1FFD0   1     ST8       #stack(gr1,-48)=gr29
    0| 000018 std      FB81FFC8   1     ST8       #stack(gr1,-56)=gr28
    0| 00001C std      FB61FFC0   1     ST8       #stack(gr1,-64)=gr27
    0| 000020 std      FB41FFB8   1     ST8       #stack(gr1,-72)=gr26
    0| 000024 std      FB21FFB0   1     ST8       #stack(gr1,-80)=gr25
    0| 000028 std      FB01FFA8   1     ST8       #stack(gr1,-88)=gr24
    0| 00002C std      FAE1FFA0   1     ST8       #stack(gr1,-96)=gr23
    0| 000030 std      FAC1FF98   1     ST8       #stack(gr1,-104)=gr22
    0| 000034 std      FAA1FF90   1     ST8       #stack(gr1,-112)=gr21
    0| 000038 std      FA81FF88   1     ST8       #stack(gr1,-120)=gr20
    0| 00003C std      FA61FF80   1     ST8       #stack(gr1,-128)=gr19
    0| 000040 std      FA41FF78   1     ST8       #stack(gr1,-136)=gr18
    0| 000044 std      FA21FF70   1     ST8       #stack(gr1,-144)=gr17
    0| 000048 std      FA01FF68   1     ST8       #stack(gr1,-152)=gr16
    0| 00004C std      F9E1FF60   1     ST8       #stack(gr1,-160)=gr15
    0| 000050 std      F9C1FF58   1     ST8       #stack(gr1,-168)=gr14
    0| 000054 mfspr    7C0802A6   1     LFLR      gr0=lr
    0| 000058 mfcr     7D800026   1     LFCR      gr12=cr4,4
    0| 00005C stw      91810008   1     ST4A      #stack(gr1,8)=gr12
    0| 000060 std      F8010010   1     ST8       #stack(gr1,16)=gr0
    0| 000064 stdu     F821FC01   1     ST8U      gr1,#stack(gr1,-1024)=gr1
   40| 000068 ld       EBA20000   1     L8        gr29=.&&N&&mpipar(gr2,0)
   36| 00006C ld       E8820000   1     L8        gr4=.+CONSTANT_AREA(gr2,0)
   36| 000070 addi     380003FF   1     LI        gr0=1023
   38| 000074 addi     38600BFF   1     LI        gr3=3071
   36| 000078 rldicr   7800A2C6   1     SLL8      gr0=gr0,52
   38| 00007C rldicr   7863A2C6   1     SLL8      gr3=gr3,52
   36| 000080 std      F80100A0   1     ST8       d0(gr1,160)=gr0
   38| 000084 std      F86100B0   1     ST8       v0(gr1,176)=gr3
   40| 000088 lwz      801D0004   1     L4Z       gr0=<s205:d4:l4>(gr29,4)
   37| 00008C lfd      CBE40028   1     LFL       fp31=+CONSTANT_AREA(gr4,40)
   36| 000090 lfs      C3C40024   1     LFS       fp30=+CONSTANT_AREA(gr4,36)
   38| 000094 lfs      C3A40030   1     LFS       fp29=+CONSTANT_AREA(gr4,48)
   40| 000098 cmpdi    2C200000   1     C8        cr0=gr0,0
   37| 00009C stfd     DBE100A8   1     STFL      p0(gr1,168)=fp31
   40| 0000A0 bc       4082013C   1     BF        CL.1,cr0,0x4/eq,taken=60%(60,40)
    0| 0000A4 ld       E9020000   1     L8        gr8=.+CONSTANT_AREA(gr2,0)
    0| 0000A8 addi     38000004   1     LI        gr0=4
    0| 0000AC addi     38800008   1     LI        gr4=8
    0| 0000B0 std      F8010178   1     ST8       <a1:d376:l8>(gr1,376)=gr0
    0| 0000B4 std      F80100E0   1     ST8       <a1:d224:l8>(gr1,224)=gr0
    0| 0000B8 std      F88100E8   1     ST8       <a1:d232:l8>(gr1,232)=gr4
    0| 0000BC std      F8010110   1     ST8       <a1:d272:l8>(gr1,272)=gr0
    0| 0000C0 std      F8810118   1     ST8       <a1:d280:l8>(gr1,280)=gr4
    0| 0000C4 std      F8010140   1     ST8       <a1:d320:l8>(gr1,320)=gr0
    0| 0000C8 std      F8810148   1     ST8       <a1:d328:l8>(gr1,328)=gr4
    0| 0000CC std      F80100D0   1     ST8       <a1:d208:l8>(gr1,208)=gr0
    0| 0000D0 std      F80100D8   1     ST8       <a1:d216:l8>(gr1,216)=gr0
    0| 0000D4 std      F8010180   1     ST8       <a1:d384:l8>(gr1,384)=gr0
    0| 0000D8 std      F88100F0   1     ST8       <a1:d240:l8>(gr1,240)=gr4
   41| 0000DC ld       EBC20000   1     L8        gr30=.$STATIC(gr2,0)
    0| 0000E0 std      F8810120   1     ST8       <a1:d288:l8>(gr1,288)=gr4
    0| 0000E4 std      F8810150   1     ST8       <a1:d336:l8>(gr1,336)=gr4
    0| 0000E8 addi     3808000C   1     AI        gr0=gr8,12
    0| 0000EC addi     38C00000   1     LI        gr6=0
    0| 0000F0 std      F80100F8   1     ST8       <a1:d248:l8>(gr1,248)=gr0
    0| 0000F4 addi     38080010   1     AI        gr0=gr8,16
    0| 0000F8 std      F8C10170   1     ST8       <a1:d368:l8>(gr1,368)=gr6
    0| 0000FC addi     38880012   1     AI        gr4=gr8,18
   41| 000100 stw      90C100C4   1     ST4Z      <a1:d196:l4>(gr1,196)=gr6
    0| 000104 std      F8010158   1     ST8       <a1:d344:l8>(gr1,344)=gr0
    0| 000108 std      F8810188   1     ST8       <a1:d392:l8>(gr1,392)=gr4
    0| 00010C addi     38E100B0   1     AI        gr7=gr1,176
    0| 000110 addi     38A00081   1     LI        gr5=129
    0| 000114 std      F8E10168   1     ST8       <a1:d360:l8>(gr1,360)=gr7
    0| 000118 stw      90A100C0   1     ST4Z      <a1:d192:l4>(gr1,192)=gr5
    0| 00011C addi     38680008   1     AI        gr3=gr8,8
    0| 000120 addi     38000007   1     LI        gr0=7
    0| 000124 std      F86100C8   1     ST8       <a1:d200:l8>(gr1,200)=gr3
    0| 000128 addi     38E10080   1     AI        gr7=gr1,128
   41| 00012C ori      60DF8000   1     OIL       gr31=gr6,0x8000
    0| 000130 std      F8010190   1     ST8       <a1:d400:l8>(gr1,400)=gr0
    0| 000134 std      F8E10198   1     ST8       <a1:d408:l8>(gr1,408)=gr7
    0| 000138 addi     38600002   1     LI        gr3=2
    0| 00013C addi     388100A8   1     AI        gr4=gr1,168
    0| 000140 addi     38A8000E   1     AI        gr5=gr8,14
    0| 000144 addi     38C100A0   1     AI        gr6=gr1,160
    0| 000148 std      F8610160   1     ST8       <a1:d352:l8>(gr1,352)=gr3
    0| 00014C std      F8610100   1     ST8       <a1:d256:l8>(gr1,256)=gr3
    0| 000150 std      F8810108   1     ST8       <a1:d264:l8>(gr1,264)=gr4
    0| 000154 std      F8A10128   1     ST8       <a1:d296:l8>(gr1,296)=gr5
    0| 000158 std      F8610130   1     ST8       <a1:d304:l8>(gr1,304)=gr3
    0| 00015C std      F8C10138   1     ST8       <a1:d312:l8>(gr1,312)=gr6
   41| 000160 addi     38600001   1     LI        gr3=1
   41| 000164 addi     38800002   1     LI        gr4=2
   41| 000168 or       7FC5F378   1     LR        gr5=gr30
   41| 00016C or       7FE6FB78   1     LR        gr6=gr31
   41| 000170 addi     38E00000   1     LI        gr7=0
   41| 000174 addi     39000000   1     LI        gr8=0
   41| 000178 addi     392100C0   1     AI        gr9=gr1,192
   41| 00017C bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#1",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,|pgen,gr9,#def_xlfBeginIO11",_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   41| 000180 ori      60000000   1
   41| 000184 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   41| 000188 ori      60000000   1
   42| 00018C addi     38BE0040   1     AI        gr5=gr30,64
   42| 000190 addi     38600002   1     LI        gr3=2
   42| 000194 addi     38800102   1     LI        gr4=258
   42| 000198 or       7FE6FB78   1     LR        gr6=gr31
   42| 00019C addi     38E00000   1     LI        gr7=0
   42| 0001A0 addi     39000000   1     LI        gr8=0
   42| 0001A4 addi     392100C0   1     AI        gr9=gr1,192
   42| 0001A8 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#3",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,|pgen,gr9,#use_xlfBeginIO21,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   42| 0001AC ori      60000000   1
   42| 0001B0 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   42| 0001B4 ori      60000000   1
   43| 0001B8 lfd      CBC100A0   1     LFL       fp30=d0(gr1,160)
   44| 0001BC lfd      CBE100A8   1     LFL       fp31=p0(gr1,168)
   45| 0001C0 lfd      CBA100B0   1     LFL       fp29=v0(gr1,176)
   46| 0001C4 lwa      EB810082   1     L4A       gr28=idirect(gr1,128)
   43| 0001C8 stfd     DBDD06D0   1     STFL      <s205:d1744:l8>(gr29,1744)=fp30
   44| 0001CC stfd     DBFD06D8   1     STFL      <s205:d1752:l8>(gr29,1752)=fp31
   46| 0001D0 std      FB8101C8   1     ST8       #SPILL0(gr1,456)=gr28
   45| 0001D4 stfd     DBBD06E0   1     STFL      <s205:d1760:l8>(gr29,1760)=fp29
   46| 0001D8 stw      939D0090   1     ST4Z      <s205:d144:l4>(gr29,144)=gr28
   47|                              CL.1:
   48| 0001DC addis    3FC04C00   1     LIU       gr30=19456
   48| 0001E0 addi     38000003   1     LI        gr0=3
   48| 0001E4 addi     387E081F   1     AI        gr3=gr30,2079
   48| 0001E8 stw      90010084   1     ST4Z      T_2(gr1,132)=gr0
   48| 0001EC stw      90610088   1     ST4Z      T_3(gr1,136)=gr3
   48| 0001F0 addi     3BE00000   1     LI        gr31=0
   48| 0001F4 addi     387D06D0   1     AI        gr3=gr29,1744
   48| 0001F8 stw      93E1008C   1     ST4Z      T_4(gr1,140)=gr31
   48| 0001FC addi     38C1008C   1     AI        gr6=gr1,140
   48| 000200 addi     38A10088   1     AI        gr5=gr1,136
   48| 000204 addi     38810084   1     AI        gr4=gr1,132
   48| 000208 addi     38FD0020   1     AI        gr7=gr29,32
   48| 00020C addi     391D0014   1     AI        gr8=gr29,20
   48| 000210 bl       48000001   1     CALL      mpi_bcast,6,buf_in[]",gr3,T_2",gr4,T_3",gr5,T_4",gr6,comm3d",gr7,ierr",gr8,#ProcAlias",mpi_bcast",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   48| 000214 ori      60000000   1
   50| 000218 addi     387E041B   1     AI        gr3=gr30,1051
   50| 00021C stw      93E10098   1     ST4Z      T_7(gr1,152)=gr31
   50| 000220 addi     38000001   1     LI        gr0=1
   50| 000224 stw      90610094   1     ST4Z      T_6(gr1,148)=gr3
   50| 000228 stw      90010090   1     ST4Z      T_5(gr1,144)=gr0
   50| 00022C addi     38C10098   1     AI        gr6=gr1,152
   50| 000230 addi     38A10094   1     AI        gr5=gr1,148
   50| 000234 addi     38810090   1     AI        gr4=gr1,144
   50| 000238 addi     387D0090   1     AI        gr3=gr29,144
   50| 00023C addi     38FD0020   1     AI        gr7=gr29,32
   50| 000240 addi     391D0014   1     AI        gr8=gr29,20
   50| 000244 bl       48000001   1     CALL      mpi_bcast,6,ibuf_in[]",gr3,T_5",gr4,T_6",gr5,T_7",gr6,comm3d",gr7,ierr",gr8,#ProcAlias",mpi_bcast",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   50| 000248 ori      60000000   1
   52| 00024C lwz      801D0004   1     L4Z       gr0=<s205:d4:l4>(gr29,4)
   52| 000250 cmpdi    2C200000   1     C8        cr0=gr0,0
   52| 000254 bc       41820018   1     BT        CL.2,cr0,0x4/eq,taken=50%(0,0)
   56| 000258 lwa      E81D0092   1     L4A       gr0=<s205:d144:l4>(gr29,144)
   53| 00025C lfd      CBDD06D0   1     LFL       fp30=<s205:d1744:l8>(gr29,1744)
   54| 000260 lfd      CBFD06D8   1     LFL       fp31=<s205:d1752:l8>(gr29,1752)
   55| 000264 lfd      CBBD06E0   1     LFL       fp29=<s205:d1760:l8>(gr29,1760)
   56| 000268 std      F80101C8   1     ST8       #SPILL0(gr1,456)=gr0
   57|                              CL.2:
   61| 00026C ld       E8620000   1     L8        gr3=.&&N&&grid(gr2,0)
   61| 000270 lwa      E8030016   1     L4A       gr0=<s232:d20:l4>(gr3,20)
   61| 000274 lwa      E8C30012   1     L4A       gr6=<s232:d16:l4>(gr3,16)
   61| 000278 subf     7C860050   1     S         gr4=gr0,gr6
   61| 00027C addi     38040001   1     AI        gr0=gr4,1
   61| 000280 sradi    7C041674   1     SRA8CA    gr4,ca=gr0,2
   61| 000284 cmpdi    2F200000   1     C8        cr6=gr0,0
   61| 000288 addze    7C840194   1     ADDE      gr4,ca=gr4,0,ca
   61| 00028C rldicr   78841764   1     SLL8      gr4=gr4,2
   61| 000290 subf     7CA40051   1     S_R       gr5,cr0=gr0,gr4
   61| 000294 crand    4C390A02   1     CR_N      cr0=cr[60],0x2/gt,0x2/gt,0x2/gt,cr0
   61| 000298 bc       40810100   1     BF        CL.127,cr0,0x2/gt,taken=50%(0,0)
   64| 00029C ld       EB220000   1     L8        gr25=.&&N&field(gr2,0)
   62| 0002A0 lwa      EA83000A   1     L4A       gr20=<s232:d8:l4>(gr3,8)
   62| 0002A4 lwa      EB83000E   1     L4A       gr28=<s232:d12:l4>(gr3,12)
   63| 0002A8 lwa      E9430002   1     L4A       gr10=<s232:d0:l4>(gr3,0)
   65| 0002AC ld       EB020000   1     L8        gr24=.&&N&&root(gr2,0)
   61| 0002B0 addi     38E00000   1     LI        gr7=0
   64| 0002B4 ld       E9790030   1     L8        gr11=<s22:d48:l8>(gr25,48)
   64| 0002B8 ld       E9990048   1     L8        gr12=<s22:d72:l8>(gr25,72)
   64| 0002BC ld       E9190060   1     L8        gr8=<s22:d96:l8>(gr25,96)
   65| 0002C0 ld       EBD90098   1     L8        gr30=<s22:d152:l8>(gr25,152)
   65| 0002C4 ld       EBB900B0   1     L8        gr29=<s22:d176:l8>(gr25,176)
   65| 0002C8 ld       E93900C8   1     L8        gr9=<s22:d200:l8>(gr25,200)
   62| 0002CC subf     7F94E050   1     S         gr28=gr28,gr20
   65| 0002D0 ld       EA390068   1     L8        gr17=<s22:d104:l8>(gr25,104)
   62| 0002D4 addic.   379C0001   1     AI_R      gr28,cr0=gr28,1,ca"
   64| 0002D8 ld       EA590000   1     L8        gr18=<s22:d0:l8>(gr25,0)
   63| 0002DC lwa      EB630006   1     L4A       gr27=<s232:d4:l4>(gr3,4)
   64| 0002E0 ld       EB590018   1     L8        gr26=<s22:d24:l8>(gr25,24)
   65| 0002E4 lfd      C81800E8   1     LFL       fp0=<s241:d232:l8>(gr24,232)
   65| 0002E8 ld       EB390080   1     L8        gr25=<s22:d128:l8>(gr25,128)
    0| 0002EC bc       40810DFC   1     BF        CL.318,cr0,0x2/gt,taken=50%(0,0)
    0| 0002F0 mulld    7F0659D2   1     M         gr24=gr6,gr11
    0| 0002F4 mulld    7EECA1D2   1     M         gr23=gr12,gr20
    0| 0002F8 mulld    7EC951D2   1     M         gr22=gr9,gr10
    0| 0002FC mulld    7EA6F1D2   1     M         gr21=gr6,gr30
    0| 000300 mulld    7E94E9D2   1     M         gr20=gr20,gr29
    0| 000304 mulld    7E6851D2   1     M         gr19=gr8,gr10
    0| 000308 subf     7E298850   1     S         gr17=gr17,gr9
    0| 00030C subf     7E489050   1     S         gr18=gr18,gr8
    0| 000310 add      7F398A14   1     A         gr25=gr25,gr17
    0| 000314 add      7F18BA14   1     A         gr24=gr24,gr23
    0| 000318 subfic   22EA0001   1     SFI       gr23=1,gr10,ca"
    0| 00031C add      7ED5B214   1     A         gr22=gr21,gr22
    0| 000320 add      7F34CA14   1     A         gr25=gr20,gr25
    0| 000324 add      7F5A9214   1     A         gr26=gr26,gr18
    0| 000328 add      7F13C214   1     A         gr24=gr19,gr24
    0| 00032C subf     7D4AD850   1     S         gr10=gr27,gr10
    0| 000330 add      7F7BBA14   1     A         gr27=gr27,gr23
    0| 000334 add      7F36CA14   1     A         gr25=gr22,gr25
    0| 000338 add      7F58D214   1     A         gr26=gr24,gr26
    0| 00033C addic.   354A0001   1     AI_R      gr10,cr0=gr10,1,ca"
   61|                              CL.122:
   62| 000340 or       7FEAFB78   1     LR        gr10=gr31
    0| 000344 bc       40810040   1     BF        CL.126,cr0,0x2/gt,taken=20%(20,80)
    0| 000348 fdiv     FC3F0024   1     DFL       fp1=fp31,fp0,fcr
    0| 00034C or       7F56D378   1     LR        gr22=gr26
    0| 000350 or       7F35CB78   1     LR        gr21=gr25
   62|                              CL.123:
   65| 000354 or       7EB8AB78   1     LR        gr24=gr21
   64| 000358 or       7ED7B378   1     LR        gr23=gr22
    0| 00035C mtspr    7F6903A6   1     LCTR      ctr=gr27
    0| 000360 ori      60210000   1     XNOP      
    0|                              CL.536:
   64| 000364 stfdux   7FD745EE   1     STFDU     gr23,d(gr23,gr8,0)=fp30
   65| 000368 stfdux   7C384DEE   1     STFDU     gr24,e(gr24,gr9,0)=fp1
    0| 00036C bc       4200FFF8   1     BCT       ctr=CL.536,taken=100%(100,0)
   67| 000370 addi     394A0001   1     AI        gr10=gr10,1
    0| 000374 add      7ECCB214   1     A         gr22=gr12,gr22
   67| 000378 cmpld    7CAAE040   1     CL8       cr1=gr10,gr28
    0| 00037C add      7EB5EA14   1     A         gr21=gr21,gr29
   67| 000380 bc       4184FFD4   1     BT        CL.123,cr1,0x8/llt,taken=80%(80,20)
   67|                              CL.126:
   68| 000384 addi     38E70001   1     AI        gr7=gr7,1
    0| 000388 add      7F4BD214   1     A         gr26=gr11,gr26
   68| 00038C cmpd     7CA53800   1     C8        cr1=gr5,gr7
    0| 000390 add      7F39F214   1     A         gr25=gr25,gr30
   68| 000394 bc       4185FFAC   1     BT        CL.122,cr1,0x2/gt,taken=80%(80,20)
   68|                              CL.127:
   61| 000398 cmpd     7CA02800   1     C8        cr1=gr0,gr5
   61| 00039C crand    4C392A02   1     CR_N      cr0=cr[61],0x2/gt,0x2/gt,0x2/gt,cr0
   61| 0003A0 bc       40810238   1     BF        CL.59,cr0,0x2/gt,taken=50%(0,0)
   61| 0003A4 std      FBE101E0   1     ST8       #SPILL3(gr1,480)=gr31
   64| 0003A8 ld       EB620000   1     L8        gr27=.&&N&field(gr2,0)
   62| 0003AC lwa      E943000A   1     L4A       gr10=<s232:d8:l4>(gr3,8)
   63| 0003B0 lwa      E9230002   1     L4A       gr9=<s232:d0:l4>(gr3,0)
   62| 0003B4 lwa      E983000E   1     L4A       gr12=<s232:d12:l4>(gr3,12)
   68| 0003B8 addi     3904FFFF   1     AI        gr8=gr4,-1
   63| 0003BC lwa      E9630006   1     L4A       gr11=<s232:d4:l4>(gr3,4)
   64| 0003C0 ld       E8FB0030   1     L8        gr7=<s22:d48:l8>(gr27,48)
   64| 0003C4 ld       E81B0048   1     L8        gr0=<s22:d72:l8>(gr27,72)
   65| 0003C8 ld       EBBB00B0   1     L8        gr29=<s22:d176:l8>(gr27,176)
   64| 0003CC ld       E87B0060   1     L8        gr3=<s22:d96:l8>(gr27,96)
   65| 0003D0 ld       EBDB0098   1     L8        gr30=<s22:d152:l8>(gr27,152)
   65| 0003D4 ld       E89B00C8   1     L8        gr4=<s22:d200:l8>(gr27,200)
   65| 0003D8 ld       EA9B0068   1     L8        gr20=<s22:d104:l8>(gr27,104)
   65| 0003DC ld       EAFB0080   1     L8        gr23=<s22:d128:l8>(gr27,128)
   64| 0003E0 ld       EB9B0000   1     L8        gr28=<s22:d0:l8>(gr27,0)
    0| 0003E4 mulld    7EC639D2   1     M         gr22=gr6,gr7
    0| 0003E8 mulld    7EA051D2   1     M         gr21=gr0,gr10
    0| 0003EC mulld    7F2AE9D2   1     M         gr25=gr10,gr29
   64| 0003F0 ld       EB7B0018   1     L8        gr27=<s22:d24:l8>(gr27,24)
    0| 0003F4 mulld    7F4449D2   1     M         gr26=gr4,gr9
    0| 0003F8 mulld    7CC6F1D2   1     M         gr6=gr6,gr30
    0| 0003FC mulld    7F0349D2   1     M         gr24=gr3,gr9
    0| 000400 subf     7E84A050   1     S         gr20=gr20,gr4
   62| 000404 subf     7D4A6050   1     S         gr10=gr12,gr10
    0| 000408 add      7D94BA14   1     A         gr12=gr20,gr23
    0| 00040C subf     7EE3E050   1     S         gr23=gr28,gr3
    0| 000410 add      7ED6AA14   1     A         gr22=gr22,gr21
   62| 000414 addic.   378A0001   1     AI_R      gr28,cr0=gr10,1,ca"
    0| 000418 mulld    7D45F1D2   1     M         gr10=gr5,gr30
    0| 00041C mulld    7CA539D2   1     M         gr5=gr5,gr7
    0| 000420 add      7D8CCA14   1     A         gr12=gr12,gr25
   65| 000424 ld       EB220000   1     L8        gr25=.&&N&&root(gr2,0)
    0| 000428 add      7CC6D214   1     A         gr6=gr6,gr26
    0| 00042C add      7F7BBA14   1     A         gr27=gr27,gr23
    0| 000430 add      7F56C214   1     A         gr26=gr22,gr24
   68| 000434 sradi    7D181674   1     SRA8CA    gr24,ca=gr8,2
    0| 000438 rldicr   7BD31764   1     SLL8      gr19=gr30,2
    0| 00043C add      7D866214   1     A         gr12=gr6,gr12
    0| 000440 std      FA6101D0   1     ST8       #SPILL1(gr1,464)=gr19
    0| 000444 rldicr   78F21764   1     SLL8      gr18=gr7,2
    0| 000448 add      7D1ADA14   1     A         gr8=gr26,gr27
    0| 00044C std      FA4101D8   1     ST8       #SPILL2(gr1,472)=gr18
   68| 000450 addze    7CD80194   1     ADDE      gr6,ca=gr24,0,ca
    0| 000454 add      7F6A6214   1     A         gr27=gr10,gr12
    0| 000458 subf     7F1E9850   1     S         gr24=gr19,gr30
    0| 00045C rldicr   7BCC0FA4   1     SLL8      gr12=gr30,1
    0| 000460 rldicr   78EA0FA4   1     SLL8      gr10=gr7,1
    0| 000464 add      7F454214   1     A         gr26=gr5,gr8
    0| 000468 subf     7D079050   1     S         gr8=gr18,gr7
    0| 00046C subf     7CA95850   1     S         gr5=gr11,gr9
   65| 000470 lfd      C81900E8   1     LFL       fp0=<s241:d232:l8>(gr25,232)
    0| 000474 bc       40810164   1     BF        CL.59,cr0,0x2/gt,taken=20%(20,80)
    0| 000478 subfic   21290001   1     SFI       gr9=1,gr9,ca"
    0| 00047C add      7EBBF214   1     A         gr21=gr27,gr30
    0| 000480 add      7F295A14   1     A         gr25=gr9,gr11
    0| 000484 std      FAA101E8   1     ST8       #SPILL4(gr1,488)=gr21
    0| 000488 add      7D78DA14   1     A         gr11=gr24,gr27
    0| 00048C add      7FCCDA14   1     A         gr30=gr12,gr27
    0| 000490 std      F96101F0   1     ST8       #SPILL5(gr1,496)=gr11
    0| 000494 std      FBC101F8   1     ST8       #SPILL6(gr1,504)=gr30
    0| 000498 add      7EC7D214   1     A         gr22=gr7,gr26
    0| 00049C addi     38E60001   1     AI        gr7=gr6,1
    0| 0004A0 add      7F0AD214   1     A         gr24=gr10,gr26
    0| 0004A4 std      F8E10200   1     ST8       #SPILL7(gr1,512)=gr7
    0| 0004A8 add      7EE8D214   1     A         gr23=gr8,gr26
    0| 0004AC addic.   34A50001   1     AI_R      gr5,cr0=gr5,1,ca"
   61|                              CL.60:
   62| 0004B0 or       7FE5FB78   1     LR        gr5=gr31
    0| 0004B4 bc       408100CC   1     BF        CL.61,cr0,0x2/gt,taken=20%(20,80)
    0| 0004B8 fdiv     FC3F0024   1     DFL       fp1=fp31,fp0,fcr
    0| 0004BC or       7F55D378   1     LR        gr21=gr26
    0| 0004C0 or       7EF4BB78   1     LR        gr20=gr23
    0| 0004C4 or       7ED3B378   1     LR        gr19=gr22
    0| 0004C8 or       7F12C378   1     LR        gr18=gr24
    0| 0004CC or       7F71DB78   1     LR        gr17=gr27
    0| 0004D0 ld       EA0101F0   1     L8        gr16=#SPILL5(gr1,496)
    0| 0004D4 ld       E9E101F8   1     L8        gr15=#SPILL6(gr1,504)
    0| 0004D8 ld       E9C101E8   1     L8        gr14=#SPILL4(gr1,488)
   62|                              CL.62:
   64| 0004DC or       7EA6AB78   1     LR        gr6=gr21
   65| 0004E0 or       7E278B78   1     LR        gr7=gr17
   64| 0004E4 stfdux   7FC61DEE   1     STFDU     gr6,d(gr6,gr3,0)=fp30
   65| 0004E8 or       7DC97378   1     LR        gr9=gr14
   65| 0004EC stfdux   7C2725EE   1     STFDU     gr7,e(gr7,gr4,0)=fp1
   65| 0004F0 or       7DEB7B78   1     LR        gr11=gr15
   65| 0004F4 stfdux   7C2925EE   1     STFDU     gr9,e(gr9,gr4,0)=fp1
    0| 0004F8 mtspr    7F2903A6   1     LCTR      ctr=gr25
   65| 0004FC stfdux   7C2B25EE   1     STFDU     gr11,e(gr11,gr4,0)=fp1
   64| 000500 or       7E689B78   1     LR        gr8=gr19
   64| 000504 or       7E4A9378   1     LR        gr10=gr18
   64| 000508 stfdux   7FC81DEE   1     STFDU     gr8,d(gr8,gr3,0)=fp30
   64| 00050C stfdux   7FCA1DEE   1     STFDU     gr10,d(gr10,gr3,0)=fp30
   64| 000510 or       7E8CA378   1     LR        gr12=gr20
   65| 000514 or       7E1E8378   1     LR        gr30=gr16
   64| 000518 stfdux   7FCC1DEE   1     STFDU     gr12,d(gr12,gr3,0)=fp30
    0| 00051C bc       42400034   1     BCF       ctr=CL.537,taken=0%(0,100)
    0| 000520 ori      60210000   1     XNOP      
    0| 000524 ori      60210000   1     XNOP      
    0| 000528 ori      60210000   1     XNOP      
    0|                              CL.538:
   64| 00052C stfdux   7FC61DEE   1     STFDU     gr6,d(gr6,gr3,0)=fp30
   64| 000530 stfdux   7FC81DEE   1     STFDU     gr8,d(gr8,gr3,0)=fp30
   64| 000534 stfdux   7FCA1DEE   1     STFDU     gr10,d(gr10,gr3,0)=fp30
   65| 000538 stfdux   7C3E25EE   1     STFDU     gr30,e(gr30,gr4,0)=fp1
   64| 00053C stfdux   7FCC1DEE   1     STFDU     gr12,d(gr12,gr3,0)=fp30
   65| 000540 stfdux   7C2725EE   1     STFDU     gr7,e(gr7,gr4,0)=fp1
   65| 000544 stfdux   7C2925EE   1     STFDU     gr9,e(gr9,gr4,0)=fp1
   65| 000548 stfdux   7C2B25EE   1     STFDU     gr11,e(gr11,gr4,0)=fp1
    0| 00054C bc       4200FFE0   1     BCT       ctr=CL.538,taken=100%(100,0)
    0|                              CL.537:
   67| 000550 addi     38A50001   1     AI        gr5=gr5,1
   65| 000554 stfdux   7C3E25EE   1     STFDU     gr30,e(gr30,gr4,0)=fp1
   67| 000558 cmpld    7CA5E040   1     CL8       cr1=gr5,gr28
    0| 00055C add      7EA0AA14   1     A         gr21=gr0,gr21
    0| 000560 add      7E80A214   1     A         gr20=gr0,gr20
    0| 000564 add      7E609A14   1     A         gr19=gr0,gr19
    0| 000568 add      7E409214   1     A         gr18=gr0,gr18
    0| 00056C add      7E31EA14   1     A         gr17=gr17,gr29
    0| 000570 add      7E10EA14   1     A         gr16=gr16,gr29
    0| 000574 add      7DEFEA14   1     A         gr15=gr15,gr29
    0| 000578 add      7DCEEA14   1     A         gr14=gr14,gr29
   67| 00057C bc       4184FF60   1     BT        CL.62,cr1,0x8/llt,taken=80%(80,20)
   67|                              CL.61:
   68| 000580 ld       E8A101E0   1     L8        gr5=#SPILL3(gr1,480)
    0| 000584 ld       E8C101D0   1     L8        gr6=#SPILL1(gr1,464)
    0| 000588 ld       E8E101E8   1     L8        gr7=#SPILL4(gr1,488)
   68| 00058C ld       E9010200   1     L8        gr8=#SPILL7(gr1,512)
    0| 000590 ld       E92101F0   1     L8        gr9=#SPILL5(gr1,496)
    0| 000594 ld       E94101F8   1     L8        gr10=#SPILL6(gr1,504)
    0| 000598 ld       E96101D8   1     L8        gr11=#SPILL2(gr1,472)
   68| 00059C addi     38A50001   1     AI        gr5=gr5,1
    0| 0005A0 add      7CE63A14   1     A         gr7=gr6,gr7
   68| 0005A4 std      F8A101E0   1     ST8       #SPILL3(gr1,480)=gr5
    0| 0005A8 std      F8E101E8   1     ST8       #SPILL4(gr1,488)=gr7
   68| 0005AC cmpld    7CA54040   1     CL8       cr1=gr5,gr8
    0| 0005B0 add      7D264A14   1     A         gr9=gr6,gr9
    0| 0005B4 add      7D465214   1     A         gr10=gr6,gr10
    0| 0005B8 std      F92101F0   1     ST8       #SPILL5(gr1,496)=gr9
    0| 0005BC std      F94101F8   1     ST8       #SPILL6(gr1,504)=gr10
    0| 0005C0 add      7F66DA14   1     A         gr27=gr6,gr27
    0| 0005C4 add      7F0BC214   1     A         gr24=gr11,gr24
    0| 0005C8 add      7EEBBA14   1     A         gr23=gr11,gr23
    0| 0005CC add      7ECBB214   1     A         gr22=gr11,gr22
    0| 0005D0 add      7F4BD214   1     A         gr26=gr11,gr26
   68| 0005D4 bc       4184FEDC   1     BT        CL.60,cr1,0x8/llt,taken=80%(80,20)
   68|                              CL.59:
   70| 0005D8 ld       E8820000   1     L8        gr4=.&&N&&param(gr2,0)
   70| 0005DC lwa      E8A4000A   1     L4A       gr5=<s245:d8:l4>(gr4,8)
   70| 0005E0 sradi    7CA01674   1     SRA8CA    gr0,ca=gr5,2
   70| 0005E4 cmpwi    2C850000   1     C4        cr1=gr5,0
   70| 0005E8 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
   70| 0005EC std      F8A10208   1     ST8       #SPILL8(gr1,520)=gr5
   70| 0005F0 rldicr   78061764   1     SLL8      gr6=gr0,2
   70| 0005F4 subf     7C662851   1     S_R       gr3,cr0=gr5,gr6
   70| 0005F8 std      F8C10210   1     ST8       #SPILL9(gr1,528)=gr6
   70| 0005FC crand    4C250A02   1     CR_N      cr0=cr[10],0x2/gt,0x2/gt,0x2/gt,cr0
   70| 000600 bc       40810150   1     BF        CL.103,cr0,0x2/gt,taken=50%(0,0)
   74| 000604 ld       E9020000   1     L8        gr8=.&&N&field(gr2,0)
   71| 000608 lwa      E8040006   1     L4A       gr0=<s245:d4:l4>(gr4,4)
   72| 00060C ld       EAE20000   1     L8        gr23=.&&N&&param(gr2,0)
   70| 000610 addi     38800000   1     LI        gr4=0
   74| 000614 ld       E92801A0   1     L8        gr9=<s22:d416:l8>(gr8,416)
   75| 000618 ld       E9480208   1     L8        gr10=<s22:d520:l8>(gr8,520)
   76| 00061C ld       E9680270   1     L8        gr11=<s22:d624:l8>(gr8,624)
   74| 000620 ld       EB4801B8   1     L8        gr26=<s22:d440:l8>(gr8,440)
   75| 000624 ld       EB080220   1     L8        gr24=<s22:d544:l8>(gr8,544)
   76| 000628 ld       EB280288   1     L8        gr25=<s22:d648:l8>(gr8,648)
   74| 00062C ld       EAC801D0   1     L8        gr22=<s22:d464:l8>(gr8,464)
   74| 000630 ld       EBC801E8   1     L8        gr30=<s22:d488:l8>(gr8,488)
   75| 000634 ld       EBA80250   1     L8        gr29=<s22:d592:l8>(gr8,592)
   76| 000638 ld       EB8802B8   1     L8        gr28=<s22:d696:l8>(gr8,696)
    0| 00063C cmpwi    2F000000   1     C4        cr6=gr0,0
   74| 000640 ld       E8A80200   1     L8        gr5=<s22:d512:l8>(gr8,512)
   75| 000644 ld       E8C80268   1     L8        gr6=<s22:d616:l8>(gr8,616)
   76| 000648 ld       E8E802D0   1     L8        gr7=<s22:d720:l8>(gr8,720)
   75| 00064C ld       E9C80238   1     L8        gr14=<s22:d568:l8>(gr8,568)
   72| 000650 lwa      E9970002   1     L4A       gr12=<s245:d0:l4>(gr23,0)
   74| 000654 std      FAC10218   1     ST8       #SPILL10(gr1,536)=gr22
   76| 000658 ld       EB6802A0   1     L8        gr27=<s22:d672:l8>(gr8,672)
    0| 00065C bc       40990A78   1     BF        CL.329,cr6,0x2/gt,taken=40%(40,60)
    0| 000660 add      7D0BCA14   1     A         gr8=gr11,gr25
    0| 000664 add      7D4AC214   1     A         gr10=gr10,gr24
    0| 000668 add      7D29D214   1     A         gr9=gr9,gr26
    0| 00066C ld       EA8101C8   1     L8        gr20=#SPILL0(gr1,456)
    0| 000670 ld       EA620000   1     L8        gr19=.+CONSTANT_AREA(gr2,0)
    0| 000674 add      7F28E214   1     A         gr25=gr8,gr28
    0| 000678 add      7D4AEA14   1     A         gr10=gr10,gr29
    0| 00067C add      7D09F214   1     A         gr8=gr9,gr30
    0| 000680 add      7F47CA14   1     A         gr26=gr7,gr25
    0| 000684 add      7D665214   1     A         gr11=gr6,gr10
    0| 000688 add      7D254214   1     A         gr9=gr5,gr8
    0| 00068C add      7EEA7214   1     A         gr23=gr10,gr14
    0| 000690 or       7ECAB378   1     LR        gr10=gr22
    0| 000694 add      7F5ADA14   1     A         gr26=gr26,gr27
    0| 000698 add      7F39DA14   1     A         gr25=gr25,gr27
    0| 00069C add      7F0B7214   1     A         gr24=gr11,gr14
    0| 0006A0 add      7ED64A14   1     A         gr22=gr22,gr9
    0| 0006A4 add      7EA85214   1     A         gr21=gr8,gr10
    0| 0006A8 cmpdi    2C2C0000   1     C8        cr0=gr12,0
    0| 0006AC cmpwi    2F140001   1     C4        cr6=gr20,1
    0| 0006B0 cmpwi    2E940002   1     C4        cr5=gr20,2
    0| 0006B4 lfs      C0130034   1     LFS       fp0=+CONSTANT_AREA(gr19,52)
    0| 0006B8 ori      60210000   1     XNOP      
    0| 0006BC ori      60210000   1     XNOP      
   70|                              CL.94:
   71| 0006C0 or       7FE8FB78   1     LR        gr8=gr31
    0| 0006C4 bc       40810064   1     BF        CL.102,cr0,0x2/gt,taken=50%(0,0)
    0| 0006C8 or       7EB4AB78   1     LR        gr20=gr21
    0| 0006CC or       7ED3B378   1     LR        gr19=gr22
    0| 0006D0 or       7EF2BB78   1     LR        gr18=gr23
    0| 0006D4 or       7F11C378   1     LR        gr17=gr24
    0| 0006D8 or       7F30CB78   1     LR        gr16=gr25
    0| 0006DC or       7F4FD378   1     LR        gr15=gr26
   71|                              CL.95:
    0| 0006E0 addi     39080001   1     AI        gr8=gr8,1
    0| 0006E4 bc       409A09A0   1     BF        CL.325,cr6,0x4/eq,taken=50%(0,0)
   76| 0006E8 or       7E098378   1     LR        gr9=gr16
   75| 0006EC or       7E4A9378   1     LR        gr10=gr18
   74| 0006F0 or       7E8BA378   1     LR        gr11=gr20
    0| 0006F4 mtspr    7D8903A6   1     LCTR      ctr=gr12
    0|                              CL.539:
   74| 0006F8 stfdux   7FAB2DEE   1     STFDU     gr11,v1(gr11,gr5,0)=fp29
   75| 0006FC stfdux   7C0A35EE   1     STFDU     gr10,v2(gr10,gr6,0)=fp0
   76| 000700 stfdux   7C093DEE   1     STFDU     gr9,v3(gr9,gr7,0)=fp0
    0| 000704 bc       4200FFF4   1     BCT       ctr=CL.539,taken=100%(100,0)
   86|                              CL.101:
   87| 000708 cmpld    7FA80040   1     CL8       cr7=gr8,gr0
    0| 00070C add      7E94F214   1     A         gr20=gr20,gr30
    0| 000710 add      7E73F214   1     A         gr19=gr19,gr30
    0| 000714 add      7E52EA14   1     A         gr18=gr18,gr29
    0| 000718 add      7E31EA14   1     A         gr17=gr17,gr29
    0| 00071C add      7E10E214   1     A         gr16=gr16,gr28
    0| 000720 add      7DEFE214   1     A         gr15=gr15,gr28
   87| 000724 bc       419CFFBC   1     BT        CL.95,cr7,0x8/llt,taken=80%(80,20)
   87|                              CL.102:
    0| 000728 ld       E9010218   1     L8        gr8=#SPILL10(gr1,536)
   88| 00072C addi     38840001   1     AI        gr4=gr4,1
    0| 000730 add      7EEEBA14   1     A         gr23=gr14,gr23
   88| 000734 cmpd     7FA32000   1     C8        cr7=gr3,gr4
    0| 000738 add      7F0EC214   1     A         gr24=gr14,gr24
    0| 00073C add      7F39DA14   1     A         gr25=gr25,gr27
    0| 000740 add      7EA8AA14   1     A         gr21=gr8,gr21
    0| 000744 add      7EC8B214   1     A         gr22=gr8,gr22
    0| 000748 add      7F5ADA14   1     A         gr26=gr26,gr27
   88| 00074C bc       419DFF74   1     BT        CL.94,cr7,0x2/gt,taken=80%(80,20)
   88|                              CL.103:
   70| 000750 ld       E8810208   1     L8        gr4=#SPILL8(gr1,520)
   88| 000754 ld       E8A10210   1     L8        gr5=#SPILL9(gr1,528)
   70| 000758 cmpd     7F241800   1     C8        cr6=gr4,gr3
   88| 00075C addi     3805FFFF   1     AI        gr0=gr5,-1
   70| 000760 crand    4C25CA02   1     CR_N      cr0=cr[16],0x2/gt,0x2/gt,0x2/gt,cr0
   70| 000764 bc       40810378   1     BF        CL.65,cr0,0x2/gt,taken=20%(20,80)
   70| 000768 std      FBE10230   1     ST8       #SPILL13(gr1,560)=gr31
   74| 00076C ld       EBA20000   1     L8        gr29=.&&N&field(gr2,0)
   88| 000770 sradi    7C001674   1     SRA8CA    gr0,ca=gr0,2
   71| 000774 ld       EB820000   1     L8        gr28=.&&N&&param(gr2,0)
   88| 000778 addze    7C800194   1     ADDE      gr4,ca=gr0,0,ca
   75| 00077C ld       E93D0238   1     L8        gr9=<s22:d568:l8>(gr29,568)
   76| 000780 ld       E99D02A0   1     L8        gr12=<s22:d672:l8>(gr29,672)
   75| 000784 ld       E91D0208   1     L8        gr8=<s22:d520:l8>(gr29,520)
   76| 000788 ld       E97D0270   1     L8        gr11=<s22:d624:l8>(gr29,624)
   75| 00078C ld       E95D0220   1     L8        gr10=<s22:d544:l8>(gr29,544)
   76| 000790 ld       EBDD0288   1     L8        gr30=<s22:d648:l8>(gr29,648)
   74| 000794 ld       E8BD01D0   1     L8        gr5=<s22:d464:l8>(gr29,464)
   74| 000798 ld       E8DD01A0   1     L8        gr6=<s22:d416:l8>(gr29,416)
   74| 00079C ld       E8FD01B8   1     L8        gr7=<s22:d440:l8>(gr29,440)
   75| 0007A0 ld       EADD0250   1     L8        gr22=<s22:d592:l8>(gr29,592)
   76| 0007A4 ld       EABD02B8   1     L8        gr21=<s22:d696:l8>(gr29,696)
   75| 0007A8 ld       EB7D0268   1     L8        gr27=<s22:d616:l8>(gr29,616)
   76| 0007AC ld       EB5D02D0   1     L8        gr26=<s22:d720:l8>(gr29,720)
   74| 0007B0 ld       EAFD01E8   1     L8        gr23=<s22:d488:l8>(gr29,488)
    0| 0007B4 add      7D6BF214   1     A         gr11=gr11,gr30
   75| 0007B8 std      FAC10240   1     ST8       #SPILL15(gr1,576)=gr22
   76| 0007BC std      FAA10248   1     ST8       #SPILL16(gr1,584)=gr21
    0| 0007C0 add      7D085214   1     A         gr8=gr8,gr10
    0| 0007C4 add      7CC63A14   1     A         gr6=gr6,gr7
   74| 0007C8 std      FAE10238   1     ST8       #SPILL14(gr1,568)=gr23
    0| 0007CC mulld    7D4361D2   1     M         gr10=gr3,gr12
    0| 0007D0 mulld    7CE349D2   1     M         gr7=gr3,gr9
   74| 0007D4 ld       E81D0200   1     L8        gr0=<s22:d512:l8>(gr29,512)
    0| 0007D8 add      7D6BAA14   1     A         gr11=gr11,gr21
    0| 0007DC add      7D08B214   1     A         gr8=gr8,gr22
    0| 0007E0 mulld    7C6329D2   1     M         gr3=gr3,gr5
    0| 0007E4 rldicr   79941764   1     SLL8      gr20=gr12,2
    0| 0007E8 add      7D6BD214   1     A         gr11=gr11,gr26
    0| 0007EC std      FA810250   1     ST8       #SPILL17(gr1,592)=gr20
    0| 0007F0 rldicr   79331764   1     SLL8      gr19=gr9,2
    0| 0007F4 add      7D08DA14   1     A         gr8=gr8,gr27
    0| 0007F8 std      FA610258   1     ST8       #SPILL18(gr1,600)=gr19
    0| 0007FC add      7CC6BA14   1     A         gr6=gr6,gr23
   71| 000800 lwa      EB3C0006   1     L4A       gr25=<s245:d4:l4>(gr28,4)
   72| 000804 lwa      EB1C0002   1     L4A       gr24=<s245:d0:l4>(gr28,0)
    0| 000808 subf     7F8CA050   1     S         gr28=gr20,gr12
    0| 00080C add      7FCA5A14   1     A         gr30=gr10,gr11
    0| 000810 add      7D074214   1     A         gr8=gr7,gr8
    0| 000814 subf     7D499850   1     S         gr10=gr19,gr9
   71| 000818 std      FB210220   1     ST8       #SPILL11(gr1,544)=gr25
   72| 00081C std      FB010228   1     ST8       #SPILL12(gr1,552)=gr24
    0| 000820 rldicr   78B21764   1     SLL8      gr18=gr5,2
    0| 000824 add      7CC60214   1     A         gr6=gr6,gr0
    0| 000828 std      FA410260   1     ST8       #SPILL19(gr1,608)=gr18
    0| 00082C rldicr   792B0FA4   1     SLL8      gr11=gr9,1
    0| 000830 add      7E3CF214   1     A         gr17=gr28,gr30
    0| 000834 add      7F884A14   1     A         gr28=gr8,gr9
    0| 000838 std      FA210268   1     ST8       #SPILL20(gr1,616)=gr17
    0| 00083C std      FB810290   1     ST8       #SPILL25(gr1,656)=gr28
    0| 000840 add      7D285214   1     A         gr9=gr8,gr10
    0| 000844 addi     39440001   1     AI        gr10=gr4,1
    0| 000848 std      F9210298   1     ST8       #SPILL26(gr1,664)=gr9
    0| 00084C std      F94102C8   1     ST8       #SPILL32(gr1,712)=gr10
    0| 000850 ld       E88101C8   1     L8        gr4=#SPILL0(gr1,456)
    0| 000854 rldicr   799D0FA4   1     SLL8      gr29=gr12,1
    0| 000858 rldicr   78A70FA4   1     SLL8      gr7=gr5,1
    0| 00085C add      7C633214   1     A         gr3=gr3,gr6
    0| 000860 subf     7CC59050   1     S         gr6=gr18,gr5
    0| 000864 add      7E1DF214   1     A         gr16=gr29,gr30
    0| 000868 add      7DECF214   1     A         gr15=gr12,gr30
    0| 00086C std      FA010270   1     ST8       #SPILL21(gr1,624)=gr16
    0| 000870 std      F9E10278   1     ST8       #SPILL22(gr1,632)=gr15
    0| 000874 add      7DD4F214   1     A         gr14=gr20,gr30
    0| 000878 add      7D885A14   1     A         gr12=gr8,gr11
    0| 00087C std      F9C10280   1     ST8       #SPILL23(gr1,640)=gr14
    0| 000880 std      F9810288   1     ST8       #SPILL24(gr1,648)=gr12
    0| 000884 add      7FC89A14   1     A         gr30=gr8,gr19
    0| 000888 add      7FA33A14   1     A         gr29=gr3,gr7
    0| 00088C std      FBC102A0   1     ST8       #SPILL27(gr1,672)=gr30
    0| 000890 std      FBA102A8   1     ST8       #SPILL28(gr1,680)=gr29
    0| 000894 add      7D632A14   1     A         gr11=gr3,gr5
    0| 000898 add      7CA33214   1     A         gr5=gr3,gr6
    0| 00089C std      F96102B0   1     ST8       #SPILL29(gr1,688)=gr11
    0| 0008A0 add      7D039214   1     A         gr8=gr3,gr18
    0| 0008A4 std      F8A102B8   1     ST8       #SPILL30(gr1,696)=gr5
    0| 0008A8 std      F90102C0   1     ST8       #SPILL31(gr1,704)=gr8
    0| 0008AC cmpwi    2C190000   1     C4        cr0=gr25,0
    0| 0008B0 cmpdi    2F380000   1     C8        cr6=gr24,0
    0| 0008B4 cmpwi    2F840001   1     C4        cr7=gr4,1
    0| 0008B8 cmpwi    2E040002   1     C4        cr4=gr4,2
   70|                              CL.66:
   71| 0008BC bc       4081016C   1     BF        CL.67,cr0,0x2/gt,taken=20%(20,80)
   71| 0008C0 or       7FE3FB78   1     LR        gr3=gr31
    0| 0008C4 ld       EB2102A8   1     L8        gr25=#SPILL28(gr1,680)
    0| 0008C8 ld       EB0102B0   1     L8        gr24=#SPILL29(gr1,688)
    0| 0008CC ld       EAE102C0   1     L8        gr23=#SPILL31(gr1,704)
    0| 0008D0 ld       EAC102B8   1     L8        gr22=#SPILL30(gr1,696)
    0| 0008D4 ld       EAA10288   1     L8        gr21=#SPILL24(gr1,648)
    0| 0008D8 ld       EA810290   1     L8        gr20=#SPILL25(gr1,656)
    0| 0008DC ld       EA6102A0   1     L8        gr19=#SPILL27(gr1,672)
    0| 0008E0 ld       EA410298   1     L8        gr18=#SPILL26(gr1,664)
    0| 0008E4 ld       EA210270   1     L8        gr17=#SPILL21(gr1,624)
    0| 0008E8 ld       EA010278   1     L8        gr16=#SPILL22(gr1,632)
    0| 0008EC ld       E9E10280   1     L8        gr15=#SPILL23(gr1,640)
    0| 0008F0 ld       E9C10268   1     L8        gr14=#SPILL20(gr1,616)
   71|                              CL.68:
    0| 0008F4 addi     38630001   1     AI        gr3=gr3,1
   72| 0008F8 bc       409900E8   1     BF        CL.69,cr6,0x2/gt,taken=20%(20,80)
    0| 0008FC std      F80102D0   1     ST8       #SPILL33(gr1,720)=gr0
    0| 000900 ld       E8010228   1     L8        gr0=#SPILL12(gr1,552)
    0| 000904 or       7E048378   1     LR        gr4=gr16
    0| 000908 or       7DE57B78   1     LR        gr5=gr15
    0| 00090C or       7DC67378   1     LR        gr6=gr14
    0| 000910 or       7E278B78   1     LR        gr7=gr17
    0| 000914 or       7E88A378   1     LR        gr8=gr20
    0| 000918 or       7E699B78   1     LR        gr9=gr19
    0| 00091C or       7E4A9378   1     LR        gr10=gr18
    0| 000920 or       7EABAB78   1     LR        gr11=gr21
    0| 000924 or       7F0CC378   1     LR        gr12=gr24
    0| 000928 or       7EFEBB78   1     LR        gr30=gr23
    0| 00092C or       7EDDB378   1     LR        gr29=gr22
    0| 000930 or       7F3CCB78   1     LR        gr28=gr25
    0| 000934 mtspr    7C0903A6   1     LCTR      ctr=gr0
    0| 000938 ld       E80102D0   1     L8        gr0=#SPILL33(gr1,720)
    0| 00093C ori      60210000   1     XNOP      
   72|                              CL.70:
   73| 000940 bc       409E0038   1     BF        CL.18,cr7,0x4/eq,taken=50%(0,0)
   74| 000944 stfd     DBAC0000   1     STFL      v1(gr12,0)=fp29
   75| 000948 std      FBE80000   1     ST8       v2(gr8,0)=gr31
   76| 00094C std      FBE40000   1     ST8       v3(gr4,0)=gr31
   74| 000950 stfd     DBBC0000   1     STFL      v1(gr28,0)=fp29
   75| 000954 std      FBEB0000   1     ST8       v2(gr11,0)=gr31
   76| 000958 std      FBE70000   1     ST8       v3(gr7,0)=gr31
   74| 00095C stfd     DBBD0000   1     STFL      v1(gr29,0)=fp29
   75| 000960 std      FBEA0000   1     ST8       v2(gr10,0)=gr31
   76| 000964 std      FBE60000   1     ST8       v3(gr6,0)=gr31
   74| 000968 stfd     DBBE0000   1     STFL      v1(gr30,0)=fp29
   75| 00096C std      FBE90000   1     ST8       v2(gr9,0)=gr31
   76| 000970 std      FBE50000   1     ST8       v3(gr5,0)=gr31
   81| 000974 b        48000038   1     B         CL.114,-1
   77|                              CL.18:
   77| 000978 bc       409206D8   1     BF        CL.20,cr4,0x4/eq,taken=50%(0,0)
   78| 00097C stfd     DBA80000   1     STFL      v2(gr8,0)=fp29
   79| 000980 std      FBEC0000   1     ST8       v1(gr12,0)=gr31
   80| 000984 std      FBE40000   1     ST8       v3(gr4,0)=gr31
   78| 000988 stfd     DBAB0000   1     STFL      v2(gr11,0)=fp29
   79| 00098C std      FBFC0000   1     ST8       v1(gr28,0)=gr31
   80| 000990 std      FBE70000   1     ST8       v3(gr7,0)=gr31
   78| 000994 stfd     DBAA0000   1     STFL      v2(gr10,0)=fp29
   79| 000998 std      FBFD0000   1     ST8       v1(gr29,0)=gr31
   80| 00099C std      FBE60000   1     ST8       v3(gr6,0)=gr31
   78| 0009A0 stfd     DBA90000   1     STFL      v2(gr9,0)=fp29
   79| 0009A4 std      FBFE0000   1     ST8       v1(gr30,0)=gr31
   80| 0009A8 std      FBE50000   1     ST8       v3(gr5,0)=gr31
   85|                              CL.114:
    0| 0009AC add      7C84D214   1     A         gr4=gr4,gr26
    0| 0009B0 add      7CA5D214   1     A         gr5=gr5,gr26
    0| 0009B4 add      7CC6D214   1     A         gr6=gr6,gr26
    0| 0009B8 add      7CE7D214   1     A         gr7=gr7,gr26
    0| 0009BC add      7D08DA14   1     A         gr8=gr8,gr27
    0| 0009C0 add      7D29DA14   1     A         gr9=gr9,gr27
    0| 0009C4 add      7D4ADA14   1     A         gr10=gr10,gr27
    0| 0009C8 add      7D6BDA14   1     A         gr11=gr11,gr27
    0| 0009CC add      7D806214   1     A         gr12=gr0,gr12
    0| 0009D0 add      7FC0F214   1     A         gr30=gr0,gr30
    0| 0009D4 add      7FA0EA14   1     A         gr29=gr0,gr29
    0| 0009D8 add      7F80E214   1     A         gr28=gr0,gr28
    0| 0009DC bc       4200FF64   1     BCT       ctr=CL.70,taken=100%(100,0)
   86|                              CL.69:
   87| 0009E0 ld       E8810220   1     L8        gr4=#SPILL11(gr1,544)
    0| 0009E4 ld       E8A10238   1     L8        gr5=#SPILL14(gr1,568)
    0| 0009E8 ld       E8C10240   1     L8        gr6=#SPILL15(gr1,576)
    0| 0009EC ld       E8E10248   1     L8        gr7=#SPILL16(gr1,584)
   87| 0009F0 cmpld    7EA32040   1     CL8       cr5=gr3,gr4
    0| 0009F4 add      7F25CA14   1     A         gr25=gr5,gr25
    0| 0009F8 add      7F05C214   1     A         gr24=gr5,gr24
    0| 0009FC add      7EE5BA14   1     A         gr23=gr5,gr23
    0| 000A00 add      7EC5B214   1     A         gr22=gr5,gr22
    0| 000A04 add      7EA6AA14   1     A         gr21=gr6,gr21
    0| 000A08 add      7E86A214   1     A         gr20=gr6,gr20
    0| 000A0C add      7E669A14   1     A         gr19=gr6,gr19
    0| 000A10 add      7E469214   1     A         gr18=gr6,gr18
    0| 000A14 add      7E278A14   1     A         gr17=gr7,gr17
    0| 000A18 add      7E078214   1     A         gr16=gr7,gr16
    0| 000A1C add      7DE77A14   1     A         gr15=gr7,gr15
    0| 000A20 add      7DC77214   1     A         gr14=gr7,gr14
   87| 000A24 bc       4194FED0   1     BT        CL.68,cr5,0x8/llt,taken=80%(80,20)
   87|                              CL.67:
   88| 000A28 ld       E8610230   1     L8        gr3=#SPILL13(gr1,560)
    0| 000A2C ld       E8810250   1     L8        gr4=#SPILL17(gr1,592)
    0| 000A30 ld       E8A10268   1     L8        gr5=#SPILL20(gr1,616)
   88| 000A34 ld       E8C102C8   1     L8        gr6=#SPILL32(gr1,712)
    0| 000A38 ld       E8E10270   1     L8        gr7=#SPILL21(gr1,624)
    0| 000A3C ld       E9010278   1     L8        gr8=#SPILL22(gr1,632)
    0| 000A40 ld       E9210280   1     L8        gr9=#SPILL23(gr1,640)
    0| 000A44 ld       E9410258   1     L8        gr10=#SPILL18(gr1,600)
    0| 000A48 ld       E9610288   1     L8        gr11=#SPILL24(gr1,648)
    0| 000A4C ld       E9810290   1     L8        gr12=#SPILL25(gr1,656)
    0| 000A50 ld       EBC10298   1     L8        gr30=#SPILL26(gr1,664)
    0| 000A54 ld       EBA102A0   1     L8        gr29=#SPILL27(gr1,672)
    0| 000A58 ld       EB810260   1     L8        gr28=#SPILL19(gr1,608)
    0| 000A5C ld       EB2102A8   1     L8        gr25=#SPILL28(gr1,680)
    0| 000A60 ld       EB0102B0   1     L8        gr24=#SPILL29(gr1,688)
    0| 000A64 ld       EAE102B8   1     L8        gr23=#SPILL30(gr1,696)
    0| 000A68 ld       EAC102C0   1     L8        gr22=#SPILL31(gr1,704)
   88| 000A6C addi     38630001   1     AI        gr3=gr3,1
    0| 000A70 add      7CA42A14   1     A         gr5=gr4,gr5
   88| 000A74 std      F8610230   1     ST8       #SPILL13(gr1,560)=gr3
    0| 000A78 std      F8A10268   1     ST8       #SPILL20(gr1,616)=gr5
   88| 000A7C cmpld    7EA33040   1     CL8       cr5=gr3,gr6
    0| 000A80 add      7CE43A14   1     A         gr7=gr4,gr7
    0| 000A84 add      7D044214   1     A         gr8=gr4,gr8
    0| 000A88 std      F8E10270   1     ST8       #SPILL21(gr1,624)=gr7
    0| 000A8C std      F9010278   1     ST8       #SPILL22(gr1,632)=gr8
    0| 000A90 add      7D244A14   1     A         gr9=gr4,gr9
    0| 000A94 add      7D6A5A14   1     A         gr11=gr10,gr11
    0| 000A98 std      F9210280   1     ST8       #SPILL23(gr1,640)=gr9
    0| 000A9C std      F9610288   1     ST8       #SPILL24(gr1,648)=gr11
    0| 000AA0 add      7D8A6214   1     A         gr12=gr10,gr12
    0| 000AA4 add      7FCAF214   1     A         gr30=gr10,gr30
    0| 000AA8 std      F9810290   1     ST8       #SPILL25(gr1,656)=gr12
    0| 000AAC std      FBC10298   1     ST8       #SPILL26(gr1,664)=gr30
    0| 000AB0 add      7FAAEA14   1     A         gr29=gr10,gr29
    0| 000AB4 add      7F39E214   1     A         gr25=gr25,gr28
    0| 000AB8 std      FBA102A0   1     ST8       #SPILL27(gr1,672)=gr29
    0| 000ABC std      FB2102A8   1     ST8       #SPILL28(gr1,680)=gr25
    0| 000AC0 add      7F18E214   1     A         gr24=gr24,gr28
    0| 000AC4 add      7EF7E214   1     A         gr23=gr23,gr28
    0| 000AC8 std      FB0102B0   1     ST8       #SPILL29(gr1,688)=gr24
    0| 000ACC std      FAE102B8   1     ST8       #SPILL30(gr1,696)=gr23
    0| 000AD0 add      7ED6E214   1     A         gr22=gr22,gr28
    0| 000AD4 std      FAC102C0   1     ST8       #SPILL31(gr1,704)=gr22
   88| 000AD8 bc       4194FDE4   1     BT        CL.66,cr5,0x8/llt,taken=80%(80,20)
   88|                              CL.65:
   90| 000ADC ld       E80101C8   1     L8        gr0=#SPILL0(gr1,456)
   90| 000AE0 cmpwi    2C000001   1     C4        cr0=gr0,1
   90| 000AE4 bc       40820220   1     BF        CL.31,cr0,0x4/eq,taken=50%(0,0)
   91| 000AE8 bc       408501B0   1     BF        CL.128,cr1,0x2/gt,taken=30%(30,70)
  101| 000AEC ld       E8620000   1     L8        gr3=.&&N&&root(gr2,0)
   99| 000AF0 ld       E8E20000   1     L8        gr7=.&&N&bndry(gr2,0)
   92| 000AF4 ld       EA820000   1     L8        gr20=.&&N&&param(gr2,0)
  101| 000AF8 lfd      C80300E8   1     LFL       fp0=<s241:d232:l8>(gr3,232)
  101| 000AFC ld       E8670C38   1     L8        gr3=<s69:d3128:l8>(gr7,3128)
   93| 000B00 ld       E9070EA8   1     L8        gr8=<s69:d3752:l8>(gr7,3752)
   93| 000B04 ld       EB870EC0   1     L8        gr28=<s69:d3776:l8>(gr7,3776)
  101| 000B08 ld       E9270C50   1     L8        gr9=<s69:d3152:l8>(gr7,3152)
   92| 000B0C lwa      EA540006   1     L4A       gr18=<s245:d4:l4>(gr20,4)
   99| 000B10 ld       E88709C8   1     L8        gr4=<s69:d2504:l8>(gr7,2504)
   95| 000B14 ld       E8C71118   1     L8        gr6=<s69:d4376:l8>(gr7,4376)
   97| 000B18 ld       E8A71388   1     L8        gr5=<s69:d5000:l8>(gr7,5000)
   95| 000B1C ld       EBA71130   1     L8        gr29=<s69:d4400:l8>(gr7,4400)
   97| 000B20 ld       E98713A0   1     L8        gr12=<s69:d5024:l8>(gr7,5024)
   92| 000B24 std      FA4102D8   1     ST8       #SPILL34(gr1,728)=gr18
   99| 000B28 ld       E96709E0   1     L8        gr11=<s69:d2528:l8>(gr7,2528)
  101| 000B2C ld       E9470C68   1     L8        gr10=<s69:d3176:l8>(gr7,3176)
  101| 000B30 ld       EA070C80   1     L8        gr16=<s69:d3200:l8>(gr7,3200)
   93| 000B34 ld       E8070EF0   1     L8        gr0=<s69:d3824:l8>(gr7,3824)
   99| 000B38 ld       EBC709F8   1     L8        gr30=<s69:d2552:l8>(gr7,2552)
   99| 000B3C ld       EA270A10   1     L8        gr17=<s69:d2576:l8>(gr7,2576)
   93| 000B40 ld       EAE70ED8   1     L8        gr23=<s69:d3800:l8>(gr7,3800)
   95| 000B44 ld       EAA71148   1     L8        gr21=<s69:d4424:l8>(gr7,4424)
   95| 000B48 ld       EB271160   1     L8        gr25=<s69:d4448:l8>(gr7,4448)
   97| 000B4C ld       EB6713B8   1     L8        gr27=<s69:d5048:l8>(gr7,5048)
   97| 000B50 ld       EB0713D0   1     L8        gr24=<s69:d5072:l8>(gr7,5072)
    0| 000B54 add      7D08E214   1     A         gr8=gr8,gr28
    0| 000B58 add      7C634A14   1     A         gr3=gr3,gr9
    0| 000B5C add      7CC6EA14   1     A         gr6=gr6,gr29
    0| 000B60 add      7CA56214   1     A         gr5=gr5,gr12
   99| 000B64 std      FA2102E0   1     ST8       #SPILL35(gr1,736)=gr17
    0| 000B68 add      7C845A14   1     A         gr4=gr4,gr11
    0| 000B6C cmpwi    2C120000   1     C4        cr0=gr18,0
    0| 000B70 add      7EC04214   1     A         gr22=gr0,gr8
    0| 000B74 add      7D038214   1     A         gr8=gr3,gr16
    0| 000B78 rldicr   79490FA4   1     SLL8      gr9=gr10,1
  101| 000B7C std      FA0102E8   1     ST8       #SPILL36(gr1,744)=gr16
    0| 000B80 rldicr   7AF30FA4   1     SLL8      gr19=gr23,1
    0| 000B84 add      7F46CA14   1     A         gr26=gr6,gr25
    0| 000B88 rldicr   7AB40FA4   1     SLL8      gr20=gr21,1
    0| 000B8C add      7FA5C214   1     A         gr29=gr5,gr24
    0| 000B90 rldicr   7B7C0FA4   1     SLL8      gr28=gr27,1
    0| 000B94 add      7D648A14   1     A         gr11=gr4,gr17
    0| 000B98 rldicr   7BCC0FA4   1     SLL8      gr12=gr30,1
   99| 000B9C ld       E8670A28   1     L8        gr3=<s69:d2600:l8>(gr7,2600)
  101| 000BA0 ld       E8870C98   1     L8        gr4=<s69:d3224:l8>(gr7,3224)
   93| 000BA4 ld       E8A70F08   1     L8        gr5=<s69:d3848:l8>(gr7,3848)
   95| 000BA8 ld       E8C71178   1     L8        gr6=<s69:d4472:l8>(gr7,4472)
   97| 000BAC ld       E8E713E8   1     L8        gr7=<s69:d5096:l8>(gr7,5096)
    0| 000BB0 bc       408100E8   1     BF        CL.128,cr0,0x2/gt,taken=20%(20,80)
    0| 000BB4 fdiv     FC1F0024   1     DFL       fp0=fp31,fp0,fcr
    0| 000BB8 std      F80102F0   1     ST8       #SPILL37(gr1,752)=gr0
    0| 000BBC add      7DE85214   1     A         gr15=gr8,gr10
    0| 000BC0 add      7DC84A14   1     A         gr14=gr8,gr9
    0| 000BC4 ld       E9020000   1     L8        gr8=.+CONSTANT_AREA(gr2,0)
    0| 000BC8 add      7EF7B214   1     A         gr23=gr23,gr22
    0| 000BCC add      7ED69A14   1     A         gr22=gr22,gr19
    0| 000BD0 add      7EB5D214   1     A         gr21=gr21,gr26
    0| 000BD4 add      7E94D214   1     A         gr20=gr20,gr26
    0| 000BD8 add      7E7BEA14   1     A         gr19=gr27,gr29
    0| 000BDC add      7E5CEA14   1     A         gr18=gr28,gr29
    0| 000BE0 add      7E2BF214   1     A         gr17=gr11,gr30
    0| 000BE4 add      7E0B6214   1     A         gr16=gr11,gr12
    0| 000BE8 lfs      C0280034   1     LFS       fp1=+CONSTANT_AREA(gr8,52)
   91|                              CL.72:
    0| 000BEC ld       E80102D8   1     L8        gr0=#SPILL34(gr1,728)
    0| 000BF0 addi     3BFF0001   1     AI        gr31=gr31,1
  102| 000BF4 or       7DC87378   1     LR        gr8=gr14
  101| 000BF8 or       7DE97B78   1     LR        gr9=gr15
  100| 000BFC or       7E0A8378   1     LR        gr10=gr16
   99| 000C00 or       7E2B8B78   1     LR        gr11=gr17
   98| 000C04 or       7E4C9378   1     LR        gr12=gr18
   97| 000C08 or       7E7E9B78   1     LR        gr30=gr19
   96| 000C0C or       7E9DA378   1     LR        gr29=gr20
   95| 000C10 or       7EBCAB78   1     LR        gr28=gr21
   94| 000C14 or       7EDBB378   1     LR        gr27=gr22
   93| 000C18 or       7EFABB78   1     LR        gr26=gr23
    0| 000C1C mtspr    7C0903A6   1     LCTR      ctr=gr0
    0| 000C20 ori      60210000   1     XNOP      
    0|                              CL.540:
   93| 000C24 stfdux   7FBA2DEE   1     STFDU     gr26,v1oib(gr26,gr5,0)=fp29
   94| 000C28 stfdux   7FBB2DEE   1     STFDU     gr27,v1oib(gr27,gr5,0)=fp29
   95| 000C2C stfdux   7C3C35EE   1     STFDU     gr28,v2oib(gr28,gr6,0)=fp1
   96| 000C30 stfdux   7C3D35EE   1     STFDU     gr29,v2oib(gr29,gr6,0)=fp1
   97| 000C34 stfdux   7C3E3DEE   1     STFDU     gr30,v3oib(gr30,gr7,0)=fp1
   98| 000C38 stfdux   7C2C3DEE   1     STFDU     gr12,v3oib(gr12,gr7,0)=fp1
   99| 000C3C stfdux   7FCB1DEE   1     STFDU     gr11,doib(gr11,gr3,0)=fp30
  100| 000C40 stfdux   7FCA1DEE   1     STFDU     gr10,doib(gr10,gr3,0)=fp30
  101| 000C44 stfdux   7C0925EE   1     STFDU     gr9,eoib(gr9,gr4,0)=fp0
  102| 000C48 stfdux   7C0825EE   1     STFDU     gr8,eoib(gr8,gr4,0)=fp0
    0| 000C4C bc       4200FFD8   1     BCT       ctr=CL.540,taken=100%(100,0)
  104| 000C50 ld       E9010208   1     L8        gr8=#SPILL8(gr1,520)
    0| 000C54 ld       E80102F0   1     L8        gr0=#SPILL37(gr1,752)
    0| 000C58 ld       E92102E0   1     L8        gr9=#SPILL35(gr1,736)
    0| 000C5C ld       E94102E8   1     L8        gr10=#SPILL36(gr1,744)
    0| 000C60 add      7EB5CA14   1     A         gr21=gr21,gr25
    0| 000C64 add      7E94CA14   1     A         gr20=gr20,gr25
  104| 000C68 cmpld    7C3F4040   1     CL8       cr0=gr31,gr8
    0| 000C6C add      7EE0BA14   1     A         gr23=gr0,gr23
    0| 000C70 add      7EC0B214   1     A         gr22=gr0,gr22
    0| 000C74 add      7E73C214   1     A         gr19=gr19,gr24
    0| 000C78 add      7E52C214   1     A         gr18=gr18,gr24
    0| 000C7C add      7E298A14   1     A         gr17=gr9,gr17
    0| 000C80 add      7E098214   1     A         gr16=gr9,gr16
    0| 000C84 add      7DEA7A14   1     A         gr15=gr10,gr15
    0| 000C88 add      7DCA7214   1     A         gr14=gr10,gr14
  104| 000C8C bc       4180FF60   1     BT        CL.72,cr0,0x8/llt,taken=80%(80,20)
    0| 000C90 ori      60210000   1     XNOP      
    0| 000C94 ori      60210000   1     XNOP      
  138|                              CL.128:
  138| 000C98 ld       E8010410   1     L8        gr0=#stack(gr1,1040)
  138| 000C9C lwa      E981040A   1     L4A       gr12=#stack(gr1,1032)
  138| 000CA0 lfd      CBE103F8   1     LFL       fp31=#stack(gr1,1016)
  138| 000CA4 lfd      CBC103F0   1     LFL       fp30=#stack(gr1,1008)
  138| 000CA8 lfd      CBA103E8   1     LFL       fp29=#stack(gr1,1000)
  138| 000CAC addi     38210400   1     AI        gr1=gr1,1024
  138| 000CB0 mtspr    7C0803A6   1     LLR       lr=gr0
  138| 000CB4 mtcrf    7D808120   1     MTCRF     cr4=gr12
  138| 000CB8 ld       E9C1FF58   1     L8        gr14=#stack(gr1,-168)
  138| 000CBC ld       E9E1FF60   1     L8        gr15=#stack(gr1,-160)
  138| 000CC0 ld       EA01FF68   1     L8        gr16=#stack(gr1,-152)
  138| 000CC4 ld       EA21FF70   1     L8        gr17=#stack(gr1,-144)
  138| 000CC8 ld       EA41FF78   1     L8        gr18=#stack(gr1,-136)
  138| 000CCC ld       EA61FF80   1     L8        gr19=#stack(gr1,-128)
  138| 000CD0 ld       EA81FF88   1     L8        gr20=#stack(gr1,-120)
  138| 000CD4 ld       EAA1FF90   1     L8        gr21=#stack(gr1,-112)
  138| 000CD8 ld       EAC1FF98   1     L8        gr22=#stack(gr1,-104)
  138| 000CDC ld       EAE1FFA0   1     L8        gr23=#stack(gr1,-96)
  138| 000CE0 ld       EB01FFA8   1     L8        gr24=#stack(gr1,-88)
  138| 000CE4 ld       EB21FFB0   1     L8        gr25=#stack(gr1,-80)
  138| 000CE8 ld       EB41FFB8   1     L8        gr26=#stack(gr1,-72)
  138| 000CEC ld       EB61FFC0   1     L8        gr27=#stack(gr1,-64)
  138| 000CF0 ld       EB81FFC8   1     L8        gr28=#stack(gr1,-56)
  138| 000CF4 ld       EBA1FFD0   1     L8        gr29=#stack(gr1,-48)
  138| 000CF8 ld       EBC1FFD8   1     L8        gr30=#stack(gr1,-40)
  138| 000CFC ld       EBE1FFE0   1     L8        gr31=#stack(gr1,-32)
  138| 000D00 bclr     4E800020   1     BA        lr
  105|                              CL.31:
  105| 000D04 cmpwi    2C000002   1     C4        cr0=gr0,2
  105| 000D08 bc       408201AC   1     BF        CL.41,cr0,0x4/eq,taken=50%(0,0)
  106| 000D0C bc       4085FF8C   1     BF        CL.128,cr1,0x2/gt,taken=30%(30,70)
  116| 000D10 ld       E8620000   1     L8        gr3=.&&N&&root(gr2,0)
  114| 000D14 ld       E8E20000   1     L8        gr7=.&&N&bndry(gr2,0)
  107| 000D18 ld       EA820000   1     L8        gr20=.&&N&&param(gr2,0)
  116| 000D1C lfd      C80300E8   1     LFL       fp0=<s241:d232:l8>(gr3,232)
  116| 000D20 ld       E8670D08   1     L8        gr3=<s69:d3336:l8>(gr7,3336)
  108| 000D24 ld       E90711E8   1     L8        gr8=<s69:d4584:l8>(gr7,4584)
  108| 000D28 ld       EB871200   1     L8        gr28=<s69:d4608:l8>(gr7,4608)
  116| 000D2C ld       E9270D20   1     L8        gr9=<s69:d3360:l8>(gr7,3360)
  107| 000D30 lwa      EA540002   1     L4A       gr18=<s245:d0:l4>(gr20,0)
  114| 000D34 ld       E8870A98   1     L8        gr4=<s69:d2712:l8>(gr7,2712)
  110| 000D38 ld       E8C70F78   1     L8        gr6=<s69:d3960:l8>(gr7,3960)
  112| 000D3C ld       E8A71458   1     L8        gr5=<s69:d5208:l8>(gr7,5208)
  110| 000D40 ld       EBA70F90   1     L8        gr29=<s69:d3984:l8>(gr7,3984)
  112| 000D44 ld       E9871470   1     L8        gr12=<s69:d5232:l8>(gr7,5232)
  107| 000D48 std      FA4102F8   1     ST8       #SPILL38(gr1,760)=gr18
  114| 000D4C ld       E9670AB0   1     L8        gr11=<s69:d2736:l8>(gr7,2736)
  116| 000D50 ld       E9470D38   1     L8        gr10=<s69:d3384:l8>(gr7,3384)
  116| 000D54 ld       EA070D50   1     L8        gr16=<s69:d3408:l8>(gr7,3408)
  108| 000D58 ld       EB271230   1     L8        gr25=<s69:d4656:l8>(gr7,4656)
  114| 000D5C ld       EBC70AC8   1     L8        gr30=<s69:d2760:l8>(gr7,2760)
  114| 000D60 ld       EA270AE0   1     L8        gr17=<s69:d2784:l8>(gr7,2784)
  110| 000D64 ld       EAA70FA8   1     L8        gr21=<s69:d4008:l8>(gr7,4008)
  110| 000D68 ld       E8070FC0   1     L8        gr0=<s69:d4032:l8>(gr7,4032)
  108| 000D6C ld       EAE71218   1     L8        gr23=<s69:d4632:l8>(gr7,4632)
  112| 000D70 ld       EB671488   1     L8        gr27=<s69:d5256:l8>(gr7,5256)
  112| 000D74 ld       EB0714A0   1     L8        gr24=<s69:d5280:l8>(gr7,5280)
    0| 000D78 add      7D08E214   1     A         gr8=gr8,gr28
    0| 000D7C add      7C634A14   1     A         gr3=gr3,gr9
    0| 000D80 add      7CC6EA14   1     A         gr6=gr6,gr29
    0| 000D84 add      7CA56214   1     A         gr5=gr5,gr12
  114| 000D88 std      FA210300   1     ST8       #SPILL39(gr1,768)=gr17
    0| 000D8C add      7C845A14   1     A         gr4=gr4,gr11
    0| 000D90 cmpwi    2C120000   1     C4        cr0=gr18,0
    0| 000D94 add      7EC8CA14   1     A         gr22=gr8,gr25
    0| 000D98 add      7D038214   1     A         gr8=gr3,gr16
    0| 000D9C rldicr   79490FA4   1     SLL8      gr9=gr10,1
  116| 000DA0 std      FA010308   1     ST8       #SPILL40(gr1,776)=gr16
    0| 000DA4 rldicr   7AF30FA4   1     SLL8      gr19=gr23,1
    0| 000DA8 add      7F403214   1     A         gr26=gr0,gr6
    0| 000DAC rldicr   7AB40FA4   1     SLL8      gr20=gr21,1
    0| 000DB0 add      7FA5C214   1     A         gr29=gr5,gr24
    0| 000DB4 rldicr   7B7C0FA4   1     SLL8      gr28=gr27,1
    0| 000DB8 add      7D648A14   1     A         gr11=gr4,gr17
    0| 000DBC rldicr   7BCC0FA4   1     SLL8      gr12=gr30,1
  114| 000DC0 ld       E8670AF8   1     L8        gr3=<s69:d2808:l8>(gr7,2808)
  116| 000DC4 ld       E8870D68   1     L8        gr4=<s69:d3432:l8>(gr7,3432)
  110| 000DC8 ld       E8A70FD8   1     L8        gr5=<s69:d4056:l8>(gr7,4056)
  108| 000DCC ld       E8C71248   1     L8        gr6=<s69:d4680:l8>(gr7,4680)
  112| 000DD0 ld       E8E714B8   1     L8        gr7=<s69:d5304:l8>(gr7,5304)
    0| 000DD4 bc       4081FEC4   1     BF        CL.128,cr0,0x2/gt,taken=20%(20,80)
    0| 000DD8 fdiv     FC1F0024   1     DFL       fp0=fp31,fp0,fcr
    0| 000DDC std      F8010310   1     ST8       #SPILL41(gr1,784)=gr0
    0| 000DE0 add      7DE85214   1     A         gr15=gr8,gr10
    0| 000DE4 add      7DC84A14   1     A         gr14=gr8,gr9
    0| 000DE8 ld       E9020000   1     L8        gr8=.+CONSTANT_AREA(gr2,0)
    0| 000DEC add      7EF7B214   1     A         gr23=gr23,gr22
    0| 000DF0 add      7ED69A14   1     A         gr22=gr22,gr19
    0| 000DF4 add      7EB5D214   1     A         gr21=gr21,gr26
    0| 000DF8 add      7E94D214   1     A         gr20=gr20,gr26
    0| 000DFC add      7E7BEA14   1     A         gr19=gr27,gr29
    0| 000E00 add      7E5CEA14   1     A         gr18=gr28,gr29
    0| 000E04 add      7E2BF214   1     A         gr17=gr11,gr30
    0| 000E08 add      7E0B6214   1     A         gr16=gr11,gr12
    0| 000E0C lfs      C0280034   1     LFS       fp1=+CONSTANT_AREA(gr8,52)
  106|                              CL.76:
    0| 000E10 ld       E80102F8   1     L8        gr0=#SPILL38(gr1,760)
    0| 000E14 addi     3BFF0001   1     AI        gr31=gr31,1
  117| 000E18 or       7DC87378   1     LR        gr8=gr14
  116| 000E1C or       7DE97B78   1     LR        gr9=gr15
  115| 000E20 or       7E0A8378   1     LR        gr10=gr16
  114| 000E24 or       7E2B8B78   1     LR        gr11=gr17
  113| 000E28 or       7E4C9378   1     LR        gr12=gr18
  112| 000E2C or       7E7E9B78   1     LR        gr30=gr19
  111| 000E30 or       7E9DA378   1     LR        gr29=gr20
  110| 000E34 or       7EBCAB78   1     LR        gr28=gr21
  109| 000E38 or       7EDBB378   1     LR        gr27=gr22
  108| 000E3C or       7EFABB78   1     LR        gr26=gr23
    0| 000E40 mtspr    7C0903A6   1     LCTR      ctr=gr0
    0|                              CL.541:
  108| 000E44 stfdux   7FBA35EE   1     STFDU     gr26,v2ojb(gr26,gr6,0)=fp29
  109| 000E48 stfdux   7FBB35EE   1     STFDU     gr27,v2ojb(gr27,gr6,0)=fp29
  110| 000E4C stfdux   7C3C2DEE   1     STFDU     gr28,v1ojb(gr28,gr5,0)=fp1
  111| 000E50 stfdux   7C3D2DEE   1     STFDU     gr29,v1ojb(gr29,gr5,0)=fp1
  112| 000E54 stfdux   7C3E3DEE   1     STFDU     gr30,v3ojb(gr30,gr7,0)=fp1
  113| 000E58 stfdux   7C2C3DEE   1     STFDU     gr12,v3ojb(gr12,gr7,0)=fp1
  114| 000E5C stfdux   7FCB1DEE   1     STFDU     gr11,dojb(gr11,gr3,0)=fp30
  115| 000E60 stfdux   7FCA1DEE   1     STFDU     gr10,dojb(gr10,gr3,0)=fp30
  116| 000E64 stfdux   7C0925EE   1     STFDU     gr9,eojb(gr9,gr4,0)=fp0
  117| 000E68 stfdux   7C0825EE   1     STFDU     gr8,eojb(gr8,gr4,0)=fp0
    0| 000E6C bc       4200FFD8   1     BCT       ctr=CL.541,taken=100%(100,0)
  119| 000E70 ld       E9010208   1     L8        gr8=#SPILL8(gr1,520)
    0| 000E74 ld       E8010310   1     L8        gr0=#SPILL41(gr1,784)
    0| 000E78 ld       E9210300   1     L8        gr9=#SPILL39(gr1,768)
    0| 000E7C ld       E9410308   1     L8        gr10=#SPILL40(gr1,776)
    0| 000E80 add      7EF7CA14   1     A         gr23=gr23,gr25
    0| 000E84 add      7ED6CA14   1     A         gr22=gr22,gr25
  119| 000E88 cmpld    7C3F4040   1     CL8       cr0=gr31,gr8
    0| 000E8C add      7EA0AA14   1     A         gr21=gr0,gr21
    0| 000E90 add      7E80A214   1     A         gr20=gr0,gr20
    0| 000E94 add      7E73C214   1     A         gr19=gr19,gr24
    0| 000E98 add      7E52C214   1     A         gr18=gr18,gr24
    0| 000E9C add      7E298A14   1     A         gr17=gr9,gr17
    0| 000EA0 add      7E098214   1     A         gr16=gr9,gr16
    0| 000EA4 add      7DEA7A14   1     A         gr15=gr10,gr15
    0| 000EA8 add      7DCA7214   1     A         gr14=gr10,gr14
  119| 000EAC bc       4080FDEC   1     BF        CL.128,cr0,0x8/llt,taken=20%(20,80)
  119| 000EB0 b        4BFFFF60   1     B         CL.76,-1
  120|                              CL.41:
  121| 000EB4 ld       E8620000   1     L8        gr3=.&&N&&param(gr2,0)
  121| 000EB8 lwa      E8030006   1     L4A       gr0=<s245:d4:l4>(gr3,4)
  121| 000EBC cmpwi    2C000000   1     C4        cr0=gr0,0
  121| 000EC0 bc       4081FDD8   1     BF        CL.128,cr0,0x2/gt,taken=20%(20,80)
  131| 000EC4 ld       E8620000   1     L8        gr3=.&&N&&root(gr2,0)
  129| 000EC8 ld       E8E20000   1     L8        gr7=.&&N&bndry(gr2,0)
    0| 000ECC ld       EA820000   1     L8        gr20=.+CONSTANT_AREA(gr2,0)
  131| 000ED0 lfd      C80300E8   1     LFL       fp0=<s241:d232:l8>(gr3,232)
  129| 000ED4 ld       E8870B68   1     L8        gr4=<s69:d2920:l8>(gr7,2920)
  131| 000ED8 ld       E8670DD8   1     L8        gr3=<s69:d3544:l8>(gr7,3544)
  125| 000EDC ld       E8C71048   1     L8        gr6=<s69:d4168:l8>(gr7,4168)
  127| 000EE0 ld       E8A712B8   1     L8        gr5=<s69:d4792:l8>(gr7,4792)
  123| 000EE4 ld       E9071528   1     L8        gr8=<s69:d5416:l8>(gr7,5416)
  123| 000EE8 ld       EB871540   1     L8        gr28=<s69:d5440:l8>(gr7,5440)
    0| 000EEC fdiv     FC1F0024   1     DFL       fp0=fp31,fp0,fcr
  125| 000EF0 ld       EBA71060   1     L8        gr29=<s69:d4192:l8>(gr7,4192)
  127| 000EF4 ld       E98712D0   1     L8        gr12=<s69:d4816:l8>(gr7,4816)
  129| 000EF8 ld       E9670B80   1     L8        gr11=<s69:d2944:l8>(gr7,2944)
  131| 000EFC ld       E9270DF0   1     L8        gr9=<s69:d3568:l8>(gr7,3568)
  129| 000F00 ld       EBC70B98   1     L8        gr30=<s69:d2968:l8>(gr7,2968)
  129| 000F04 ld       EA470BB0   1     L8        gr18=<s69:d2992:l8>(gr7,2992)
  131| 000F08 ld       E9470E08   1     L8        gr10=<s69:d3592:l8>(gr7,3592)
  131| 000F0C ld       EA270E20   1     L8        gr17=<s69:d3616:l8>(gr7,3616)
  125| 000F10 ld       EAA71078   1     L8        gr21=<s69:d4216:l8>(gr7,4216)
  125| 000F14 ld       EA071090   1     L8        gr16=<s69:d4240:l8>(gr7,4240)
  127| 000F18 ld       EB6712E8   1     L8        gr27=<s69:d4840:l8>(gr7,4840)
  129| 000F1C std      FA410318   1     ST8       #SPILL42(gr1,792)=gr18
  127| 000F20 ld       EB271300   1     L8        gr25=<s69:d4864:l8>(gr7,4864)
  123| 000F24 ld       EAE71558   1     L8        gr23=<s69:d5464:l8>(gr7,5464)
  123| 000F28 ld       EB071570   1     L8        gr24=<s69:d5488:l8>(gr7,5488)
    0| 000F2C add      7D08E214   1     A         gr8=gr8,gr28
    0| 000F30 add      7CC6EA14   1     A         gr6=gr6,gr29
    0| 000F34 add      7CA56214   1     A         gr5=gr5,gr12
    0| 000F38 add      7C845A14   1     A         gr4=gr4,gr11
    0| 000F3C add      7C634A14   1     A         gr3=gr3,gr9
    0| 000F40 add      7EC8C214   1     A         gr22=gr8,gr24
    0| 000F44 rldicr   7AF30FA4   1     SLL8      gr19=gr23,1
    0| 000F48 add      7F468214   1     A         gr26=gr6,gr16
    0| 000F4C add      7FA5CA14   1     A         gr29=gr5,gr25
    0| 000F50 rldicr   7B7C0FA4   1     SLL8      gr28=gr27,1
    0| 000F54 add      7D649214   1     A         gr11=gr4,gr18
    0| 000F58 rldicr   7BCC0FA4   1     SLL8      gr12=gr30,1
  131| 000F5C std      FA210320   1     ST8       #SPILL43(gr1,800)=gr17
    0| 000F60 add      7D038A14   1     A         gr8=gr3,gr17
    0| 000F64 rldicr   79490FA4   1     SLL8      gr9=gr10,1
  125| 000F68 std      FA010328   1     ST8       #SPILL44(gr1,808)=gr16
    0| 000F6C lfs      C0340034   1     LFS       fp1=+CONSTANT_AREA(gr20,52)
    0| 000F70 rldicr   7AB40FA4   1     SLL8      gr20=gr21,1
  129| 000F74 ld       E8670BC8   1     L8        gr3=<s69:d3016:l8>(gr7,3016)
  131| 000F78 ld       E8870E38   1     L8        gr4=<s69:d3640:l8>(gr7,3640)
  125| 000F7C ld       E8A710A8   1     L8        gr5=<s69:d4264:l8>(gr7,4264)
  127| 000F80 ld       E8C71318   1     L8        gr6=<s69:d4888:l8>(gr7,4888)
  123| 000F84 ld       E8E71588   1     L8        gr7=<s69:d5512:l8>(gr7,5512)
    0| 000F88 add      7EF7B214   1     A         gr23=gr23,gr22
    0| 000F8C add      7ED69A14   1     A         gr22=gr22,gr19
    0| 000F90 add      7EB5D214   1     A         gr21=gr21,gr26
    0| 000F94 add      7E94D214   1     A         gr20=gr20,gr26
    0| 000F98 add      7E7BEA14   1     A         gr19=gr27,gr29
    0| 000F9C add      7E5CEA14   1     A         gr18=gr28,gr29
    0| 000FA0 add      7E2BF214   1     A         gr17=gr11,gr30
    0| 000FA4 add      7E0B6214   1     A         gr16=gr11,gr12
    0| 000FA8 add      7DE85214   1     A         gr15=gr8,gr10
    0| 000FAC add      7DC84A14   1     A         gr14=gr8,gr9
  121|                              CL.80:
    0| 000FB0 addi     3BFF0001   1     AI        gr31=gr31,1
  132| 000FB4 or       7DC87378   1     LR        gr8=gr14
  131| 000FB8 or       7DE97B78   1     LR        gr9=gr15
  130| 000FBC or       7E0A8378   1     LR        gr10=gr16
  129| 000FC0 or       7E2B8B78   1     LR        gr11=gr17
  128| 000FC4 or       7E4C9378   1     LR        gr12=gr18
  127| 000FC8 or       7E7E9B78   1     LR        gr30=gr19
  126| 000FCC or       7E9DA378   1     LR        gr29=gr20
  125| 000FD0 or       7EBCAB78   1     LR        gr28=gr21
  124| 000FD4 or       7EDBB378   1     LR        gr27=gr22
  123| 000FD8 or       7EFABB78   1     LR        gr26=gr23
    0| 000FDC mtspr    7C0903A6   1     LCTR      ctr=gr0
    0| 000FE0 ori      60210000   1     XNOP      
    0|                              CL.542:
  123| 000FE4 stfdux   7FBA3DEE   1     STFDU     gr26,v3okb(gr26,gr7,0)=fp29
  124| 000FE8 stfdux   7FBB3DEE   1     STFDU     gr27,v3okb(gr27,gr7,0)=fp29
  125| 000FEC stfdux   7C3C2DEE   1     STFDU     gr28,v1okb(gr28,gr5,0)=fp1
  126| 000FF0 stfdux   7C3D2DEE   1     STFDU     gr29,v1okb(gr29,gr5,0)=fp1
  127| 000FF4 stfdux   7C3E35EE   1     STFDU     gr30,v2okb(gr30,gr6,0)=fp1
  128| 000FF8 stfdux   7C2C35EE   1     STFDU     gr12,v2okb(gr12,gr6,0)=fp1
  129| 000FFC stfdux   7FCB1DEE   1     STFDU     gr11,dokb(gr11,gr3,0)=fp30
  130| 001000 stfdux   7FCA1DEE   1     STFDU     gr10,dokb(gr10,gr3,0)=fp30
  131| 001004 stfdux   7C0925EE   1     STFDU     gr9,eokb(gr9,gr4,0)=fp0
  132| 001008 stfdux   7C0825EE   1     STFDU     gr8,eokb(gr8,gr4,0)=fp0
    0| 00100C bc       4200FFD8   1     BCT       ctr=CL.542,taken=100%(100,0)
    0| 001010 ld       E9010328   1     L8        gr8=#SPILL44(gr1,808)
    0| 001014 ld       E9210318   1     L8        gr9=#SPILL42(gr1,792)
    0| 001018 ld       E9410320   1     L8        gr10=#SPILL43(gr1,800)
  134| 00101C cmpld    7C3F0040   1     CL8       cr0=gr31,gr0
    0| 001020 add      7EF7C214   1     A         gr23=gr23,gr24
    0| 001024 add      7ED6C214   1     A         gr22=gr22,gr24
    0| 001028 add      7EA8AA14   1     A         gr21=gr8,gr21
    0| 00102C add      7E88A214   1     A         gr20=gr8,gr20
    0| 001030 add      7E73CA14   1     A         gr19=gr19,gr25
    0| 001034 add      7E52CA14   1     A         gr18=gr18,gr25
    0| 001038 add      7E298A14   1     A         gr17=gr9,gr17
    0| 00103C add      7E098214   1     A         gr16=gr9,gr16
    0| 001040 add      7DEA7A14   1     A         gr15=gr10,gr15
    0| 001044 add      7DCA7214   1     A         gr14=gr10,gr14
  134| 001048 bc       4080FC50   1     BF        CL.128,cr0,0x8/llt,taken=20%(20,80)
  134| 00104C b        4BFFFF64   1     B         CL.80,-1
   81|                              CL.20:
   82| 001050 stfd     DBA40000   1     STFL      v3(gr4,0)=fp29
   83| 001054 std      FBEC0000   1     ST8       v1(gr12,0)=gr31
   84| 001058 std      FBE80000   1     ST8       v2(gr8,0)=gr31
   82| 00105C stfd     DBA70000   1     STFL      v3(gr7,0)=fp29
   83| 001060 std      FBFC0000   1     ST8       v1(gr28,0)=gr31
   84| 001064 std      FBEB0000   1     ST8       v2(gr11,0)=gr31
   82| 001068 stfd     DBA60000   1     STFL      v3(gr6,0)=fp29
   83| 00106C std      FBFD0000   1     ST8       v1(gr29,0)=gr31
   84| 001070 std      FBEA0000   1     ST8       v2(gr10,0)=gr31
   82| 001074 stfd     DBA50000   1     STFL      v3(gr5,0)=fp29
   83| 001078 std      FBFE0000   1     ST8       v1(gr30,0)=gr31
   84| 00107C std      FBE90000   1     ST8       v2(gr9,0)=gr31
    0| 001080 b        4BFFF92C   1     B         CL.114,-1
    0|                              CL.325:
    0| 001084 or       7DE97B78   1     LR        gr9=gr15
    0| 001088 or       7E6A9B78   1     LR        gr10=gr19
    0| 00108C or       7E2B8B78   1     LR        gr11=gr17
    0| 001090 mtspr    7D8903A6   1     LCTR      ctr=gr12
    0| 001094 ori      60210000   1     XNOP      
    0| 001098 ori      60210000   1     XNOP      
    0| 00109C ori      60210000   1     XNOP      
   72|                              CL.280:
   77| 0010A0 bc       40960014   1     BF        CL.282,cr5,0x4/eq,taken=50%(0,0)
   78| 0010A4 stfd     DBAB0000   1     STFL      v2(gr11,0)=fp29
   79| 0010A8 std      FBEA0000   1     ST8       v1(gr10,0)=gr31
   80| 0010AC std      FBE90000   1     ST8       v3(gr9,0)=gr31
    0| 0010B0 b        48000010   1     B         CL.283,-1
   81|                              CL.282:
   82| 0010B4 stfd     DBA90000   1     STFL      v3(gr9,0)=fp29
   83| 0010B8 std      FBEA0000   1     ST8       v1(gr10,0)=gr31
   84| 0010BC std      FBEB0000   1     ST8       v2(gr11,0)=gr31
   85|                              CL.283:
    0| 0010C0 add      7D274A14   1     A         gr9=gr7,gr9
    0| 0010C4 add      7D455214   1     A         gr10=gr5,gr10
    0| 0010C8 add      7D665A14   1     A         gr11=gr6,gr11
   86| 0010CC bc       4200FFD4   1     BCT       ctr=CL.280,taken=100%(100,0)
    0| 0010D0 b        4BFFF638   1     B         CL.101,-1
   87|                              CL.329:
    0| 0010D4 mtspr    7C6903A6   1     LCTR      ctr=gr3
   87|                              CL.268:
   88| 0010D8 addi     38840001   1     AI        gr4=gr4,1
   88| 0010DC cmpd     7F241800   1     C8        cr6=gr4,gr3
   88| 0010E0 bc       4118FFF8   1     BCTT      ctr=CL.268,cr6,0x1/lt,taken=80%(80,20)
    0| 0010E4 b        4BFFF66C   1     B         CL.103,-1
   67|                              CL.318:
    0| 0010E8 mtspr    7CA903A6   1     LCTR      ctr=gr5
   67|                              CL.307:
   68| 0010EC addi     38E70001   1     AI        gr7=gr7,1
   68| 0010F0 cmpd     7CA72800   1     C8        cr1=gr7,gr5
   68| 0010F4 bc       4104FFF8   1     BCTT      ctr=CL.307,cr1,0x1/lt,taken=80%(80,20)
    0| 0010F8 b        4BFFF2A0   1     B         CL.127,-1
     |               Tag Table
     | 0010FC        00000000 00012203 83120000 000010FC
     |               Instruction count         1087
     |               Straight-line exec time   1087
     |               Constant Area
     | 000000        6E6F682E 66393000 7067656E 70306430 76306964 69726563
     | 000018        74496E6F 682E6639 3049424D 3F800000 3EB0C6F7 A0B5ED8D
     | 000030        BF800000 00000000

 
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    noh.f90                     07/08/15   15:48:51
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
 
    Source records read.......................................     138
1501-510  Compilation successful for file noh.f90.
1501-543  Object file created.
