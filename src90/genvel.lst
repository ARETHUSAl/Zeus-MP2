IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- genvel.f90 07/08/15 15:48:54
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** genvel   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-534 (I) Loop (loop index 4) at genvel.f90 <line 109> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 5) at genvel.f90 <line 110> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 6) at genvel.f90 <line 111> was not SIMD vectorized because it contains memory references ((double *)((char *)d-vp2i%addr  + d-vp2i%rvo))->vp2i[].rns22.[$$CIV5 + 1ll][$$CIV4 + 1ll][$$CIV3 + 1ll] = ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[$$CIV5 + 1ll][$$CIV4 + 1ll][$$CIV3 + 1ll]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 6) at genvel.f90 <line 111> was not SIMD vectorized because it contains memory references ((double *)((char *)d-vp3i%addr  + d-vp3i%rvo))->vp3i[].rns23.[$$CIV5 + 1ll][$$CIV4 + 1ll][$$CIV3 + 1ll] = ((double *)((char *)d-w3dc%addr  + d-w3dc%rvo))->w3dc[].rns19.[$$CIV5 + 1ll][$$CIV4 + 1ll][$$CIV3 + 1ll]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 6) at genvel.f90 <line 111> was not SIMD vectorized because it contains memory references ((double *)((char *)d-vp1i%addr  + d-vp1i%rvo))->vp1i[].rns21.[$$CIV5 + 1ll][$$CIV4 + 1ll][$$CIV3 + 1ll] = ((double *)((char *)d-w3da%addr  + d-w3da%rvo))->w3da[].rns15.[$$CIV5 + 1ll][$$CIV4 + 1ll][$$CIV3 + 1ll]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 6) at genvel.f90 <line 113> was not SIMD vectorized because it contains memory references ((char *)d-vp2i%addr  + d-vp2i%rvo + (d-vp2i%bounds%mult[].off360)*($$CIV5 + 1ll) + (d-vp2i%bounds%mult[].off384)*($$CIV4 + 1ll) + (d-vp2i%bounds%mult[].off408)*($$CIV3 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 6) at genvel.f90 <line 113> was not SIMD vectorized because it contains memory references ((char *)d-vp2i%addr  + d-vp2i%rvo + (d-vp2i%bounds%mult[].off360)*($$CIV5 + 1ll) + (d-vp2i%bounds%mult[].off384)*($$CIV4 + 1ll) + (d-vp2i%bounds%mult[].off408)*($$CIV3 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at genvel.f90 <line 113> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 6) at genvel.f90 <line 113> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-vp2i%addr  + d-vp2i%rvo + (d-vp2i%bounds%mult[].off360)*($$CIV5 + 1ll) + (d-vp2i%bounds%mult[].off384)*($$CIV4 + 1ll) + (d-vp2i%bounds%mult[].off408)*($$CIV3 + 1ll)).
1586-536 (I) Loop (loop index 6) at genvel.f90 <line 114> was not SIMD vectorized because it contains memory references ((char *)d-vp3i%addr  + d-vp3i%rvo + (d-vp3i%bounds%mult[].off568)*($$CIV5 + 1ll) + (d-vp3i%bounds%mult[].off592)*($$CIV4 + 1ll) + (d-vp3i%bounds%mult[].off616)*($$CIV3 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 6) at genvel.f90 <line 114> was not SIMD vectorized because it contains memory references ((char *)d-vp3i%addr  + d-vp3i%rvo + (d-vp3i%bounds%mult[].off568)*($$CIV5 + 1ll) + (d-vp3i%bounds%mult[].off592)*($$CIV4 + 1ll) + (d-vp3i%bounds%mult[].off616)*($$CIV3 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at genvel.f90 <line 114> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 6) at genvel.f90 <line 114> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-vp3i%addr  + d-vp3i%rvo + (d-vp3i%bounds%mult[].off568)*($$CIV5 + 1ll) + (d-vp3i%bounds%mult[].off592)*($$CIV4 + 1ll) + (d-vp3i%bounds%mult[].off616)*($$CIV3 + 1ll)).
1586-536 (I) Loop (loop index 6) at genvel.f90 <line 112> was not SIMD vectorized because it contains memory references ((char *)d-vp1i%addr  + d-vp1i%rvo + (d-vp1i%bounds%mult[].off152)*($$CIV5 + 1ll) + (d-vp1i%bounds%mult[].off176)*($$CIV4 + 1ll) + (d-vp1i%bounds%mult[].off200)*($$CIV3 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 6) at genvel.f90 <line 112> was not SIMD vectorized because it contains memory references ((char *)d-vp1i%addr  + d-vp1i%rvo + (d-vp1i%bounds%mult[].off152)*($$CIV5 + 1ll) + (d-vp1i%bounds%mult[].off176)*($$CIV4 + 1ll) + (d-vp1i%bounds%mult[].off200)*($$CIV3 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 6) at genvel.f90 <line 112> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 6) at genvel.f90 <line 112> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-vp1i%addr  + d-vp1i%rvo + (d-vp1i%bounds%mult[].off152)*($$CIV5 + 1ll) + (d-vp1i%bounds%mult[].off176)*($$CIV4 + 1ll) + (d-vp1i%bounds%mult[].off200)*($$CIV3 + 1ll)).
1586-534 (I) Loop (loop index 7) at genvel.f90 <line 140> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 8) at genvel.f90 <line 141> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 9) at genvel.f90 <line 142> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns32.[$$CIV8 + 1ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = ((double *)((char *)d-vp1i%addr  + d-vp1i%rvo))->vp1i[].rns33.[$$CIV8 + 1ll][$$CIV7 + 1ll][$$CIV6 + 1ll]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 9) at genvel.f90 <line 142> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns34.[$$CIV8 + 1ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = ((double *)((char *)d-vp2i%addr  + d-vp2i%rvo))->vp2i[].rns35.[$$CIV8 + 1ll][$$CIV7 + 1ll][$$CIV6 + 1ll]; with non-vectorizable strides.
1586-540 (I) Loop (loop index 9) at genvel.f90 <line 142> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns36.[$$CIV8 + 1ll][$$CIV7 + 1ll][$$CIV6 + 1ll] = ((double *)((char *)d-vp3i%addr  + d-vp3i%rvo))->vp3i[].rns37.[$$CIV8 + 1ll][$$CIV7 + 1ll][$$CIV6 + 1ll]; with non-vectorizable strides.
1586-536 (I) Loop (loop index 9) at genvel.f90 <line 143> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV8 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV7 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 9) at genvel.f90 <line 143> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV8 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV7 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 9) at genvel.f90 <line 143> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 9) at genvel.f90 <line 143> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV8 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV7 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 9) at genvel.f90 <line 144> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV8 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV7 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 9) at genvel.f90 <line 144> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV8 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV7 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 9) at genvel.f90 <line 144> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 9) at genvel.f90 <line 144> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV8 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV7 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV6 + 1ll)).
1586-536 (I) Loop (loop index 9) at genvel.f90 <line 145> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV8 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV7 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV6 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 9) at genvel.f90 <line 145> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV8 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV7 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV6 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 9) at genvel.f90 <line 145> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 9) at genvel.f90 <line 145> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV8 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV7 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV6 + 1ll)).
1586-534 (I) Loop (loop index 10) at genvel.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 11) at genvel.f90 <line 90> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 12) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3da%addr  + d-w3da%rvo))->w3da[].rns15.[3ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] = (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[3ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[3ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3da%addr  + d-w3da%rvo))->w3da[].rns15.[4ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] = (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[4ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[4ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3da%addr  + d-w3da%rvo))->w3da[].rns15.[1ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] = (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[1ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[1ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3da%addr  + d-w3da%rvo))->w3da[].rns15.[2ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] = (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[2ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[2ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-536 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(3ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[3ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[3ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(3ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(3ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
1586-536 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(4ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[4ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[4ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(4ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(4ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
1586-536 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(1ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[1ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[1ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(1ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(1ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
1586-536 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(2ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[2ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[2ll + ($$CIV9 * 4ll + (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(2ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at genvel.f90 <line 102> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(2ll + ($$CIV9 * 4ll + (long long) kn % 4ll)) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
1586-534 (I) Loop (loop index 13) at genvel.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 14) at genvel.f90 <line 90> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-536 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-536 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-536 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-536 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-536 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-536 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-536 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-536 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 15) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll + (long long) kn % 4ll)) + (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + (long long) jn % 2ll)) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-534 (I) Loop (loop index 16) at genvel.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 17) at genvel.f90 <line 90> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 18) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dc%addr  + d-w3dc%rvo))->w3dc[].rns19.[2ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] = (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[2ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) (1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? (int) (1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 18) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dc%addr  + d-w3dc%rvo))->w3dc[].rns19.[1ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] = (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[1ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) ($$CIVC * 4ll + (long long) kn % 4ll) ? (int) ($$CIVC * 4ll + (long long) kn % 4ll) + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 18) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dc%addr  + d-w3dc%rvo))->w3dc[].rns19.[3ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] = (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[3ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) (2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? (int) (2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-540 (I) Loop (loop index 18) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dc%addr  + d-w3dc%rvo))->w3dc[].rns19.[4ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] = (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[4ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) (3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? (int) (3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-536 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[2ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) (1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? (int) (1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
1586-536 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[1ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) ($$CIVC * 4ll + (long long) kn % 4ll) ? (int) ($$CIVC * 4ll + (long long) kn % 4ll) + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
1586-536 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[3ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) (2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? (int) (2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
1586-536 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(4ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[4ll + ($$CIVC * 4ll + (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) (3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? (int) (3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(4ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 18) at genvel.f90 <line 104> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(4ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
1586-534 (I) Loop (loop index 19) at genvel.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 20) at genvel.f90 <line 90> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 21) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3dc%addr  + d-w3dc%rvo))->w3dc[].rns19.[$$DCIV6 + 1ll][$$DCIV7 + 1ll][$$DCIV8 + 1ll] = (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[$$DCIV6 + 1ll][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) $$DCIV6 ? (int) $$DCIV6 + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-536 (I) Loop (loop index 21) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*($$DCIV6 + 1ll) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 21) at genvel.f90 <line 104> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[$$DCIV6 + 1ll][$$DCIV7 + 1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr  + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - (int) $$DCIV6 ? (int) $$DCIV6 + 2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 21) at genvel.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*($$DCIV6 + 1ll) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 21) at genvel.f90 <line 104> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 21) at genvel.f90 <line 104> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3dc%addr  + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*($$DCIV6 + 1ll) + (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
1586-534 (I) Loop (loop index 22) at genvel.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 22) at genvel.f90 <line 84> was not SIMD vectorized because it contains unsupported loop structure.
1586-534 (I) Loop (loop index 25) at genvel.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 26) at genvel.f90 <line 90> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 27) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[$$DCIV3 + 1ll][$$DCIV4 + 1ll][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][$$DCIV4 + 1ll][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][(long long) (1 != jn - (int) $$DCIV4 ? (int) $$DCIV4 + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-536 (I) Loop (loop index 27) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 27) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][$$DCIV4 + 1ll][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][(long long) (1 != jn - (int) $$DCIV4 ? (int) $$DCIV4 + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 27) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 27) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 27) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-534 (I) Loop (loop index 28) at genvel.f90 <line 90> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 29) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3db%addr  + d-w3db%rvo))->w3db[].rns17.[$$DCIV3 + 1ll][$$DCIV4 + 1ll][$$DCIV5 + 1ll] = (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][$$DCIV4 + 1ll][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][(long long) (1 != jn - (int) $$DCIV4 ? (int) $$DCIV4 + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-536 (I) Loop (loop index 29) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 29) at genvel.f90 <line 103> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][$$DCIV4 + 1ll][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][(long long) (1 != jn - (int) $$DCIV4 ? (int) $$DCIV4 + 2 : 1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 29) at genvel.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 29) at genvel.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 29) at genvel.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3db%addr  + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
1586-534 (I) Loop (loop index 33) at genvel.f90 <line 84> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 34) at genvel.f90 <line 90> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 35) at genvel.f90 <line 96> was not SIMD vectorized because it contains memory references ((double *)((char *)d-w3da%addr  + d-w3da%rvo))->w3da[].rns15.[$$DCIV0 + 1ll][$$DCIV1 + 1ll][$$DCIV2 + 1ll] = (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[$$DCIV0 + 1ll][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[$$DCIV0 + 1ll][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001; with non-vectorizable strides.
1586-536 (I) Loop (loop index 35) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*($$DCIV0 + 1ll) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable alignment.
1586-537 (I) Loop (loop index 35) at genvel.f90 <line 102> was not SIMD vectorized because it contains operation in (((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[$$DCIV0 + 1ll][$$DCIV1 + 1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr  + d-vp1r%rvo))->vp1r[].rns16.[$$DCIV0 + 1ll][$$DCIV1 + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001 which is not suitable for SIMD vectorization.
1586-540 (I) Loop (loop index 35) at genvel.f90 <line 102> was not SIMD vectorized because it contains memory references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*($$DCIV0 + 1ll) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 35) at genvel.f90 <line 102> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 35) at genvel.f90 <line 102> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-w3da%addr  + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*($$DCIV0 + 1ll) + (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"9">. Total number of the innermost loops SIMD vectorized <"0">.


     1|         SUBROUTINE genvel (nmodes, vrms, idx)
    59|           bak_rtd_1 = d-vp1r
                  d-vp1r%dscr_type = 3
                  d-vp1r%data_type = 14
                  d-vp1r%version = 129
                  d-vp1r%element_len = 8
                  d-vp1r%rank = 3
                  d-vp1r%bounds%lbound[].off80 = 1
                  d-vp1r%bounds%extent[].off88 = max(int(in),0)
                  d-vp1r%bounds%mult[].off96 = 8
                  d-vp1r%bounds%lbound[].off56 = 1
                  d-vp1r%bounds%extent[].off64 = max(int(jn),0)
                  d-vp1r%bounds%mult[].off72 = max(int(in),0) * 8
                  d-vp1r%bounds%lbound[].off32 = 1
                  d-vp1r%bounds%extent[].off40 = max(int(kn),0)
                  d-vp1r%bounds%mult[].off48 = 8 * (max(int(jn),0) * max(int(in)&
                &   ,0))
                  d-vp1r%rvo = -((1 + (max(int(jn),0) * max(int(in),0) + max(&
                &   int(in),0))) * 8)
                  IF ((0 <> (d-vp1r%flags  .AND.  128))) THEN
                    d-vp1r = bak_rtd_1
                  ELSE
                    lab_1
                    IF ((0 == 8 * (max(int(kn),0) * (max(int(jn),0) * max(int(&
                &     in),0))))) THEN
                      d-vp1r%addr = NULL
                      d-vp1r%flags = 240
                    ELSE
                      lab_3
                      d-vp1r%addr = __xlf_malloc((8 * (max(int(%VAL(kn)),0) * (&
                &       max(int(%VAL(jn)),0) * max(int(%VAL(in)),0)))),32)
                      CALL __alignx(32,d-vp1r%addr)
                      IF (.NOT.(d-vp1r%addr == NULL)) GOTO lab_5
                      d-vp1r = bak_rtd_1
                      GOTO lab_6
                      lab_5
                      d-vp1r%flags = 240
                      lab_6
                      lab_4
                      lab_2
    60|               bak_rtd_2 = d-vp1i
                      d-vp1i%dscr_type = 3
                      d-vp1i%data_type = 14
                      d-vp1i%version = 129
                      d-vp1i%element_len = 8
                      d-vp1i%rank = 3
                      d-vp1i%bounds%lbound[].off184 = 1
                      d-vp1i%bounds%extent[].off192 = max(int(in),0)
                      d-vp1i%bounds%mult[].off200 = 8
                      d-vp1i%bounds%lbound[].off160 = 1
                      d-vp1i%bounds%extent[].off168 = max(int(jn),0)
                      d-vp1i%bounds%mult[].off176 = max(int(in),0) * 8
                      d-vp1i%bounds%lbound[].off136 = 1
                      d-vp1i%bounds%extent[].off144 = max(int(kn),0)
                      d-vp1i%bounds%mult[].off152 = 8 * (max(int(jn),0) * max(&
                &       int(in),0))
                      d-vp1i%rvo = -((1 + (max(int(jn),0) * max(int(in),0) + &
                &       max(int(in),0))) * 8)
                      IF ((0 <> (d-vp1i%flags  .AND.  128))) THEN
                        d-vp1i = bak_rtd_2
                      ELSE
                        lab_7
                        IF ((0 == 8 * (max(int(kn),0) * (max(int(jn),0) * max(&
                &         int(in),0))))) THEN
                          d-vp1i%addr = NULL
                          d-vp1i%flags = 240
                        ELSE
                          lab_9
                          d-vp1i%addr = __xlf_malloc((8 * (max(int(%VAL(kn)),0) &
                &           * (max(int(%VAL(jn)),0) * max(int(%VAL(in)),0)))),32)
                          CALL __alignx(32,d-vp1i%addr)
                          IF (.NOT.(d-vp1i%addr == NULL)) GOTO lab_11
                          d-vp1i = bak_rtd_2
                          GOTO lab_12
                          lab_11
                          d-vp1i%flags = 240
                          lab_12
                          lab_10
                          lab_8
    61|                   bak_rtd_3 = d-vp2r
                          d-vp2r%dscr_type = 3
                          d-vp2r%data_type = 14
                          d-vp2r%version = 129
                          d-vp2r%element_len = 8
                          d-vp2r%rank = 3
                          d-vp2r%bounds%lbound[].off288 = 1
                          d-vp2r%bounds%extent[].off296 = max(int(in),0)
                          d-vp2r%bounds%mult[].off304 = 8
                          d-vp2r%bounds%lbound[].off264 = 1
                          d-vp2r%bounds%extent[].off272 = max(int(jn),0)
                          d-vp2r%bounds%mult[].off280 = max(int(in),0) * 8
                          d-vp2r%bounds%lbound[].off240 = 1
                          d-vp2r%bounds%extent[].off248 = max(int(kn),0)
                          d-vp2r%bounds%mult[].off256 = 8 * (max(int(jn),0) * &
                &           max(int(in),0))
                          d-vp2r%rvo = -((1 + (max(int(jn),0) * max(int(in),0) &
                &           + max(int(in),0))) * 8)
                          IF ((0 <> (d-vp2r%flags  .AND.  128))) THEN
                            d-vp2r = bak_rtd_3
                          ELSE
                            lab_13
                            IF ((0 == 8 * (max(int(kn),0) * (max(int(jn),0) * &
                &             max(int(in),0))))) THEN
                              d-vp2r%addr = NULL
                              d-vp2r%flags = 240
                            ELSE
                              lab_15
                              d-vp2r%addr = __xlf_malloc((8 * (max(int(%VAL(kn))&
                &               ,0) * (max(int(%VAL(jn)),0) * max(int(%VAL(in)),0)&
                &               ))),32)
                              CALL __alignx(32,d-vp2r%addr)
                              IF (.NOT.(d-vp2r%addr == NULL)) GOTO lab_17
                              d-vp2r = bak_rtd_3
                              GOTO lab_18
                              lab_17
                              d-vp2r%flags = 240
                              lab_18
                              lab_16
                              lab_14
    62|                       bak_rtd_4 = d-vp2i
                              d-vp2i%dscr_type = 3
                              d-vp2i%data_type = 14
                              d-vp2i%version = 129
                              d-vp2i%element_len = 8
                              d-vp2i%rank = 3
                              d-vp2i%bounds%lbound[].off392 = 1
                              d-vp2i%bounds%extent[].off400 = max(int(in),0)
                              d-vp2i%bounds%mult[].off408 = 8
                              d-vp2i%bounds%lbound[].off368 = 1
                              d-vp2i%bounds%extent[].off376 = max(int(jn),0)
                              d-vp2i%bounds%mult[].off384 = max(int(in),0) * 8
                              d-vp2i%bounds%lbound[].off344 = 1
                              d-vp2i%bounds%extent[].off352 = max(int(kn),0)
                              d-vp2i%bounds%mult[].off360 = 8 * (max(int(jn),0) &
                &               * max(int(in),0))
                              d-vp2i%rvo = -((1 + (max(int(jn),0) * max(int(in),&
                &               0) + max(int(in),0))) * 8)
                              IF ((0 <> (d-vp2i%flags  .AND.  128))) THEN
                                d-vp2i = bak_rtd_4
                              ELSE
                                lab_19
                                IF ((0 == 8 * (max(int(kn),0) * (max(int(jn),0) &
                &                 * max(int(in),0))))) THEN
                                  d-vp2i%addr = NULL
                                  d-vp2i%flags = 240
                                ELSE
                                  lab_21
                                  d-vp2i%addr = __xlf_malloc((8 * (max(int(%VAL(&
                &                   kn)),0) * (max(int(%VAL(jn)),0) * max(int(&
                &                   %VAL(in)),0)))),32)
                                  CALL __alignx(32,d-vp2i%addr)
                                  IF (.NOT.(d-vp2i%addr == NULL)) GOTO lab_23
                                  d-vp2i = bak_rtd_4
                                  GOTO lab_24
                                  lab_23
                                  d-vp2i%flags = 240
                                  lab_24
                                  lab_22
                                  lab_20
    63|                           bak_rtd_5 = d-vp3r
                                  d-vp3r%dscr_type = 3
                                  d-vp3r%data_type = 14
                                  d-vp3r%version = 129
                                  d-vp3r%element_len = 8
                                  d-vp3r%rank = 3
                                  d-vp3r%bounds%lbound[].off496 = 1
                                  d-vp3r%bounds%extent[].off504 = max(int(in),0)&
                &                   
                                  d-vp3r%bounds%mult[].off512 = 8
                                  d-vp3r%bounds%lbound[].off472 = 1
                                  d-vp3r%bounds%extent[].off480 = max(int(jn),0)&
                &                   
                                  d-vp3r%bounds%mult[].off488 = max(int(in),0) &
                &                   * 8
                                  d-vp3r%bounds%lbound[].off448 = 1
                                  d-vp3r%bounds%extent[].off456 = max(int(kn),0)&
                &                   
                                  d-vp3r%bounds%mult[].off464 = 8 * (max(int(jn)&
                &                   ,0) * max(int(in),0))
                                  d-vp3r%rvo = -((1 + (max(int(jn),0) * max(int(&
                &                   in),0) + max(int(in),0))) * 8)
                                  IF ((0 <> (d-vp3r%flags  .AND.  128))) THEN
                                    d-vp3r = bak_rtd_5
                                  ELSE
                                    lab_25
                                    IF ((0 == 8 * (max(int(kn),0) * (max(int(jn)&
                &                     ,0) * max(int(in),0))))) THEN
                                      d-vp3r%addr = NULL
                                      d-vp3r%flags = 240
                                    ELSE
                                      lab_27
                                      d-vp3r%addr = __xlf_malloc((8 * (max(int(&
                &                       %VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &                       max(int(%VAL(in)),0)))),32)
                                      CALL __alignx(32,d-vp3r%addr)
                                      IF (.NOT.(d-vp3r%addr == NULL)) GOTO &
                &                       lab_29
                                      d-vp3r = bak_rtd_5
                                      GOTO lab_30
                                      lab_29
                                      d-vp3r%flags = 240
                                      lab_30
                                      lab_28
                                      lab_26
    64|                               bak_rtd_6 = d-vp3i
                                      d-vp3i%dscr_type = 3
                                      d-vp3i%data_type = 14
                                      d-vp3i%version = 129
                                      d-vp3i%element_len = 8
                                      d-vp3i%rank = 3
                                      d-vp3i%bounds%lbound[].off600 = 1
                                      d-vp3i%bounds%extent[].off608 = max(int(&
                &                       in),0)
                                      d-vp3i%bounds%mult[].off616 = 8
                                      d-vp3i%bounds%lbound[].off576 = 1
                                      d-vp3i%bounds%extent[].off584 = max(int(&
                &                       jn),0)
                                      d-vp3i%bounds%mult[].off592 = max(int(in),&
                &                       0) * 8
                                      d-vp3i%bounds%lbound[].off552 = 1
                                      d-vp3i%bounds%extent[].off560 = max(int(&
                &                       kn),0)
                                      d-vp3i%bounds%mult[].off568 = 8 * (max(&
                &                       int(jn),0) * max(int(in),0))
                                      d-vp3i%rvo = -((1 + (max(int(jn),0) * max(&
                &                       int(in),0) + max(int(in),0))) * 8)
                                      IF ((0 <> (d-vp3i%flags  .AND.  128))) &
                &                       THEN
                                        d-vp3i = bak_rtd_6
                                      ELSE
                                        lab_31
                                        IF ((0 == 8 * (max(int(kn),0) * (max(&
                &                         int(jn),0) * max(int(in),0))))) THEN
                                          d-vp3i%addr = NULL
                                          d-vp3i%flags = 240
                                        ELSE
                                          lab_33
                                          d-vp3i%addr = __xlf_malloc((8 * (max(&
                &                           int(%VAL(kn)),0) * (max(int(%VAL(jn)),&
                &                           0) * max(int(%VAL(in)),0)))),32)
                                          CALL __alignx(32,d-vp3i%addr)
                                          IF (.NOT.(d-vp3i%addr == NULL)) GOTO &
                &                           lab_35
                                          d-vp3i = bak_rtd_6
                                          GOTO lab_36
                                          lab_35
                                          d-vp3i%flags = 240
                                          lab_36
                                          lab_34
                                          lab_32
    67|                                   IF ((myid_w == 0)) THEN
    66|                                     iseed = -500
    68|                                     #14 = _xlfBeginIO(6,257,#13,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#14),&
                &                             "GENVEL                 : &
                &                             ------------------ ",44,1)
                                            _xlfEndIO(%VAL(#14))
    69|                                     #16 = _xlfBeginIO(6,257,#15,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#16),&
                &                             "GENVEL                 : start &
                &                             generate of  ",44,1)
                                            _xlfEndIO(%VAL(#16))
    70|                                     #18 = _xlfBeginIO(6,257,#17,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#18),&
                &                             "GENVEL                 : velocity &
                &                             field     ",44,1)
                                            _xlfEndIO(%VAL(#18))
    71|                                     #20 = _xlfBeginIO(6,257,#19,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#20),&
                &                             "GENVEL                 : &
                &                             ------------------ ",44,1)
                                            _xlfEndIO(%VAL(#20))
    72|                                     CALL ran1(iseed,rnd)
    73|                                   ENDIF
    74|                                   T_2 = 0
                                          CALL fouramp(d-vp1r%addr,d-vp1i%addr,&
                &                           nmodes,idx,T_2)
    75|                                   T_3 = 0
                                          CALL fouramp(d-vp2r%addr,d-vp2i%addr,&
                &                           nmodes,idx,T_3)
    76|                                   T_4 = 0
                                          CALL fouramp(d-vp3r%addr,d-vp3i%addr,&
                &                           nmodes,idx,T_4)
    77|                                   CALL fafotr(d-vp1r%addr,d-vp1i%addr)
    78|                                   CALL fafotr(d-vp2r%addr,d-vp2i%addr)
    79|                                   CALL fafotr(d-vp3r%addr,d-vp3i%addr)
    84|                                   IF ((MOD(int(kn), 4) > 0  .AND.  int(&
                &                           kn) > 0)) THEN
                                            $$DCIV0 = 0
       Id=33                                DO $$DCIV0 = $$DCIV0, MOD(int(kn),&
                &                                int(4))-1
                                              ! DIR_INDEPENDENT loopId = 0 
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV1 = 0
       Id=34                                    DO $$DCIV1 = $$DCIV1, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV2 = 0
       Id=35                                        DO $$DCIV2 = $$DCIV2, int(&
                &                                       int(in))-1
   102|                                               d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,$$DCIV0 + &
                &                                       1) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,&
                &                                       $$DCIV0 + 1) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,$$DCIV0 + 1)) &
                &                                       *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ((int(kn) > 0  .AND.  int(kn) > &
                &                           MOD(int(kn), 4))) THEN
                                            $$CIV9 = int(0)
       Id=10                                DO $$CIV9 = $$CIV9, int((((int(kn)&
                &                                - MOD(int(kn), 4)) - 1) / 4 + 1))&
                &                               -1
                                              ! DIR_INDEPENDENT loopId = 0 
                                              ! DIR_NEW loopId = 10, varId = &
                &                               706 
                                              ! DIR_NEW loopId = 10, varId = &
                &                               707 
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV1 = 0
       Id=11                                    DO $$DCIV1 = $$DCIV1, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV2 = 0
       Id=12                                        DO $$DCIV2 = $$DCIV2, int(&
                &                                       int(in))-1
   102|                                               d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,1 + (&
                &                                       $$CIV9 * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,1 &
                &                                       + ($$CIV9 * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,1 + ($$CIV9 * &
                &                                       4 + MOD(int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,2 + (&
                &                                       $$CIV9 * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,2 &
                &                                       + ($$CIV9 * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,2 + ($$CIV9 * &
                &                                       4 + MOD(int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,3 + (&
                &                                       $$CIV9 * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,3 &
                &                                       + ($$CIV9 * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,3 + ($$CIV9 * &
                &                                       4 + MOD(int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,4 + (&
                &                                       $$CIV9 * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,4 &
                &                                       + ($$CIV9 * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,4 + ($$CIV9 * &
                &                                       4 + MOD(int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ((MOD(int(kn), 4) > 0  .AND.  int(&
                &                           kn) > 0)) THEN
                                            $$DCIV3 = 0
       Id=25                                DO $$DCIV3 = $$DCIV3, MOD(int(kn),&
                &                                int(4))-1
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV4 = 0
       Id=26                                    DO $$DCIV4 = $$DCIV4, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV5 = 0
       Id=27                                        DO $$DCIV5 = $$DCIV5, int(&
                &                                       int(in))-1
   103|                                               d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,$$DCIV4 + 1,$$DCIV3 + &
                &                                       1) = (d-vp2r%addr%vp2r(&
                &                                       $$DCIV5 + 1,$$DCIV4 + 1,&
                &                                       $$DCIV3 + 1) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int(&
                &                                       $$DCIV4) ? int($$DCIV4) + &
                &                                       2 : 1)),$$DCIV3 + 1)) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ((int(kn) > MOD(int(kn), 4)  .AND. &
                &                            int(kn) > 0)) THEN
                                            $$DCIV3 = MOD(int(kn), int(4))
       Id=22                                DO $$DCIV3 = $$DCIV3, int(int(kn))&
                &                               
    90|                                       IF ((MOD(int(jn), 2) > 0  .AND.  &
                &                               int(jn) > 0)) THEN
                                                $$DCIV4 = 0
       Id=28                                    DO $$DCIV4 = $$DCIV4, MOD(int(&
                &                                   jn), int(2))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV5 = 0
       Id=29                                        DO $$DCIV5 = $$DCIV5, int(&
                &                                       int(in))-1
   103|                                               d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,$$DCIV4 + 1,$$DCIV3 + &
                &                                       1) = (d-vp2r%addr%vp2r(&
                &                                       $$DCIV5 + 1,$$DCIV4 + 1,&
                &                                       $$DCIV3 + 1) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int(&
                &                                       $$DCIV4) ? int($$DCIV4) + &
                &                                       2 : 1)),$$DCIV3 + 1)) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ((int(kn) > 0  .AND.  int(kn) > &
                &                           MOD(int(kn), 4))) THEN
                                            $$CIVB = int(0)
       Id=13                                DO $$CIVB = $$CIVB, int((((int(kn)&
                &                                - MOD(int(kn), 4)) - 1) / 4 + 1))&
                &                               -1
    90|                                       IF ((int(jn) > 0  .AND.  int(jn) &
                &                               > MOD(int(jn), 2))) THEN
                                                $$CIVA = int(0)
       Id=14                                    DO $$CIVA = $$CIVA, int((((&
                &                                   int(jn) - MOD(int(jn), 2)) - &
                &                                   1) / 2 + 1))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV5 = 0
       Id=15                                        DO $$DCIV5 = $$DCIV5, int(&
                &                                       int(in))-1
   103|                                               d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),1 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),1 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2))) ? int(($$CIVA * 2 + &
                &                                       MOD(int(jn), 2))) + 2 : 1)&
                &                                       ),1 + ($$CIVB * 4 + MOD(&
                &                                       int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),1 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),1 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((1 &
                &                                       + ($$CIVA * 2 + MOD(int(&
                &                                       jn), 2)))) ? int((1 + (&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2)))) + 2 : 1)),1 + (&
                &                                       $$CIVB * 4 + MOD(int(kn), &
                &                                       4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),2 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),2 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2))) ? int(($$CIVA * 2 + &
                &                                       MOD(int(jn), 2))) + 2 : 1)&
                &                                       ),2 + ($$CIVB * 4 + MOD(&
                &                                       int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),2 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),2 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((1 &
                &                                       + ($$CIVA * 2 + MOD(int(&
                &                                       jn), 2)))) ? int((1 + (&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2)))) + 2 : 1)),2 + (&
                &                                       $$CIVB * 4 + MOD(int(kn), &
                &                                       4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),3 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),3 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2))) ? int(($$CIVA * 2 + &
                &                                       MOD(int(jn), 2))) + 2 : 1)&
                &                                       ),3 + ($$CIVB * 4 + MOD(&
                &                                       int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),3 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),3 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((1 &
                &                                       + ($$CIVA * 2 + MOD(int(&
                &                                       jn), 2)))) ? int((1 + (&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2)))) + 2 : 1)),3 + (&
                &                                       $$CIVB * 4 + MOD(int(kn), &
                &                                       4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),4 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),4 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2))) ? int(($$CIVA * 2 + &
                &                                       MOD(int(jn), 2))) + 2 : 1)&
                &                                       ),4 + ($$CIVB * 4 + MOD(&
                &                                       int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),4 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),4 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((1 &
                &                                       + ($$CIVA * 2 + MOD(int(&
                &                                       jn), 2)))) ? int((1 + (&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2)))) + 2 : 1)),4 + (&
                &                                       $$CIVB * 4 + MOD(int(kn), &
                &                                       4)))) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ((MOD(int(kn), 4) > 0  .AND.  int(&
                &                           kn) > 0)) THEN
                                            $$DCIV6 = 0
       Id=19                                DO $$DCIV6 = $$DCIV6, MOD(int(kn),&
                &                                int(4))-1
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV7 = 0
       Id=20                                    DO $$DCIV7 = $$DCIV7, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV8 = 0
       Id=21                                        DO $$DCIV8 = $$DCIV8, int(&
                &                                       int(in))-1
   104|                                               d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,$$DCIV6 + &
                &                                       1) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,&
                &                                       $$DCIV6 + 1) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int($$DCIV6) ? int(&
                &                                       $$DCIV6) + 2 : 1)))) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ((int(kn) > 0  .AND.  int(kn) > &
                &                           MOD(int(kn), 4))) THEN
                                            $$CIVC = int(0)
       Id=16                                DO $$CIVC = $$CIVC, int((((int(kn)&
                &                                - MOD(int(kn), 4)) - 1) / 4 + 1))&
                &                               -1
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV7 = 0
       Id=17                                    DO $$DCIV7 = $$DCIV7, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV8 = 0
       Id=18                                        DO $$DCIV8 = $$DCIV8, int(&
                &                                       int(in))-1
   104|                                               d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,1 + (&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,1 &
                &                                       + ($$CIVC * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int(($$CIVC * 4 + &
                &                                       MOD(int(kn), 4))) ? int((&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) + 2 : 1)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,2 + (&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,2 &
                &                                       + ($$CIVC * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int((1 + ($$CIVC * 4 &
                &                                       + MOD(int(kn), 4)))) ? &
                &                                       int((1 + ($$CIVC * 4 + &
                &                                       MOD(int(kn), 4)))) + 2 : &
                &                                       1)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,3 + (&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,3 &
                &                                       + ($$CIVC * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int((2 + ($$CIVC * 4 &
                &                                       + MOD(int(kn), 4)))) ? &
                &                                       int((2 + ($$CIVC * 4 + &
                &                                       MOD(int(kn), 4)))) + 2 : &
                &                                       1)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,4 + (&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,4 &
                &                                       + ($$CIVC * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int((3 + ($$CIVC * 4 &
                &                                       + MOD(int(kn), 4)))) ? &
                &                                       int((3 + ($$CIVC * 4 + &
                &                                       MOD(int(kn), 4)))) + 2 : &
                &                                       1)))) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
   109|                                   IF ((int(kn) > 0)) THEN
                                            $$CIV5 = 0
       Id=4                                 DO $$CIV5 = $$CIV5, int(int(kn))&
                &                               -1
   110|                                       IF ((int(jn) > 0)) THEN
                                                $$CIV4 = 0
       Id=5                                     DO $$CIV4 = $$CIV4, int(int(&
                &                                   jn))-1
   111|                                           IF ((int(in) > 0)) THEN
                                                    $$CIV3 = 0
       Id=6                                         DO $$CIV3 = $$CIV3, int(&
                &                                       int(in))-1
   112|                                               d-vp1i%addr%vp1i($$CIV3 + &
                &                                       1,$$CIV4 + 1,$$CIV5 + 1) &
                &                                       = d-w3da%addr%w3da($$CIV3 &
                &                                       + 1,$$CIV4 + 1,$$CIV5 + 1)&
                &                                       
   113|                                               d-vp2i%addr%vp2i($$CIV3 + &
                &                                       1,$$CIV4 + 1,$$CIV5 + 1) &
                &                                       = d-w3db%addr%w3db($$CIV3 &
                &                                       + 1,$$CIV4 + 1,$$CIV5 + 1)&
                &                                       
   114|                                               d-vp3i%addr%vp3i($$CIV3 + &
                &                                       1,$$CIV4 + 1,$$CIV5 + 1) &
                &                                       = d-w3dc%addr%w3dc($$CIV3 &
                &                                       + 1,$$CIV4 + 1,$$CIV5 + 1)&
                &                                       
   115|                                             ENDDO
                                                  ENDIF
   116|                                         ENDDO
                                              ENDIF
   117|                                     ENDDO
                                          ENDIF
   121|                                   nreq = 0
   122|                                   nsub = nsub + 1
   123|                                   T_5 = 3
                                          T_6 = 3
                                          T_7 = 0
                                          T_8 = 0
                                          T_9 = 0
                                          T_10 = 0
                                          CALL bvalv1(T_5,T_6,T_7,T_8,T_9,T_10,&
                &                           d-vp1i%addr)
   124|                                   T_11 = 3
                                          T_12 = 3
                                          T_13 = 0
                                          T_14 = 0
                                          T_15 = 0
                                          T_16 = 0
                                          CALL bvalv2(T_11,T_12,T_13,T_14,T_15,&
                &                           T_16,d-vp2i%addr)
   125|                                   T_17 = 3
                                          T_18 = 3
                                          T_19 = 0
                                          T_20 = 0
                                          T_21 = 0
                                          T_22 = 0
                                          CALL bvalv3(T_17,T_18,T_19,T_20,T_21,&
                &                           T_22,d-vp3i%addr)
   126|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   127|                                   nreq = 0
   128|                                   nsub = nsub + 1
   129|                                   T_23 = 0
                                          T_24 = 0
                                          T_25 = 3
                                          T_26 = 3
                                          T_27 = 0
                                          T_28 = 0
                                          CALL bvalv1(T_23,T_24,T_25,T_26,T_27,&
                &                           T_28,d-vp1i%addr)
   130|                                   T_29 = 0
                                          T_30 = 0
                                          T_31 = 3
                                          T_32 = 3
                                          T_33 = 0
                                          T_34 = 0
                                          CALL bvalv2(T_29,T_30,T_31,T_32,T_33,&
                &                           T_34,d-vp2i%addr)
   131|                                   T_35 = 0
                                          T_36 = 0
                                          T_37 = 3
                                          T_38 = 3
                                          T_39 = 0
                                          T_40 = 0
                                          CALL bvalv3(T_35,T_36,T_37,T_38,T_39,&
                &                           T_40,d-vp3i%addr)
   132|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   133|                                   nreq = 0
   134|                                   nsub = nsub + 1
   135|                                   T_41 = 0
                                          T_42 = 0
                                          T_43 = 0
                                          T_44 = 0
                                          T_45 = 3
                                          T_46 = 3
                                          CALL bvalv1(T_41,T_42,T_43,T_44,T_45,&
                &                           T_46,d-vp1i%addr)
   136|                                   T_47 = 0
                                          T_48 = 0
                                          T_49 = 0
                                          T_50 = 0
                                          T_51 = 3
                                          T_52 = 3
                                          CALL bvalv2(T_47,T_48,T_49,T_50,T_51,&
                &                           T_52,d-vp2i%addr)
   137|                                   T_53 = 0
                                          T_54 = 0
                                          T_55 = 0
                                          T_56 = 0
                                          T_57 = 3
                                          T_58 = 3
                                          CALL bvalv3(T_53,T_54,T_55,T_56,T_57,&
                &                           T_58,d-vp3i%addr)
   138|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   140|                                   IF ((int(kn) > 0)) THEN
                                            $$CIV8 = 0
       Id=7                                 DO $$CIV8 = $$CIV8, int(int(kn))&
                &                               -1
   141|                                       IF ((int(jn) > 0)) THEN
                                                $$CIV7 = 0
       Id=8                                     DO $$CIV7 = $$CIV7, int(int(&
                &                                   jn))-1
   142|                                           IF ((int(in) > 0)) THEN
                                                    $$CIV6 = 0
       Id=9                                         DO $$CIV6 = $$CIV6, int(&
                &                                       int(in))-1
   143|                                               d-v1%addr%v1($$CIV6 + 1,&
                &                                       $$CIV7 + 1,$$CIV8 + 1) = &
                &                                       d-vp1i%addr%vp1i($$CIV6 + &
                &                                       1,$$CIV7 + 1,$$CIV8 + 1)
   144|                                               d-v2%addr%v2($$CIV6 + 1,&
                &                                       $$CIV7 + 1,$$CIV8 + 1) = &
                &                                       d-vp2i%addr%vp2i($$CIV6 + &
                &                                       1,$$CIV7 + 1,$$CIV8 + 1)
   145|                                               d-v3%addr%v3($$CIV6 + 1,&
                &                                       $$CIV7 + 1,$$CIV8 + 1) = &
                &                                       d-vp3i%addr%vp3i($$CIV6 + &
                &                                       1,$$CIV7 + 1,$$CIV8 + 1)
   146|                                             ENDDO
                                                  ENDIF
   147|                                         ENDDO
                                              ENDIF
   148|                                     ENDDO
                                          ENDIF
   149|                                   IF ((0 <> (RSHIFT((int(d-vp1i%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp1i%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp1i%flags  &
                &                             .AND.  32))) GOTO lab_84
                                            filenameaddr_1 = "genvel.f90"
                                            filenamelen_1 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_1,149,NULL)
                                            CALL _trap(3)
                                            RETURN
                                            lab_84
                                            IF ((d-vp1i%addr <> NULL)) THEN
                                              CALL free(d-vp1i%addr)
                                            ENDIF
                                            d-vp1i%flags = d-vp1i%flags  .AND.  &
                &                             15
                                          ENDIF
   150|                                   IF ((0 <> (RSHIFT((int(d-vp1r%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp1r%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp1r%flags  &
                &                             .AND.  32))) GOTO lab_88
                                            filenameaddr_2 = "genvel.f90"
                                            filenamelen_2 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_2,150,NULL)
                                            CALL _trap(3)
                                            RETURN
                                            lab_88
                                            IF ((d-vp1r%addr <> NULL)) THEN
                                              CALL free(d-vp1r%addr)
                                            ENDIF
                                            d-vp1r%flags = d-vp1r%flags  .AND.  &
                &                             15
                                          ENDIF
   151|                                   IF ((0 <> (RSHIFT((int(d-vp2i%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp2i%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp2i%flags  &
                &                             .AND.  32))) GOTO lab_92
                                            filenameaddr_3 = "genvel.f90"
                                            filenamelen_3 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_3,151,NULL)
                                            CALL _trap(3)
                                            RETURN
                                            lab_92
                                            IF ((d-vp2i%addr <> NULL)) THEN
                                              CALL free(d-vp2i%addr)
                                            ENDIF
                                            d-vp2i%flags = d-vp2i%flags  .AND.  &
                &                             15
                                          ENDIF
   152|                                   IF ((0 <> (RSHIFT((int(d-vp2r%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp2r%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp2r%flags  &
                &                             .AND.  32))) GOTO lab_96
                                            filenameaddr_4 = "genvel.f90"
                                            filenamelen_4 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_4,152,NULL)
                                            CALL _trap(3)
                                            RETURN
                                            lab_96
                                            IF ((d-vp2r%addr <> NULL)) THEN
                                              CALL free(d-vp2r%addr)
                                            ENDIF
                                            d-vp2r%flags = d-vp2r%flags  .AND.  &
                &                             15
                                          ENDIF
   153|                                   IF ((0 <> (RSHIFT((int(d-vp3i%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp3i%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp3i%flags  &
                &                             .AND.  32))) GOTO lab_100
                                            filenameaddr_5 = "genvel.f90"
                                            filenamelen_5 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_5,153,NULL)
                                            CALL _trap(3)
                                            RETURN
                                            lab_100
                                            IF ((d-vp3i%addr <> NULL)) THEN
                                              CALL free(d-vp3i%addr)
                                            ENDIF
                                            d-vp3i%flags = d-vp3i%flags  .AND.  &
                &                             15
                                          ENDIF
   154|                                   IF ((0 <> (RSHIFT((int(d-vp3r%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp3r%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp3r%flags  &
                &                             .AND.  32))) GOTO lab_104
                                            filenameaddr_6 = "genvel.f90"
                                            filenamelen_6 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_6,154,NULL)
                                            CALL _trap(3)
                                            RETURN
                                            lab_104
                                            IF ((d-vp3r%addr <> NULL)) THEN
                                              CALL free(d-vp3r%addr)
                                            ENDIF
                                            d-vp3r%flags = d-vp3r%flags  .AND.  &
                &                             15
                                          ENDIF
   159|                                   nreq = 0
   160|                                   nsub = nsub + 1
   161|                                   T_59 = 3
                                          T_60 = 3
                                          T_61 = 0
                                          T_62 = 0
                                          T_63 = 0
                                          T_64 = 0
                                          CALL bvalv1(T_59,T_60,T_61,T_62,T_63,&
                &                           T_64,d-v1%addr)
   162|                                   T_65 = 3
                                          T_66 = 3
                                          T_67 = 0
                                          T_68 = 0
                                          T_69 = 0
                                          T_70 = 0
                                          CALL bvalv2(T_65,T_66,T_67,T_68,T_69,&
                &                           T_70,d-v2%addr)
   163|                                   T_71 = 3
                                          T_72 = 3
                                          T_73 = 0
                                          T_74 = 0
                                          T_75 = 0
                                          T_76 = 0
                                          CALL bvalv3(T_71,T_72,T_73,T_74,T_75,&
                &                           T_76,d-v3%addr)
   164|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   165|                                   nreq = 0
   166|                                   nsub = nsub + 1
   167|                                   T_77 = 0
                                          T_78 = 0
                                          T_79 = 3
                                          T_80 = 3
                                          T_81 = 0
                                          T_82 = 0
                                          CALL bvalv1(T_77,T_78,T_79,T_80,T_81,&
                &                           T_82,d-v1%addr)
   168|                                   T_83 = 0
                                          T_84 = 0
                                          T_85 = 3
                                          T_86 = 3
                                          T_87 = 0
                                          T_88 = 0
                                          CALL bvalv2(T_83,T_84,T_85,T_86,T_87,&
                &                           T_88,d-v2%addr)
   169|                                   T_89 = 0
                                          T_90 = 0
                                          T_91 = 3
                                          T_92 = 3
                                          T_93 = 0
                                          T_94 = 0
                                          CALL bvalv3(T_89,T_90,T_91,T_92,T_93,&
                &                           T_94,d-v3%addr)
   170|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   171|                                   nreq = 0
   172|                                   nsub = nsub + 1
   173|                                   T_95 = 0
                                          T_96 = 0
                                          T_97 = 0
                                          T_98 = 0
                                          T_99 = 3
                                          T_100 = 3
                                          CALL bvalv1(T_95,T_96,T_97,T_98,T_99,&
                &                           T_100,d-v1%addr)
   174|                                   T_101 = 0
                                          T_102 = 0
                                          T_103 = 0
                                          T_104 = 0
                                          T_105 = 3
                                          T_106 = 3
                                          CALL bvalv2(T_101,T_102,T_103,T_104,&
                &                           T_105,T_106,d-v2%addr)
   175|                                   T_107 = 0
                                          T_108 = 0
                                          T_109 = 0
                                          T_110 = 0
                                          T_111 = 3
                                          T_112 = 3
                                          CALL bvalv3(T_107,T_108,T_109,T_110,&
                &                           T_111,T_112,d-v3%addr)
   176|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   180|                                   CALL normvel(vrms)
   183|                                   IF ((myid_w == 0)) THEN
   184|                                     #22 = _xlfBeginIO(6,257,#21,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#22),&
                &                             "GENVEL                 : &
                &                             ------------------ ",44,1)
                                            _xlfEndIO(%VAL(#22))
   185|                                     #24 = _xlfBeginIO(6,257,#23,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#24),&
                &                             "GENVEL                 : &
                &                             generation of ",39,1)
                                            _xlfEndIO(%VAL(#24))
   186|                                     #26 = _xlfBeginIO(6,257,#25,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#26),&
                &                             "GENVEL                 : velocity &
                &                             field ",40,1)
                                            _xlfEndIO(%VAL(#26))
   187|                                     #28 = _xlfBeginIO(6,257,#27,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#28),&
                &                             "GENVEL                 : finished &
                &                             !! ",37,1)
                                            _xlfEndIO(%VAL(#28))
   188|                                     #30 = _xlfBeginIO(6,257,#29,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#30),&
                &                             "GENVEL                 : &
                &                             ------------------ ",44,1)
                                            _xlfEndIO(%VAL(#30))
   189|                                   ENDIF
   190|                                   RETURN
                                        END SUBROUTINE genvel


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0            84            33    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            90            34    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*($$DCIV0 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll))  with 
                                          non-vectorizable alignment.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[$$DCIV0 + 1ll][$$DCIV1 + 
                                          1ll][$$DCIV2 + 1ll] + ((double *)((char *)d-vp1r%addr 
                                          + d-vp1r%rvo))->vp1r[].rns16.[$$DCIV0 + 1ll][$$DCIV1 
                                          + 1ll][(long long) (1 != in - (int) $$DCIV2 ? (int) 
                                          $$DCIV2 + 2 : 1)]) *  5.0000000000000000E-001 which 
                                          is not  suitable for SIMD vectorization.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*($$DCIV0 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with  
                                          non-vectorizable strides.
         0           102                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3da%addr 
                                          + d-w3da%rvo + 
                                          (d-w3da%bounds%mult[].off1224)*($$DCIV0 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
         0            84            10    Outer loop has been unrolled 4 time(s).
         0            84            10    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            90            11    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*(1ll + ($$CIV9 * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll))  with 
                                          non-vectorizable alignment.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[1ll + ($$CIV9 * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] 
                                          + ((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[1ll + ($$CIV9 * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 
                                          != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*(1ll + ($$CIV9 * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with  
                                          non-vectorizable strides.
         0           102                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3da%addr 
                                          + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(1ll + 
                                          ($$CIV9 * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*(2ll + ($$CIV9 * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll))  with 
                                          non-vectorizable alignment.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[2ll + ($$CIV9 * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] 
                                          + ((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[2ll + ($$CIV9 * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 
                                          != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*(2ll + ($$CIV9 * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with  
                                          non-vectorizable strides.
         0           102                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3da%addr 
                                          + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(2ll + 
                                          ($$CIV9 * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*(3ll + ($$CIV9 * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll))  with 
                                          non-vectorizable alignment.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[3ll + ($$CIV9 * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] 
                                          + ((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[3ll + ($$CIV9 * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 
                                          != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*(3ll + ($$CIV9 * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with  
                                          non-vectorizable strides.
         0           102                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3da%addr 
                                          + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(3ll + 
                                          ($$CIV9 * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*(4ll + ($$CIV9 * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll))  with 
                                          non-vectorizable alignment.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[4ll + ($$CIV9 * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV1 + 1ll][$$DCIV2 + 1ll] 
                                          + ((double *)((char *)d-vp1r%addr  + 
                                          d-vp1r%rvo))->vp1r[].rns16.[4ll + ($$CIV9 * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV1 + 1ll][(long long) (1 
                                          != in - (int) $$DCIV2 ? (int) $$DCIV2 + 2 : 1)]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3da%addr  + d-w3da%rvo 
                                          + (d-w3da%bounds%mult[].off1224)*(4ll + ($$CIV9 * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)) with  
                                          non-vectorizable strides.
         0           102                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           102                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3da%addr 
                                          + d-w3da%rvo + (d-w3da%bounds%mult[].off1224)*(4ll + 
                                          ($$CIV9 * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3da%bounds%mult[].off1248)*($$DCIV1 + 1ll) + 
                                          (d-w3da%bounds%mult[].off1272)*($$DCIV2 + 1ll)).
         0            84            25    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            90            26    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][$$DCIV4 + 
                                          1ll][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr 
                                          + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][(long 
                                          long) (1 != jn - (int) $$DCIV4 ? (int) $$DCIV4 + 2 : 
                                          1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which 
                                          is not  suitable for SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + 
                                          (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0            84            22    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            84            22    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0            90            28    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][$$DCIV4 + 
                                          1ll][$$DCIV5 + 1ll] + ((double *)((char *)d-vp2r%addr 
                                          + d-vp2r%rvo))->vp2r[].rns18.[$$DCIV3 + 1ll][(long 
                                          long) (1 != jn - (int) $$DCIV4 ? (int) $$DCIV4 + 2 : 
                                          1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which 
                                          is not  suitable for SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + 
                                          (d-w3db%bounds%mult[].off1328)*($$DCIV3 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1352)*($$DCIV4 + 1ll) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0            84            13    Outer loop has been unrolled 4 time(s).
         0            84            13    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            90            14    Outer loop has been unrolled 2 time(s).
         0            90            14    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + 
                                          (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long 
                                          long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char 
                                          *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 
                                          != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? 
                                          (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 
                                          1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which 
                                          is not  suitable for SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(1ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[1ll + ($$CIVB * 4ll + 
                                          (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long 
                                          long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char 
                                          *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[1ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 
                                          != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 
                                          2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 
                                          2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(1ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(1ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + 
                                          (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long 
                                          long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char 
                                          *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 
                                          != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? 
                                          (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 
                                          1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which 
                                          is not  suitable for SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(2ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[2ll + ($$CIVB * 4ll + 
                                          (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long 
                                          long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char 
                                          *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[2ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 
                                          != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 
                                          2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 
                                          2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(2ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(2ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + 
                                          (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long 
                                          long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char 
                                          *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 
                                          != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? 
                                          (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 
                                          1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which 
                                          is not  suitable for SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(3ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[3ll + ($$CIVB * 4ll + 
                                          (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long 
                                          long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char 
                                          *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[3ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 
                                          != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 
                                          2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 
                                          2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(3ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(3ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + 
                                          (long long) kn % 4ll)][1ll + ($$CIVA * 2ll + (long 
                                          long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char 
                                          *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 
                                          != jn - (int) ($$CIVA * 2ll + (long long) jn % 2ll) ? 
                                          (int) ($$CIVA * 2ll + (long long) jn % 2ll) + 2 : 
                                          1)][$$DCIV5 + 1ll]) *  5.0000000000000000E-001 which 
                                          is not  suitable for SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(4ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(1ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp2r%addr  + 
                                          d-vp2r%rvo))->vp2r[].rns18.[4ll + ($$CIVB * 4ll + 
                                          (long long) kn % 4ll)][2ll + ($$CIVA * 2ll + (long 
                                          long) jn % 2ll)][$$DCIV5 + 1ll] + ((double *)((char 
                                          *)d-vp2r%addr  + d-vp2r%rvo))->vp2r[].rns18.[4ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)][(long long) (1 
                                          != jn - (int) (1ll + ($$CIVA * 2ll + (long long) jn % 
                                          2ll)) ? (int) (1ll + ($$CIVA * 2ll + (long long) jn % 
                                          2ll)) + 2 : 1)][$$DCIV5 + 1ll]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3db%addr  + d-w3db%rvo 
                                          + (d-w3db%bounds%mult[].off1328)*(4ll + ($$CIVB * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3db%addr 
                                          + d-w3db%rvo + (d-w3db%bounds%mult[].off1328)*(4ll + 
                                          ($$CIVB * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3db%bounds%mult[].off1352)*(2ll + ($$CIVA * 2ll + 
                                          (long long) jn % 2ll)) + 
                                          (d-w3db%bounds%mult[].off1376)*($$DCIV5 + 1ll)).
         0            84            19    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            90            20    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*($$DCIV6 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[$$DCIV6 + 1ll][$$DCIV7 + 
                                          1ll][$$DCIV8 + 1ll] + ((double *)((char *)d-vp3r%addr 
                                          + d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - 
                                          (int) $$DCIV6 ? (int) $$DCIV6 + 2 : 1)][$$DCIV7 + 
                                          1ll][$$DCIV8 + 1ll]) *  5.0000000000000000E-001 which 
                                          is not  suitable for SIMD vectorization.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*($$DCIV6 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           104                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dc%addr 
                                          + d-w3dc%rvo + 
                                          (d-w3dc%bounds%mult[].off1432)*($$DCIV6 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
         0            84            16    Outer loop has been unrolled 4 time(s).
         0            84            16    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0            90            17    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*(1ll + ($$CIVC * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[1ll + ($$CIVC * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] 
                                          + ((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - 
                                          (int) ($$CIVC * 4ll + (long long) kn % 4ll) ? (int) 
                                          ($$CIVC * 4ll + (long long) kn % 4ll) + 2 : 
                                          1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*(1ll + ($$CIVC * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           104                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dc%addr 
                                          + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(1ll + 
                                          ($$CIVC * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*(2ll + ($$CIVC * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[2ll + ($$CIVC * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] 
                                          + ((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - 
                                          (int) (1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? 
                                          (int) (1ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 
                                          2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*(2ll + ($$CIVC * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           104                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dc%addr 
                                          + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(2ll + 
                                          ($$CIVC * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*(3ll + ($$CIVC * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[3ll + ($$CIVC * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] 
                                          + ((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - 
                                          (int) (2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? 
                                          (int) (2ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 
                                          2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*(3ll + ($$CIVC * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           104                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dc%addr 
                                          + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(3ll + 
                                          ($$CIVC * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*(4ll + ($$CIVC * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll))  with 
                                          non-vectorizable alignment.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          operation in (((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[4ll + ($$CIVC * 4ll + 
                                          (long long) kn % 4ll)][$$DCIV7 + 1ll][$$DCIV8 + 1ll] 
                                          + ((double *)((char *)d-vp3r%addr  + 
                                          d-vp3r%rvo))->vp3r[].rns20.[(long long) (1 != kn - 
                                          (int) (3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) ? 
                                          (int) (3ll + ($$CIVC * 4ll + (long long) kn % 4ll)) + 
                                          2 : 1)][$$DCIV7 + 1ll][$$DCIV8 + 1ll]) *  
                                          5.0000000000000000E-001 which is not  suitable for 
                                          SIMD vectorization.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-w3dc%addr  + d-w3dc%rvo 
                                          + (d-w3dc%bounds%mult[].off1432)*(4ll + ($$CIVC * 4ll 
                                          + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)) with  
                                          non-vectorizable strides.
         0           104                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-w3dc%addr 
                                          + d-w3dc%rvo + (d-w3dc%bounds%mult[].off1432)*(4ll + 
                                          ($$CIVC * 4ll + (long long) kn % 4ll)) + 
                                          (d-w3dc%bounds%mult[].off1456)*($$DCIV7 + 1ll) + 
                                          (d-w3dc%bounds%mult[].off1480)*($$DCIV8 + 1ll)).
         0           109             4    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           110             5    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           112                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-vp1i%addr  + d-vp1i%rvo 
                                          + (d-vp1i%bounds%mult[].off152)*($$CIV5 + 1ll) + 
                                          (d-vp1i%bounds%mult[].off176)*($$CIV4 + 1ll) + 
                                          (d-vp1i%bounds%mult[].off200)*($$CIV3 + 1ll))  with 
                                          non-vectorizable alignment.
         0           112                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-vp1i%addr  + d-vp1i%rvo 
                                          + (d-vp1i%bounds%mult[].off152)*($$CIV5 + 1ll) + 
                                          (d-vp1i%bounds%mult[].off176)*($$CIV4 + 1ll) + 
                                          (d-vp1i%bounds%mult[].off200)*($$CIV3 + 1ll)) with  
                                          non-vectorizable strides.
         0           112                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           112                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-vp1i%addr 
                                          + d-vp1i%rvo + (d-vp1i%bounds%mult[].off152)*($$CIV5 
                                          + 1ll) + (d-vp1i%bounds%mult[].off176)*($$CIV4 + 1ll) 
                                          + (d-vp1i%bounds%mult[].off200)*($$CIV3 + 1ll)).
         0           113                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-vp2i%addr  + d-vp2i%rvo 
                                          + (d-vp2i%bounds%mult[].off360)*($$CIV5 + 1ll) + 
                                          (d-vp2i%bounds%mult[].off384)*($$CIV4 + 1ll) + 
                                          (d-vp2i%bounds%mult[].off408)*($$CIV3 + 1ll))  with 
                                          non-vectorizable alignment.
         0           113                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-vp2i%addr  + d-vp2i%rvo 
                                          + (d-vp2i%bounds%mult[].off360)*($$CIV5 + 1ll) + 
                                          (d-vp2i%bounds%mult[].off384)*($$CIV4 + 1ll) + 
                                          (d-vp2i%bounds%mult[].off408)*($$CIV3 + 1ll)) with  
                                          non-vectorizable strides.
         0           113                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           113                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-vp2i%addr 
                                          + d-vp2i%rvo + (d-vp2i%bounds%mult[].off360)*($$CIV5 
                                          + 1ll) + (d-vp2i%bounds%mult[].off384)*($$CIV4 + 1ll) 
                                          + (d-vp2i%bounds%mult[].off408)*($$CIV3 + 1ll)).
         0           114                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-vp3i%addr  + d-vp3i%rvo 
                                          + (d-vp3i%bounds%mult[].off568)*($$CIV5 + 1ll) + 
                                          (d-vp3i%bounds%mult[].off592)*($$CIV4 + 1ll) + 
                                          (d-vp3i%bounds%mult[].off616)*($$CIV3 + 1ll))  with 
                                          non-vectorizable alignment.
         0           114                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-vp3i%addr  + d-vp3i%rvo 
                                          + (d-vp3i%bounds%mult[].off568)*($$CIV5 + 1ll) + 
                                          (d-vp3i%bounds%mult[].off592)*($$CIV4 + 1ll) + 
                                          (d-vp3i%bounds%mult[].off616)*($$CIV3 + 1ll)) with  
                                          non-vectorizable strides.
         0           114                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           114                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-vp3i%addr 
                                          + d-vp3i%rvo + (d-vp3i%bounds%mult[].off568)*($$CIV5 
                                          + 1ll) + (d-vp3i%bounds%mult[].off592)*($$CIV4 + 1ll) 
                                          + (d-vp3i%bounds%mult[].off616)*($$CIV3 + 1ll)).
         0           140             7    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           141             8    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           143                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*($$CIV8 + 1ll) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV7 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0           143                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*($$CIV8 + 1ll) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV7 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0           143                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           143                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v1%addr  
                                          + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV8 + 
                                          1ll) + (d-v1%bounds%mult[].off488)*($$CIV7 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV6 + 1ll)).
         0           144                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*($$CIV8 + 1ll) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV7 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0           144                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*($$CIV8 + 1ll) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV7 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0           144                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           144                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v2%addr  
                                          + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV8 + 
                                          1ll) + (d-v2%bounds%mult[].off592)*($$CIV7 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV6 + 1ll)).
         0           145                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*($$CIV8 + 1ll) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV7 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV6 + 1ll))  with 
                                          non-vectorizable alignment.
         0           145                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*($$CIV8 + 1ll) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV7 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV6 + 1ll)) with  
                                          non-vectorizable strides.
         0           145                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           145                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v3%addr  
                                          + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV8 + 
                                          1ll) + (d-v3%bounds%mult[].off696)*($$CIV7 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV6 + 1ll)).


     1|         SUBROUTINE genvel (nmodes, vrms, idx)
    59|           bak_rtd_1 = d-vp1r
                  d-vp1r%dscr_type = 3
                  d-vp1r%data_type = 14
                  d-vp1r%version = 129
                  d-vp1r%element_len = 8
                  d-vp1r%rank = 3
                  d-vp1r%bounds%lbound[].off80 = 1
                  d-vp1r%bounds%extent[].off88 = max(int(in),0)
                  d-vp1r%bounds%mult[].off96 = 8
                  d-vp1r%bounds%lbound[].off56 = 1
                  d-vp1r%bounds%extent[].off64 = max(int(jn),0)
                  d-vp1r%bounds%mult[].off72 = max(int(in),0) * 8
                  d-vp1r%bounds%lbound[].off32 = 1
                  d-vp1r%bounds%extent[].off40 = max(int(kn),0)
                  d-vp1r%bounds%mult[].off48 = 8 * (max(int(jn),0) * max(int(in)&
                &   ,0))
                  d-vp1r%rvo = -((1 + (max(int(jn),0) * max(int(in),0) + max(&
                &   int(in),0))) * 8)
                  IF ((0 <> (d-vp1r%flags  .AND.  128))) THEN
                    d-vp1r = bak_rtd_1
                  ELSE
                    lab_1
                    IF ((0 == 8 * (max(int(kn),0) * (max(int(jn),0) * max(int(&
                &     in),0))))) THEN
                      d-vp1r%addr = NULL
                      d-vp1r%flags = 240
                    ELSE
                      lab_3
                      d-vp1r%addr = __xlf_malloc(8 * (max(int(%VAL(kn)),0) * (&
                &       max(int(%VAL(jn)),0) * max(int(%VAL(in)),0))),32)
                      CALL __alignx(32,d-vp1r%addr)
                      IF (.NOT.(d-vp1r%addr == NULL)) GOTO lab_5
                      d-vp1r = bak_rtd_1
                      GOTO lab_6
                      lab_5
                      d-vp1r%flags = 240
                      lab_6
                      lab_4
                      lab_2
    60|               bak_rtd_2 = d-vp1i
                      d-vp1i%dscr_type = 3
                      d-vp1i%data_type = 14
                      d-vp1i%version = 129
                      d-vp1i%element_len = 8
                      d-vp1i%rank = 3
                      d-vp1i%bounds%lbound[].off184 = 1
                      d-vp1i%bounds%extent[].off192 = max(int(in),0)
                      d-vp1i%bounds%mult[].off200 = 8
                      d-vp1i%bounds%lbound[].off160 = 1
                      d-vp1i%bounds%extent[].off168 = max(int(jn),0)
                      d-vp1i%bounds%mult[].off176 = max(int(in),0) * 8
                      d-vp1i%bounds%lbound[].off136 = 1
                      d-vp1i%bounds%extent[].off144 = max(int(kn),0)
                      d-vp1i%bounds%mult[].off152 = 8 * (max(int(jn),0) * max(&
                &       int(in),0))
                      d-vp1i%rvo = -((1 + (max(int(jn),0) * max(int(in),0) + &
                &       max(int(in),0))) * 8)
                      IF ((0 <> (d-vp1i%flags  .AND.  128))) THEN
                        d-vp1i = bak_rtd_2
                      ELSE
                        lab_7
                        IF ((0 == 8 * (max(int(kn),0) * (max(int(jn),0) * max(&
                &         int(in),0))))) THEN
                          d-vp1i%addr = NULL
                          d-vp1i%flags = 240
                        ELSE
                          lab_9
                          d-vp1i%addr = __xlf_malloc(8 * (max(int(%VAL(kn)),0) &
                &           * (max(int(%VAL(jn)),0) * max(int(%VAL(in)),0))),32)
                          CALL __alignx(32,d-vp1i%addr)
                          IF (.NOT.(d-vp1i%addr == NULL)) GOTO lab_11
                          d-vp1i = bak_rtd_2
                          GOTO lab_12
                          lab_11
                          d-vp1i%flags = 240
                          lab_12
                          lab_10
                          lab_8
    61|                   bak_rtd_3 = d-vp2r
                          d-vp2r%dscr_type = 3
                          d-vp2r%data_type = 14
                          d-vp2r%version = 129
                          d-vp2r%element_len = 8
                          d-vp2r%rank = 3
                          d-vp2r%bounds%lbound[].off288 = 1
                          d-vp2r%bounds%extent[].off296 = max(int(in),0)
                          d-vp2r%bounds%mult[].off304 = 8
                          d-vp2r%bounds%lbound[].off264 = 1
                          d-vp2r%bounds%extent[].off272 = max(int(jn),0)
                          d-vp2r%bounds%mult[].off280 = max(int(in),0) * 8
                          d-vp2r%bounds%lbound[].off240 = 1
                          d-vp2r%bounds%extent[].off248 = max(int(kn),0)
                          d-vp2r%bounds%mult[].off256 = 8 * (max(int(jn),0) * &
                &           max(int(in),0))
                          d-vp2r%rvo = -((1 + (max(int(jn),0) * max(int(in),0) &
                &           + max(int(in),0))) * 8)
                          IF ((0 <> (d-vp2r%flags  .AND.  128))) THEN
                            d-vp2r = bak_rtd_3
                          ELSE
                            lab_13
                            IF ((0 == 8 * (max(int(kn),0) * (max(int(jn),0) * &
                &             max(int(in),0))))) THEN
                              d-vp2r%addr = NULL
                              d-vp2r%flags = 240
                            ELSE
                              lab_15
                              d-vp2r%addr = __xlf_malloc(8 * (max(int(%VAL(kn)),&
                &               0) * (max(int(%VAL(jn)),0) * max(int(%VAL(in)),0))&
                &               ),32)
                              CALL __alignx(32,d-vp2r%addr)
                              IF (.NOT.(d-vp2r%addr == NULL)) GOTO lab_17
                              d-vp2r = bak_rtd_3
                              GOTO lab_18
                              lab_17
                              d-vp2r%flags = 240
                              lab_18
                              lab_16
                              lab_14
    62|                       bak_rtd_4 = d-vp2i
                              d-vp2i%dscr_type = 3
                              d-vp2i%data_type = 14
                              d-vp2i%version = 129
                              d-vp2i%element_len = 8
                              d-vp2i%rank = 3
                              d-vp2i%bounds%lbound[].off392 = 1
                              d-vp2i%bounds%extent[].off400 = max(int(in),0)
                              d-vp2i%bounds%mult[].off408 = 8
                              d-vp2i%bounds%lbound[].off368 = 1
                              d-vp2i%bounds%extent[].off376 = max(int(jn),0)
                              d-vp2i%bounds%mult[].off384 = max(int(in),0) * 8
                              d-vp2i%bounds%lbound[].off344 = 1
                              d-vp2i%bounds%extent[].off352 = max(int(kn),0)
                              d-vp2i%bounds%mult[].off360 = 8 * (max(int(jn),0) &
                &               * max(int(in),0))
                              d-vp2i%rvo = -((1 + (max(int(jn),0) * max(int(in),&
                &               0) + max(int(in),0))) * 8)
                              IF ((0 <> (d-vp2i%flags  .AND.  128))) THEN
                                d-vp2i = bak_rtd_4
                              ELSE
                                lab_19
                                IF ((0 == 8 * (max(int(kn),0) * (max(int(jn),0) &
                &                 * max(int(in),0))))) THEN
                                  d-vp2i%addr = NULL
                                  d-vp2i%flags = 240
                                ELSE
                                  lab_21
                                  d-vp2i%addr = __xlf_malloc(8 * (max(int(%VAL(&
                &                   kn)),0) * (max(int(%VAL(jn)),0) * max(int(&
                &                   %VAL(in)),0))),32)
                                  CALL __alignx(32,d-vp2i%addr)
                                  IF (.NOT.(d-vp2i%addr == NULL)) GOTO lab_23
                                  d-vp2i = bak_rtd_4
                                  GOTO lab_24
                                  lab_23
                                  d-vp2i%flags = 240
                                  lab_24
                                  lab_22
                                  lab_20
    63|                           bak_rtd_5 = d-vp3r
                                  d-vp3r%dscr_type = 3
                                  d-vp3r%data_type = 14
                                  d-vp3r%version = 129
                                  d-vp3r%element_len = 8
                                  d-vp3r%rank = 3
                                  d-vp3r%bounds%lbound[].off496 = 1
                                  d-vp3r%bounds%extent[].off504 = max(int(in),0)&
                &                   
                                  d-vp3r%bounds%mult[].off512 = 8
                                  d-vp3r%bounds%lbound[].off472 = 1
                                  d-vp3r%bounds%extent[].off480 = max(int(jn),0)&
                &                   
                                  d-vp3r%bounds%mult[].off488 = max(int(in),0) &
                &                   * 8
                                  d-vp3r%bounds%lbound[].off448 = 1
                                  d-vp3r%bounds%extent[].off456 = max(int(kn),0)&
                &                   
                                  d-vp3r%bounds%mult[].off464 = 8 * (max(int(jn)&
                &                   ,0) * max(int(in),0))
                                  d-vp3r%rvo = -((1 + (max(int(jn),0) * max(int(&
                &                   in),0) + max(int(in),0))) * 8)
                                  IF ((0 <> (d-vp3r%flags  .AND.  128))) THEN
                                    d-vp3r = bak_rtd_5
                                  ELSE
                                    lab_25
                                    IF ((0 == 8 * (max(int(kn),0) * (max(int(jn)&
                &                     ,0) * max(int(in),0))))) THEN
                                      d-vp3r%addr = NULL
                                      d-vp3r%flags = 240
                                    ELSE
                                      lab_27
                                      d-vp3r%addr = __xlf_malloc(8 * (max(int(&
                &                       %VAL(kn)),0) * (max(int(%VAL(jn)),0) * &
                &                       max(int(%VAL(in)),0))),32)
                                      CALL __alignx(32,d-vp3r%addr)
                                      IF (.NOT.(d-vp3r%addr == NULL)) GOTO &
                &                       lab_29
                                      d-vp3r = bak_rtd_5
                                      GOTO lab_30
                                      lab_29
                                      d-vp3r%flags = 240
                                      lab_30
                                      lab_28
                                      lab_26
    64|                               bak_rtd_6 = d-vp3i
                                      d-vp3i%dscr_type = 3
                                      d-vp3i%data_type = 14
                                      d-vp3i%version = 129
                                      d-vp3i%element_len = 8
                                      d-vp3i%rank = 3
                                      d-vp3i%bounds%lbound[].off600 = 1
                                      d-vp3i%bounds%extent[].off608 = max(int(&
                &                       in),0)
                                      d-vp3i%bounds%mult[].off616 = 8
                                      d-vp3i%bounds%lbound[].off576 = 1
                                      d-vp3i%bounds%extent[].off584 = max(int(&
                &                       jn),0)
                                      d-vp3i%bounds%mult[].off592 = max(int(in),&
                &                       0) * 8
                                      d-vp3i%bounds%lbound[].off552 = 1
                                      d-vp3i%bounds%extent[].off560 = max(int(&
                &                       kn),0)
                                      d-vp3i%bounds%mult[].off568 = 8 * (max(&
                &                       int(jn),0) * max(int(in),0))
                                      d-vp3i%rvo = -((1 + (max(int(jn),0) * max(&
                &                       int(in),0) + max(int(in),0))) * 8)
                                      IF ((0 <> (d-vp3i%flags  .AND.  128))) &
                &                       THEN
                                        d-vp3i = bak_rtd_6
                                      ELSE
                                        lab_31
                                        IF ((0 == 8 * (max(int(kn),0) * (max(&
                &                         int(jn),0) * max(int(in),0))))) THEN
                                          d-vp3i%addr = NULL
                                          d-vp3i%flags = 240
                                        ELSE
                                          lab_33
                                          d-vp3i%addr = __xlf_malloc(8 * (max(&
                &                           int(%VAL(kn)),0) * (max(int(%VAL(jn)),&
                &                           0) * max(int(%VAL(in)),0))),32)
                                          CALL __alignx(32,d-vp3i%addr)
                                          IF (.NOT.(d-vp3i%addr == NULL)) GOTO &
                &                           lab_35
                                          d-vp3i = bak_rtd_6
                                          GOTO lab_36
                                          lab_35
                                          d-vp3i%flags = 240
                                          lab_36
                                          lab_34
                                          lab_32
    67|                                   IF ((myid_w == 0)) THEN
    66|                                     iseed = -500
    68|                                     #14 = _xlfBeginIO(6,257,#13,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#14),&
                &                             "GENVEL                 : &
                &                             ------------------ ",44,1)
                                            _xlfEndIO(%VAL(#14))
    69|                                     #16 = _xlfBeginIO(6,257,#15,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#16),&
                &                             "GENVEL                 : start &
                &                             generate of  ",44,1)
                                            _xlfEndIO(%VAL(#16))
    70|                                     #18 = _xlfBeginIO(6,257,#17,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#18),&
                &                             "GENVEL                 : velocity &
                &                             field     ",44,1)
                                            _xlfEndIO(%VAL(#18))
    71|                                     #20 = _xlfBeginIO(6,257,#19,32768,&
                &                             NULL,0,NULL)
                                            CALL _xlfWriteLDChar(%VAL(#20),&
                &                             "GENVEL                 : &
                &                             ------------------ ",44,1)
                                            _xlfEndIO(%VAL(#20))
    72|                                     CALL ran1(iseed,rnd)
    73|                                   ENDIF
    74|                                   T_2 = 0
                                          CALL fouramp(d-vp1r%addr,d-vp1i%addr,&
                &                           nmodes,idx,T_2)
    75|                                   T_3 = 0
                                          CALL fouramp(d-vp2r%addr,d-vp2i%addr,&
                &                           nmodes,idx,T_3)
    76|                                   T_4 = 0
                                          CALL fouramp(d-vp3r%addr,d-vp3i%addr,&
                &                           nmodes,idx,T_4)
    77|                                   CALL fafotr(d-vp1r%addr,d-vp1i%addr)
    78|                                   CALL fafotr(d-vp2r%addr,d-vp2i%addr)
    79|                                   CALL fafotr(d-vp3r%addr,d-vp3i%addr)
    84|                                   IF ((MOD(int(kn), 4) > 0  .AND.  int(&
                &                           kn) > 0)) THEN
                                            $$DCIV0 = 0
       Id=33                                DO $$DCIV0 = $$DCIV0, MOD(int(kn),&
                &                                int(4))-1
                                              ! DIR_INDEPENDENT loopId = 0 
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV1 = 0
       Id=34                                    DO $$DCIV1 = $$DCIV1, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV2 = 0
       Id=35                                        DO $$DCIV2 = $$DCIV2, int(&
                &                                       int(in))-1
   102|                                               d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,$$DCIV0 + &
                &                                       1) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,&
                &                                       $$DCIV0 + 1) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,$$DCIV0 + 1)) &
                &                                       *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          $$csx0 = int(kn) > 0  .AND.  int(kn) &
                &                           > MOD(int(kn), 4)
                                          IF ($$csx0) THEN
                                            $$CIV9 = int(0)
       Id=10                                DO $$CIV9 = $$CIV9, int((((int(kn)&
                &                                - MOD(int(kn), 4)) - 1) / 4 + 1))&
                &                               -1
                                              ! DIR_INDEPENDENT loopId = 0 
                                              ! DIR_NEW loopId = 10, varId = &
                &                               706 
                                              ! DIR_NEW loopId = 10, varId = &
                &                               707 
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV1 = 0
       Id=11                                    DO $$DCIV1 = $$DCIV1, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV2 = 0
       Id=12                                        DO $$DCIV2 = $$DCIV2, int(&
                &                                       int(in))-1
   102|                                               d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,1 + (&
                &                                       $$CIV9 * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,1 &
                &                                       + ($$CIV9 * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,1 + ($$CIV9 * &
                &                                       4 + MOD(int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,2 + (&
                &                                       $$CIV9 * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,2 &
                &                                       + ($$CIV9 * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,2 + ($$CIV9 * &
                &                                       4 + MOD(int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,3 + (&
                &                                       $$CIV9 * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,3 &
                &                                       + ($$CIV9 * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,3 + ($$CIV9 * &
                &                                       4 + MOD(int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3da%addr%w3da($$DCIV2 &
                &                                       + 1,$$DCIV1 + 1,4 + (&
                &                                       $$CIV9 * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp1r%addr%vp1r(&
                &                                       $$DCIV2 + 1,$$DCIV1 + 1,4 &
                &                                       + ($$CIV9 * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp1r%addr%vp1r(int((1 &
                &                                       <> in - int($$DCIV2) ? &
                &                                       int($$DCIV2) + 2 : 1)),&
                &                                       $$DCIV1 + 1,4 + ($$CIV9 * &
                &                                       4 + MOD(int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ((MOD(int(kn), 4) > 0  .AND.  int(&
                &                           kn) > 0)) THEN
                                            $$DCIV3 = 0
       Id=25                                DO $$DCIV3 = $$DCIV3, MOD(int(kn),&
                &                                int(4))-1
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV4 = 0
       Id=26                                    DO $$DCIV4 = $$DCIV4, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV5 = 0
       Id=27                                        DO $$DCIV5 = $$DCIV5, int(&
                &                                       int(in))-1
   103|                                               d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,$$DCIV4 + 1,$$DCIV3 + &
                &                                       1) = (d-vp2r%addr%vp2r(&
                &                                       $$DCIV5 + 1,$$DCIV4 + 1,&
                &                                       $$DCIV3 + 1) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int(&
                &                                       $$DCIV4) ? int($$DCIV4) + &
                &                                       2 : 1)),$$DCIV3 + 1)) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ($$csx0) THEN
                                            $$DCIV3 = MOD(int(kn), int(4))
       Id=22                                DO $$DCIV3 = $$DCIV3, int(int(kn))&
                &                               
    90|                                       IF ((MOD(int(jn), 2) > 0  .AND.  &
                &                               int(jn) > 0)) THEN
                                                $$DCIV4 = 0
       Id=28                                    DO $$DCIV4 = $$DCIV4, MOD(int(&
                &                                   jn), int(2))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV5 = 0
       Id=29                                        DO $$DCIV5 = $$DCIV5, int(&
                &                                       int(in))-1
   103|                                               d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,$$DCIV4 + 1,$$DCIV3 + &
                &                                       1) = (d-vp2r%addr%vp2r(&
                &                                       $$DCIV5 + 1,$$DCIV4 + 1,&
                &                                       $$DCIV3 + 1) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int(&
                &                                       $$DCIV4) ? int($$DCIV4) + &
                &                                       2 : 1)),$$DCIV3 + 1)) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ($$csx0) THEN
                                            $$CIVB = int(0)
       Id=13                                DO $$CIVB = $$CIVB, int((((int(kn)&
                &                                - MOD(int(kn), 4)) - 1) / 4 + 1))&
                &                               -1
    90|                                       IF ((int(jn) > 0  .AND.  int(jn) &
                &                               > MOD(int(jn), 2))) THEN
                                                $$CIVA = int(0)
       Id=14                                    DO $$CIVA = $$CIVA, int((((&
                &                                   int(jn) - MOD(int(jn), 2)) - &
                &                                   1) / 2 + 1))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV5 = 0
       Id=15                                        DO $$DCIV5 = $$DCIV5, int(&
                &                                       int(in))-1
   103|                                               d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),1 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),1 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2))) ? int(($$CIVA * 2 + &
                &                                       MOD(int(jn), 2))) + 2 : 1)&
                &                                       ),1 + ($$CIVB * 4 + MOD(&
                &                                       int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),1 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),1 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((1 &
                &                                       + ($$CIVA * 2 + MOD(int(&
                &                                       jn), 2)))) ? int((1 + (&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2)))) + 2 : 1)),1 + (&
                &                                       $$CIVB * 4 + MOD(int(kn), &
                &                                       4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),2 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),2 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2))) ? int(($$CIVA * 2 + &
                &                                       MOD(int(jn), 2))) + 2 : 1)&
                &                                       ),2 + ($$CIVB * 4 + MOD(&
                &                                       int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),2 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),2 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((1 &
                &                                       + ($$CIVA * 2 + MOD(int(&
                &                                       jn), 2)))) ? int((1 + (&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2)))) + 2 : 1)),2 + (&
                &                                       $$CIVB * 4 + MOD(int(kn), &
                &                                       4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),3 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),3 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2))) ? int(($$CIVA * 2 + &
                &                                       MOD(int(jn), 2))) + 2 : 1)&
                &                                       ),3 + ($$CIVB * 4 + MOD(&
                &                                       int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),3 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),3 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((1 &
                &                                       + ($$CIVA * 2 + MOD(int(&
                &                                       jn), 2)))) ? int((1 + (&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2)))) + 2 : 1)),3 + (&
                &                                       $$CIVB * 4 + MOD(int(kn), &
                &                                       4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),4 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,1 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),4 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2))) ? int(($$CIVA * 2 + &
                &                                       MOD(int(jn), 2))) + 2 : 1)&
                &                                       ),4 + ($$CIVB * 4 + MOD(&
                &                                       int(kn), 4)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3db%addr%w3db($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),4 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) = &
                &                                       (d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,2 + ($$CIVA * 2 + MOD(&
                &                                       int(jn), 2)),4 + ($$CIVB &
                &                                       * 4 + MOD(int(kn), 4))) + &
                &                                       d-vp2r%addr%vp2r($$DCIV5 &
                &                                       + 1,int((1 <> jn - int((1 &
                &                                       + ($$CIVA * 2 + MOD(int(&
                &                                       jn), 2)))) ? int((1 + (&
                &                                       $$CIVA * 2 + MOD(int(jn), &
                &                                       2)))) + 2 : 1)),4 + (&
                &                                       $$CIVB * 4 + MOD(int(kn), &
                &                                       4)))) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ((MOD(int(kn), 4) > 0  .AND.  int(&
                &                           kn) > 0)) THEN
                                            $$DCIV6 = 0
       Id=19                                DO $$DCIV6 = $$DCIV6, MOD(int(kn),&
                &                                int(4))-1
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV7 = 0
       Id=20                                    DO $$DCIV7 = $$DCIV7, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV8 = 0
       Id=21                                        DO $$DCIV8 = $$DCIV8, int(&
                &                                       int(in))-1
   104|                                               d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,$$DCIV6 + &
                &                                       1) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,&
                &                                       $$DCIV6 + 1) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int($$DCIV6) ? int(&
                &                                       $$DCIV6) + 2 : 1)))) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
                                          IF ($$csx0) THEN
                                            $$CIVC = int(0)
       Id=16                                DO $$CIVC = $$CIVC, int((((int(kn)&
                &                                - MOD(int(kn), 4)) - 1) / 4 + 1))&
                &                               -1
    90|                                       IF ((int(jn) > 0)) THEN
                                                $$DCIV7 = 0
       Id=17                                    DO $$DCIV7 = $$DCIV7, int(int(&
                &                                   jn))-1
    96|                                           IF ((int(in) > 0)) THEN
                                                    $$DCIV8 = 0
       Id=18                                        DO $$DCIV8 = $$DCIV8, int(&
                &                                       int(in))-1
   104|                                               d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,1 + (&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,1 &
                &                                       + ($$CIVC * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int(($$CIVC * 4 + &
                &                                       MOD(int(kn), 4))) ? int((&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) + 2 : 1)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,2 + (&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,2 &
                &                                       + ($$CIVC * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int((1 + ($$CIVC * 4 &
                &                                       + MOD(int(kn), 4)))) ? &
                &                                       int((1 + ($$CIVC * 4 + &
                &                                       MOD(int(kn), 4)))) + 2 : &
                &                                       1)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,3 + (&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,3 &
                &                                       + ($$CIVC * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int((2 + ($$CIVC * 4 &
                &                                       + MOD(int(kn), 4)))) ? &
                &                                       int((2 + ($$CIVC * 4 + &
                &                                       MOD(int(kn), 4)))) + 2 : &
                &                                       1)))) *  &
                &                                       5.0000000000000000E-001
                                                      d-w3dc%addr%w3dc($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,4 + (&
                &                                       $$CIVC * 4 + MOD(int(kn), &
                &                                       4))) = (d-vp3r%addr%vp3r(&
                &                                       $$DCIV8 + 1,$$DCIV7 + 1,4 &
                &                                       + ($$CIVC * 4 + MOD(int(&
                &                                       kn), 4))) + &
                &                                       d-vp3r%addr%vp3r($$DCIV8 &
                &                                       + 1,$$DCIV7 + 1,int((1 <> &
                &                                       kn - int((3 + ($$CIVC * 4 &
                &                                       + MOD(int(kn), 4)))) ? &
                &                                       int((3 + ($$CIVC * 4 + &
                &                                       MOD(int(kn), 4)))) + 2 : &
                &                                       1)))) *  &
                &                                       5.0000000000000000E-001
    96|                                             ENDDO
                                                  ENDIF
    90|                                         ENDDO
                                              ENDIF
    84|                                     ENDDO
                                          ENDIF
   109|                                   IF ((int(kn) > 0)) THEN
                                            $$CIV5 = 0
       Id=4                                 DO $$CIV5 = $$CIV5, int(int(kn))&
                &                               -1
   110|                                       IF ((int(jn) > 0)) THEN
                                                $$CIV4 = 0
       Id=5                                     DO $$CIV4 = $$CIV4, int(int(&
                &                                   jn))-1
   111|                                           IF ((int(in) > 0)) THEN
                                                    $$CIV3 = 0
       Id=6                                         DO $$CIV3 = $$CIV3, int(&
                &                                       int(in))-1
   112|                                               d-vp1i%addr%vp1i($$CIV3 + &
                &                                       1,$$CIV4 + 1,$$CIV5 + 1) &
                &                                       = d-w3da%addr%w3da($$CIV3 &
                &                                       + 1,$$CIV4 + 1,$$CIV5 + 1)&
                &                                       
   113|                                               d-vp2i%addr%vp2i($$CIV3 + &
                &                                       1,$$CIV4 + 1,$$CIV5 + 1) &
                &                                       = d-w3db%addr%w3db($$CIV3 &
                &                                       + 1,$$CIV4 + 1,$$CIV5 + 1)&
                &                                       
   114|                                               d-vp3i%addr%vp3i($$CIV3 + &
                &                                       1,$$CIV4 + 1,$$CIV5 + 1) &
                &                                       = d-w3dc%addr%w3dc($$CIV3 &
                &                                       + 1,$$CIV4 + 1,$$CIV5 + 1)&
                &                                       
   115|                                             ENDDO
                                                  ENDIF
   116|                                         ENDDO
                                              ENDIF
   117|                                     ENDDO
                                          ENDIF
   121|                                   nreq = 0
   122|                                   nsub = nsub + 1
   123|                                   T_5 = 3
                                          T_6 = 3
                                          T_7 = 0
                                          T_8 = 0
                                          T_9 = 0
                                          T_10 = 0
                                          CALL bvalv1(T_5,T_6,T_7,T_8,T_9,T_10,&
                &                           d-vp1i%addr)
   124|                                   T_11 = 3
                                          T_12 = 3
                                          T_13 = 0
                                          T_14 = 0
                                          T_15 = 0
                                          T_16 = 0
                                          CALL bvalv2(T_11,T_12,T_13,T_14,T_15,&
                &                           T_16,d-vp2i%addr)
   125|                                   T_17 = 3
                                          T_18 = 3
                                          T_19 = 0
                                          T_20 = 0
                                          T_21 = 0
                                          T_22 = 0
                                          CALL bvalv3(T_17,T_18,T_19,T_20,T_21,&
                &                           T_22,d-vp3i%addr)
   126|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   127|                                   nreq = 0
   128|                                   nsub = nsub + 1
   129|                                   T_23 = 0
                                          T_24 = 0
                                          T_25 = 3
                                          T_26 = 3
                                          T_27 = 0
                                          T_28 = 0
                                          CALL bvalv1(T_23,T_24,T_25,T_26,T_27,&
                &                           T_28,d-vp1i%addr)
   130|                                   T_29 = 0
                                          T_30 = 0
                                          T_31 = 3
                                          T_32 = 3
                                          T_33 = 0
                                          T_34 = 0
                                          CALL bvalv2(T_29,T_30,T_31,T_32,T_33,&
                &                           T_34,d-vp2i%addr)
   131|                                   T_35 = 0
                                          T_36 = 0
                                          T_37 = 3
                                          T_38 = 3
                                          T_39 = 0
                                          T_40 = 0
                                          CALL bvalv3(T_35,T_36,T_37,T_38,T_39,&
                &                           T_40,d-vp3i%addr)
   132|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   133|                                   nreq = 0
   134|                                   nsub = nsub + 1
   135|                                   T_41 = 0
                                          T_42 = 0
                                          T_43 = 0
                                          T_44 = 0
                                          T_45 = 3
                                          T_46 = 3
                                          CALL bvalv1(T_41,T_42,T_43,T_44,T_45,&
                &                           T_46,d-vp1i%addr)
   136|                                   T_47 = 0
                                          T_48 = 0
                                          T_49 = 0
                                          T_50 = 0
                                          T_51 = 3
                                          T_52 = 3
                                          CALL bvalv2(T_47,T_48,T_49,T_50,T_51,&
                &                           T_52,d-vp2i%addr)
   137|                                   T_53 = 0
                                          T_54 = 0
                                          T_55 = 0
                                          T_56 = 0
                                          T_57 = 3
                                          T_58 = 3
                                          CALL bvalv3(T_53,T_54,T_55,T_56,T_57,&
                &                           T_58,d-vp3i%addr)
   138|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   140|                                   IF ((int(kn) > 0)) THEN
                                            $$CIV8 = 0
       Id=7                                 DO $$CIV8 = $$CIV8, int(int(kn))&
                &                               -1
   141|                                       IF ((int(jn) > 0)) THEN
                                                $$CIV7 = 0
       Id=8                                     DO $$CIV7 = $$CIV7, int(int(&
                &                                   jn))-1
   142|                                           IF ((int(in) > 0)) THEN
                                                    $$CIV6 = 0
       Id=9                                         DO $$CIV6 = $$CIV6, int(&
                &                                       int(in))-1
   143|                                               d-v1%addr%v1($$CIV6 + 1,&
                &                                       $$CIV7 + 1,$$CIV8 + 1) = &
                &                                       d-vp1i%addr%vp1i($$CIV6 + &
                &                                       1,$$CIV7 + 1,$$CIV8 + 1)
   144|                                               d-v2%addr%v2($$CIV6 + 1,&
                &                                       $$CIV7 + 1,$$CIV8 + 1) = &
                &                                       d-vp2i%addr%vp2i($$CIV6 + &
                &                                       1,$$CIV7 + 1,$$CIV8 + 1)
   145|                                               d-v3%addr%v3($$CIV6 + 1,&
                &                                       $$CIV7 + 1,$$CIV8 + 1) = &
                &                                       d-vp3i%addr%vp3i($$CIV6 + &
                &                                       1,$$CIV7 + 1,$$CIV8 + 1)
   146|                                             ENDDO
                                                  ENDIF
   147|                                         ENDDO
                                              ENDIF
   148|                                     ENDDO
                                          ENDIF
   149|                                   IF ((0 <> (RSHIFT((int(d-vp1i%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp1i%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp1i%flags  &
                &                             .AND.  32))) GOTO lab_84
                                            filenameaddr_1 = "genvel.f90"
                                            filenamelen_1 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_1,149,NULL)
                                            CALL _trap(3)
                                            GOTO lab_110
                                            lab_84
                                            IF ((d-vp1i%addr <> NULL)) THEN
                                              CALL free(d-vp1i%addr)
                                            ENDIF
                                            d-vp1i%flags = d-vp1i%flags  .AND.  &
                &                             15
                                          ENDIF
   150|                                   IF ((0 <> (RSHIFT((int(d-vp1r%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp1r%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp1r%flags  &
                &                             .AND.  32))) GOTO lab_88
                                            filenameaddr_2 = "genvel.f90"
                                            filenamelen_2 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_2,150,NULL)
                                            CALL _trap(3)
                                            GOTO lab_110
                                            lab_88
                                            IF ((d-vp1r%addr <> NULL)) THEN
                                              CALL free(d-vp1r%addr)
                                            ENDIF
                                            d-vp1r%flags = d-vp1r%flags  .AND.  &
                &                             15
                                          ENDIF
   151|                                   IF ((0 <> (RSHIFT((int(d-vp2i%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp2i%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp2i%flags  &
                &                             .AND.  32))) GOTO lab_92
                                            filenameaddr_3 = "genvel.f90"
                                            filenamelen_3 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_3,151,NULL)
                                            CALL _trap(3)
                                            GOTO lab_110
                                            lab_92
                                            IF ((d-vp2i%addr <> NULL)) THEN
                                              CALL free(d-vp2i%addr)
                                            ENDIF
                                            d-vp2i%flags = d-vp2i%flags  .AND.  &
                &                             15
                                          ENDIF
   152|                                   IF ((0 <> (RSHIFT((int(d-vp2r%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp2r%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp2r%flags  &
                &                             .AND.  32))) GOTO lab_96
                                            filenameaddr_4 = "genvel.f90"
                                            filenamelen_4 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_4,152,NULL)
                                            CALL _trap(3)
                                            GOTO lab_110
                                            lab_96
                                            IF ((d-vp2r%addr <> NULL)) THEN
                                              CALL free(d-vp2r%addr)
                                            ENDIF
                                            d-vp2r%flags = d-vp2r%flags  .AND.  &
                &                             15
                                          ENDIF
   153|                                   IF ((0 <> (RSHIFT((int(d-vp3i%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp3i%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp3i%flags  &
                &                             .AND.  32))) GOTO lab_100
                                            filenameaddr_5 = "genvel.f90"
                                            filenamelen_5 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_5,153,NULL)
                                            CALL _trap(3)
                                            GOTO lab_110
                                            lab_100
                                            IF ((d-vp3i%addr <> NULL)) THEN
                                              CALL free(d-vp3i%addr)
                                            ENDIF
                                            d-vp3i%flags = d-vp3i%flags  .AND.  &
                &                             15
                                          ENDIF
   154|                                   IF ((0 <> (RSHIFT((int(d-vp3r%flags)  &
                &                           .AND.  128), 7)  .AND.  1))) THEN
                                            IF (.NOT.(0 == (d-vp3r%flags  .AND. &
                &                              128)  .OR.  0 == (d-vp3r%flags  &
                &                             .AND.  32))) GOTO lab_104
                                            filenameaddr_6 = "genvel.f90"
                                            filenamelen_6 = 10
                                            CALL _xlfErrorExitWithLoc(0,3,109,0,&
                &                             NULL,NULL,filename_6,154,NULL)
                                            CALL _trap(3)
                                            GOTO lab_110
                                            lab_104
                                            IF ((d-vp3r%addr <> NULL)) THEN
                                              CALL free(d-vp3r%addr)
                                            ENDIF
                                            d-vp3r%flags = d-vp3r%flags  .AND.  &
                &                             15
                                          ENDIF
   159|                                   nreq = 0
   160|                                   nsub = nsub + 1
   161|                                   T_59 = 3
                                          T_60 = 3
                                          T_61 = 0
                                          T_62 = 0
                                          T_63 = 0
                                          T_64 = 0
                                          CALL bvalv1(T_59,T_60,T_61,T_62,T_63,&
                &                           T_64,d-v1%addr)
   162|                                   T_65 = 3
                                          T_66 = 3
                                          T_67 = 0
                                          T_68 = 0
                                          T_69 = 0
                                          T_70 = 0
                                          CALL bvalv2(T_65,T_66,T_67,T_68,T_69,&
                &                           T_70,d-v2%addr)
   163|                                   T_71 = 3
                                          T_72 = 3
                                          T_73 = 0
                                          T_74 = 0
                                          T_75 = 0
                                          T_76 = 0
                                          CALL bvalv3(T_71,T_72,T_73,T_74,T_75,&
                &                           T_76,d-v3%addr)
   164|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   165|                                   nreq = 0
   166|                                   nsub = nsub + 1
   167|                                   T_77 = 0
                                          T_78 = 0
                                          T_79 = 3
                                          T_80 = 3
                                          T_81 = 0
                                          T_82 = 0
                                          CALL bvalv1(T_77,T_78,T_79,T_80,T_81,&
                &                           T_82,d-v1%addr)
   168|                                   T_83 = 0
                                          T_84 = 0
                                          T_85 = 3
                                          T_86 = 3
                                          T_87 = 0
                                          T_88 = 0
                                          CALL bvalv2(T_83,T_84,T_85,T_86,T_87,&
                &                           T_88,d-v2%addr)
   169|                                   T_89 = 0
                                          T_90 = 0
                                          T_91 = 3
                                          T_92 = 3
                                          T_93 = 0
                                          T_94 = 0
                                          CALL bvalv3(T_89,T_90,T_91,T_92,T_93,&
                &                           T_94,d-v3%addr)
   170|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   171|                                   nreq = 0
   172|                                   nsub = nsub + 1
   173|                                   T_95 = 0
                                          T_96 = 0
                                          T_97 = 0
                                          T_98 = 0
                                          T_99 = 3
                                          T_100 = 3
                                          CALL bvalv1(T_95,T_96,T_97,T_98,T_99,&
                &                           T_100,d-v1%addr)
   174|                                   T_101 = 0
                                          T_102 = 0
                                          T_103 = 0
                                          T_104 = 0
                                          T_105 = 3
                                          T_106 = 3
                                          CALL bvalv2(T_101,T_102,T_103,T_104,&
                &                           T_105,T_106,d-v2%addr)
   175|                                   T_107 = 0
                                          T_108 = 0
                                          T_109 = 0
                                          T_110 = 0
                                          T_111 = 3
                                          T_112 = 3
                                          CALL bvalv3(T_107,T_108,T_109,T_110,&
                &                           T_111,T_112,d-v3%addr)
   176|                                   IF ((nreq <> 0)) THEN
                                            CALL mpi_waitall(nreq,req,stat,ierr)&
                &                             
                                          ENDIF
   180|                                   CALL normvel(vrms)
   183|                                   IF (.NOT.(myid_w == 0)) GOTO lab_110
   184|                                   #22 = _xlfBeginIO(6,257,#21,32768,&
                &                           NULL,0,NULL)
                                          CALL _xlfWriteLDChar(%VAL(#22),&
                &                           "GENVEL                 : &
                &                           ------------------ ",44,1)
                                          _xlfEndIO(%VAL(#22))
   185|                                   #24 = _xlfBeginIO(6,257,#23,32768,&
                &                           NULL,0,NULL)
                                          CALL _xlfWriteLDChar(%VAL(#24),&
                &                           "GENVEL                 : generation &
                &                           of ",39,1)
                                          _xlfEndIO(%VAL(#24))
   186|                                   #26 = _xlfBeginIO(6,257,#25,32768,&
                &                           NULL,0,NULL)
                                          CALL _xlfWriteLDChar(%VAL(#26),&
                &                           "GENVEL                 : velocity &
                &                           field ",40,1)
                                          _xlfEndIO(%VAL(#26))
   187|                                   #28 = _xlfBeginIO(6,257,#27,32768,&
                &                           NULL,0,NULL)
                                          CALL _xlfWriteLDChar(%VAL(#28),&
                &                           "GENVEL                 : finished !! &
                &                           ",37,1)
                                          _xlfEndIO(%VAL(#28))
   188|                                   #30 = _xlfBeginIO(6,257,#29,32768,&
                &                           NULL,0,NULL)
                                          CALL _xlfWriteLDChar(%VAL(#30),&
                &                           "GENVEL                 : &
                &                           ------------------ ",44,1)
                                          _xlfEndIO(%VAL(#30))
   189|                                   lab_110
   190|                                   RETURN
                                        END SUBROUTINE genvel

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   ssus ssss ssss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ss--  ---- ---- ---- ----
 CCR's set/used:   sss- ssss
     | 000000                           PDEF     genvel
    1|                                  PROC      .nmodes,.vrms,.idx,gr3-gr5
    0| 000000 std      FBE1FFF8   1     ST8       #stack(gr1,-8)=gr31
    0| 000004 std      FBC1FFF0   1     ST8       #stack(gr1,-16)=gr30
    0| 000008 std      FBA1FFE8   1     ST8       #stack(gr1,-24)=gr29
    0| 00000C std      FB81FFE0   1     ST8       #stack(gr1,-32)=gr28
    0| 000010 std      FB61FFD8   1     ST8       #stack(gr1,-40)=gr27
    0| 000014 std      FB41FFD0   1     ST8       #stack(gr1,-48)=gr26
    0| 000018 std      FB21FFC8   1     ST8       #stack(gr1,-56)=gr25
    0| 00001C std      FB01FFC0   1     ST8       #stack(gr1,-64)=gr24
    0| 000020 std      FAE1FFB8   1     ST8       #stack(gr1,-72)=gr23
    0| 000024 std      FAC1FFB0   1     ST8       #stack(gr1,-80)=gr22
    0| 000028 std      FAA1FFA8   1     ST8       #stack(gr1,-88)=gr21
    0| 00002C std      FA81FFA0   1     ST8       #stack(gr1,-96)=gr20
    0| 000030 std      FA61FF98   1     ST8       #stack(gr1,-104)=gr19
    0| 000034 std      FA41FF90   1     ST8       #stack(gr1,-112)=gr18
    0| 000038 std      FA21FF88   1     ST8       #stack(gr1,-120)=gr17
    0| 00003C std      FA01FF80   1     ST8       #stack(gr1,-128)=gr16
    0| 000040 std      F9E1FF78   1     ST8       #stack(gr1,-136)=gr15
    0| 000044 std      F9C1FF70   1     ST8       #stack(gr1,-144)=gr14
    0| 000048 mfspr    7C0802A6   1     LFLR      gr0=lr
    0| 00004C mfcr     7D800026   1     LFCR      gr12=cr[24],2
    0| 000050 stw      91810008   1     ST4A      #stack(gr1,8)=gr12
    0| 000054 std      F8010010   1     ST8       #stack(gr1,16)=gr0
    0| 000058 stdu     F821F7C1   1     ST8U      gr1,#stack(gr1,-2112)=gr1
    0| 00005C std      F8810610   1     ST8       #SPILL0(gr1,1552)=gr4
   59| 000060 ld       E9820000   1     L8        gr12=.&&N&&param(gr2,0)
   59| 000064 ld       EBE20000   1     L8        gr31=.&&N&vcvars(gr2,0)
   59| 000068 addi     3B000003   1     LI        gr24=3
   59| 00006C addi     3BA0030E   1     LI        gr29=782
   59| 000070 addi     3B800081   1     LI        gr28=129
   59| 000074 addi     3A600008   1     LI        gr19=8
   59| 000078 lwa      E90C0002   1     L4A       gr8=<s141:d0:l4>(gr12,0)
   59| 00007C lwa      E8CC0006   1     L4A       gr6=<s141:d4:l4>(gr12,4)
   59| 000080 ld       E93F0000   1     L8        gr9=d-vp1r(gr31,0)
   59| 000084 ld       E95F0008   1     L8        gr10=d-vp1r(gr31,8)
   59| 000088 stw      931F000C   1     ST4Z      <s81:d12:l4>(gr31,12)=gr24
   59| 00008C sth      B3BF0008   1     ST2Z      d-vp1r%d|scr_type#137|ata_type#138_1(gr31,8)=gr29
   59| 000090 stb      9B9F000B   1     ST1Z      <s81:d11:l1>(gr31,11)=gr28
   59| 000094 sradi    7D0BFE76   1     SRA8      gr11=gr8,63,ca"
   59| 000098 std      F9210320   1     ST8       bak_rtd_1(gr1,800)=gr9
   59| 00009C std      F9410328   1     ST8       bak_rtd_1(gr1,808)=gr10
   59| 0000A0 sradi    7CC9FE76   1     SRA8      gr9=gr6,63,ca"
   59| 0000A4 andc     7D1B5878   1     ANDC      gr27=gr8,gr11
   59| 0000A8 andc     7CDA4878   1     ANDC      gr26=gr6,gr9
   59| 0000AC ld       E93F0018   1     L8        gr9=d-vp1r(gr31,24)
   59| 0000B0 mulld    7F3AD9D2   1     M         gr25=gr26,gr27
   59| 0000B4 std      F9210338   1     ST8       bak_rtd_1(gr1,824)=gr9
   59| 0000B8 ld       E91F0010   1     L8        gr8=d-vp1r(gr31,16)
   59| 0000BC std      FA7F0010   1     ST8       <s81:d16:l8>(gr31,16)=gr19
   59| 0000C0 ld       E93F0038   1     L8        gr9=d-vp1r(gr31,56)
   59| 0000C4 lwa      E80C000A   1     L4A       gr0=<s141:d8:l4>(gr12,8)
   59| 0000C8 add      7CD9DA14   1     A         gr6=gr25,gr27
   59| 0000CC lbz      88FF000A   1     L1Z       gr7=<s81:d10:l1>(gr31,10)
   59| 0000D0 std      F9010330   1     ST8       bak_rtd_1(gr1,816)=gr8
   59| 0000D4 ld       E91F0030   1     L8        gr8=d-vp1r(gr31,48)
   59| 0000D8 std      F9210358   1     ST8       bak_rtd_1(gr1,856)=gr9
   59| 0000DC addi     38C60001   1     AI        gr6=gr6,1
   59| 0000E0 ld       E95F0020   1     L8        gr10=d-vp1r(gr31,32)
   59| 0000E4 ld       E97F0028   1     L8        gr11=d-vp1r(gr31,40)
   59| 0000E8 ld       EB1F0040   1     L8        gr24=d-vp1r(gr31,64)
   59| 0000EC std      F9010350   1     ST8       bak_rtd_1(gr1,848)=gr8
   59| 0000F0 std      FB5F0040   1     ST8       <s81:d64:l8>(gr31,64)=gr26
   59| 0000F4 ld       EAFF0048   1     L8        gr23=d-vp1r(gr31,72)
   59| 0000F8 std      F9410340   1     ST8       bak_rtd_1(gr1,832)=gr10
   59| 0000FC std      F9610348   1     ST8       bak_rtd_1(gr1,840)=gr11
   59| 000100 std      FB010360   1     ST8       bak_rtd_1(gr1,864)=gr24
   59| 000104 ld       EADF0050   1     L8        gr22=d-vp1r(gr31,80)
   59| 000108 ld       EABF0058   1     L8        gr21=d-vp1r(gr31,88)
   59| 00010C std      FB7F0058   1     ST8       <s81:d88:l8>(gr31,88)=gr27
   59| 000110 std      FAE10368   1     ST8       bak_rtd_1(gr1,872)=gr23
   59| 000114 ld       EA9F0060   1     L8        gr20=d-vp1r(gr31,96)
   59| 000118 std      FA7F0060   1     ST8       <s81:d96:l8>(gr31,96)=gr19
   59| 00011C std      FAC10370   1     ST8       bak_rtd_1(gr1,880)=gr22
   59| 000120 std      FAA10378   1     ST8       bak_rtd_1(gr1,888)=gr21
   59| 000124 rldicr   78C91F24   1     SLL8      gr9=gr6,3
   59| 000128 sradi    7C06FE76   1     SRA8      gr6=gr0,63,ca"
   59| 00012C std      FA810380   1     ST8       bak_rtd_1(gr1,896)=gr20
   59| 000130 addi     39000001   1     LI        gr8=1
   59| 000134 rldicr   7B321F24   1     SLL8      gr18=gr25,3
   59| 000138 std      F91F0050   1     ST8       <s81:d80:l8>(gr31,80)=gr8
   59| 00013C std      F91F0038   1     ST8       <s81:d56:l8>(gr31,56)=gr8
   59| 000140 rldicr   7B701F24   1     SLL8      gr16=gr27,3
   59| 000144 std      F91F0020   1     ST8       <s81:d32:l8>(gr31,32)=gr8
   59| 000148 std      FA1F0048   1     ST8       <s81:d72:l8>(gr31,72)=gr16
   59| 00014C neg      7E2900D0   1     COMP      gr17=gr9
   59| 000150 andc     7C0F3078   1     ANDC      gr15=gr0,gr6
   59| 000154 std      FA5F0030   1     ST8       <s81:d48:l8>(gr31,48)=gr18
   59| 000158 andi.    70E70080   1     RN4_R     gr7,cr0=gr7,0,0x80
   59| 00015C std      FA3F0018   1     ST8       <s81:d24:l8>(gr31,24)=gr17
   59| 000160 or       7C3E0B78   1     LR        gr30=gr1
    0| 000164 or       7C6E1B78   1     LR        gr14=gr3
   59| 000168 std      F9FF0028   1     ST8       <s81:d40:l8>(gr31,40)=gr15
    0| 00016C or       7CBF2B78   1     LR        gr31=gr5
   59| 000170 bc       41820060   1     BT        CL.1,cr0,0x4/eq,taken=50%(0,0)
   59|                              CL.221:
   59| 000174 ld       E9020000   1     L8        gr8=.&&N&vcvars(gr2,0)
   59| 000178 ld       E81E0320   1     L8        gr0=bak_rtd_1(gr30,800)
   59| 00017C ld       E87E0328   1     L8        gr3=bak_rtd_1(gr30,808)
   59| 000180 ld       E89E0330   1     L8        gr4=bak_rtd_1(gr30,816)
   59| 000184 ld       E8BE0338   1     L8        gr5=bak_rtd_1(gr30,824)
   59| 000188 ld       E8DE0340   1     L8        gr6=bak_rtd_1(gr30,832)
   59| 00018C std      FB080040   1     ST8       d-vp1r(gr8,64)=gr24
   59| 000190 std      F8080000   1     ST8       d-vp1r(gr8,0)=gr0
   59| 000194 std      F8680008   1     ST8       d-vp1r(gr8,8)=gr3
   59| 000198 std      FAE80048   1     ST8       d-vp1r(gr8,72)=gr23
   59| 00019C std      FAC80050   1     ST8       d-vp1r(gr8,80)=gr22
   59| 0001A0 std      FAA80058   1     ST8       d-vp1r(gr8,88)=gr21
   59| 0001A4 std      FA880060   1     ST8       d-vp1r(gr8,96)=gr20
   59| 0001A8 std      F8880010   1     ST8       d-vp1r(gr8,16)=gr4
   59| 0001AC ld       E81E0350   1     L8        gr0=bak_rtd_1(gr30,848)
   59| 0001B0 std      F8A80018   1     ST8       d-vp1r(gr8,24)=gr5
   59| 0001B4 ld       E87E0358   1     L8        gr3=bak_rtd_1(gr30,856)
   59| 0001B8 std      F8C80020   1     ST8       d-vp1r(gr8,32)=gr6
   59| 0001BC ld       E8FE0348   1     L8        gr7=bak_rtd_1(gr30,840)
   59| 0001C0 std      F8080030   1     ST8       d-vp1r(gr8,48)=gr0
   59| 0001C4 std      F8680038   1     ST8       d-vp1r(gr8,56)=gr3
   59| 0001C8 std      F8E80028   1     ST8       d-vp1r(gr8,40)=gr7
   59| 0001CC b        48000024   1     B         CL.2,-1
   59|                              CL.1:
   59| 0001D0 mulld    7C0FC9D2   1     M         gr0=gr15,gr25
   59| 0001D4 rldicr   78031F25   1     SLL8_R    gr3,cr0=gr0,3
   59| 0001D8 bc       40822B80   1     BF        CL.3,cr0,0x4/eq,taken=40%(40,60)
   59| 0001DC ld       E8A20000   1     L8        gr5=.&&N&vcvars(gr2,0)
   59| 0001E0 addi     38000000   1     LI        gr0=0
   59| 0001E4 addi     386000F0   1     LI        gr3=240
   59| 0001E8 std      F8050000   1     ST8       <s81:d0:l8>(gr5,0)=gr0
   59| 0001EC stb      9865000A   1     ST1Z      <s81:d10:l1>(gr5,10)=gr3
   59|                              CL.2:
   60| 0001F0 ld       E9820000   1     L8        gr12=.&&N&vcvars(gr2,0)
   60| 0001F4 addi     38A00003   1     LI        gr5=3
   60| 0001F8 addi     39600001   1     LI        gr11=1
   59| 0001FC or       7C340B78   1     LR        gr20=gr1
   60| 000200 lbz      880C0072   1     L1Z       gr0=<s81:d114:l1>(gr12,114)
   60| 000204 ld       E86C0068   1     L8        gr3=d-vp1i(gr12,104)
   60| 000208 ld       E88C0070   1     L8        gr4=d-vp1i(gr12,112)
   60| 00020C stw      90AC0074   1     ST4Z      <s81:d116:l4>(gr12,116)=gr5
   60| 000210 sth      B3AC0070   1     ST2Z      d-vp1i%d|scr_type#150|ata_type#151_1(gr12,112)=gr29
   60| 000214 stb      9B8C0073   1     ST1Z      <s81:d115:l1>(gr12,115)=gr28
   60| 000218 ld       E8AC0078   1     L8        gr5=d-vp1i(gr12,120)
   60| 00021C std      FA6C0078   1     ST8       <s81:d120:l8>(gr12,120)=gr19
   60| 000220 std      F86103A0   1     ST8       bak_rtd_2(gr1,928)=gr3
   60| 000224 std      F88103A8   1     ST8       bak_rtd_2(gr1,936)=gr4
   60| 000228 ld       E8CC0080   1     L8        gr6=d-vp1i(gr12,128)
   60| 00022C std      FA2C0080   1     ST8       <s81:d128:l8>(gr12,128)=gr17
   60| 000230 std      F8A103B0   1     ST8       bak_rtd_2(gr1,944)=gr5
   60| 000234 ld       E8EC0088   1     L8        gr7=d-vp1i(gr12,136)
   60| 000238 std      F96C0088   1     ST8       <s81:d136:l8>(gr12,136)=gr11
   60| 00023C ld       E90C0090   1     L8        gr8=d-vp1i(gr12,144)
   60| 000240 std      F9EC0090   1     ST8       <s81:d144:l8>(gr12,144)=gr15
   60| 000244 std      F8C103B8   1     ST8       bak_rtd_2(gr1,952)=gr6
   60| 000248 ld       E92C0098   1     L8        gr9=d-vp1i(gr12,152)
   60| 00024C std      FA4C0098   1     ST8       <s81:d152:l8>(gr12,152)=gr18
   60| 000250 std      F8E103C0   1     ST8       bak_rtd_2(gr1,960)=gr7
   60| 000254 std      F90103C8   1     ST8       bak_rtd_2(gr1,968)=gr8
   60| 000258 ld       E94C00A0   1     L8        gr10=d-vp1i(gr12,160)
   60| 00025C std      F96C00A0   1     ST8       <s81:d160:l8>(gr12,160)=gr11
   60| 000260 std      F92103D0   1     ST8       bak_rtd_2(gr1,976)=gr9
   60| 000264 ld       EBCC00A8   1     L8        gr30=d-vp1i(gr12,168)
   60| 000268 std      FB4C00A8   1     ST8       <s81:d168:l8>(gr12,168)=gr26
   60| 00026C ld       EB0C00B0   1     L8        gr24=d-vp1i(gr12,176)
   60| 000270 std      FA0C00B0   1     ST8       <s81:d176:l8>(gr12,176)=gr16
   60| 000274 std      F94103D8   1     ST8       bak_rtd_2(gr1,984)=gr10
   60| 000278 ld       EAEC00B8   1     L8        gr23=d-vp1i(gr12,184)
   60| 00027C std      FBC103E0   1     ST8       bak_rtd_2(gr1,992)=gr30
   60| 000280 std      F96C00B8   1     ST8       <s81:d184:l8>(gr12,184)=gr11
   60| 000284 std      FB0103E8   1     ST8       bak_rtd_2(gr1,1000)=gr24
   60| 000288 ld       EACC00C0   1     L8        gr22=d-vp1i(gr12,192)
   60| 00028C std      FB6C00C0   1     ST8       <s81:d192:l8>(gr12,192)=gr27
   60| 000290 andi.    70000080   1     RN4_R     gr0,cr0=gr0,0,0x80
   60| 000294 std      FAE103F0   1     ST8       bak_rtd_2(gr1,1008)=gr23
   60| 000298 ld       EAAC00C8   1     L8        gr21=d-vp1i(gr12,200)
   60| 00029C std      FA6C00C8   1     ST8       <s81:d200:l8>(gr12,200)=gr19
   60| 0002A0 std      FAC103F8   1     ST8       bak_rtd_2(gr1,1016)=gr22
   60| 0002A4 std      FAA10400   1     ST8       bak_rtd_2(gr1,1024)=gr21
   60| 0002A8 bc       4182005C   1     BT        CL.7,cr0,0x4/eq,taken=50%(0,0)
   60|                              CL.220:
   60| 0002AC ld       E81403A0   1     L8        gr0=bak_rtd_2(gr20,928)
   60| 0002B0 std      FBCC00A8   1     ST8       d-vp1i(gr12,168)=gr30
   60| 0002B4 std      FB0C00B0   1     ST8       d-vp1i(gr12,176)=gr24
   60| 0002B8 std      FAEC00B8   1     ST8       d-vp1i(gr12,184)=gr23
   60| 0002BC std      FACC00C0   1     ST8       d-vp1i(gr12,192)=gr22
   60| 0002C0 ld       E87403A8   1     L8        gr3=bak_rtd_2(gr20,936)
   60| 0002C4 std      F80C0068   1     ST8       d-vp1i(gr12,104)=gr0
   60| 0002C8 ld       E89403B0   1     L8        gr4=bak_rtd_2(gr20,944)
   60| 0002CC std      FAAC00C8   1     ST8       d-vp1i(gr12,200)=gr21
   60| 0002D0 ld       E8B403B8   1     L8        gr5=bak_rtd_2(gr20,952)
   60| 0002D4 ld       E8D403C0   1     L8        gr6=bak_rtd_2(gr20,960)
   60| 0002D8 std      F86C0070   1     ST8       d-vp1i(gr12,112)=gr3
   60| 0002DC ld       E8F403C8   1     L8        gr7=bak_rtd_2(gr20,968)
   60| 0002E0 std      F88C0078   1     ST8       d-vp1i(gr12,120)=gr4
   60| 0002E4 ld       E81403D0   1     L8        gr0=bak_rtd_2(gr20,976)
   60| 0002E8 std      F8AC0080   1     ST8       d-vp1i(gr12,128)=gr5
   60| 0002EC std      F8CC0088   1     ST8       d-vp1i(gr12,136)=gr6
   60| 0002F0 ld       E87403D8   1     L8        gr3=bak_rtd_2(gr20,984)
   60| 0002F4 std      F8EC0090   1     ST8       d-vp1i(gr12,144)=gr7
   60| 0002F8 std      F80C0098   1     ST8       d-vp1i(gr12,152)=gr0
   60| 0002FC std      F86C00A0   1     ST8       d-vp1i(gr12,160)=gr3
   60| 000300 b        48000020   1     B         CL.8,-1
   60|                              CL.7:
   60| 000304 mulld    7C0FC9D2   1     M         gr0=gr15,gr25
   60| 000308 rldicr   78031F25   1     SLL8_R    gr3,cr0=gr0,3
   60| 00030C bc       40822A24   1     BF        CL.9,cr0,0x4/eq,taken=40%(40,60)
   60| 000310 addi     38000000   1     LI        gr0=0
   60| 000314 addi     386000F0   1     LI        gr3=240
   60| 000318 std      F80C0068   1     ST8       <s81:d104:l8>(gr12,104)=gr0
   60| 00031C stb      986C0072   1     ST1Z      <s81:d114:l1>(gr12,114)=gr3
   60|                              CL.8:
   61| 000320 lbz      880C00DA   1     L1Z       gr0=<s81:d218:l1>(gr12,218)
   61| 000324 addi     38A00003   1     LI        gr5=3
   61| 000328 ld       E86C00D0   1     L8        gr3=d-vp2r(gr12,208)
   61| 00032C ld       E88C00D8   1     L8        gr4=d-vp2r(gr12,216)
   61| 000330 stw      90AC00DC   1     ST4Z      <s81:d220:l4>(gr12,220)=gr5
   61| 000334 sth      B3AC00D8   1     ST2Z      d-vp2r%d|scr_type#156|ata_type#157_1(gr12,216)=gr29
   61| 000338 stb      9B8C00DB   1     ST1Z      <s81:d219:l1>(gr12,219)=gr28
   61| 00033C ld       E8AC00E0   1     L8        gr5=d-vp2r(gr12,224)
   61| 000340 std      FA6C00E0   1     ST8       <s81:d224:l8>(gr12,224)=gr19
   61| 000344 std      F8610420   1     ST8       bak_rtd_3(gr1,1056)=gr3
   61| 000348 std      F8810428   1     ST8       bak_rtd_3(gr1,1064)=gr4
   61| 00034C ld       E8CC00E8   1     L8        gr6=d-vp2r(gr12,232)
   61| 000350 std      FA2C00E8   1     ST8       <s81:d232:l8>(gr12,232)=gr17
   61| 000354 std      F8A10430   1     ST8       bak_rtd_3(gr1,1072)=gr5
   61| 000358 ld       E8EC00F0   1     L8        gr7=d-vp2r(gr12,240)
   61| 00035C ld       E90C00F8   1     L8        gr8=d-vp2r(gr12,248)
   61| 000360 std      F9EC00F8   1     ST8       <s81:d248:l8>(gr12,248)=gr15
   61| 000364 std      F8C10438   1     ST8       bak_rtd_3(gr1,1080)=gr6
   61| 000368 ld       E92C0100   1     L8        gr9=d-vp2r(gr12,256)
   61| 00036C std      FA4C0100   1     ST8       <s81:d256:l8>(gr12,256)=gr18
   61| 000370 std      F8E10440   1     ST8       bak_rtd_3(gr1,1088)=gr7
   61| 000374 std      F9010448   1     ST8       bak_rtd_3(gr1,1096)=gr8
   61| 000378 ld       E94C0108   1     L8        gr10=d-vp2r(gr12,264)
   61| 00037C ld       EBCC0110   1     L8        gr30=d-vp2r(gr12,272)
   61| 000380 std      FB4C0110   1     ST8       <s81:d272:l8>(gr12,272)=gr26
   61| 000384 std      F9210450   1     ST8       bak_rtd_3(gr1,1104)=gr9
   61| 000388 ld       EB0C0118   1     L8        gr24=d-vp2r(gr12,280)
   61| 00038C std      FA0C0118   1     ST8       <s81:d280:l8>(gr12,280)=gr16
   61| 000390 std      F9410458   1     ST8       bak_rtd_3(gr1,1112)=gr10
   61| 000394 std      FBC10460   1     ST8       bak_rtd_3(gr1,1120)=gr30
   61| 000398 ld       EAEC0120   1     L8        gr23=d-vp2r(gr12,288)
   61| 00039C ld       EACC0128   1     L8        gr22=d-vp2r(gr12,296)
   61| 0003A0 std      FB6C0128   1     ST8       <s81:d296:l8>(gr12,296)=gr27
   61| 0003A4 std      FB010468   1     ST8       bak_rtd_3(gr1,1128)=gr24
   61| 0003A8 ld       EAAC0130   1     L8        gr21=d-vp2r(gr12,304)
   61| 0003AC std      FA6C0130   1     ST8       <s81:d304:l8>(gr12,304)=gr19
   61| 0003B0 std      FAE10470   1     ST8       bak_rtd_3(gr1,1136)=gr23
   61| 0003B4 std      FAC10478   1     ST8       bak_rtd_3(gr1,1144)=gr22
   61| 0003B8 addi     39600001   1     LI        gr11=1
   61| 0003BC andi.    70000080   1     RN4_R     gr0,cr0=gr0,0,0x80
   61| 0003C0 std      FAA10480   1     ST8       bak_rtd_3(gr1,1152)=gr21
   61| 0003C4 std      F96C0120   1     ST8       <s81:d288:l8>(gr12,288)=gr11
   61| 0003C8 std      F96C0108   1     ST8       <s81:d264:l8>(gr12,264)=gr11
   61| 0003CC std      F96C00F0   1     ST8       <s81:d240:l8>(gr12,240)=gr11
   61| 0003D0 bc       4182005C   1     BT        CL.13,cr0,0x4/eq,taken=50%(0,0)
   61|                              CL.219:
   61| 0003D4 ld       E8140420   1     L8        gr0=bak_rtd_3(gr20,1056)
   61| 0003D8 std      FBCC0110   1     ST8       d-vp2r(gr12,272)=gr30
   61| 0003DC std      FB0C0118   1     ST8       d-vp2r(gr12,280)=gr24
   61| 0003E0 std      FAEC0120   1     ST8       d-vp2r(gr12,288)=gr23
   61| 0003E4 std      FACC0128   1     ST8       d-vp2r(gr12,296)=gr22
   61| 0003E8 ld       E8740428   1     L8        gr3=bak_rtd_3(gr20,1064)
   61| 0003EC std      F80C00D0   1     ST8       d-vp2r(gr12,208)=gr0
   61| 0003F0 ld       E8940430   1     L8        gr4=bak_rtd_3(gr20,1072)
   61| 0003F4 std      FAAC0130   1     ST8       d-vp2r(gr12,304)=gr21
   61| 0003F8 ld       E8B40438   1     L8        gr5=bak_rtd_3(gr20,1080)
   61| 0003FC ld       E8D40440   1     L8        gr6=bak_rtd_3(gr20,1088)
   61| 000400 std      F86C00D8   1     ST8       d-vp2r(gr12,216)=gr3
   61| 000404 ld       E8F40448   1     L8        gr7=bak_rtd_3(gr20,1096)
   61| 000408 std      F88C00E0   1     ST8       d-vp2r(gr12,224)=gr4
   61| 00040C ld       E8140450   1     L8        gr0=bak_rtd_3(gr20,1104)
   61| 000410 std      F8AC00E8   1     ST8       d-vp2r(gr12,232)=gr5
   61| 000414 std      F8CC00F0   1     ST8       d-vp2r(gr12,240)=gr6
   61| 000418 ld       E8740458   1     L8        gr3=bak_rtd_3(gr20,1112)
   61| 00041C std      F8EC00F8   1     ST8       d-vp2r(gr12,248)=gr7
   61| 000420 std      F80C0100   1     ST8       d-vp2r(gr12,256)=gr0
   61| 000424 std      F86C0108   1     ST8       d-vp2r(gr12,264)=gr3
   61| 000428 b        48000020   1     B         CL.14,-1
   61|                              CL.13:
   61| 00042C mulld    7C0FC9D2   1     M         gr0=gr15,gr25
   61| 000430 rldicr   78031F25   1     SLL8_R    gr3,cr0=gr0,3
   61| 000434 bc       408228D4   1     BF        CL.15,cr0,0x4/eq,taken=40%(40,60)
   61| 000438 addi     38000000   1     LI        gr0=0
   61| 00043C addi     386000F0   1     LI        gr3=240
   61| 000440 std      F80C00D0   1     ST8       <s81:d208:l8>(gr12,208)=gr0
   61| 000444 stb      986C00DA   1     ST1Z      <s81:d218:l1>(gr12,218)=gr3
   61|                              CL.14:
   62| 000448 lbz      880C0142   1     L1Z       gr0=<s81:d322:l1>(gr12,322)
   62| 00044C addi     38A00003   1     LI        gr5=3
   62| 000450 ld       E86C0138   1     L8        gr3=d-vp2i(gr12,312)
   62| 000454 ld       E88C0140   1     L8        gr4=d-vp2i(gr12,320)
   62| 000458 stw      90AC0144   1     ST4Z      <s81:d324:l4>(gr12,324)=gr5
   62| 00045C sth      B3AC0140   1     ST2Z      d-vp2i%d|scr_type#162|ata_type#163_1(gr12,320)=gr29
   62| 000460 stb      9B8C0143   1     ST1Z      <s81:d323:l1>(gr12,323)=gr28
   62| 000464 ld       E8AC0148   1     L8        gr5=d-vp2i(gr12,328)
   62| 000468 std      FA6C0148   1     ST8       <s81:d328:l8>(gr12,328)=gr19
   62| 00046C std      F86104A0   1     ST8       bak_rtd_4(gr1,1184)=gr3
   62| 000470 std      F88104A8   1     ST8       bak_rtd_4(gr1,1192)=gr4
   62| 000474 ld       E8CC0150   1     L8        gr6=d-vp2i(gr12,336)
   62| 000478 std      FA2C0150   1     ST8       <s81:d336:l8>(gr12,336)=gr17
   62| 00047C std      F8A104B0   1     ST8       bak_rtd_4(gr1,1200)=gr5
   62| 000480 ld       E8EC0158   1     L8        gr7=d-vp2i(gr12,344)
   62| 000484 ld       E90C0160   1     L8        gr8=d-vp2i(gr12,352)
   62| 000488 std      F9EC0160   1     ST8       <s81:d352:l8>(gr12,352)=gr15
   62| 00048C std      F8C104B8   1     ST8       bak_rtd_4(gr1,1208)=gr6
   62| 000490 ld       E92C0168   1     L8        gr9=d-vp2i(gr12,360)
   62| 000494 std      FA4C0168   1     ST8       <s81:d360:l8>(gr12,360)=gr18
   62| 000498 std      F8E104C0   1     ST8       bak_rtd_4(gr1,1216)=gr7
   62| 00049C std      F90104C8   1     ST8       bak_rtd_4(gr1,1224)=gr8
   62| 0004A0 ld       E94C0170   1     L8        gr10=d-vp2i(gr12,368)
   62| 0004A4 ld       EBCC0178   1     L8        gr30=d-vp2i(gr12,376)
   62| 0004A8 std      FB4C0178   1     ST8       <s81:d376:l8>(gr12,376)=gr26
   62| 0004AC std      F92104D0   1     ST8       bak_rtd_4(gr1,1232)=gr9
   62| 0004B0 ld       EB0C0180   1     L8        gr24=d-vp2i(gr12,384)
   62| 0004B4 std      FA0C0180   1     ST8       <s81:d384:l8>(gr12,384)=gr16
   62| 0004B8 std      F94104D8   1     ST8       bak_rtd_4(gr1,1240)=gr10
   62| 0004BC std      FBC104E0   1     ST8       bak_rtd_4(gr1,1248)=gr30
   62| 0004C0 ld       EAEC0188   1     L8        gr23=d-vp2i(gr12,392)
   62| 0004C4 ld       EACC0190   1     L8        gr22=d-vp2i(gr12,400)
   62| 0004C8 std      FB6C0190   1     ST8       <s81:d400:l8>(gr12,400)=gr27
   62| 0004CC std      FB0104E8   1     ST8       bak_rtd_4(gr1,1256)=gr24
   62| 0004D0 ld       EAAC0198   1     L8        gr21=d-vp2i(gr12,408)
   62| 0004D4 std      FA6C0198   1     ST8       <s81:d408:l8>(gr12,408)=gr19
   62| 0004D8 std      FAE104F0   1     ST8       bak_rtd_4(gr1,1264)=gr23
   62| 0004DC std      FAC104F8   1     ST8       bak_rtd_4(gr1,1272)=gr22
   62| 0004E0 addi     39600001   1     LI        gr11=1
   62| 0004E4 andi.    70000080   1     RN4_R     gr0,cr0=gr0,0,0x80
   62| 0004E8 std      FAA10500   1     ST8       bak_rtd_4(gr1,1280)=gr21
   62| 0004EC std      F96C0188   1     ST8       <s81:d392:l8>(gr12,392)=gr11
   62| 0004F0 std      F96C0170   1     ST8       <s81:d368:l8>(gr12,368)=gr11
   62| 0004F4 std      F96C0158   1     ST8       <s81:d344:l8>(gr12,344)=gr11
   62| 0004F8 bc       4182005C   1     BT        CL.19,cr0,0x4/eq,taken=50%(0,0)
   62|                              CL.218:
   62| 0004FC ld       E81404A0   1     L8        gr0=bak_rtd_4(gr20,1184)
   62| 000500 std      FBCC0178   1     ST8       d-vp2i(gr12,376)=gr30
   62| 000504 std      FB0C0180   1     ST8       d-vp2i(gr12,384)=gr24
   62| 000508 std      FAEC0188   1     ST8       d-vp2i(gr12,392)=gr23
   62| 00050C std      FACC0190   1     ST8       d-vp2i(gr12,400)=gr22
   62| 000510 ld       E87404A8   1     L8        gr3=bak_rtd_4(gr20,1192)
   62| 000514 std      F80C0138   1     ST8       d-vp2i(gr12,312)=gr0
   62| 000518 ld       E89404B0   1     L8        gr4=bak_rtd_4(gr20,1200)
   62| 00051C std      FAAC0198   1     ST8       d-vp2i(gr12,408)=gr21
   62| 000520 ld       E8B404B8   1     L8        gr5=bak_rtd_4(gr20,1208)
   62| 000524 ld       E8D404C0   1     L8        gr6=bak_rtd_4(gr20,1216)
   62| 000528 std      F86C0140   1     ST8       d-vp2i(gr12,320)=gr3
   62| 00052C ld       E8F404C8   1     L8        gr7=bak_rtd_4(gr20,1224)
   62| 000530 std      F88C0148   1     ST8       d-vp2i(gr12,328)=gr4
   62| 000534 ld       E81404D0   1     L8        gr0=bak_rtd_4(gr20,1232)
   62| 000538 std      F8AC0150   1     ST8       d-vp2i(gr12,336)=gr5
   62| 00053C std      F8CC0158   1     ST8       d-vp2i(gr12,344)=gr6
   62| 000540 ld       E87404D8   1     L8        gr3=bak_rtd_4(gr20,1240)
   62| 000544 std      F8EC0160   1     ST8       d-vp2i(gr12,352)=gr7
   62| 000548 std      F80C0168   1     ST8       d-vp2i(gr12,360)=gr0
   62| 00054C std      F86C0170   1     ST8       d-vp2i(gr12,368)=gr3
   62| 000550 b        48000020   1     B         CL.20,-1
   62|                              CL.19:
   62| 000554 mulld    7C0FC9D2   1     M         gr0=gr15,gr25
   62| 000558 rldicr   78031F25   1     SLL8_R    gr3,cr0=gr0,3
   62| 00055C bc       40822784   1     BF        CL.21,cr0,0x4/eq,taken=40%(40,60)
   62| 000560 addi     38000000   1     LI        gr0=0
   62| 000564 addi     386000F0   1     LI        gr3=240
   62| 000568 std      F80C0138   1     ST8       <s81:d312:l8>(gr12,312)=gr0
   62| 00056C stb      986C0142   1     ST1Z      <s81:d322:l1>(gr12,322)=gr3
   62|                              CL.20:
   63| 000570 lbz      880C01AA   1     L1Z       gr0=<s81:d426:l1>(gr12,426)
   63| 000574 addi     38A00003   1     LI        gr5=3
   63| 000578 ld       E86C01A0   1     L8        gr3=d-vp3r(gr12,416)
   63| 00057C ld       E88C01A8   1     L8        gr4=d-vp3r(gr12,424)
   63| 000580 stw      90AC01AC   1     ST4Z      <s81:d428:l4>(gr12,428)=gr5
   63| 000584 sth      B3AC01A8   1     ST2Z      d-vp3r%d|scr_type#168|ata_type#169_1(gr12,424)=gr29
   63| 000588 stb      9B8C01AB   1     ST1Z      <s81:d427:l1>(gr12,427)=gr28
   63| 00058C ld       E8AC01B0   1     L8        gr5=d-vp3r(gr12,432)
   63| 000590 std      FA6C01B0   1     ST8       <s81:d432:l8>(gr12,432)=gr19
   63| 000594 std      F8610520   1     ST8       bak_rtd_5(gr1,1312)=gr3
   63| 000598 std      F8810528   1     ST8       bak_rtd_5(gr1,1320)=gr4
   63| 00059C ld       E8CC01B8   1     L8        gr6=d-vp3r(gr12,440)
   63| 0005A0 std      FA2C01B8   1     ST8       <s81:d440:l8>(gr12,440)=gr17
   63| 0005A4 std      F8A10530   1     ST8       bak_rtd_5(gr1,1328)=gr5
   63| 0005A8 ld       E8EC01C0   1     L8        gr7=d-vp3r(gr12,448)
   63| 0005AC ld       E90C01C8   1     L8        gr8=d-vp3r(gr12,456)
   63| 0005B0 std      F9EC01C8   1     ST8       <s81:d456:l8>(gr12,456)=gr15
   63| 0005B4 std      F8C10538   1     ST8       bak_rtd_5(gr1,1336)=gr6
   63| 0005B8 ld       E92C01D0   1     L8        gr9=d-vp3r(gr12,464)
   63| 0005BC std      FA4C01D0   1     ST8       <s81:d464:l8>(gr12,464)=gr18
   63| 0005C0 std      F8E10540   1     ST8       bak_rtd_5(gr1,1344)=gr7
   63| 0005C4 std      F9010548   1     ST8       bak_rtd_5(gr1,1352)=gr8
   63| 0005C8 ld       E94C01D8   1     L8        gr10=d-vp3r(gr12,472)
   63| 0005CC ld       EBCC01E0   1     L8        gr30=d-vp3r(gr12,480)
   63| 0005D0 std      FB4C01E0   1     ST8       <s81:d480:l8>(gr12,480)=gr26
   63| 0005D4 std      F9210550   1     ST8       bak_rtd_5(gr1,1360)=gr9
   63| 0005D8 ld       EB0C01E8   1     L8        gr24=d-vp3r(gr12,488)
   63| 0005DC std      FA0C01E8   1     ST8       <s81:d488:l8>(gr12,488)=gr16
   63| 0005E0 std      F9410558   1     ST8       bak_rtd_5(gr1,1368)=gr10
   63| 0005E4 std      FBC10560   1     ST8       bak_rtd_5(gr1,1376)=gr30
   63| 0005E8 ld       EAEC01F0   1     L8        gr23=d-vp3r(gr12,496)
   63| 0005EC ld       EACC01F8   1     L8        gr22=d-vp3r(gr12,504)
   63| 0005F0 std      FB6C01F8   1     ST8       <s81:d504:l8>(gr12,504)=gr27
   63| 0005F4 std      FB010568   1     ST8       bak_rtd_5(gr1,1384)=gr24
   63| 0005F8 ld       EAAC0200   1     L8        gr21=d-vp3r(gr12,512)
   63| 0005FC std      FA6C0200   1     ST8       <s81:d512:l8>(gr12,512)=gr19
   63| 000600 std      FAE10570   1     ST8       bak_rtd_5(gr1,1392)=gr23
   63| 000604 std      FAC10578   1     ST8       bak_rtd_5(gr1,1400)=gr22
   63| 000608 addi     39600001   1     LI        gr11=1
   63| 00060C andi.    70000080   1     RN4_R     gr0,cr0=gr0,0,0x80
   63| 000610 std      FAA10580   1     ST8       bak_rtd_5(gr1,1408)=gr21
   63| 000614 std      F96C01F0   1     ST8       <s81:d496:l8>(gr12,496)=gr11
   63| 000618 std      F96C01D8   1     ST8       <s81:d472:l8>(gr12,472)=gr11
   63| 00061C std      F96C01C0   1     ST8       <s81:d448:l8>(gr12,448)=gr11
   63| 000620 bc       4182005C   1     BT        CL.25,cr0,0x4/eq,taken=50%(0,0)
   63|                              CL.217:
   63| 000624 ld       E8140520   1     L8        gr0=bak_rtd_5(gr20,1312)
   63| 000628 std      FBCC01E0   1     ST8       d-vp3r(gr12,480)=gr30
   63| 00062C std      FB0C01E8   1     ST8       d-vp3r(gr12,488)=gr24
   63| 000630 std      FAEC01F0   1     ST8       d-vp3r(gr12,496)=gr23
   63| 000634 std      FACC01F8   1     ST8       d-vp3r(gr12,504)=gr22
   63| 000638 ld       E8740528   1     L8        gr3=bak_rtd_5(gr20,1320)
   63| 00063C std      F80C01A0   1     ST8       d-vp3r(gr12,416)=gr0
   63| 000640 ld       E8940530   1     L8        gr4=bak_rtd_5(gr20,1328)
   63| 000644 std      FAAC0200   1     ST8       d-vp3r(gr12,512)=gr21
   63| 000648 ld       E8B40538   1     L8        gr5=bak_rtd_5(gr20,1336)
   63| 00064C ld       E8D40540   1     L8        gr6=bak_rtd_5(gr20,1344)
   63| 000650 std      F86C01A8   1     ST8       d-vp3r(gr12,424)=gr3
   63| 000654 ld       E8F40548   1     L8        gr7=bak_rtd_5(gr20,1352)
   63| 000658 std      F88C01B0   1     ST8       d-vp3r(gr12,432)=gr4
   63| 00065C ld       E8140550   1     L8        gr0=bak_rtd_5(gr20,1360)
   63| 000660 std      F8AC01B8   1     ST8       d-vp3r(gr12,440)=gr5
   63| 000664 std      F8CC01C0   1     ST8       d-vp3r(gr12,448)=gr6
   63| 000668 ld       E8740558   1     L8        gr3=bak_rtd_5(gr20,1368)
   63| 00066C std      F8EC01C8   1     ST8       d-vp3r(gr12,456)=gr7
   63| 000670 std      F80C01D0   1     ST8       d-vp3r(gr12,464)=gr0
   63| 000674 std      F86C01D8   1     ST8       d-vp3r(gr12,472)=gr3
   63| 000678 b        48000020   1     B         CL.26,-1
   63|                              CL.25:
   63| 00067C mulld    7C0FC9D2   1     M         gr0=gr15,gr25
   63| 000680 rldicr   78031F25   1     SLL8_R    gr3,cr0=gr0,3
   63| 000684 bc       40822634   1     BF        CL.27,cr0,0x4/eq,taken=40%(40,60)
   63| 000688 addi     38000000   1     LI        gr0=0
   63| 00068C addi     386000F0   1     LI        gr3=240
   63| 000690 std      F80C01A0   1     ST8       <s81:d416:l8>(gr12,416)=gr0
   63| 000694 stb      986C01AA   1     ST1Z      <s81:d426:l1>(gr12,426)=gr3
   63|                              CL.26:
   64| 000698 lbz      880C0212   1     L1Z       gr0=<s81:d530:l1>(gr12,530)
   64| 00069C ld       E86C0208   1     L8        gr3=d-vp3i(gr12,520)
   64| 0006A0 ld       E88C0210   1     L8        gr4=d-vp3i(gr12,528)
   64| 0006A4 sth      B3AC0210   1     ST2Z      d-vp3i%d|scr_type#174|ata_type#175_1(gr12,528)=gr29
   64| 0006A8 stb      9B8C0213   1     ST1Z      <s81:d531:l1>(gr12,531)=gr28
   64| 0006AC ld       E8AC0218   1     L8        gr5=d-vp3i(gr12,536)
   64| 0006B0 std      FA6C0218   1     ST8       <s81:d536:l8>(gr12,536)=gr19
   64| 0006B4 std      F86105A0   1     ST8       bak_rtd_6(gr1,1440)=gr3
   64| 0006B8 std      F88105A8   1     ST8       bak_rtd_6(gr1,1448)=gr4
   64| 0006BC ld       E8CC0220   1     L8        gr6=d-vp3i(gr12,544)
   64| 0006C0 std      FA2C0220   1     ST8       <s81:d544:l8>(gr12,544)=gr17
   64| 0006C4 std      F8A105B0   1     ST8       bak_rtd_6(gr1,1456)=gr5
   64| 0006C8 ld       E8EC0228   1     L8        gr7=d-vp3i(gr12,552)
   64| 0006CC ld       E90C0230   1     L8        gr8=d-vp3i(gr12,560)
   64| 0006D0 std      F9EC0230   1     ST8       <s81:d560:l8>(gr12,560)=gr15
   64| 0006D4 std      F8C105B8   1     ST8       bak_rtd_6(gr1,1464)=gr6
   64| 0006D8 ld       E92C0238   1     L8        gr9=d-vp3i(gr12,568)
   64| 0006DC std      FA4C0238   1     ST8       <s81:d568:l8>(gr12,568)=gr18
   64| 0006E0 std      F8E105C0   1     ST8       bak_rtd_6(gr1,1472)=gr7
   64| 0006E4 std      F90105C8   1     ST8       bak_rtd_6(gr1,1480)=gr8
   64| 0006E8 ld       E94C0240   1     L8        gr10=d-vp3i(gr12,576)
   64| 0006EC ld       EBCC0248   1     L8        gr30=d-vp3i(gr12,584)
   64| 0006F0 std      FB4C0248   1     ST8       <s81:d584:l8>(gr12,584)=gr26
   64| 0006F4 std      F92105D0   1     ST8       bak_rtd_6(gr1,1488)=gr9
   64| 0006F8 ld       EBAC0250   1     L8        gr29=d-vp3i(gr12,592)
   64| 0006FC std      FA0C0250   1     ST8       <s81:d592:l8>(gr12,592)=gr16
   64| 000700 std      F94105D8   1     ST8       bak_rtd_6(gr1,1496)=gr10
   64| 000704 std      FBC105E0   1     ST8       bak_rtd_6(gr1,1504)=gr30
   64| 000708 ld       EB8C0258   1     L8        gr28=d-vp3i(gr12,600)
   64| 00070C ld       EB4C0260   1     L8        gr26=d-vp3i(gr12,608)
   64| 000710 std      FB6C0260   1     ST8       <s81:d608:l8>(gr12,608)=gr27
   64| 000714 std      FBA105E8   1     ST8       bak_rtd_6(gr1,1512)=gr29
   64| 000718 ld       EB6C0268   1     L8        gr27=d-vp3i(gr12,616)
   64| 00071C std      FA6C0268   1     ST8       <s81:d616:l8>(gr12,616)=gr19
   64| 000720 std      FB8105F0   1     ST8       bak_rtd_6(gr1,1520)=gr28
   64| 000724 std      FB4105F8   1     ST8       bak_rtd_6(gr1,1528)=gr26
   64| 000728 addi     3AE00003   1     LI        gr23=3
   64| 00072C addi     39600001   1     LI        gr11=1
   64| 000730 stw      92EC0214   1     ST4Z      <s81:d532:l4>(gr12,532)=gr23
   64| 000734 std      F96C0258   1     ST8       <s81:d600:l8>(gr12,600)=gr11
   64| 000738 std      F96C0240   1     ST8       <s81:d576:l8>(gr12,576)=gr11
   64| 00073C andi.    70000080   1     RN4_R     gr0,cr0=gr0,0,0x80
   64| 000740 std      FB610600   1     ST8       bak_rtd_6(gr1,1536)=gr27
   63| 000744 or       7C380B78   1     LR        gr24=gr1
   64| 000748 std      F96C0228   1     ST8       <s81:d552:l8>(gr12,552)=gr11
   64| 00074C bc       4182005C   1     BT        CL.31,cr0,0x4/eq,taken=50%(0,0)
   64|                              CL.216:
   64| 000750 ld       E81805A0   1     L8        gr0=bak_rtd_6(gr24,1440)
   64| 000754 std      FBCC0248   1     ST8       d-vp3i(gr12,584)=gr30
   64| 000758 std      FBAC0250   1     ST8       d-vp3i(gr12,592)=gr29
   64| 00075C std      FB8C0258   1     ST8       d-vp3i(gr12,600)=gr28
   64| 000760 std      FB4C0260   1     ST8       d-vp3i(gr12,608)=gr26
   64| 000764 ld       E87805A8   1     L8        gr3=bak_rtd_6(gr24,1448)
   64| 000768 std      F80C0208   1     ST8       d-vp3i(gr12,520)=gr0
   64| 00076C ld       E89805B0   1     L8        gr4=bak_rtd_6(gr24,1456)
   64| 000770 std      FB6C0268   1     ST8       d-vp3i(gr12,616)=gr27
   64| 000774 ld       E8B805B8   1     L8        gr5=bak_rtd_6(gr24,1464)
   64| 000778 ld       E8D805C0   1     L8        gr6=bak_rtd_6(gr24,1472)
   64| 00077C std      F86C0210   1     ST8       d-vp3i(gr12,528)=gr3
   64| 000780 ld       E8F805C8   1     L8        gr7=bak_rtd_6(gr24,1480)
   64| 000784 std      F88C0218   1     ST8       d-vp3i(gr12,536)=gr4
   64| 000788 ld       E81805D0   1     L8        gr0=bak_rtd_6(gr24,1488)
   64| 00078C std      F8AC0220   1     ST8       d-vp3i(gr12,544)=gr5
   64| 000790 std      F8CC0228   1     ST8       d-vp3i(gr12,552)=gr6
   64| 000794 ld       E87805D8   1     L8        gr3=bak_rtd_6(gr24,1496)
   64| 000798 std      F8EC0230   1     ST8       d-vp3i(gr12,560)=gr7
   64| 00079C std      F80C0238   1     ST8       d-vp3i(gr12,568)=gr0
   64| 0007A0 std      F86C0240   1     ST8       d-vp3i(gr12,576)=gr3
   64| 0007A4 b        48000020   1     B         CL.32,-1
   64|                              CL.31:
   64| 0007A8 mulld    7C0FC9D2   1     M         gr0=gr15,gr25
   64| 0007AC rldicr   78031F25   1     SLL8_R    gr3,cr0=gr0,3
   64| 0007B0 bc       408224E0   1     BF        CL.33,cr0,0x4/eq,taken=40%(40,60)
   64| 0007B4 addi     38000000   1     LI        gr0=0
   64| 0007B8 addi     386000F0   1     LI        gr3=240
   64| 0007BC std      F80C0208   1     ST8       <s81:d520:l8>(gr12,520)=gr0
   64| 0007C0 stb      986C0212   1     ST1Z      <s81:d530:l1>(gr12,530)=gr3
   64|                              CL.32:
   67| 0007C4 ld       E8620000   1     L8        gr3=.&&N&&mpipar(gr2,0)
   67| 0007C8 lwz      80030008   1     L4Z       gr0=<s180:d8:l4>(gr3,8)
   67| 0007CC cmpdi    2C200000   1     C8        cr0=gr0,0
   67| 0007D0 bc       4082014C   1     BF        CL.37,cr0,0x4/eq,taken=60%(60,40)
   68| 0007D4 ld       EBA20000   1     L8        gr29=.$STATIC(gr2,0)
   68| 0007D8 addi     38600000   1     LI        gr3=0
   66| 0007DC addi     3800FE0C   1     LI        gr0=-500
   68| 0007E0 ori      607E8000   1     OIL       gr30=gr3,0x8000
   66| 0007E4 stw      90010080   1     ST4Z      iseed(gr1,128)=gr0
   68| 0007E8 addi     38600006   1     LI        gr3=6
   68| 0007EC addi     38800101   1     LI        gr4=257
   68| 0007F0 or       7FA5EB78   1     LR        gr5=gr29
   68| 0007F4 or       7FC6F378   1     LR        gr6=gr30
   68| 0007F8 addi     38E00000   1     LI        gr7=0
   68| 0007FC addi     39000000   1     LI        gr8=0
   68| 000800 addi     39200000   1     LI        gr9=0
   68| 000804 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#13",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   68| 000808 ori      60000000   1
   68| 00080C ld       EB620000   1     L8        gr27=.+CONSTANT_AREA(gr2,0)
   68| 000810 or       7C7C1B78   1     LR        gr28=gr3
   68| 000814 addi     38A0002C   1     LI        gr5=44
   68| 000818 addi     38C00001   1     LI        gr6=1
   68| 00081C addi     389B000C   1     AI        gr4=gr27,12
   68| 000820 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   68| 000824 ori      60000000   1
   68| 000828 or       7F83E378   1     LR        gr3=gr28
   68| 00082C bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   68| 000830 ori      60000000   1
   69| 000834 addi     38BD0040   1     AI        gr5=gr29,64
   69| 000838 addi     38600006   1     LI        gr3=6
   69| 00083C addi     38800101   1     LI        gr4=257
   69| 000840 or       7FC6F378   1     LR        gr6=gr30
   69| 000844 addi     38E00000   1     LI        gr7=0
   69| 000848 addi     39000000   1     LI        gr8=0
   69| 00084C addi     39200000   1     LI        gr9=0
   69| 000850 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#15",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   69| 000854 ori      60000000   1
   69| 000858 or       7C7C1B78   1     LR        gr28=gr3
   69| 00085C addi     389B0038   1     AI        gr4=gr27,56
   69| 000860 addi     38A0002C   1     LI        gr5=44
   69| 000864 addi     38C00001   1     LI        gr6=1
   69| 000868 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   69| 00086C ori      60000000   1
   69| 000870 or       7F83E378   1     LR        gr3=gr28
   69| 000874 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   69| 000878 ori      60000000   1
   70| 00087C addi     38BD0080   1     AI        gr5=gr29,128
   70| 000880 or       7FC6F378   1     LR        gr6=gr30
   70| 000884 addi     38600006   1     LI        gr3=6
   70| 000888 addi     38800101   1     LI        gr4=257
   70| 00088C addi     38E00000   1     LI        gr7=0
   70| 000890 addi     39000000   1     LI        gr8=0
   70| 000894 addi     39200000   1     LI        gr9=0
   70| 000898 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#17",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   70| 00089C ori      60000000   1
   70| 0008A0 or       7C7C1B78   1     LR        gr28=gr3
   70| 0008A4 addi     389B0064   1     AI        gr4=gr27,100
   70| 0008A8 addi     38A0002C   1     LI        gr5=44
   70| 0008AC addi     38C00001   1     LI        gr6=1
   70| 0008B0 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   70| 0008B4 ori      60000000   1
   70| 0008B8 or       7F83E378   1     LR        gr3=gr28
   70| 0008BC bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   70| 0008C0 ori      60000000   1
   71| 0008C4 addi     38BD00C0   1     AI        gr5=gr29,192
   71| 0008C8 or       7FC6F378   1     LR        gr6=gr30
   71| 0008CC addi     38600006   1     LI        gr3=6
   71| 0008D0 addi     38800101   1     LI        gr4=257
   71| 0008D4 addi     38E00000   1     LI        gr7=0
   71| 0008D8 addi     39000000   1     LI        gr8=0
   71| 0008DC addi     39200000   1     LI        gr9=0
   71| 0008E0 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#19",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   71| 0008E4 ori      60000000   1
   71| 0008E8 addi     389B000C   1     AI        gr4=gr27,12
   71| 0008EC or       7C7E1B78   1     LR        gr30=gr3
   71| 0008F0 addi     38A0002C   1     LI        gr5=44
   71| 0008F4 addi     38C00001   1     LI        gr6=1
   71| 0008F8 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   71| 0008FC ori      60000000   1
   71| 000900 or       7FC3F378   1     LR        gr3=gr30
   71| 000904 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   71| 000908 ori      60000000   1
   72| 00090C addi     38810240   1     AI        gr4=gr1,576
   72| 000910 addi     38610080   1     AI        gr3=gr1,128
   72| 000914 bl       48000001   1     CALL      ran1,2,iseed",gr3,rnd",gr4,#ProcAlias",ran1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   72| 000918 ori      60000000   1
   73|                              CL.37:
   74| 00091C ld       EBA20000   1     L8        gr29=.&&N&vcvars(gr2,0)
   74| 000920 addi     3BC00000   1     LI        gr30=0
   74| 000924 addi     38E10084   1     AI        gr7=gr1,132
   74| 000928 stw      93C10084   1     ST4Z      T_2(gr1,132)=gr30
   74| 00092C or       7DC57378   1     LR        gr5=gr14
   74| 000930 or       7FE6FB78   1     LR        gr6=gr31
   74| 000934 ld       E87D0000   1     L8        gr3=<s81:d0:l8>(gr29,0)
   74| 000938 ld       E89D0068   1     L8        gr4=<s81:d104:l8>(gr29,104)
   74| 00093C bl       48000001   1     CALL      fouramp,5,vp1r",gr3,vp1i",gr4,nmodes,gr5,idx,gr6,T_2",gr7,fouramp",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   74| 000940 ori      60000000   1
   75| 000944 stw      93C10088   1     ST4Z      T_3(gr1,136)=gr30
   75| 000948 ld       E87D00D0   1     L8        gr3=<s81:d208:l8>(gr29,208)
   75| 00094C ld       E89D0138   1     L8        gr4=<s81:d312:l8>(gr29,312)
   75| 000950 addi     38E10088   1     AI        gr7=gr1,136
   75| 000954 or       7DC57378   1     LR        gr5=gr14
   75| 000958 or       7FE6FB78   1     LR        gr6=gr31
   75| 00095C bl       48000001   1     CALL      fouramp,5,vp2r",gr3,vp2i",gr4,nmodes,gr5,idx,gr6,T_3",gr7,fouramp",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   75| 000960 ori      60000000   1
   76| 000964 stw      93C1008C   1     ST4Z      T_4(gr1,140)=gr30
   76| 000968 ld       E87D01A0   1     L8        gr3=<s81:d416:l8>(gr29,416)
   76| 00096C ld       E89D0208   1     L8        gr4=<s81:d520:l8>(gr29,520)
   76| 000970 addi     38E1008C   1     AI        gr7=gr1,140
   76| 000974 or       7DC57378   1     LR        gr5=gr14
   76| 000978 or       7FE6FB78   1     LR        gr6=gr31
   76| 00097C bl       48000001   1     CALL      fouramp,5,vp3r",gr3,vp3i",gr4,nmodes,gr5,idx,gr6,T_4",gr7,fouramp",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   76| 000980 ori      60000000   1
   77| 000984 ld       E87D0000   1     L8        gr3=<s81:d0:l8>(gr29,0)
   77| 000988 ld       E89D0068   1     L8        gr4=<s81:d104:l8>(gr29,104)
   77| 00098C bl       48000001   1     CALL      fafotr,2,vp1r",gr3,vp1i",gr4,fafotr",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   77| 000990 ori      60000000   1
   78| 000994 ld       E87D00D0   1     L8        gr3=<s81:d208:l8>(gr29,208)
   78| 000998 ld       E89D0138   1     L8        gr4=<s81:d312:l8>(gr29,312)
   78| 00099C bl       48000001   1     CALL      fafotr,2,vp2r",gr3,vp2i",gr4,fafotr",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   78| 0009A0 ori      60000000   1
   79| 0009A4 ld       E87D01A0   1     L8        gr3=<s81:d416:l8>(gr29,416)
   79| 0009A8 ld       E89D0208   1     L8        gr4=<s81:d520:l8>(gr29,520)
   79| 0009AC bl       48000001   1     CALL      fafotr,2,vp3r",gr3,vp3i",gr4,fafotr",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   79| 0009B0 ori      60000000   1
   84| 0009B4 ld       EBE20000   1     L8        gr31=.&&N&&param(gr2,0)
   84| 0009B8 lwa      EB9F000A   1     L4A       gr28=<s141:d8:l4>(gr31,8)
   84| 0009BC sradi    7F801674   1     SRA8CA    gr0,ca=gr28,2
   84| 0009C0 cmpwi    2C9C0000   1     C4        cr1=gr28,0
   84| 0009C4 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
   84| 0009C8 std      FB810618   1     ST8       #SPILL1(gr1,1560)=gr28
   84| 0009CC rldicr   781B1764   1     SLL8      gr27=gr0,2
   84| 0009D0 subf     7F5BE051   1     S_R       gr26,cr0=gr28,gr27
   84| 0009D4 std      FB610620   1     ST8       #SPILL2(gr1,1568)=gr27
   84| 0009D8 crand    4E412A02   1     CR_N      cr4=cr[01],0x4/eq,0x2/gt,0x2/gt,cr4
   84| 0009DC std      FB410798   1     ST8       #SPILL49(gr1,1944)=gr26
   84| 0009E0 bc       40920134   1     BF        CL.187,cr4,0x4/eq,taken=50%(0,0)
  102| 0009E4 ld       E8820000   1     L8        gr4=.&&N&scratch(gr2,0)
   90| 0009E8 lwa      E81F0006   1     L4A       gr0=<s141:d4:l4>(gr31,4)
   96| 0009EC ld       E9420000   1     L8        gr10=.&&N&&param(gr2,0)
  102| 0009F0 ld       E9620000   1     L8        gr11=.&&N&vcvars(gr2,0)
  102| 0009F4 ld       E8FD0000   1     L8        gr7=<s81:d0:l8>(gr29,0)
  102| 0009F8 ld       E93D0018   1     L8        gr9=<s81:d24:l8>(gr29,24)
  102| 0009FC ld       E8C40498   1     L8        gr6=<s52:d1176:l8>(gr4,1176)
  102| 000A00 ld       E90404B0   1     L8        gr8=<s52:d1200:l8>(gr4,1200)
  102| 000A04 ld       E99D0048   1     L8        gr12=<s81:d72:l8>(gr29,72)
    0| 000A08 cmpwi    2C000000   1     C4        cr0=gr0,0
  102| 000A0C ld       EBE404E0   1     L8        gr31=<s52:d1248:l8>(gr4,1248)
   84| 000A10 addi     38600000   1     LI        gr3=0
   96| 000A14 lwa      EBCA0002   1     L4A       gr30=<s141:d0:l4>(gr10,0)
  102| 000A18 ld       EBA404C8   1     L8        gr29=<s52:d1224:l8>(gr4,1224)
  102| 000A1C ld       E88404F8   1     L8        gr4=<s52:d1272:l8>(gr4,1272)
  102| 000A20 ld       EB8B0030   1     L8        gr28=<s81:d48:l8>(gr11,48)
  102| 000A24 ld       E8AB0060   1     L8        gr5=<s81:d96:l8>(gr11,96)
    0| 000A28 bc       40812250   1     BF        CL.496,cr0,0x2/gt,taken=40%(40,60)
    0| 000A2C add      7D064214   1     A         gr8=gr6,gr8
    0| 000A30 ld       E8C20000   1     L8        gr6=.+CONSTANT_AREA(gr2,0)
    0| 000A34 add      7CE74A14   1     A         gr7=gr7,gr9
    0| 000A38 add      7D08FA14   1     A         gr8=gr8,gr31
    0| 000A3C add      7CE76214   1     A         gr7=gr7,gr12
    0| 000A40 add      7F68EA14   1     A         gr27=gr8,gr29
    0| 000A44 add      7F47E214   1     A         gr26=gr7,gr28
    0| 000A48 cmpdi    2C3E0000   1     C8        cr0=gr30,0
    0| 000A4C lfs      C0660090   1     LFS       fp3=+CONSTANT_AREA(gr6,144)
  102| 000A50 or       7FD7F378   1     LR        gr23=gr30
   84|                              CL.182:
   90| 000A54 addi     38C00000   1     LI        gr6=0
    0| 000A58 bc       408100A4   1     BF        CL.186,cr0,0x2/gt,taken=50%(0,0)
    0| 000A5C or       7F47D378   1     LR        gr7=gr26
    0| 000A60 or       7F79DB78   1     LR        gr25=gr27
   90|                              CL.183:
  102| 000A64 or       7CE83B78   1     LR        gr8=gr7
  102| 000A68 cmpwi    2F170001   1     C4        cr6=gr23,1
  102| 000A6C addi     39600002   1     LI        gr11=2
  102| 000A70 lfdux    7C082CEE   1     LFDU      fp0,gr8=vp1r(gr8,gr5,0)
    0| 000A74 mtspr    7FC903A6   1     LCTR      ctr=gr30
    0| 000A78 addi     38C60001   1     AI        gr6=gr6,1
  102| 000A7C or       7F29CB78   1     LR        gr9=gr25
  102| 000A80 addi     39400001   1     LI        gr10=1
  102| 000A84 bc       409A0008   1     BF        CL.906,cr6,0x4/eq,taken=50%(0,0)
  102| 000A88 addi     39600001   1     LI        gr11=1
  102|                              CL.906:
    0| 000A8C extsw    7D6B07B4   1     EXTS4     gr11=gr11
  102| 000A90 mulld    7D6559D2   1     M         gr11=gr5,gr11
  102| 000A94 lfdx     7C275CAE   1     LFL       fp1=vp1r(gr7,gr11,0)
    0| 000A98 bc       42400048   1     BCF       ctr=CL.907,taken=0%(0,100)
    0| 000A9C ori      60210000   1     XNOP      
    0| 000AA0 ori      60210000   1     XNOP      
    0|                              CL.908:
  102| 000AA4 addi     3B0A0001   1     AI        gr24=gr10,1
  102| 000AA8 subf     7D6AF050   1     S         gr11=gr30,gr10
  102| 000AAC fadd     FC00082A   1     AFL       fp0=fp0,fp1,fcr
  102| 000AB0 cmpwi    2F0B0001   1     C4        cr6=gr11,1
  102| 000AB4 addi     394A0002   1     AI        gr10=gr10,2
  102| 000AB8 bc       409A0008   1     BF        CL.909,cr6,0x4/eq,taken=50%(0,0)
  102| 000ABC addi     39400001   1     LI        gr10=1
  102|                              CL.909:
    0| 000AC0 extsw    7D4B07B4   1     EXTS4     gr11=gr10
   96| 000AC4 or       7F0AC378   1     LR        gr10=gr24
  102| 000AC8 mulld    7D6559D2   1     M         gr11=gr5,gr11
  102| 000ACC fmul     FC4000F2   1     MFL       fp2=fp0,fp3,fcr
  102| 000AD0 lfdux    7C082CEE   1     LFDU      fp0,gr8=vp1r(gr8,gr5,0)
  102| 000AD4 lfdx     7C275CAE   1     LFL       fp1=vp1r(gr7,gr11,0)
  102| 000AD8 stfdux   7C4925EE   1     STFDU     gr9,w3da(gr9,gr4,0)=fp2
    0| 000ADC bc       4200FFC8   1     BCT       ctr=CL.908,taken=100%(100,0)
    0|                              CL.907:
  102| 000AE0 fadd     FC00082A   1     AFL       fp0=fp0,fp1,fcr
   90| 000AE4 cmpld    7F260040   1     CL8       cr6=gr6,gr0
    0| 000AE8 add      7CE76214   1     A         gr7=gr7,gr12
    0| 000AEC add      7F39FA14   1     A         gr25=gr25,gr31
  102| 000AF0 fmul     FC0000F2   1     MFL       fp0=fp0,fp3,fcr
  102| 000AF4 stfdux   7C0925EE   2     STFDU     gr9,w3da(gr9,gr4,0)=fp0
   90| 000AF8 bc       4198FF6C   1     BT        CL.183,cr6,0x8/llt,taken=80%(80,20)
   90|                              CL.186:
   84| 000AFC ld       E8C10798   1     L8        gr6=#SPILL49(gr1,1944)
   84| 000B00 addi     38630001   1     AI        gr3=gr3,1
    0| 000B04 add      7F5AE214   1     A         gr26=gr26,gr28
    0| 000B08 add      7F7BEA14   1     A         gr27=gr27,gr29
   84| 000B0C cmpd     7F261800   1     C8        cr6=gr6,gr3
   84| 000B10 bc       4199FF44   1     BT        CL.182,cr6,0x2/gt,taken=80%(80,20)
   84|                              CL.187:
   84| 000B14 ld       E8010618   1     L8        gr0=#SPILL1(gr1,1560)
   84| 000B18 ld       E8610798   1     L8        gr3=#SPILL49(gr1,1944)
   84| 000B1C cmpd     7F201800   1     C8        cr6=gr0,gr3
   84| 000B20 crand    4F25CA02   1     CR_N      cr6=cr[16],0x2/gt,0x2/gt,0x2/gt,cr6
   84| 000B24 bc       4099043C   1     BF        CL.129,cr6,0x2/gt,taken=50%(0,0)
  102| 000B28 or       7C6E1B78   1     LR        gr14=gr3
  102| 000B2C ld       E8620000   1     L8        gr3=.&&N&scratch(gr2,0)
  102| 000B30 ld       EBE20000   1     L8        gr31=.&&N&vcvars(gr2,0)
   90| 000B34 ld       EBC20000   1     L8        gr30=.&&N&&param(gr2,0)
   84| 000B38 ld       EBA10620   1     L8        gr29=#SPILL2(gr1,1568)
   84| 000B3C addi     3B800000   1     LI        gr28=0
   84| 000B40 std      FB810628   1     ST8       #SPILL3(gr1,1576)=gr28
  102| 000B44 ld       E93F0030   1     L8        gr9=<s81:d48:l8>(gr31,48)
  102| 000B48 ld       E96304C8   1     L8        gr11=<s52:d1224:l8>(gr3,1224)
   90| 000B4C lwa      E81E0006   1     L4A       gr0=<s141:d4:l4>(gr30,4)
  102| 000B50 ld       E89F0000   1     L8        gr4=<s81:d0:l8>(gr31,0)
  102| 000B54 ld       E8DF0018   1     L8        gr6=<s81:d24:l8>(gr31,24)
  102| 000B58 ld       E9030498   1     L8        gr8=<s52:d1176:l8>(gr3,1176)
  102| 000B5C ld       E98304B0   1     L8        gr12=<s52:d1200:l8>(gr3,1200)
  102| 000B60 ld       EAFF0048   1     L8        gr23=<s81:d72:l8>(gr31,72)
  102| 000B64 ld       EAC304E0   1     L8        gr22=<s52:d1248:l8>(gr3,1248)
   84| 000B68 addi     38BDFFFF   1     AI        gr5=gr29,-1
    0| 000B6C mulld    7D4B71D2   1     M         gr10=gr11,gr14
    0| 000B70 mulld    7CE971D2   1     M         gr7=gr9,gr14
   84| 000B74 sradi    7CA51674   1     SRA8CA    gr5,ca=gr5,2
    0| 000B78 cmpwi    2C000000   1     C4        cr0=gr0,0
    0| 000B7C add      7D886214   1     A         gr12=gr8,gr12
    0| 000B80 add      7D043214   1     A         gr8=gr4,gr6
   96| 000B84 lwa      EABE0002   1     L4A       gr21=<s141:d0:l4>(gr30,0)
  102| 000B88 ld       E86304F8   1     L8        gr3=<s52:d1272:l8>(gr3,1272)
  102| 000B8C ld       E89F0060   1     L8        gr4=<s81:d96:l8>(gr31,96)
   84| 000B90 addze    7CC50194   1     ADDE      gr6,ca=gr5,0,ca
    0| 000B94 bc       408103CC   1     BF        CL.129,cr0,0x2/gt,taken=20%(20,80)
    0| 000B98 rldicr   797B1764   1     SLL8      gr27=gr11,2
    0| 000B9C add      7D8CB214   1     A         gr12=gr12,gr22
    0| 000BA0 std      FB610630   1     ST8       #SPILL4(gr1,1584)=gr27
    0| 000BA4 rldicr   793A1764   1     SLL8      gr26=gr9,2
    0| 000BA8 add      7D08BA14   1     A         gr8=gr8,gr23
    0| 000BAC std      FB410638   1     ST8       #SPILL5(gr1,1592)=gr26
    0| 000BB0 ld       E8A20000   1     L8        gr5=.+CONSTANT_AREA(gr2,0)
    0| 000BB4 subf     7FCBD850   1     S         gr30=gr27,gr11
    0| 000BB8 add      7D8A6214   1     A         gr12=gr10,gr12
    0| 000BBC rldicr   797F0FA4   1     SLL8      gr31=gr11,1
    0| 000BC0 subf     7D49D050   1     S         gr10=gr26,gr9
    0| 000BC4 add      7CE74214   1     A         gr7=gr7,gr8
    0| 000BC8 rldicr   79280FA4   1     SLL8      gr8=gr9,1
    0| 000BCC rldicl   7AB4F842   1     SRL8      gr20=gr21,1
    0| 000BD0 add      7F2CF214   1     A         gr25=gr12,gr30
    0| 000BD4 add      7F0CDA14   1     A         gr24=gr12,gr27
    0| 000BD8 std      FB210640   1     ST8       #SPILL6(gr1,1600)=gr25
    0| 000BDC std      FB010648   1     ST8       #SPILL7(gr1,1608)=gr24
    0| 000BE0 add      7E6CFA14   1     A         gr19=gr12,gr31
    0| 000BE4 add      7E4B6214   1     A         gr18=gr11,gr12
    0| 000BE8 std      FA610650   1     ST8       #SPILL8(gr1,1616)=gr19
    0| 000BEC std      FA410658   1     ST8       #SPILL9(gr1,1624)=gr18
    0| 000BF0 add      7D675214   1     A         gr11=gr7,gr10
    0| 000BF4 add      7E274A14   1     A         gr17=gr7,gr9
    0| 000BF8 std      F9610660   1     ST8       #SPILL10(gr1,1632)=gr11
    0| 000BFC std      FA210668   1     ST8       #SPILL11(gr1,1640)=gr17
    0| 000C00 add      7D274214   1     A         gr9=gr7,gr8
    0| 000C04 add      7E07D214   1     A         gr16=gr7,gr26
    0| 000C08 std      F9210670   1     ST8       #SPILL12(gr1,1648)=gr9
    0| 000C0C addi     39E60001   1     AI        gr15=gr6,1
    0| 000C10 std      FA010678   1     ST8       #SPILL13(gr1,1656)=gr16
    0| 000C14 std      F9E10680   1     ST8       #SPILL14(gr1,1664)=gr15
    0| 000C18 cmpdi    2FB50000   1     C8        cr7=gr21,0
    0| 000C1C lfs      C0050090   1     LFS       fp0=+CONSTANT_AREA(gr5,144)
    0| 000C20 andi.    72A50001   1     RN4_R     gr5,cr0=gr21,0,0x1
    0| 000C24 cmpdi    2D340000   1     C8        cr2=gr20,0
   84|                              CL.130:
   90| 000C28 addi     38A00000   1     LI        gr5=0
    0| 000C2C bc       409D02B4   1     BF        CL.131,cr7,0x2/gt,taken=20%(20,80)
    0| 000C30 ld       E8C10668   1     L8        gr6=#SPILL11(gr1,1640)
    0| 000C34 ld       E8E10670   1     L8        gr7=#SPILL12(gr1,1648)
    0| 000C38 ld       E9010678   1     L8        gr8=#SPILL13(gr1,1656)
    0| 000C3C ld       E9210660   1     L8        gr9=#SPILL10(gr1,1632)
    0| 000C40 ld       EA610640   1     L8        gr19=#SPILL6(gr1,1600)
    0| 000C44 ld       EA410648   1     L8        gr18=#SPILL7(gr1,1608)
    0| 000C48 ld       EA210658   1     L8        gr17=#SPILL9(gr1,1624)
    0| 000C4C ld       EA010650   1     L8        gr16=#SPILL8(gr1,1616)
   90|                              CL.132:
   96| 000C50 addi     3B400000   1     LI        gr26=0
  102| 000C54 or       7CCA3378   1     LR        gr10=gr6
  102| 000C58 or       7CEB3B78   1     LR        gr11=gr7
  102| 000C5C or       7D2C4B78   1     LR        gr12=gr9
  102| 000C60 or       7D1F4378   1     LR        gr31=gr8
  102| 000C64 or       7E3E8B78   1     LR        gr30=gr17
  102| 000C68 or       7E1D8378   1     LR        gr29=gr16
  102| 000C6C or       7E7C9B78   1     LR        gr28=gr19
  102| 000C70 or       7E5B9378   1     LR        gr27=gr18
    0| 000C74 addi     38A50001   1     AI        gr5=gr5,1
    0| 000C78 mtspr    7E8903A6   1     LCTR      ctr=gr20
    0| 000C7C bc       41820074   1     BT        CL.877,cr0,0x4/eq,taken=50%(0,0)
  102| 000C80 cmpwi    2E950001   1     C4        cr5=gr21,1
  102| 000C84 addi     3B200002   1     LI        gr25=2
  102| 000C88 lfdux    7C2B24EE   1     LFDU      fp1,gr11=vp1r(gr11,gr4,0)
  102| 000C8C lfdux    7C4C24EE   1     LFDU      fp2,gr12=vp1r(gr12,gr4,0)
  102| 000C90 lfdux    7C7F24EE   1     LFDU      fp3,gr31=vp1r(gr31,gr4,0)
  102| 000C94 addi     3B400001   1     LI        gr26=1
  102| 000C98 lfdux    7C8A24EE   1     LFDU      fp4,gr10=vp1r(gr10,gr4,0)
  102| 000C9C bc       40960008   1     BF        CL.794,cr5,0x4/eq,taken=50%(0,0)
  102| 000CA0 addi     3B200001   1     LI        gr25=1
  102|                              CL.794:
    0| 000CA4 extsw    7F3907B4   1     EXTS4     gr25=gr25
  102| 000CA8 mulld    7F24C9D2   1     M         gr25=gr4,gr25
  102| 000CAC lfdx     7CA6CCAE   1     LFL       fp5=vp1r(gr6,gr25,0)
  102| 000CB0 lfdx     7CC7CCAE   1     LFL       fp6=vp1r(gr7,gr25,0)
  102| 000CB4 lfdx     7CE9CCAE   1     LFL       fp7=vp1r(gr9,gr25,0)
  102| 000CB8 lfdx     7D08CCAE   1     LFL       fp8=vp1r(gr8,gr25,0)
  102| 000CBC fadd     FC84282A   1     AFL       fp4=fp4,fp5,fcr
  102| 000CC0 fadd     FC21302A   2     AFL       fp1=fp1,fp6,fcr
  102| 000CC4 fadd     FC42382A   2     AFL       fp2=fp2,fp7,fcr
  102| 000CC8 fadd     FC63402A   2     AFL       fp3=fp3,fp8,fcr
  102| 000CCC fmul     FC840032   2     MFL       fp4=fp4,fp0,fcr
  102| 000CD0 fmul     FC210032   2     MFL       fp1=fp1,fp0,fcr
  102| 000CD4 fmul     FC420032   2     MFL       fp2=fp2,fp0,fcr
  102| 000CD8 fmul     FC630032   2     MFL       fp3=fp3,fp0,fcr
  102| 000CDC stfdux   7C9E1DEE   2     STFDU     gr30,w3da(gr30,gr3,0)=fp4
  102| 000CE0 stfdux   7C3D1DEE   1     STFDU     gr29,w3da(gr29,gr3,0)=fp1
  102| 000CE4 stfdux   7C5C1DEE   1     STFDU     gr28,w3da(gr28,gr3,0)=fp2
  102| 000CE8 stfdux   7C7B1DEE   1     STFDU     gr27,w3da(gr27,gr3,0)=fp3
    0| 000CEC bc       418A01CC   1     BT        CL.797,cr2,0x4/eq,taken=20%(20,80)
    0|                              CL.877:
  102| 000CF0 subf     7F3AA850   1     S         gr25=gr21,gr26
  102| 000CF4 addi     39FA0001   1     AI        gr15=gr26,1
  102| 000CF8 cmpwi    2E990001   1     C4        cr5=gr25,1
  102| 000CFC addi     3B3A0002   1     AI        gr25=gr26,2
  102| 000D00 lfdux    7C8A24EE   1     LFDU      fp4,gr10=vp1r(gr10,gr4,0)
  102| 000D04 lfdux    7C2B24EE   1     LFDU      fp1,gr11=vp1r(gr11,gr4,0)
  102| 000D08 lfdux    7C4C24EE   1     LFDU      fp2,gr12=vp1r(gr12,gr4,0)
  102| 000D0C addi     3B1A0003   1     AI        gr24=gr26,3
  102| 000D10 subf     7DEFA850   1     S         gr15=gr21,gr15
  102| 000D14 bc       40960008   1     BF        CL.910,cr5,0x4/eq,taken=50%(0,0)
  102| 000D18 addi     3B200001   1     LI        gr25=1
  102|                              CL.910:
    0| 000D1C extsw    7F3907B4   1     EXTS4     gr25=gr25
  102| 000D20 cmpwi    2E8F0001   1     C4        cr5=gr15,1
  102| 000D24 addi     3B5A0002   1     AI        gr26=gr26,2
  102| 000D28 mulld    7F24C9D2   1     M         gr25=gr4,gr25
  102| 000D2C bc       40960008   1     BF        CL.911,cr5,0x4/eq,taken=50%(0,0)
  102| 000D30 addi     3B000001   1     LI        gr24=1
  102|                              CL.911:
    0| 000D34 extsw    7F1807B4   1     EXTS4     gr24=gr24
  102| 000D38 lfdx     7CE6CCAE   1     LFL       fp7=vp1r(gr6,gr25,0)
  102| 000D3C lfdx     7CA7CCAE   1     LFL       fp5=vp1r(gr7,gr25,0)
  102| 000D40 mulld    7F04C1D2   1     M         gr24=gr4,gr24
  102| 000D44 lfdx     7C69CCAE   1     LFL       fp3=vp1r(gr9,gr25,0)
    0| 000D48 bc       424000E8   1     BCF       ctr=CL.912,taken=0%(0,100)
    0|                              CL.913:
  102| 000D4C addi     39FA0002   1     AI        gr15=gr26,2
  102| 000D50 lfdux    7CDF24EE   1     LFDU      fp6,gr31=vp1r(gr31,gr4,0)
  102| 000D54 lfdx     7D08CCAE   1     LFL       fp8=vp1r(gr8,gr25,0)
  102| 000D58 subf     7F3AA850   1     S         gr25=gr21,gr26
  102| 000D5C fadd     FC84382A   1     AFL       fp4=fp4,fp7,fcr
  102| 000D60 fadd     FC21282A   2     AFL       fp1=fp1,fp5,fcr
  102| 000D64 fadd     FC42182A   2     AFL       fp2=fp2,fp3,fcr
  102| 000D68 lfdux    7C6A24EE   1     LFDU      fp3,gr10=vp1r(gr10,gr4,0)
  102| 000D6C lfdx     7CA6C4AE   1     LFL       fp5=vp1r(gr6,gr24,0)
  102| 000D70 fadd     FCC6402A   1     AFL       fp6=fp6,fp8,fcr
  102| 000D74 fmul     FC840032   2     MFL       fp4=fp4,fp0,fcr
  102| 000D78 fmul     FC210032   2     MFL       fp1=fp1,fp0,fcr
  102| 000D7C fmul     FC420032   2     MFL       fp2=fp2,fp0,fcr
  102| 000D80 lfdux    7CEB24EE   1     LFDU      fp7,gr11=vp1r(gr11,gr4,0)
  102| 000D84 lfdx     7D07C4AE   1     LFL       fp8=vp1r(gr7,gr24,0)
  102| 000D88 fadd     FC63282A   1     AFL       fp3=fp3,fp5,fcr
  102| 000D8C fmul     FCA60032   2     MFL       fp5=fp6,fp0,fcr
  102| 000D90 stfdux   7C9E1DEE   2     STFDU     gr30,w3da(gr30,gr3,0)=fp4
  102| 000D94 stfdux   7C3D1DEE   1     STFDU     gr29,w3da(gr29,gr3,0)=fp1
  102| 000D98 stfdux   7C5C1DEE   1     STFDU     gr28,w3da(gr28,gr3,0)=fp2
  102| 000D9C addi     39DA0001   1     AI        gr14=gr26,1
  102| 000DA0 cmpwi    2E990001   1     C4        cr5=gr25,1
  102| 000DA4 lfdux    7C2C24EE   1     LFDU      fp1,gr12=vp1r(gr12,gr4,0)
  102| 000DA8 lfdx     7C49C4AE   1     LFL       fp2=vp1r(gr9,gr24,0)
  102| 000DAC fadd     FC87402A   1     AFL       fp4=fp7,fp8,fcr
  102| 000DB0 fmul     FC630032   2     MFL       fp3=fp3,fp0,fcr
  102| 000DB4 stfdux   7CBB1DEE   2     STFDU     gr27,w3da(gr27,gr3,0)=fp5
  102| 000DB8 bc       40960008   1     BF        CL.914,cr5,0x4/eq,taken=50%(0,0)
  102| 000DBC addi     39E00001   1     LI        gr15=1
  102|                              CL.914:
    0| 000DC0 extsw    7DF907B4   1     EXTS4     gr25=gr15
  102| 000DC4 lfdux    7CBF24EE   1     LFDU      fp5,gr31=vp1r(gr31,gr4,0)
  102| 000DC8 lfdx     7CC8C4AE   1     LFL       fp6=vp1r(gr8,gr24,0)
  102| 000DCC fadd     FC21102A   1     AFL       fp1=fp1,fp2,fcr
  102| 000DD0 fmul     FC440032   2     MFL       fp2=fp4,fp0,fcr
  102| 000DD4 stfdux   7C7E1DEE   2     STFDU     gr30,w3da(gr30,gr3,0)=fp3
  102| 000DD8 subf     7F0EA850   1     S         gr24=gr21,gr14
  102| 000DDC mulld    7F24C9D2   1     M         gr25=gr4,gr25
  102| 000DE0 fadd     FC65302A   1     AFL       fp3=fp5,fp6,fcr
  102| 000DE4 fmul     FC210032   2     MFL       fp1=fp1,fp0,fcr
  102| 000DE8 stfdux   7C5D1DEE   2     STFDU     gr29,w3da(gr29,gr3,0)=fp2
  102| 000DEC cmpwi    2E980001   1     C4        cr5=gr24,1
  102| 000DF0 addi     3B1A0003   1     AI        gr24=gr26,3
  102| 000DF4 bc       40960008   1     BF        CL.915,cr5,0x4/eq,taken=50%(0,0)
  102| 000DF8 addi     3B000001   1     LI        gr24=1
  102|                              CL.915:
    0| 000DFC extsw    7F1807B4   1     EXTS4     gr24=gr24
  102| 000E00 fmul     FC430032   1     MFL       fp2=fp3,fp0,fcr
  102| 000E04 stfdux   7C3C1DEE   2     STFDU     gr28,w3da(gr28,gr3,0)=fp1
  102| 000E08 addi     3B5A0002   1     AI        gr26=gr26,2
  102| 000E0C mulld    7F04C1D2   1     M         gr24=gr4,gr24
  102| 000E10 stfdux   7C5B1DEE   1     STFDU     gr27,w3da(gr27,gr3,0)=fp2
  102| 000E14 lfdux    7C8A24EE   1     LFDU      fp4,gr10=vp1r(gr10,gr4,0)
  102| 000E18 lfdux    7C2B24EE   1     LFDU      fp1,gr11=vp1r(gr11,gr4,0)
  102| 000E1C lfdux    7C4C24EE   1     LFDU      fp2,gr12=vp1r(gr12,gr4,0)
  102| 000E20 lfdx     7CE6CCAE   1     LFL       fp7=vp1r(gr6,gr25,0)
  102| 000E24 lfdx     7CA7CCAE   1     LFL       fp5=vp1r(gr7,gr25,0)
  102| 000E28 lfdx     7C69CCAE   1     LFL       fp3=vp1r(gr9,gr25,0)
    0| 000E2C bc       4200FF20   1     BCT       ctr=CL.913,taken=100%(100,0)
    0|                              CL.912:
  102| 000E30 lfdux    7CDF24EE   1     LFDU      fp6,gr31=vp1r(gr31,gr4,0)
  102| 000E34 fadd     FC84382A   1     AFL       fp4=fp4,fp7,fcr
  102| 000E38 lfdx     7CE8CCAE   1     LFL       fp7=vp1r(gr8,gr25,0)
  102| 000E3C fadd     FD01282A   1     AFL       fp8=fp1,fp5,fcr
  102| 000E40 lfdux    7C2A24EE   1     LFDU      fp1,gr10=vp1r(gr10,gr4,0)
  102| 000E44 fadd     FC42182A   1     AFL       fp2=fp2,fp3,fcr
  102| 000E48 lfdx     7C66C4AE   1     LFL       fp3=vp1r(gr6,gr24,0)
  102| 000E4C fmul     FC840032   1     MFL       fp4=fp4,fp0,fcr
  102| 000E50 lfdux    7CAB24EE   1     LFDU      fp5,gr11=vp1r(gr11,gr4,0)
  102| 000E54 fadd     FCC6382A   1     AFL       fp6=fp6,fp7,fcr
  102| 000E58 lfdx     7CE7C4AE   1     LFL       fp7=vp1r(gr7,gr24,0)
  102| 000E5C fmul     FD080032   1     MFL       fp8=fp8,fp0,fcr
  102| 000E60 lfdux    7D2C24EE   1     LFDU      fp9,gr12=vp1r(gr12,gr4,0)
  102| 000E64 fadd     FC21182A   1     AFL       fp1=fp1,fp3,fcr
  102| 000E68 stfdux   7C9E1DEE   2     STFDU     gr30,w3da(gr30,gr3,0)=fp4
  102| 000E6C fmul     FC420032   1     MFL       fp2=fp2,fp0,fcr
  102| 000E70 lfdx     7C69C4AE   1     LFL       fp3=vp1r(gr9,gr24,0)
  102| 000E74 fadd     FC85382A   1     AFL       fp4=fp5,fp7,fcr
  102| 000E78 stfdux   7D1D1DEE   2     STFDU     gr29,w3da(gr29,gr3,0)=fp8
  102| 000E7C fmul     FCA60032   1     MFL       fp5=fp6,fp0,fcr
  102| 000E80 lfdux    7CDF24EE   1     LFDU      fp6,gr31=vp1r(gr31,gr4,0)
  102| 000E84 fmul     FC210032   1     MFL       fp1=fp1,fp0,fcr
  102| 000E88 stfdux   7C5C1DEE   2     STFDU     gr28,w3da(gr28,gr3,0)=fp2
  102| 000E8C fadd     FC49182A   1     AFL       fp2=fp9,fp3,fcr
  102| 000E90 lfdx     7C68C4AE   1     LFL       fp3=vp1r(gr8,gr24,0)
  102| 000E94 fmul     FC840032   1     MFL       fp4=fp4,fp0,fcr
  102| 000E98 stfdux   7CBB1DEE   2     STFDU     gr27,w3da(gr27,gr3,0)=fp5
  102| 000E9C stfdux   7C3E1DEE   1     STFDU     gr30,w3da(gr30,gr3,0)=fp1
  102| 000EA0 fmul     FC220032   1     MFL       fp1=fp2,fp0,fcr
  102| 000EA4 fadd     FC46182A   2     AFL       fp2=fp6,fp3,fcr
  102| 000EA8 stfdux   7C9D1DEE   2     STFDU     gr29,w3da(gr29,gr3,0)=fp4
  102| 000EAC stfdux   7C3C1DEE   1     STFDU     gr28,w3da(gr28,gr3,0)=fp1
  102| 000EB0 fmul     FC220032   1     MFL       fp1=fp2,fp0,fcr
  102| 000EB4 stfdux   7C3B1DEE   2     STFDU     gr27,w3da(gr27,gr3,0)=fp1
    0|                              CL.797:
   90| 000EB8 cmpld    7EA50040   1     CL8       cr5=gr5,gr0
    0| 000EBC add      7CC6BA14   1     A         gr6=gr6,gr23
    0| 000EC0 add      7CE7BA14   1     A         gr7=gr7,gr23
    0| 000EC4 add      7D08BA14   1     A         gr8=gr8,gr23
    0| 000EC8 add      7D29BA14   1     A         gr9=gr9,gr23
    0| 000ECC add      7E73B214   1     A         gr19=gr19,gr22
    0| 000ED0 add      7E52B214   1     A         gr18=gr18,gr22
    0| 000ED4 add      7E31B214   1     A         gr17=gr17,gr22
    0| 000ED8 add      7E10B214   1     A         gr16=gr16,gr22
   90| 000EDC bc       4194FD74   1     BT        CL.132,cr5,0x8/llt,taken=80%(80,20)
   90|                              CL.131:
   84| 000EE0 ld       E8A10628   1     L8        gr5=#SPILL3(gr1,1576)
    0| 000EE4 ld       E8C10630   1     L8        gr6=#SPILL4(gr1,1584)
    0| 000EE8 ld       E8E10640   1     L8        gr7=#SPILL6(gr1,1600)
   84| 000EEC ld       E9010680   1     L8        gr8=#SPILL14(gr1,1664)
    0| 000EF0 ld       E9210648   1     L8        gr9=#SPILL7(gr1,1608)
    0| 000EF4 ld       E9410650   1     L8        gr10=#SPILL8(gr1,1616)
    0| 000EF8 ld       E9610658   1     L8        gr11=#SPILL9(gr1,1624)
    0| 000EFC ld       E9810638   1     L8        gr12=#SPILL5(gr1,1592)
    0| 000F00 ld       EBE10660   1     L8        gr31=#SPILL10(gr1,1632)
    0| 000F04 ld       EBC10668   1     L8        gr30=#SPILL11(gr1,1640)
    0| 000F08 ld       EBA10670   1     L8        gr29=#SPILL12(gr1,1648)
    0| 000F0C ld       EB810678   1     L8        gr28=#SPILL13(gr1,1656)
   84| 000F10 addi     38A50001   1     AI        gr5=gr5,1
    0| 000F14 add      7CE63A14   1     A         gr7=gr6,gr7
   84| 000F18 std      F8A10628   1     ST8       #SPILL3(gr1,1576)=gr5
    0| 000F1C std      F8E10640   1     ST8       #SPILL6(gr1,1600)=gr7
   84| 000F20 cmpld    7EA54040   1     CL8       cr5=gr5,gr8
    0| 000F24 add      7D264A14   1     A         gr9=gr6,gr9
    0| 000F28 add      7D465214   1     A         gr10=gr6,gr10
    0| 000F2C std      F9210648   1     ST8       #SPILL7(gr1,1608)=gr9
    0| 000F30 std      F9410650   1     ST8       #SPILL8(gr1,1616)=gr10
    0| 000F34 add      7D665A14   1     A         gr11=gr6,gr11
    0| 000F38 add      7FECFA14   1     A         gr31=gr12,gr31
    0| 000F3C std      F9610658   1     ST8       #SPILL9(gr1,1624)=gr11
    0| 000F40 std      FBE10660   1     ST8       #SPILL10(gr1,1632)=gr31
    0| 000F44 add      7FCCF214   1     A         gr30=gr12,gr30
    0| 000F48 add      7FACEA14   1     A         gr29=gr12,gr29
    0| 000F4C std      FBC10668   1     ST8       #SPILL11(gr1,1640)=gr30
    0| 000F50 std      FBA10670   1     ST8       #SPILL12(gr1,1648)=gr29
    0| 000F54 add      7F8CE214   1     A         gr28=gr12,gr28
    0| 000F58 std      FB810678   1     ST8       #SPILL13(gr1,1656)=gr28
   84| 000F5C bc       4194FCCC   1     BT        CL.130,cr5,0x8/llt,taken=80%(80,20)
   84|                              CL.129:
   84| 000F60 bc       40920118   1     BF        CL.171,cr4,0x4/eq,taken=50%(0,0)
   90| 000F64 ld       E8C20000   1     L8        gr6=.&&N&&param(gr2,0)
  103| 000F68 ld       EB820000   1     L8        gr28=.&&N&vcvars(gr2,0)
  103| 000F6C ld       E8820000   1     L8        gr4=.&&N&scratch(gr2,0)
   84| 000F70 addi     38600000   1     LI        gr3=0
   90| 000F74 lwa      E8060006   1     L4A       gr0=<s141:d4:l4>(gr6,4)
  103| 000F78 ld       EBDC00D0   1     L8        gr30=<s81:d208:l8>(gr28,208)
  103| 000F7C ld       EBBC00E8   1     L8        gr29=<s81:d232:l8>(gr28,232)
  103| 000F80 ld       E93C0100   1     L8        gr9=<s81:d256:l8>(gr28,256)
  103| 000F84 ld       E8E40500   1     L8        gr7=<s52:d1280:l8>(gr4,1280)
  103| 000F88 ld       E9040518   1     L8        gr8=<s52:d1304:l8>(gr4,1304)
  103| 000F8C ld       E9440530   1     L8        gr10=<s52:d1328:l8>(gr4,1328)
  103| 000F90 ld       E9640548   1     L8        gr11=<s52:d1352:l8>(gr4,1352)
    0| 000F94 cmpwi    2C000000   1     C4        cr0=gr0,0
   96| 000F98 lwa      E9860002   1     L4A       gr12=<s141:d0:l4>(gr6,0)
  103| 000F9C ld       E8840560   1     L8        gr4=<s52:d1376:l8>(gr4,1376)
  103| 000FA0 ld       EBFC0118   1     L8        gr31=<s81:d280:l8>(gr28,280)
  103| 000FA4 ld       E8BC0130   1     L8        gr5=<s81:d304:l8>(gr28,304)
    0| 000FA8 bc       40811CB8   1     BF        CL.506,cr0,0x2/gt,taken=40%(40,60)
    0| 000FAC ld       E8C20000   1     L8        gr6=.+CONSTANT_AREA(gr2,0)
    0| 000FB0 add      7FDEEA14   1     A         gr30=gr30,gr29
    0| 000FB4 add      7CE74214   1     A         gr7=gr7,gr8
    0| 000FB8 add      7D0A5A14   1     A         gr8=gr10,gr11
    0| 000FBC add      7FC9F214   1     A         gr30=gr9,gr30
    0| 000FC0 add      7FA74214   1     A         gr29=gr7,gr8
    0| 000FC4 add      7F9EFA14   1     A         gr28=gr30,gr31
    0| 000FC8 cmpdi    2C2C0000   1     C8        cr0=gr12,0
    0| 000FCC lfs      C0860090   1     LFS       fp4=+CONSTANT_AREA(gr6,144)
   84|                              CL.166:
   90| 000FD0 addi     38C00000   1     LI        gr6=0
    0| 000FD4 bc       40810088   1     BF        CL.170,cr0,0x2/gt,taken=50%(0,0)
    0| 000FD8 or       7F9BE378   1     LR        gr27=gr28
    0| 000FDC or       7FB9EB78   1     LR        gr25=gr29
   90|                              CL.167:
  103| 000FE0 subf     7D060050   1     S         gr8=gr0,gr6
  103| 000FE4 or       7F67DB78   1     LR        gr7=gr27
  103| 000FE8 cmpwi    2F880001   1     C4        cr7=gr8,1
  103| 000FEC addi     3B460002   1     AI        gr26=gr6,2
  103| 000FF0 lfdux    7C072CEE   1     LFDU      fp0,gr7=vp2r(gr7,gr5,0)
    0| 000FF4 mtspr    7D8903A6   1     LCTR      ctr=gr12
    0| 000FF8 addi     3B060001   1     AI        gr24=gr6,1
  103| 000FFC or       7F28CB78   1     LR        gr8=gr25
  103| 001000 bc       409E0008   1     BF        CL.665,cr7,0x4/eq,taken=50%(0,0)
  103| 001004 addi     3B400001   1     LI        gr26=1
  103|                              CL.665:
    0| 001008 extsw    7F4607B4   1     EXTS4     gr6=gr26
  103| 00100C mulld    7CC6F9D2   1     M         gr6=gr6,gr31
  103| 001010 add      7CC6F214   1     A         gr6=gr6,gr30
  103| 001014 lfdux    7C262CEE   1     LFDU      fp1,gr6=vp2r(gr6,gr5,0)
  103| 001018 fadd     FC00082A   1     AFL       fp0=fp0,fp1,fcr
    0| 00101C bc       42400024   1     BCF       ctr=CL.916,taken=0%(0,100)
    0| 001020 ori      60210000   1     XNOP      
    0| 001024 ori      60210000   1     XNOP      
    0|                              CL.917:
  103| 001028 lfdux    7C272CEE   1     LFDU      fp1,gr7=vp2r(gr7,gr5,0)
  103| 00102C lfdux    7C462CEE   1     LFDU      fp2,gr6=vp2r(gr6,gr5,0)
  103| 001030 fmul     FC600132   1     MFL       fp3=fp0,fp4,fcr
  103| 001034 fadd     FC01102A   2     AFL       fp0=fp1,fp2,fcr
  103| 001038 stfdux   7C6825EE   2     STFDU     gr8,w3db(gr8,gr4,0)=fp3
    0| 00103C bc       4200FFEC   1     BCT       ctr=CL.917,taken=100%(100,0)
    0|                              CL.916:
  103| 001040 fmul     FC000132   1     MFL       fp0=fp0,fp4,fcr
   90| 001044 cmpld    7FB80040   1     CL8       cr7=gr24,gr0
   90| 001048 or       7F06C378   1     LR        gr6=gr24
    0| 00104C add      7F7BFA14   1     A         gr27=gr27,gr31
    0| 001050 add      7F2BCA14   1     A         gr25=gr11,gr25
  103| 001054 stfdux   7C0825EE   1     STFDU     gr8,w3db(gr8,gr4,0)=fp0
   90| 001058 bc       419CFF88   1     BT        CL.167,cr7,0x8/llt,taken=80%(80,20)
   90|                              CL.170:
   84| 00105C ld       E8C10798   1     L8        gr6=#SPILL49(gr1,1944)
   84| 001060 addi     38630001   1     AI        gr3=gr3,1
    0| 001064 add      7FC9F214   1     A         gr30=gr9,gr30
    0| 001068 add      7F89E214   1     A         gr28=gr9,gr28
    0| 00106C add      7FAAEA14   1     A         gr29=gr10,gr29
   84| 001070 cmpd     7FA61800   1     C8        cr7=gr6,gr3
   84| 001074 bc       419DFF5C   1     BT        CL.166,cr7,0x2/gt,taken=80%(80,20)
   84|                              CL.171:
   84| 001078 bc       4099074C   1     BF        CL.135,cr6,0x2/gt,taken=50%(0,0)
   90| 00107C ld       E9220000   1     L8        gr9=.&&N&&param(gr2,0)
  103| 001080 ld       EB620000   1     L8        gr27=.&&N&vcvars(gr2,0)
  103| 001084 ld       E8620000   1     L8        gr3=.&&N&scratch(gr2,0)
   84| 001088 ld       E8E10798   1     L8        gr7=#SPILL49(gr1,1944)
   90| 00108C lwa      E9490006   1     L4A       gr10=<s141:d4:l4>(gr9,4)
  103| 001090 ld       E91B0100   1     L8        gr8=<s81:d256:l8>(gr27,256)
  103| 001094 ld       E8A30530   1     L8        gr5=<s52:d1328:l8>(gr3,1328)
   96| 001098 lwa      EB290002   1     L4A       gr25=<s141:d0:l4>(gr9,0)
  103| 00109C ld       EB1B0118   1     L8        gr24=<s81:d280:l8>(gr27,280)
  103| 0010A0 ld       E81B00D0   1     L8        gr0=<s81:d208:l8>(gr27,208)
   90| 0010A4 std      F9410628   1     ST8       #SPILL3(gr1,1576)=gr10
  103| 0010A8 sradi    7D440E74   1     SRA8CA    gr4,ca=gr10,1
  103| 0010AC ld       EBFB00E8   1     L8        gr31=<s81:d232:l8>(gr27,232)
   96| 0010B0 std      FB210638   1     ST8       #SPILL5(gr1,1592)=gr25
  103| 0010B4 addze    7C840194   1     ADDE      gr4,ca=gr4,0,ca
  103| 0010B8 ld       EBC30500   1     L8        gr30=<s52:d1280:l8>(gr3,1280)
   90| 0010BC rldicr   78860FA4   1     SLL8      gr6=gr4,1
  103| 0010C0 ld       EBA30518   1     L8        gr29=<s52:d1304:l8>(gr3,1304)
  103| 0010C4 ld       E9630548   1     L8        gr11=<s52:d1352:l8>(gr3,1352)
   90| 0010C8 cmpwi    2E8A0000   1     C4        cr5=gr10,0
   90| 0010CC subf     7F465051   1     S_R       gr26,cr0=gr10,gr6
  103| 0010D0 std      FB010640   1     ST8       #SPILL6(gr1,1600)=gr24
    0| 0010D4 mulld    7D8741D2   1     M         gr12=gr7,gr8
   90| 0010D8 crand    4C350A02   1     CR_N      cr0=cr[50],0x2/gt,0x2/gt,0x2/gt,cr0
    0| 0010DC add      7F80FA14   1     A         gr28=gr0,gr31
   90| 0010E0 std      FB410630   1     ST8       #SPILL4(gr1,1584)=gr26
  103| 0010E4 ld       E8630560   1     L8        gr3=<s52:d1376:l8>(gr3,1376)
  103| 0010E8 ld       E89B0130   1     L8        gr4=<s81:d304:l8>(gr27,304)
    0| 0010EC bc       408100E0   1     BF        CL.418,cr0,0x2/gt,taken=20%(20,80)
    0| 0010F0 mulld    7D4539D2   1     M         gr10=gr5,gr7
    0| 0010F4 ld       E9220000   1     L8        gr9=.+CONSTANT_AREA(gr2,0)
    0| 0010F8 add      7F7DF214   1     A         gr27=gr29,gr30
    0| 0010FC add      7F455A14   1     A         gr26=gr5,gr11
    0| 001100 add      7F88E214   1     A         gr28=gr8,gr28
    0| 001104 add      7F7BD214   1     A         gr27=gr27,gr26
    0| 001108 add      7F8CE214   1     A         gr28=gr12,gr28
    0| 00110C add      7F6ADA14   1     A         gr27=gr10,gr27
    0| 001110 add      7F58E214   1     A         gr26=gr24,gr28
    0| 001114 cmpdi    2C390000   1     C8        cr0=gr25,0
    0| 001118 lfs      C0890090   1     LFS       fp4=+CONSTANT_AREA(gr9,144)
  103| 00111C ld       EAC10628   1     L8        gr22=#SPILL3(gr1,1576)
    0| 001120 ld       EAA10638   1     L8        gr21=#SPILL5(gr1,1592)
  103| 001124 ld       EA810640   1     L8        gr20=#SPILL6(gr1,1600)
   84|                              CL.160:
   90| 001128 addi     39200000   1     LI        gr9=0
    0| 00112C bc       40810084   1     BF        CL.175,cr0,0x2/gt,taken=50%(0,0)
    0| 001130 or       7F59D378   1     LR        gr25=gr26
    0| 001134 or       7F78DB78   1     LR        gr24=gr27
    0| 001138 ori      60210000   1     XNOP      
   90|                              CL.172:
  103| 00113C subf     7D89B050   1     S         gr12=gr22,gr9
  103| 001140 or       7F2ACB78   1     LR        gr10=gr25
  103| 001144 cmpwi    2F8C0001   1     C4        cr7=gr12,1
  103| 001148 addi     3AE90002   1     AI        gr23=gr9,2
  103| 00114C lfdux    7C0A24EE   1     LFDU      fp0,gr10=vp2r(gr10,gr4,0)
    0| 001150 mtspr    7EA903A6   1     LCTR      ctr=gr21
    0| 001154 addi     39290001   1     AI        gr9=gr9,1
  103| 001158 or       7F0CC378   1     LR        gr12=gr24
  103| 00115C bc       409E0008   1     BF        CL.666,cr7,0x4/eq,taken=50%(0,0)
  103| 001160 addi     3AE00001   1     LI        gr23=1
  103|                              CL.666:
    0| 001164 extsw    7EF707B4   1     EXTS4     gr23=gr23
  103| 001168 mulld    7EF4B9D2   1     M         gr23=gr20,gr23
  103| 00116C add      7EF7E214   1     A         gr23=gr23,gr28
  103| 001170 lfdux    7C3724EE   1     LFDU      fp1,gr23=vp2r(gr23,gr4,0)
  103| 001174 fadd     FC00082A   1     AFL       fp0=fp0,fp1,fcr
    0| 001178 bc       4240001C   1     BCF       ctr=CL.918,taken=0%(0,100)
    0|                              CL.919:
  103| 00117C lfdux    7C2A24EE   1     LFDU      fp1,gr10=vp2r(gr10,gr4,0)
  103| 001180 lfdux    7C5724EE   1     LFDU      fp2,gr23=vp2r(gr23,gr4,0)
  103| 001184 fmul     FC600132   1     MFL       fp3=fp0,fp4,fcr
  103| 001188 fadd     FC01102A   2     AFL       fp0=fp1,fp2,fcr
  103| 00118C stfdux   7C6C1DEE   2     STFDU     gr12,w3db(gr12,gr3,0)=fp3
    0| 001190 bc       4200FFEC   1     BCT       ctr=CL.919,taken=100%(100,0)
    0|                              CL.918:
   90| 001194 ld       E9410630   1     L8        gr10=#SPILL4(gr1,1584)
  103| 001198 fmul     FC000132   1     MFL       fp0=fp0,fp4,fcr
    0| 00119C add      7F34CA14   1     A         gr25=gr20,gr25
    0| 0011A0 add      7F0BC214   1     A         gr24=gr11,gr24
   90| 0011A4 cmpd     7FA95000   1     C8        cr7=gr9,gr10
  103| 0011A8 stfdux   7C0C1DEE   1     STFDU     gr12,w3db(gr12,gr3,0)=fp0
   90| 0011AC bc       419CFF90   1     BT        CL.172,cr7,0x1/lt,taken=80%(80,20)
   90|                              CL.175:
   84| 0011B0 ld       E9210618   1     L8        gr9=#SPILL1(gr1,1560)
   84| 0011B4 addi     38E70001   1     AI        gr7=gr7,1
    0| 0011B8 add      7F7B2A14   1     A         gr27=gr27,gr5
    0| 0011BC add      7F48D214   1     A         gr26=gr8,gr26
    0| 0011C0 add      7F9C4214   1     A         gr28=gr28,gr8
   84| 0011C4 cmpld    7FA74840   1     CL8       cr7=gr7,gr9
   84| 0011C8 bc       419CFF60   1     BT        CL.160,cr7,0x8/llt,taken=80%(80,20)
    0|                              CL.418:
   84| 0011CC bc       409905F8   1     BF        CL.135,cr6,0x2/gt,taken=50%(0,0)
    0| 0011D0 ld       EB610798   1     L8        gr27=#SPILL49(gr1,1944)
    0| 0011D4 ld       EB410630   1     L8        gr26=#SPILL4(gr1,1584)
    0| 0011D8 ld       EAC10640   1     L8        gr22=#SPILL6(gr1,1600)
   84| 0011DC ld       EAE10620   1     L8        gr23=#SPILL2(gr1,1568)
   90| 0011E0 ld       EB010628   1     L8        gr24=#SPILL3(gr1,1576)
    0| 0011E4 add      7C00FA14   1     A         gr0=gr0,gr31
    0| 0011E8 mulld    7D88D9D2   1     M         gr12=gr8,gr27
    0| 0011EC mulld    7D4BD1D2   1     M         gr10=gr11,gr26
    0| 0011F0 mulld    7D36D1D2   1     M         gr9=gr22,gr26
    0| 0011F4 mulld    7CE5D9D2   1     M         gr7=gr5,gr27
   84| 0011F8 addi     3B97FFFF   1     AI        gr28=gr23,-1
    0| 0011FC add      7FDEEA14   1     A         gr30=gr30,gr29
   90| 001200 cmpd     7FB8D000   1     C8        cr7=gr24,gr26
   84| 001204 sradi    7F9F1674   1     SRA8CA    gr31,ca=gr28,2
    0| 001208 add      7FA06214   1     A         gr29=gr0,gr12
    0| 00120C add      7D4AF214   1     A         gr10=gr10,gr30
   84| 001210 addi     3AA00000   1     LI        gr21=0
   90| 001214 crand    4C35EA02   1     CR_N      cr0=cr[57],0x2/gt,0x2/gt,0x2/gt,cr0
   84| 001218 std      FAA10648   1     ST8       #SPILL7(gr1,1608)=gr21
   84| 00121C addze    7F3F0194   1     ADDE      gr25,ca=gr31,0,ca
    0| 001220 bc       408105A4   1     BF        CL.135,cr0,0x2/gt,taken=20%(20,80)
    0| 001224 rldicr   79141764   1     SLL8      gr20=gr8,2
    0| 001228 add      7D29EA14   1     A         gr9=gr9,gr29
    0| 00122C std      FA810650   1     ST8       #SPILL8(gr1,1616)=gr20
    0| 001230 rldicr   7AC00FA4   1     SLL8      gr0=gr22,1
    0| 001234 add      7CE75214   1     A         gr7=gr7,gr10
    0| 001238 rldicr   796E0FA4   1     SLL8      gr14=gr11,1
    0| 00123C rldicr   78B31764   1     SLL8      gr19=gr5,2
    0| 001240 ld       EB020000   1     L8        gr24=.+CONSTANT_AREA(gr2,0)
    0| 001244 std      FA610658   1     ST8       #SPILL9(gr1,1624)=gr19
    0| 001248 addi     3B46FFFF   1     AI        gr26=gr6,-1
    0| 00124C subf     7FE8A050   1     S         gr31=gr20,gr8
    0| 001250 rldicr   790C0FA4   1     SLL8      gr12=gr8,1
    0| 001254 add      7D49B214   1     A         gr10=gr9,gr22
    0| 001258 add      7D204A14   1     A         gr9=gr0,gr9
    0| 00125C add      7FC55A14   1     A         gr30=gr5,gr11
    0| 001260 rldicr   78BB0FA4   1     SLL8      gr27=gr5,1
    0| 001264 add      7CC77214   1     A         gr6=gr7,gr14
    0| 001268 add      7D6B3A14   1     A         gr11=gr11,gr7
    0| 00126C subf     7F859850   1     S         gr28=gr19,gr5
    0| 001270 add      7E54EA14   1     A         gr18=gr20,gr29
    0| 001274 add      7E28EA14   1     A         gr17=gr8,gr29
    0| 001278 std      FA410660   1     ST8       #SPILL10(gr1,1632)=gr18
    0| 00127C std      FA210668   1     ST8       #SPILL11(gr1,1640)=gr17
    0| 001280 add      7E1DFA14   1     A         gr16=gr29,gr31
    0| 001284 add      7DECEA14   1     A         gr15=gr12,gr29
    0| 001288 std      FA010670   1     ST8       #SPILL12(gr1,1648)=gr16
    0| 00128C std      F9E10678   1     ST8       #SPILL13(gr1,1656)=gr15
    0| 001290 add      7FA85214   1     A         gr29=gr8,gr10
    0| 001294 add      7EA96214   1     A         gr21=gr9,gr12
    0| 001298 std      FBA10680   1     ST8       #SPILL14(gr1,1664)=gr29
    0| 00129C std      FAA10688   1     ST8       #SPILL15(gr1,1672)=gr21
    0| 0012A0 add      7EC9FA14   1     A         gr22=gr9,gr31
    0| 0012A4 add      7EEAA214   1     A         gr23=gr10,gr20
    0| 0012A8 std      FAC10690   1     ST8       #SPILL16(gr1,1680)=gr22
    0| 0012AC std      FAE10698   1     ST8       #SPILL17(gr1,1688)=gr23
    0| 0012B0 add      7E49A214   1     A         gr18=gr9,gr20
    0| 0012B4 add      7D084A14   1     A         gr8=gr8,gr9
    0| 0012B8 std      FA4106A0   1     ST8       #SPILL18(gr1,1696)=gr18
    0| 0012BC std      F90106A8   1     ST8       #SPILL19(gr1,1704)=gr8
    0| 0012C0 add      7D27F214   1     A         gr9=gr7,gr30
    0| 0012C4 add      7CE6DA14   1     A         gr7=gr6,gr27
    0| 0012C8 std      F92106B0   1     ST8       #SPILL20(gr1,1712)=gr9
    0| 0012CC std      F8E106B8   1     ST8       #SPILL21(gr1,1720)=gr7
    0| 0012D0 add      7FCB9A14   1     A         gr30=gr11,gr19
    0| 0012D4 add      7E869A14   1     A         gr20=gr6,gr19
    0| 0012D8 std      FBC106C0   1     ST8       #SPILL22(gr1,1728)=gr30
    0| 0012DC std      FA8106C8   1     ST8       #SPILL23(gr1,1736)=gr20
    0| 0012E0 add      7CA53214   1     A         gr5=gr5,gr6
    0| 0012E4 add      7CC6E214   1     A         gr6=gr6,gr28
    0| 0012E8 std      F8A106D0   1     ST8       #SPILL24(gr1,1744)=gr5
    0| 0012EC std      F8C106D8   1     ST8       #SPILL25(gr1,1752)=gr6
    0| 0012F0 add      7F9C5A14   1     A         gr28=gr28,gr11
    0| 0012F4 add      7D6BDA14   1     A         gr11=gr11,gr27
    0| 0012F8 std      FB8106E0   1     ST8       #SPILL26(gr1,1760)=gr28
    0| 0012FC std      F96106E8   1     ST8       #SPILL27(gr1,1768)=gr11
    0| 001300 add      7F6A6214   1     A         gr27=gr10,gr12
    0| 001304 add      7D8AFA14   1     A         gr12=gr10,gr31
    0| 001308 std      FB6106F0   1     ST8       #SPILL28(gr1,1776)=gr27
    0| 00130C addi     3BF90001   1     AI        gr31=gr25,1
    0| 001310 std      F98106F8   1     ST8       #SPILL29(gr1,1784)=gr12
    0| 001314 ld       EB210638   1     L8        gr25=#SPILL5(gr1,1592)
    0| 001318 lfs      C0180090   1     LFS       fp0=+CONSTANT_AREA(gr24,144)
    0| 00131C std      FBE10700   1     ST8       #SPILL30(gr1,1792)=gr31
    0| 001320 sradi    7F5A0E74   1     SRA8CA    gr26,ca=gr26,1
    0| 001324 addze    7F1A0194   1     ADDE      gr24,ca=gr26,0,ca
    0| 001328 cmpdi    2C390000   1     C8        cr0=gr25,0
    0| 00132C std      FB010708   1     ST8       #SPILL31(gr1,1800)=gr24
   84|                              CL.136:
   90| 001330 addi     38A00000   1     LI        gr5=0
    0| 001334 bc       40810380   1     BF        CL.137,cr0,0x2/gt,taken=20%(20,80)
    0| 001338 ld       EAC10708   1     L8        gr22=#SPILL31(gr1,1800)
    0| 00133C ld       E8C10698   1     L8        gr6=#SPILL17(gr1,1688)
    0| 001340 ld       E8E106F8   1     L8        gr7=#SPILL29(gr1,1784)
    0| 001344 ld       E9010680   1     L8        gr8=#SPILL14(gr1,1664)
    0| 001348 ld       E9210688   1     L8        gr9=#SPILL15(gr1,1672)
    0| 00134C ld       E94106F0   1     L8        gr10=#SPILL28(gr1,1776)
    0| 001350 ld       E9610690   1     L8        gr11=#SPILL16(gr1,1680)
    0| 001354 std      F8C10710   1     ST8       #SPILL32(gr1,1808)=gr6
    0| 001358 std      F8E10718   1     ST8       #SPILL33(gr1,1816)=gr7
    0| 00135C std      F9010720   1     ST8       #SPILL34(gr1,1824)=gr8
    0| 001360 std      F9210728   1     ST8       #SPILL35(gr1,1832)=gr9
    0| 001364 std      F9410730   1     ST8       #SPILL36(gr1,1840)=gr10
    0| 001368 std      F9610738   1     ST8       #SPILL37(gr1,1848)=gr11
    0| 00136C ld       E98106A8   1     L8        gr12=#SPILL19(gr1,1704)
    0| 001370 ld       EBE106E8   1     L8        gr31=#SPILL27(gr1,1768)
    0| 001374 ld       EBC106B0   1     L8        gr30=#SPILL20(gr1,1712)
    0| 001378 ld       EBA106C0   1     L8        gr29=#SPILL22(gr1,1728)
    0| 00137C ld       EB8106E0   1     L8        gr28=#SPILL26(gr1,1760)
    0| 001380 ld       EB6106B8   1     L8        gr27=#SPILL21(gr1,1720)
    0| 001384 std      F9810740   1     ST8       #SPILL38(gr1,1856)=gr12
    0| 001388 std      FBE10748   1     ST8       #SPILL39(gr1,1864)=gr31
    0| 00138C std      FBC10750   1     ST8       #SPILL40(gr1,1872)=gr30
    0| 001390 std      FBA10758   1     ST8       #SPILL41(gr1,1880)=gr29
    0| 001394 std      FB810760   1     ST8       #SPILL42(gr1,1888)=gr28
    0| 001398 std      FB610768   1     ST8       #SPILL43(gr1,1896)=gr27
    0| 00139C ld       EB4106C8   1     L8        gr26=#SPILL23(gr1,1736)
    0| 0013A0 ld       EB2106D8   1     L8        gr25=#SPILL25(gr1,1752)
    0| 0013A4 ld       EB0106D0   1     L8        gr24=#SPILL24(gr1,1744)
    0| 0013A8 ld       EAE106A0   1     L8        gr23=#SPILL18(gr1,1696)
    0| 0013AC addi     3AB60001   1     AI        gr21=gr22,1
    0| 0013B0 std      FB410770   1     ST8       #SPILL44(gr1,1904)=gr26
    0| 0013B4 std      FB210778   1     ST8       #SPILL45(gr1,1912)=gr25
    0| 0013B8 std      FB010780   1     ST8       #SPILL46(gr1,1920)=gr24
    0| 0013BC std      FAE10788   1     ST8       #SPILL47(gr1,1928)=gr23
    0| 0013C0 std      FAA10790   1     ST8       #SPILL48(gr1,1936)=gr21
   90|                              CL.138:
  103| 0013C4 ld       E9210630   1     L8        gr9=#SPILL4(gr1,1584)
  103| 0013C8 ld       E9410628   1     L8        gr10=#SPILL3(gr1,1576)
  103| 0013CC rldicr   78A60FA4   1     SLL8      gr6=gr5,1
  103| 0013D0 add      7CC64A14   1     A         gr6=gr6,gr9
  103| 0013D4 subf     7CE65050   1     S         gr7=gr10,gr6
  103| 0013D8 addi     39060002   1     AI        gr8=gr6,2
  103| 0013DC cmpwi    2F870001   1     C4        cr7=gr7,1
  103| 0013E0 addi     38E60003   1     AI        gr7=gr6,3
  103| 0013E4 bc       409E0008   1     BF        CL.667,cr7,0x4/eq,taken=50%(0,0)
  103| 0013E8 addi     39000001   1     LI        gr8=1
  103|                              CL.667:
  103| 0013EC ld       E9610640   1     L8        gr11=#SPILL6(gr1,1600)
    0| 0013F0 extsw    7D0807B4   1     EXTS4     gr8=gr8
  103| 0013F4 addi     38C60001   1     AI        gr6=gr6,1
  103| 0013F8 ld       E9810670   1     L8        gr12=#SPILL12(gr1,1648)
  103| 0013FC mulld    7F4859D2   1     M         gr26=gr8,gr11
  103| 001400 subf     7D065050   1     S         gr8=gr10,gr6
  103| 001404 add      7CCCD214   1     A         gr6=gr12,gr26
  103| 001408 cmpwi    2F880001   1     C4        cr7=gr8,1
  103| 00140C bc       409E0008   1     BF        CL.668,cr7,0x4/eq,taken=50%(0,0)
  103| 001410 addi     38E00001   1     LI        gr7=1
  103|                              CL.668:
    0| 001414 extsw    7CE807B4   1     EXTS4     gr8=gr7
  103| 001418 ld       EB010668   1     L8        gr24=#SPILL11(gr1,1640)
  103| 00141C mulld    7F2859D2   1     M         gr25=gr8,gr11
  103| 001420 ld       EAE10678   1     L8        gr23=#SPILL13(gr1,1656)
  103| 001424 ld       E9410720   1     L8        gr10=#SPILL34(gr1,1824)
  103| 001428 ld       E9810740   1     L8        gr12=#SPILL38(gr1,1856)
  103| 00142C ld       EBE10730   1     L8        gr31=#SPILL36(gr1,1840)
  103| 001430 ld       EBC10728   1     L8        gr30=#SPILL35(gr1,1832)
  103| 001434 add      7CF8D214   1     A         gr7=gr24,gr26
  103| 001438 add      7D17D214   1     A         gr8=gr23,gr26
  103| 00143C add      7D38CA14   1     A         gr9=gr24,gr25
  103| 001440 add      7D77CA14   1     A         gr11=gr23,gr25
  103| 001444 lfdux    7C2A24EE   1     LFDU      fp1,gr10=vp2r(gr10,gr4,0)
  103| 001448 lfdux    7D0724EE   1     LFDU      fp8,gr7=vp2r(gr7,gr4,0)
  103| 00144C lfdux    7C4C24EE   1     LFDU      fp2,gr12=vp2r(gr12,gr4,0)
  103| 001450 lfdux    7C8924EE   1     LFDU      fp4,gr9=vp2r(gr9,gr4,0)
  103| 001454 lfdux    7C7F24EE   1     LFDU      fp3,gr31=vp2r(gr31,gr4,0)
  103| 001458 lfdux    7CC824EE   1     LFDU      fp6,gr8=vp2r(gr8,gr4,0)
  103| 00145C lfdux    7CBE24EE   1     LFDU      fp5,gr30=vp2r(gr30,gr4,0)
  103| 001460 lfdux    7CEB24EE   1     LFDU      fp7,gr11=vp2r(gr11,gr4,0)
  103| 001464 fadd     FC21402A   1     AFL       fp1=fp1,fp8,fcr
  103| 001468 ld       EBA10718   1     L8        gr29=#SPILL33(gr1,1816)
  103| 00146C fadd     FC42202A   1     AFL       fp2=fp2,fp4,fcr
  103| 001470 ld       E9E10670   1     L8        gr15=#SPILL12(gr1,1648)
  103| 001474 fadd     FC63302A   1     AFL       fp3=fp3,fp6,fcr
  103| 001478 lfdux    7CC624EE   1     LFDU      fp6,gr6=vp2r(gr6,gr4,0)
  103| 00147C fadd     FCA5382A   1     AFL       fp5=fp5,fp7,fcr
  103| 001480 lfdux    7C9D24EE   1     LFDU      fp4,gr29=vp2r(gr29,gr4,0)
  103| 001484 fmul     FC210032   1     MFL       fp1=fp1,fp0,fcr
  103| 001488 ld       EB610738   1     L8        gr27=#SPILL37(gr1,1848)
  103| 00148C fmul     FC420032   1     MFL       fp2=fp2,fp0,fcr
    0| 001490 ld       EAC10638   1     L8        gr22=#SPILL5(gr1,1592)
  103| 001494 fmul     FC630032   1     MFL       fp3=fp3,fp0,fcr
  103| 001498 add      7F8FCA14   1     A         gr28=gr15,gr25
  103| 00149C fmul     FCA50032   1     MFL       fp5=fp5,fp0,fcr
  103| 0014A0 ld       E9E10660   1     L8        gr15=#SPILL10(gr1,1632)
  103| 0014A4 fadd     FCC4302A   1     AFL       fp6=fp4,fp6,fcr
  103| 0014A8 lfdux    7CFB24EE   1     LFDU      fp7,gr27=vp2r(gr27,gr4,0)
  103| 0014AC lfdux    7D1C24EE   1     LFDU      fp8,gr28=vp2r(gr28,gr4,0)
    0| 0014B0 mtspr    7EC903A6   1     LCTR      ctr=gr22
  103| 0014B4 ld       EB010710   1     L8        gr24=#SPILL32(gr1,1808)
  103| 0014B8 ld       EAE10788   1     L8        gr23=#SPILL47(gr1,1928)
  103| 0014BC ld       EAC10750   1     L8        gr22=#SPILL40(gr1,1872)
  103| 0014C0 ld       EAA10780   1     L8        gr21=#SPILL46(gr1,1920)
  103| 0014C4 ld       EA810748   1     L8        gr20=#SPILL39(gr1,1864)
  103| 0014C8 fadd     FC87402A   1     AFL       fp4=fp7,fp8,fcr
  103| 0014CC ld       EA610768   1     L8        gr19=#SPILL43(gr1,1896)
  103| 0014D0 fmul     FCE60032   1     MFL       fp7=fp6,fp0,fcr
  103| 0014D4 stfdux   7C361DEE   2     STFDU     gr22,w3db(gr22,gr3,0)=fp1
  103| 0014D8 stfdux   7C551DEE   1     STFDU     gr21,w3db(gr21,gr3,0)=fp2
  103| 0014DC stfdux   7C741DEE   1     STFDU     gr20,w3db(gr20,gr3,0)=fp3
  103| 0014E0 add      7F4FD214   1     A         gr26=gr15,gr26
  103| 0014E4 stfdux   7CB31DEE   1     STFDU     gr19,w3db(gr19,gr3,0)=fp5
  103| 0014E8 add      7F2FCA14   1     A         gr25=gr15,gr25
  103| 0014EC lfdux    7C5824EE   1     LFDU      fp2,gr24=vp2r(gr24,gr4,0)
  103| 0014F0 lfdux    7C7A24EE   1     LFDU      fp3,gr26=vp2r(gr26,gr4,0)
  103| 0014F4 lfdux    7CD724EE   1     LFDU      fp6,gr23=vp2r(gr23,gr4,0)
  103| 0014F8 lfdux    7CB924EE   1     LFDU      fp5,gr25=vp2r(gr25,gr4,0)
  103| 0014FC ld       EA410760   1     L8        gr18=#SPILL42(gr1,1888)
  103| 001500 ld       EA210778   1     L8        gr17=#SPILL45(gr1,1912)
  103| 001504 ld       EA010758   1     L8        gr16=#SPILL41(gr1,1880)
  103| 001508 ld       E9E10770   1     L8        gr15=#SPILL44(gr1,1904)
    0| 00150C bc       424000B4   1     BCF       ctr=CL.920,taken=0%(0,100)
    0| 001510 ori      60210000   1     XNOP      
    0| 001514 ori      60210000   1     XNOP      
    0| 001518 ori      60210000   1     XNOP      
    0|                              CL.921:
  103| 00151C lfdux    7C2A24EE   1     LFDU      fp1,gr10=vp2r(gr10,gr4,0)
  103| 001520 fadd     FD02182A   1     AFL       fp8=fp2,fp3,fcr
  103| 001524 fmul     FC840032   2     MFL       fp4=fp4,fp0,fcr
  103| 001528 stfdux   7CF21DEE   2     STFDU     gr18,w3db(gr18,gr3,0)=fp7
  103| 00152C lfdux    7C4724EE   1     LFDU      fp2,gr7=vp2r(gr7,gr4,0)
  103| 001530 lfdux    7C6C24EE   1     LFDU      fp3,gr12=vp2r(gr12,gr4,0)
  103| 001534 fadd     FCC6282A   1     AFL       fp6=fp6,fp5,fcr
  103| 001538 fmul     FCE80032   2     MFL       fp7=fp8,fp0,fcr
  103| 00153C stfdux   7C911DEE   2     STFDU     gr17,w3db(gr17,gr3,0)=fp4
  103| 001540 lfdux    7C8924EE   1     LFDU      fp4,gr9=vp2r(gr9,gr4,0)
  103| 001544 lfdux    7CBF24EE   1     LFDU      fp5,gr31=vp2r(gr31,gr4,0)
  103| 001548 fmul     FD260032   1     MFL       fp9=fp6,fp0,fcr
  103| 00154C stfdux   7CF01DEE   2     STFDU     gr16,w3db(gr16,gr3,0)=fp7
  103| 001550 lfdux    7CC824EE   1     LFDU      fp6,gr8=vp2r(gr8,gr4,0)
  103| 001554 lfdux    7CFE24EE   1     LFDU      fp7,gr30=vp2r(gr30,gr4,0)
  103| 001558 lfdux    7D0B24EE   1     LFDU      fp8,gr11=vp2r(gr11,gr4,0)
  103| 00155C stfdux   7D2F1DEE   1     STFDU     gr15,w3db(gr15,gr3,0)=fp9
  103| 001560 lfdux    7D3D24EE   1     LFDU      fp9,gr29=vp2r(gr29,gr4,0)
  103| 001564 lfdux    7D4624EE   1     LFDU      fp10,gr6=vp2r(gr6,gr4,0)
  103| 001568 fadd     FC21102A   1     AFL       fp1=fp1,fp2,fcr
  103| 00156C fadd     FC43202A   2     AFL       fp2=fp3,fp4,fcr
  103| 001570 fadd     FC65302A   2     AFL       fp3=fp5,fp6,fcr
  103| 001574 lfdux    7C9B24EE   1     LFDU      fp4,gr27=vp2r(gr27,gr4,0)
  103| 001578 lfdux    7CBC24EE   1     LFDU      fp5,gr28=vp2r(gr28,gr4,0)
  103| 00157C fadd     FCC7402A   1     AFL       fp6=fp7,fp8,fcr
  103| 001580 fmul     FC210032   2     MFL       fp1=fp1,fp0,fcr
  103| 001584 fmul     FCE20032   2     MFL       fp7=fp2,fp0,fcr
  103| 001588 fmul     FD030032   2     MFL       fp8=fp3,fp0,fcr
  103| 00158C lfdux    7C5824EE   1     LFDU      fp2,gr24=vp2r(gr24,gr4,0)
  103| 001590 lfdux    7C7A24EE   1     LFDU      fp3,gr26=vp2r(gr26,gr4,0)
  103| 001594 fadd     FD29502A   1     AFL       fp9=fp9,fp10,fcr
  103| 001598 fmul     FD460032   2     MFL       fp10=fp6,fp0,fcr
  103| 00159C stfdux   7C361DEE   2     STFDU     gr22,w3db(gr22,gr3,0)=fp1
  103| 0015A0 stfdux   7CF51DEE   1     STFDU     gr21,w3db(gr21,gr3,0)=fp7
  103| 0015A4 stfdux   7D141DEE   1     STFDU     gr20,w3db(gr20,gr3,0)=fp8
  103| 0015A8 lfdux    7CD724EE   1     LFDU      fp6,gr23=vp2r(gr23,gr4,0)
  103| 0015AC fadd     FC84282A   1     AFL       fp4=fp4,fp5,fcr
  103| 0015B0 fmul     FCE90032   2     MFL       fp7=fp9,fp0,fcr
  103| 0015B4 stfdux   7D531DEE   2     STFDU     gr19,w3db(gr19,gr3,0)=fp10
  103| 0015B8 lfdux    7CB924EE   1     LFDU      fp5,gr25=vp2r(gr25,gr4,0)
    0| 0015BC bc       4200FF60   1     BCT       ctr=CL.921,taken=100%(100,0)
    0|                              CL.920:
  103| 0015C0 fadd     FC22182A   1     AFL       fp1=fp2,fp3,fcr
   90| 0015C4 ld       E8C10790   1     L8        gr6=#SPILL48(gr1,1936)
  103| 0015C8 fadd     FC46282A   1     AFL       fp2=fp6,fp5,fcr
  103| 0015CC stfdux   7CF21DEE   2     STFDU     gr18,w3db(gr18,gr3,0)=fp7
  103| 0015D0 fmul     FC640032   1     MFL       fp3=fp4,fp0,fcr
    0| 0015D4 ld       E8E10710   1     L8        gr7=#SPILL32(gr1,1808)
  103| 0015D8 fmul     FC210032   1     MFL       fp1=fp1,fp0,fcr
    0| 0015DC ld       E9010718   1     L8        gr8=#SPILL33(gr1,1816)
  103| 0015E0 fmul     FC420032   1     MFL       fp2=fp2,fp0,fcr
    0| 0015E4 ld       E9210720   1     L8        gr9=#SPILL34(gr1,1824)
    0| 0015E8 ld       E9410728   1     L8        gr10=#SPILL35(gr1,1832)
  103| 0015EC stfdux   7C711DEE   1     STFDU     gr17,w3db(gr17,gr3,0)=fp3
    0| 0015F0 ld       E9610730   1     L8        gr11=#SPILL36(gr1,1840)
  103| 0015F4 stfdux   7C301DEE   1     STFDU     gr16,w3db(gr16,gr3,0)=fp1
    0| 0015F8 ld       E9810738   1     L8        gr12=#SPILL37(gr1,1848)
  103| 0015FC stfdux   7C4F1DEE   1     STFDU     gr15,w3db(gr15,gr3,0)=fp2
    0| 001600 ld       EBE10740   1     L8        gr31=#SPILL38(gr1,1856)
    0| 001604 ld       EBC10748   1     L8        gr30=#SPILL39(gr1,1864)
    0| 001608 ld       EBA10750   1     L8        gr29=#SPILL40(gr1,1872)
    0| 00160C ld       EB810758   1     L8        gr28=#SPILL41(gr1,1880)
    0| 001610 ld       EB610760   1     L8        gr27=#SPILL42(gr1,1888)
    0| 001614 ld       EB410768   1     L8        gr26=#SPILL43(gr1,1896)
    0| 001618 ld       EB210770   1     L8        gr25=#SPILL44(gr1,1904)
    0| 00161C ld       EB010778   1     L8        gr24=#SPILL45(gr1,1912)
    0| 001620 ld       EAE10780   1     L8        gr23=#SPILL46(gr1,1920)
    0| 001624 ld       EAC10788   1     L8        gr22=#SPILL47(gr1,1928)
   90| 001628 addi     38A50001   1     AI        gr5=gr5,1
    0| 00162C add      7CE03A14   1     A         gr7=gr0,gr7
   90| 001630 cmpld    7FA53040   1     CL8       cr7=gr5,gr6
    0| 001634 std      F8E10710   1     ST8       #SPILL32(gr1,1808)=gr7
    0| 001638 add      7D004214   1     A         gr8=gr0,gr8
    0| 00163C add      7D204A14   1     A         gr9=gr0,gr9
    0| 001640 std      F9010718   1     ST8       #SPILL33(gr1,1816)=gr8
    0| 001644 std      F9210720   1     ST8       #SPILL34(gr1,1824)=gr9
    0| 001648 add      7D405214   1     A         gr10=gr0,gr10
    0| 00164C add      7D605A14   1     A         gr11=gr0,gr11
    0| 001650 std      F9410728   1     ST8       #SPILL35(gr1,1832)=gr10
    0| 001654 std      F9610730   1     ST8       #SPILL36(gr1,1840)=gr11
    0| 001658 add      7D806214   1     A         gr12=gr0,gr12
    0| 00165C add      7FE0FA14   1     A         gr31=gr0,gr31
    0| 001660 std      F9810738   1     ST8       #SPILL37(gr1,1848)=gr12
    0| 001664 std      FBE10740   1     ST8       #SPILL38(gr1,1856)=gr31
    0| 001668 add      7FCEF214   1     A         gr30=gr14,gr30
    0| 00166C add      7FAEEA14   1     A         gr29=gr14,gr29
    0| 001670 std      FBC10748   1     ST8       #SPILL39(gr1,1864)=gr30
    0| 001674 std      FBA10750   1     ST8       #SPILL40(gr1,1872)=gr29
    0| 001678 add      7F8EE214   1     A         gr28=gr14,gr28
    0| 00167C add      7F6EDA14   1     A         gr27=gr14,gr27
    0| 001680 std      FB810758   1     ST8       #SPILL41(gr1,1880)=gr28
    0| 001684 std      FB610760   1     ST8       #SPILL42(gr1,1888)=gr27
    0| 001688 add      7F4ED214   1     A         gr26=gr14,gr26
    0| 00168C add      7F2ECA14   1     A         gr25=gr14,gr25
    0| 001690 std      FB410768   1     ST8       #SPILL43(gr1,1896)=gr26
    0| 001694 std      FB210770   1     ST8       #SPILL44(gr1,1904)=gr25
    0| 001698 add      7F0EC214   1     A         gr24=gr14,gr24
    0| 00169C add      7EEEBA14   1     A         gr23=gr14,gr23
    0| 0016A0 std      FB010778   1     ST8       #SPILL45(gr1,1912)=gr24
    0| 0016A4 std      FAE10780   1     ST8       #SPILL46(gr1,1920)=gr23
    0| 0016A8 add      7EC0B214   1     A         gr22=gr0,gr22
    0| 0016AC std      FAC10788   1     ST8       #SPILL47(gr1,1928)=gr22
   90| 0016B0 bc       419CFD14   1     BT        CL.138,cr7,0x8/llt,taken=80%(80,20)
   90|                              CL.137:
   84| 0016B4 ld       E8A10648   1     L8        gr5=#SPILL7(gr1,1608)
    0| 0016B8 ld       E8C10650   1     L8        gr6=#SPILL8(gr1,1616)
    0| 0016BC ld       E8E10660   1     L8        gr7=#SPILL10(gr1,1632)
   84| 0016C0 ld       E9010700   1     L8        gr8=#SPILL30(gr1,1792)
    0| 0016C4 ld       E9210668   1     L8        gr9=#SPILL11(gr1,1640)
    0| 0016C8 ld       E9410670   1     L8        gr10=#SPILL12(gr1,1648)
    0| 0016CC ld       E9610678   1     L8        gr11=#SPILL13(gr1,1656)
    0| 0016D0 ld       E9810680   1     L8        gr12=#SPILL14(gr1,1664)
    0| 0016D4 ld       EBE10688   1     L8        gr31=#SPILL15(gr1,1672)
    0| 0016D8 ld       EBC10690   1     L8        gr30=#SPILL16(gr1,1680)
    0| 0016DC ld       EBA10698   1     L8        gr29=#SPILL17(gr1,1688)
    0| 0016E0 ld       EB8106A0   1     L8        gr28=#SPILL18(gr1,1696)
    0| 0016E4 ld       EB6106A8   1     L8        gr27=#SPILL19(gr1,1704)
    0| 0016E8 ld       EB410658   1     L8        gr26=#SPILL9(gr1,1624)
    0| 0016EC ld       EB2106B0   1     L8        gr25=#SPILL20(gr1,1712)
    0| 0016F0 ld       EB0106B8   1     L8        gr24=#SPILL21(gr1,1720)
    0| 0016F4 ld       EAE106C0   1     L8        gr23=#SPILL22(gr1,1728)
    0| 0016F8 ld       EAC106C8   1     L8        gr22=#SPILL23(gr1,1736)
    0| 0016FC ld       EAA106D0   1     L8        gr21=#SPILL24(gr1,1744)
    0| 001700 ld       EA8106D8   1     L8        gr20=#SPILL25(gr1,1752)
    0| 001704 ld       EA6106E0   1     L8        gr19=#SPILL26(gr1,1760)
    0| 001708 ld       EA4106E8   1     L8        gr18=#SPILL27(gr1,1768)
    0| 00170C ld       EA2106F0   1     L8        gr17=#SPILL28(gr1,1776)
    0| 001710 ld       EA0106F8   1     L8        gr16=#SPILL29(gr1,1784)
   84| 001714 addi     38A50001   1     AI        gr5=gr5,1
    0| 001718 add      7CE63A14   1     A         gr7=gr6,gr7
   84| 00171C std      F8A10648   1     ST8       #SPILL7(gr1,1608)=gr5
    0| 001720 std      F8E10660   1     ST8       #SPILL10(gr1,1632)=gr7
   84| 001724 cmpld    7FA54040   1     CL8       cr7=gr5,gr8
    0| 001728 add      7D264A14   1     A         gr9=gr6,gr9
    0| 00172C add      7D465214   1     A         gr10=gr6,gr10
    0| 001730 std      F9210668   1     ST8       #SPILL11(gr1,1640)=gr9
    0| 001734 std      F9410670   1     ST8       #SPILL12(gr1,1648)=gr10
    0| 001738 add      7D665A14   1     A         gr11=gr6,gr11
    0| 00173C add      7D866214   1     A         gr12=gr6,gr12
    0| 001740 std      F9610678   1     ST8       #SPILL13(gr1,1656)=gr11
    0| 001744 std      F9810680   1     ST8       #SPILL14(gr1,1664)=gr12
    0| 001748 add      7FE6FA14   1     A         gr31=gr6,gr31
    0| 00174C add      7FC6F214   1     A         gr30=gr6,gr30
    0| 001750 std      FBE10688   1     ST8       #SPILL15(gr1,1672)=gr31
    0| 001754 std      FBC10690   1     ST8       #SPILL16(gr1,1680)=gr30
    0| 001758 add      7FA6EA14   1     A         gr29=gr6,gr29
    0| 00175C add      7F86E214   1     A         gr28=gr6,gr28
    0| 001760 std      FBA10698   1     ST8       #SPILL17(gr1,1688)=gr29
    0| 001764 std      FB8106A0   1     ST8       #SPILL18(gr1,1696)=gr28
    0| 001768 add      7F66DA14   1     A         gr27=gr6,gr27
    0| 00176C add      7F39D214   1     A         gr25=gr25,gr26
    0| 001770 std      FB6106A8   1     ST8       #SPILL19(gr1,1704)=gr27
    0| 001774 std      FB2106B0   1     ST8       #SPILL20(gr1,1712)=gr25
    0| 001778 add      7F18D214   1     A         gr24=gr24,gr26
    0| 00177C add      7EF7D214   1     A         gr23=gr23,gr26
    0| 001780 std      FB0106B8   1     ST8       #SPILL21(gr1,1720)=gr24
    0| 001784 std      FAE106C0   1     ST8       #SPILL22(gr1,1728)=gr23
    0| 001788 add      7ED6D214   1     A         gr22=gr22,gr26
    0| 00178C add      7EB5D214   1     A         gr21=gr21,gr26
    0| 001790 std      FAC106C8   1     ST8       #SPILL23(gr1,1736)=gr22
    0| 001794 std      FAA106D0   1     ST8       #SPILL24(gr1,1744)=gr21
    0| 001798 add      7E94D214   1     A         gr20=gr20,gr26
    0| 00179C add      7E73D214   1     A         gr19=gr19,gr26
    0| 0017A0 std      FA8106D8   1     ST8       #SPILL25(gr1,1752)=gr20
    0| 0017A4 std      FA6106E0   1     ST8       #SPILL26(gr1,1760)=gr19
    0| 0017A8 add      7E52D214   1     A         gr18=gr18,gr26
    0| 0017AC add      7E268A14   1     A         gr17=gr6,gr17
    0| 0017B0 std      FA4106E8   1     ST8       #SPILL27(gr1,1768)=gr18
    0| 0017B4 std      FA2106F0   1     ST8       #SPILL28(gr1,1776)=gr17
    0| 0017B8 add      7E068214   1     A         gr16=gr6,gr16
    0| 0017BC std      FA0106F8   1     ST8       #SPILL29(gr1,1784)=gr16
   84| 0017C0 bc       419CFB70   1     BT        CL.136,cr7,0x8/llt,taken=80%(80,20)
   84|                              CL.135:
   84| 0017C4 bc       40920120   1     BF        CL.159,cr4,0x4/eq,taken=50%(0,0)
   90| 0017C8 ld       E8C20000   1     L8        gr6=.&&N&&param(gr2,0)
  104| 0017CC ld       E8820000   1     L8        gr4=.&&N&scratch(gr2,0)
  104| 0017D0 ld       EB820000   1     L8        gr28=.&&N&vcvars(gr2,0)
   84| 0017D4 addi     38600000   1     LI        gr3=0
   90| 0017D8 lwa      E8060006   1     L4A       gr0=<s141:d4:l4>(gr6,4)
  104| 0017DC ld       E9040568   1     L8        gr8=<s52:d1384:l8>(gr4,1384)
  104| 0017E0 ld       E8FC01A0   1     L8        gr7=<s81:d416:l8>(gr28,416)
  104| 0017E4 ld       EBBC01B8   1     L8        gr29=<s81:d440:l8>(gr28,440)
  104| 0017E8 ld       E9240580   1     L8        gr9=<s52:d1408:l8>(gr4,1408)
  104| 0017EC ld       E95C01E8   1     L8        gr10=<s81:d488:l8>(gr28,488)
  104| 0017F0 ld       E96405B0   1     L8        gr11=<s52:d1456:l8>(gr4,1456)
    0| 0017F4 cmpwi    2C000000   1     C4        cr0=gr0,0
   96| 0017F8 lwa      E9860002   1     L4A       gr12=<s141:d0:l4>(gr6,0)
  104| 0017FC ld       EBE40598   1     L8        gr31=<s52:d1432:l8>(gr4,1432)
  104| 001800 ld       E88405C8   1     L8        gr4=<s52:d1480:l8>(gr4,1480)
  104| 001804 ld       EBDC01D0   1     L8        gr30=<s81:d464:l8>(gr28,464)
  104| 001808 ld       E8BC0200   1     L8        gr5=<s81:d512:l8>(gr28,512)
    0| 00180C bc       4081143C   1     BF        CL.521,cr0,0x2/gt,taken=40%(40,60)
    0| 001810 ld       E8C20000   1     L8        gr6=.+CONSTANT_AREA(gr2,0)
    0| 001814 add      7D084A14   1     A         gr8=gr8,gr9
    0| 001818 add      7CE7EA14   1     A         gr7=gr7,gr29
    0| 00181C add      7D085A14   1     A         gr8=gr8,gr11
    0| 001820 add      7FA75214   1     A         gr29=gr7,gr10
    0| 001824 add      7F88FA14   1     A         gr28=gr8,gr31
    0| 001828 add      7F7DF214   1     A         gr27=gr29,gr30
    0| 00182C cmpdi    2C2C0000   1     C8        cr0=gr12,0
    0| 001830 lfs      C0860090   1     LFS       fp4=+CONSTANT_AREA(gr6,144)
   84|                              CL.154:
   90| 001834 addi     38C00000   1     LI        gr6=0
    0| 001838 bc       40810094   1     BF        CL.158,cr0,0x2/gt,taken=50%(0,0)
    0| 00183C ld       E9210618   1     L8        gr9=#SPILL1(gr1,1560)
    0| 001840 addi     38E30002   1     AI        gr7=gr3,2
    0| 001844 or       7FBAEB78   1     LR        gr26=gr29
    0| 001848 or       7F79DB78   1     LR        gr25=gr27
    0| 00184C or       7F97E378   1     LR        gr23=gr28
    0| 001850 subf     7D034850   1     S         gr8=gr9,gr3
    0| 001854 cmpwi    2F880001   1     C4        cr7=gr8,1
    0| 001858 bc       409E0008   1     BF        CL.669,cr7,0x4/eq,taken=50%(0,0)
    0| 00185C addi     38E00001   1     LI        gr7=1
    0|                              CL.669:
    0| 001860 extsw    7CE707B4   1     EXTS4     gr7=gr7
    0| 001864 mulld    7F07F1D2   1     M         gr24=gr7,gr30
   90|                              CL.155:
  104| 001868 add      7CF8D214   1     A         gr7=gr24,gr26
  104| 00186C or       7F28CB78   1     LR        gr8=gr25
  104| 001870 lfdux    7C072CEE   1     LFDU      fp0,gr7=vp3r(gr7,gr5,0)
  104| 001874 lfdux    7C282CEE   1     LFDU      fp1,gr8=vp3r(gr8,gr5,0)
    0| 001878 mtspr    7D8903A6   1     LCTR      ctr=gr12
    0| 00187C addi     38C60001   1     AI        gr6=gr6,1
  104| 001880 or       7EE9BB78   1     LR        gr9=gr23
  104| 001884 fadd     FC01002A   1     AFL       fp0=fp1,fp0,fcr
    0| 001888 bc       42400028   1     BCF       ctr=CL.922,taken=0%(0,100)
    0| 00188C ori      60210000   1     XNOP      
    0| 001890 ori      60210000   1     XNOP      
    0| 001894 ori      60210000   1     XNOP      
    0|                              CL.923:
  104| 001898 lfdux    7C282CEE   1     LFDU      fp1,gr8=vp3r(gr8,gr5,0)
  104| 00189C lfdux    7C472CEE   1     LFDU      fp2,gr7=vp3r(gr7,gr5,0)
  104| 0018A0 fmul     FC600132   1     MFL       fp3=fp0,fp4,fcr
  104| 0018A4 fadd     FC01102A   2     AFL       fp0=fp1,fp2,fcr
  104| 0018A8 stfdux   7C6925EE   2     STFDU     gr9,w3dc(gr9,gr4,0)=fp3
    0| 0018AC bc       4200FFEC   1     BCT       ctr=CL.923,taken=100%(100,0)
    0|                              CL.922:
  104| 0018B0 fmul     FC000132   1     MFL       fp0=fp0,fp4,fcr
   90| 0018B4 cmpld    7FA60040   1     CL8       cr7=gr6,gr0
    0| 0018B8 add      7F4AD214   1     A         gr26=gr10,gr26
    0| 0018BC add      7F2ACA14   1     A         gr25=gr10,gr25
    0| 0018C0 add      7EEBBA14   1     A         gr23=gr11,gr23
  104| 0018C4 stfdux   7C0925EE   1     STFDU     gr9,w3dc(gr9,gr4,0)=fp0
   90| 0018C8 bc       419CFFA0   1     BT        CL.155,cr7,0x8/llt,taken=80%(80,20)
   90|                              CL.158:
   84| 0018CC ld       E8C10798   1     L8        gr6=#SPILL49(gr1,1944)
   84| 0018D0 addi     38630001   1     AI        gr3=gr3,1
    0| 0018D4 add      7F7BF214   1     A         gr27=gr27,gr30
    0| 0018D8 add      7F9CFA14   1     A         gr28=gr28,gr31
   84| 0018DC cmpd     7FA61800   1     C8        cr7=gr6,gr3
   84| 0018E0 bc       419DFF54   1     BT        CL.154,cr7,0x2/gt,taken=80%(80,20)
   84|                              CL.159:
   84| 0018E4 bc       40990370   1     BF        CL.141,cr6,0x2/gt,taken=50%(0,0)
  104| 0018E8 ld       E9620000   1     L8        gr11=.&&N&vcvars(gr2,0)
  104| 0018EC ld       E8620000   1     L8        gr3=.&&N&scratch(gr2,0)
   90| 0018F0 ld       EBC20000   1     L8        gr30=.&&N&&param(gr2,0)
   84| 0018F4 ld       EB810620   1     L8        gr28=#SPILL2(gr1,1568)
    0| 0018F8 ld       EB610798   1     L8        gr27=#SPILL49(gr1,1944)
   84| 0018FC addi     3B200000   1     LI        gr25=0
  104| 001900 ld       EBEB01D0   1     L8        gr31=<s81:d464:l8>(gr11,464)
   84| 001904 std      FB210620   1     ST8       #SPILL2(gr1,1568)=gr25
  104| 001908 ld       E9830598   1     L8        gr12=<s52:d1432:l8>(gr3,1432)
   90| 00190C lwa      EBBE0006   1     L4A       gr29=<s141:d4:l4>(gr30,4)
  104| 001910 ld       E88B01A0   1     L8        gr4=<s81:d416:l8>(gr11,416)
  104| 001914 ld       E8CB01B8   1     L8        gr6=<s81:d440:l8>(gr11,440)
  104| 001918 std      FBE10628   1     ST8       #SPILL3(gr1,1576)=gr31
  104| 00191C ld       E9230568   1     L8        gr9=<s52:d1384:l8>(gr3,1384)
  104| 001920 ld       E9430580   1     L8        gr10=<s52:d1408:l8>(gr3,1408)
   90| 001924 std      FBA10630   1     ST8       #SPILL4(gr1,1584)=gr29
   96| 001928 lwa      EB1E0002   1     L4A       gr24=<s141:d0:l4>(gr30,0)
   84| 00192C addi     38BCFFFF   1     AI        gr5=gr28,-1
  104| 001930 ld       E80B01E8   1     L8        gr0=<s81:d488:l8>(gr11,488)
  104| 001934 ld       EB4305B0   1     L8        gr26=<s52:d1456:l8>(gr3,1456)
    0| 001938 cmpwi    2C1D0000   1     C4        cr0=gr29,0
   84| 00193C sradi    7CA51674   1     SRA8CA    gr5,ca=gr5,2
   96| 001940 std      FB010638   1     ST8       #SPILL5(gr1,1592)=gr24
    0| 001944 mulld    7D0CD9D2   1     M         gr8=gr12,gr27
    0| 001948 mulld    7CFBF9D2   1     M         gr7=gr27,gr31
    0| 00194C add      7D295214   1     A         gr9=gr9,gr10
    0| 001950 add      7D443214   1     A         gr10=gr4,gr6
  104| 001954 ld       E86305C8   1     L8        gr3=<s52:d1480:l8>(gr3,1480)
  104| 001958 ld       E88B0200   1     L8        gr4=<s81:d512:l8>(gr11,512)
   84| 00195C addze    7CC50194   1     ADDE      gr6,ca=gr5,0,ca
    0| 001960 bc       408102F4   1     BF        CL.141,cr0,0x2/gt,taken=20%(20,80)
    0| 001964 ld       EAA10628   1     L8        gr21=#SPILL3(gr1,1576)
    0| 001968 rldicr   799C1764   1     SLL8      gr28=gr12,2
    0| 00196C add      7D29D214   1     A         gr9=gr9,gr26
    0| 001970 std      FB810640   1     ST8       #SPILL6(gr1,1600)=gr28
    0| 001974 rldicr   7BF71764   1     SLL8      gr23=gr31,2
    0| 001978 add      7EC05214   1     A         gr22=gr0,gr10
    0| 00197C std      FAE10648   1     ST8       #SPILL7(gr1,1608)=gr23
    0| 001980 std      FAC10650   1     ST8       #SPILL8(gr1,1616)=gr22
    0| 001984 ld       E8A20000   1     L8        gr5=.+CONSTANT_AREA(gr2,0)
    0| 001988 add      7D484A14   1     A         gr10=gr8,gr9
    0| 00198C rldicr   799F0FA4   1     SLL8      gr31=gr12,1
    0| 001990 subf     7D6CE050   1     S         gr11=gr28,gr12
    0| 001994 subf     7D35B850   1     S         gr9=gr23,gr21
    0| 001998 add      7CE7B214   1     A         gr7=gr7,gr22
    0| 00199C rldicr   7AA80FA4   1     SLL8      gr8=gr21,1
    0| 0019A0 add      7E8AE214   1     A         gr20=gr10,gr28
    0| 0019A4 add      7E6A6214   1     A         gr19=gr10,gr12
    0| 0019A8 std      FA810658   1     ST8       #SPILL9(gr1,1624)=gr20
    0| 0019AC std      FA610660   1     ST8       #SPILL10(gr1,1632)=gr19
    0| 0019B0 add      7D8AFA14   1     A         gr12=gr10,gr31
    0| 0019B4 add      7E4A5A14   1     A         gr18=gr10,gr11
    0| 0019B8 std      F9810668   1     ST8       #SPILL11(gr1,1640)=gr12
    0| 0019BC std      FA410670   1     ST8       #SPILL12(gr1,1648)=gr18
    0| 0019C0 add      7E274A14   1     A         gr17=gr7,gr9
    0| 0019C4 add      7E07AA14   1     A         gr16=gr7,gr21
    0| 0019C8 std      FA210678   1     ST8       #SPILL13(gr1,1656)=gr17
    0| 0019CC std      FA010680   1     ST8       #SPILL14(gr1,1664)=gr16
    0| 0019D0 add      7DE74214   1     A         gr15=gr7,gr8
    0| 0019D4 add      7DC7BA14   1     A         gr14=gr7,gr23
    0| 0019D8 std      F9E10688   1     ST8       #SPILL15(gr1,1672)=gr15
    0| 0019DC std      F9C10690   1     ST8       #SPILL16(gr1,1680)=gr14
    0| 0019E0 addi     39460001   1     AI        gr10=gr6,1
    0| 0019E4 cmpdi    2C380000   1     C8        cr0=gr24,0
    0| 0019E8 std      F9410698   1     ST8       #SPILL17(gr1,1688)=gr10
    0| 0019EC lfs      C0050090   1     LFS       fp0=+CONSTANT_AREA(gr5,144)
   84|                              CL.142:
   90| 0019F0 addi     38A00000   1     LI        gr5=0
    0| 0019F4 bc       408101E0   1     BF        CL.143,cr0,0x2/gt,taken=50%(0,0)
    0| 0019F8 ld       E9210620   1     L8        gr9=#SPILL2(gr1,1568)
    0| 0019FC ld       E9410798   1     L8        gr10=#SPILL49(gr1,1944)
    0| 001A00 ld       E9610618   1     L8        gr11=#SPILL1(gr1,1560)
    0| 001A04 ld       EB210650   1     L8        gr25=#SPILL8(gr1,1616)
    0| 001A08 ld       EB010680   1     L8        gr24=#SPILL14(gr1,1664)
    0| 001A0C ld       EAE10688   1     L8        gr23=#SPILL15(gr1,1672)
    0| 001A10 rldicr   79261764   1     SLL8      gr6=gr9,2
    0| 001A14 ld       EAC10690   1     L8        gr22=#SPILL16(gr1,1680)
    0| 001A18 add      7CC65214   1     A         gr6=gr6,gr10
    0| 001A1C ld       EAA10678   1     L8        gr21=#SPILL13(gr1,1656)
    0| 001A20 subf     7D065850   1     S         gr8=gr11,gr6
    0| 001A24 addi     38E60002   1     AI        gr7=gr6,2
    0| 001A28 cmpwi    2F080001   1     C4        cr6=gr8,1
    0| 001A2C or       7CE83B78   1     LR        gr8=gr7
    0| 001A30 ld       EA810658   1     L8        gr20=#SPILL9(gr1,1624)
    0| 001A34 ld       EA610660   1     L8        gr19=#SPILL10(gr1,1632)
    0| 001A38 ld       EA410670   1     L8        gr18=#SPILL12(gr1,1648)
    0| 001A3C ld       EA210668   1     L8        gr17=#SPILL11(gr1,1640)
    0| 001A40 bc       409A0008   1     BF        CL.670,cr6,0x4/eq,taken=50%(0,0)
    0| 001A44 addi     39000001   1     LI        gr8=1
    0|                              CL.670:
    0| 001A48 addi     39260001   1     AI        gr9=gr6,1
    0| 001A4C addi     39460003   1     AI        gr10=gr6,3
    0| 001A50 subf     7D695850   1     S         gr11=gr11,gr9
    0| 001A54 or       7D495378   1     LR        gr9=gr10
    0| 001A58 cmpwi    2F0B0001   1     C4        cr6=gr11,1
    0| 001A5C bc       409A0008   1     BF        CL.671,cr6,0x4/eq,taken=50%(0,0)
    0| 001A60 addi     39200001   1     LI        gr9=1
    0|                              CL.671:
    0| 001A64 ld       E9810618   1     L8        gr12=#SPILL1(gr1,1560)
    0| 001A68 subf     7D676050   1     S         gr11=gr12,gr7
    0| 001A6C addi     38E60004   1     AI        gr7=gr6,4
    0| 001A70 cmpwi    2F0B0001   1     C4        cr6=gr11,1
    0| 001A74 bc       409A0008   1     BF        CL.672,cr6,0x4/eq,taken=50%(0,0)
    0| 001A78 addi     38E00001   1     LI        gr7=1
    0|                              CL.672:
    0| 001A7C subf     7D4A6050   1     S         gr10=gr12,gr10
    0| 001A80 addi     38C60005   1     AI        gr6=gr6,5
    0| 001A84 cmpwi    2F0A0001   1     C4        cr6=gr10,1
    0| 001A88 bc       409A0008   1     BF        CL.673,cr6,0x4/eq,taken=50%(0,0)
    0| 001A8C addi     38C00001   1     LI        gr6=1
    0|                              CL.673:
    0| 001A90 ld       E9410628   1     L8        gr10=#SPILL3(gr1,1576)
    0| 001A94 extsw    7D2907B4   1     EXTS4     gr9=gr9
    0| 001A98 extsw    7D0807B4   1     EXTS4     gr8=gr8
    0| 001A9C extsw    7CE707B4   1     EXTS4     gr7=gr7
    0| 001AA0 extsw    7CC607B4   1     EXTS4     gr6=gr6
    0| 001AA4 mulld    7D6951D2   1     M         gr11=gr9,gr10
    0| 001AA8 mulld    7E0851D2   1     M         gr16=gr8,gr10
    0| 001AAC std      F96106A0   1     ST8       #SPILL18(gr1,1696)=gr11
    0| 001AB0 mulld    7DE751D2   1     M         gr15=gr7,gr10
    0| 001AB4 mulld    7DC651D2   1     M         gr14=gr6,gr10
   90|                              CL.144:
  104| 001AB8 ld       E90106A0   1     L8        gr8=#SPILL18(gr1,1696)
  104| 001ABC add      7CD0CA14   1     A         gr6=gr16,gr25
  104| 001AC0 or       7F09C378   1     LR        gr9=gr24
  104| 001AC4 or       7EEABB78   1     LR        gr10=gr23
  104| 001AC8 or       7EABAB78   1     LR        gr11=gr21
    0| 001ACC ld       EBC10638   1     L8        gr30=#SPILL5(gr1,1592)
  104| 001AD0 add      7CE8CA14   1     A         gr7=gr8,gr25
  104| 001AD4 add      7D0FCA14   1     A         gr8=gr15,gr25
  104| 001AD8 lfdux    7CA924EE   1     LFDU      fp5,gr9=vp3r(gr9,gr4,0)
  104| 001ADC lfdux    7CC624EE   1     LFDU      fp6,gr6=vp3r(gr6,gr4,0)
  104| 001AE0 lfdux    7C2A24EE   1     LFDU      fp1,gr10=vp3r(gr10,gr4,0)
  104| 001AE4 lfdux    7C8724EE   1     LFDU      fp4,gr7=vp3r(gr7,gr4,0)
  104| 001AE8 lfdux    7C4B24EE   1     LFDU      fp2,gr11=vp3r(gr11,gr4,0)
  104| 001AEC lfdux    7C6824EE   1     LFDU      fp3,gr8=vp3r(gr8,gr4,0)
  104| 001AF0 add      7D8ECA14   1     A         gr12=gr14,gr25
  104| 001AF4 or       7EDFB378   1     LR        gr31=gr22
  104| 001AF8 fadd     FD05302A   1     AFL       fp8=fp5,fp6,fcr
    0| 001AFC mtspr    7FC903A6   1     LCTR      ctr=gr30
  104| 001B00 fadd     FCA1202A   1     AFL       fp5=fp1,fp4,fcr
  104| 001B04 lfdux    7C3F24EE   1     LFDU      fp1,gr31=vp3r(gr31,gr4,0)
  104| 001B08 fadd     FCC2182A   1     AFL       fp6=fp2,fp3,fcr
  104| 001B0C lfdux    7C4C24EE   1     LFDU      fp2,gr12=vp3r(gr12,gr4,0)
  104| 001B10 or       7E7E9B78   1     LR        gr30=gr19
  104| 001B14 or       7E3D8B78   1     LR        gr29=gr17
  104| 001B18 or       7E5C9378   1     LR        gr28=gr18
    0| 001B1C addi     38A50001   1     AI        gr5=gr5,1
  104| 001B20 or       7E9BA378   1     LR        gr27=gr20
    0| 001B24 bc       4240005C   1     BCF       ctr=CL.924,taken=0%(0,100)
    0| 001B28 ori      60210000   1     XNOP      
    0|                              CL.925:
  104| 001B2C lfdux    7C6924EE   1     LFDU      fp3,gr9=vp3r(gr9,gr4,0)
  104| 001B30 lfdux    7C8624EE   1     LFDU      fp4,gr6=vp3r(gr6,gr4,0)
  104| 001B34 fadd     FC21102A   1     AFL       fp1=fp1,fp2,fcr
  104| 001B38 fmul     FC480032   2     MFL       fp2=fp8,fp0,fcr
  104| 001B3C fmul     FD450032   2     MFL       fp10=fp5,fp0,fcr
  104| 001B40 fmul     FD260032   2     MFL       fp9=fp6,fp0,fcr
  104| 001B44 lfdux    7CAA24EE   1     LFDU      fp5,gr10=vp3r(gr10,gr4,0)
  104| 001B48 lfdux    7CC724EE   1     LFDU      fp6,gr7=vp3r(gr7,gr4,0)
  104| 001B4C lfdux    7CEB24EE   1     LFDU      fp7,gr11=vp3r(gr11,gr4,0)
  104| 001B50 fmul     FD010032   1     MFL       fp8=fp1,fp0,fcr
  104| 001B54 stfdux   7C5E1DEE   2     STFDU     gr30,w3dc(gr30,gr3,0)=fp2
  104| 001B58 stfdux   7D5D1DEE   1     STFDU     gr29,w3dc(gr29,gr3,0)=fp10
  104| 001B5C stfdux   7D3C1DEE   1     STFDU     gr28,w3dc(gr28,gr3,0)=fp9
  104| 001B60 lfdux    7D2824EE   1     LFDU      fp9,gr8=vp3r(gr8,gr4,0)
  104| 001B64 lfdux    7C3F24EE   1     LFDU      fp1,gr31=vp3r(gr31,gr4,0)
  104| 001B68 lfdux    7C4C24EE   1     LFDU      fp2,gr12=vp3r(gr12,gr4,0)
  104| 001B6C stfdux   7D1B1DEE   1     STFDU     gr27,w3dc(gr27,gr3,0)=fp8
  104| 001B70 fadd     FD03202A   1     AFL       fp8=fp3,fp4,fcr
  104| 001B74 fadd     FCA5302A   2     AFL       fp5=fp5,fp6,fcr
  104| 001B78 fadd     FCC7482A   2     AFL       fp6=fp7,fp9,fcr
    0| 001B7C bc       4200FFB0   1     BCT       ctr=CL.925,taken=100%(100,0)
    0|                              CL.924:
  104| 001B80 fadd     FC21102A   1     AFL       fp1=fp1,fp2,fcr
   90| 001B84 ld       E8C10630   1     L8        gr6=#SPILL4(gr1,1584)
  104| 001B88 fmul     FC480032   1     MFL       fp2=fp8,fp0,fcr
    0| 001B8C add      7F20CA14   1     A         gr25=gr0,gr25
  104| 001B90 fmul     FC650032   1     MFL       fp3=fp5,fp0,fcr
    0| 001B94 add      7F00C214   1     A         gr24=gr0,gr24
  104| 001B98 fmul     FC860032   1     MFL       fp4=fp6,fp0,fcr
   90| 001B9C cmpld    7F253040   1     CL8       cr6=gr5,gr6
  104| 001BA0 fmul     FC210032   1     MFL       fp1=fp1,fp0,fcr
  104| 001BA4 stfdux   7C5E1DEE   2     STFDU     gr30,w3dc(gr30,gr3,0)=fp2
    0| 001BA8 add      7EE0BA14   1     A         gr23=gr0,gr23
  104| 001BAC stfdux   7C7D1DEE   1     STFDU     gr29,w3dc(gr29,gr3,0)=fp3
    0| 001BB0 add      7EC0B214   1     A         gr22=gr0,gr22
  104| 001BB4 stfdux   7C9C1DEE   1     STFDU     gr28,w3dc(gr28,gr3,0)=fp4
    0| 001BB8 add      7EA0AA14   1     A         gr21=gr0,gr21
  104| 001BBC stfdux   7C3B1DEE   1     STFDU     gr27,w3dc(gr27,gr3,0)=fp1
    0| 001BC0 add      7E94D214   1     A         gr20=gr20,gr26
    0| 001BC4 add      7E73D214   1     A         gr19=gr19,gr26
    0| 001BC8 add      7E52D214   1     A         gr18=gr18,gr26
    0| 001BCC add      7E31D214   1     A         gr17=gr17,gr26
   90| 001BD0 bc       4198FEE8   1     BT        CL.144,cr6,0x8/llt,taken=80%(80,20)
   90|                              CL.143:
   84| 001BD4 ld       E8A10620   1     L8        gr5=#SPILL2(gr1,1568)
    0| 001BD8 ld       E8C10640   1     L8        gr6=#SPILL6(gr1,1600)
    0| 001BDC ld       E8E10658   1     L8        gr7=#SPILL9(gr1,1624)
   84| 001BE0 ld       E9010698   1     L8        gr8=#SPILL17(gr1,1688)
    0| 001BE4 ld       E9210660   1     L8        gr9=#SPILL10(gr1,1632)
    0| 001BE8 ld       E9410668   1     L8        gr10=#SPILL11(gr1,1640)
    0| 001BEC ld       E9610670   1     L8        gr11=#SPILL12(gr1,1648)
    0| 001BF0 ld       E9810648   1     L8        gr12=#SPILL7(gr1,1608)
    0| 001BF4 ld       EBE10678   1     L8        gr31=#SPILL13(gr1,1656)
    0| 001BF8 ld       EBC10680   1     L8        gr30=#SPILL14(gr1,1664)
    0| 001BFC ld       EBA10688   1     L8        gr29=#SPILL15(gr1,1672)
    0| 001C00 ld       EB810690   1     L8        gr28=#SPILL16(gr1,1680)
   84| 001C04 addi     38A50001   1     AI        gr5=gr5,1
    0| 001C08 add      7CE63A14   1     A         gr7=gr6,gr7
   84| 001C0C std      F8A10620   1     ST8       #SPILL2(gr1,1568)=gr5
    0| 001C10 std      F8E10658   1     ST8       #SPILL9(gr1,1624)=gr7
   84| 001C14 cmpld    7F254040   1     CL8       cr6=gr5,gr8
    0| 001C18 add      7D264A14   1     A         gr9=gr6,gr9
    0| 001C1C add      7D465214   1     A         gr10=gr6,gr10
    0| 001C20 std      F9210660   1     ST8       #SPILL10(gr1,1632)=gr9
    0| 001C24 std      F9410668   1     ST8       #SPILL11(gr1,1640)=gr10
    0| 001C28 add      7D665A14   1     A         gr11=gr6,gr11
    0| 001C2C add      7FECFA14   1     A         gr31=gr12,gr31
    0| 001C30 std      F9610670   1     ST8       #SPILL12(gr1,1648)=gr11
    0| 001C34 std      FBE10678   1     ST8       #SPILL13(gr1,1656)=gr31
    0| 001C38 add      7FCCF214   1     A         gr30=gr12,gr30
    0| 001C3C add      7FACEA14   1     A         gr29=gr12,gr29
    0| 001C40 std      FBC10680   1     ST8       #SPILL14(gr1,1664)=gr30
    0| 001C44 std      FBA10688   1     ST8       #SPILL15(gr1,1672)=gr29
    0| 001C48 add      7F8CE214   1     A         gr28=gr12,gr28
    0| 001C4C std      FB810690   1     ST8       #SPILL16(gr1,1680)=gr28
   84| 001C50 bc       4198FDA0   1     BT        CL.142,cr6,0x8/llt,taken=80%(80,20)
   84|                              CL.141:
    0| 001C54 ld       E8620000   1     L8        gr3=.&&N&vcvars(gr2,0)
    0| 001C58 ld       E9230068   1     L8        gr9=<s81:d104:l8>(gr3,104)
  109| 001C5C bc       40850284   1     BF        CL.117,cr1,0x2/gt,taken=50%(0,0)
  112| 001C60 ld       E8A20000   1     L8        gr5=.&&N&scratch(gr2,0)
  111| 001C64 ld       EAA20000   1     L8        gr21=.&&N&&param(gr2,0)
  112| 001C68 ld       EA420000   1     L8        gr18=.&&N&vcvars(gr2,0)
  113| 001C6C ld       E8C30138   1     L8        gr6=<s81:d312:l8>(gr3,312)
  114| 001C70 ld       E8E30208   1     L8        gr7=<s81:d520:l8>(gr3,520)
  113| 001C74 ld       E9030150   1     L8        gr8=<s81:d336:l8>(gr3,336)
  114| 001C78 ld       EAC50598   1     L8        gr22=<s52:d1432:l8>(gr5,1432)
  112| 001C7C ld       EAE504C8   1     L8        gr23=<s52:d1224:l8>(gr5,1224)
  114| 001C80 ld       E9630220   1     L8        gr11=<s81:d544:l8>(gr3,544)
  112| 001C84 ld       E9850498   1     L8        gr12=<s52:d1176:l8>(gr5,1176)
  114| 001C88 ld       EBE50568   1     L8        gr31=<s52:d1384:l8>(gr5,1384)
  112| 001C8C ld       EBC504B0   1     L8        gr30=<s52:d1200:l8>(gr5,1200)
  114| 001C90 std      FAC10648   1     ST8       #SPILL7(gr1,1608)=gr22
  112| 001C94 std      FAE10640   1     ST8       #SPILL6(gr1,1600)=gr23
  114| 001C98 ld       EBA50580   1     L8        gr29=<s52:d1408:l8>(gr5,1408)
  113| 001C9C ld       E8650500   1     L8        gr3=<s52:d1280:l8>(gr5,1280)
  110| 001CA0 lwa      E8150006   1     L4A       gr0=<s141:d4:l4>(gr21,4)
  113| 001CA4 ld       E8850518   1     L8        gr4=<s52:d1304:l8>(gr5,1304)
  111| 001CA8 lwa      E9550002   1     L4A       gr10=<s141:d0:l4>(gr21,0)
  112| 001CAC ld       EB920080   1     L8        gr28=<s81:d128:l8>(gr18,128)
  112| 001CB0 ld       EB6504E0   1     L8        gr27=<s52:d1248:l8>(gr5,1248)
  113| 001CB4 ld       EA250530   1     L8        gr17=<s52:d1328:l8>(gr5,1328)
  113| 001CB8 ld       EB450548   1     L8        gr26=<s52:d1352:l8>(gr5,1352)
  114| 001CBC ld       EB2505B0   1     L8        gr25=<s52:d1456:l8>(gr5,1456)
  112| 001CC0 ld       EA120098   1     L8        gr16=<s81:d152:l8>(gr18,152)
  112| 001CC4 ld       EB1200B0   1     L8        gr24=<s81:d176:l8>(gr18,176)
  113| 001CC8 ld       E9F20168   1     L8        gr15=<s81:d360:l8>(gr18,360)
  113| 001CCC std      FA210620   1     ST8       #SPILL2(gr1,1568)=gr17
  114| 001CD0 ld       E9D20238   1     L8        gr14=<s81:d568:l8>(gr18,568)
    0| 001CD4 add      7CE75A14   1     A         gr7=gr7,gr11
  112| 001CD8 std      FA010628   1     ST8       #SPILL3(gr1,1576)=gr16
    0| 001CDC add      7D7DFA14   1     A         gr11=gr29,gr31
  113| 001CE0 std      F9E10630   1     ST8       #SPILL4(gr1,1584)=gr15
    0| 001CE4 add      7D064214   1     A         gr8=gr6,gr8
  114| 001CE8 std      F9C10638   1     ST8       #SPILL5(gr1,1592)=gr14
    0| 001CEC add      7CCCF214   1     A         gr6=gr12,gr30
    0| 001CF0 cmpwi    2C000000   1     C4        cr0=gr0,0
    0| 001CF4 add      7FA32214   1     A         gr29=gr3,gr4
  109| 001CF8 addi     38600000   1     LI        gr3=0
  113| 001CFC ld       EAF20180   1     L8        gr23=<s81:d384:l8>(gr18,384)
  109| 001D00 std      F8610650   1     ST8       #SPILL8(gr1,1616)=gr3
  114| 001D04 ld       EAD20250   1     L8        gr22=<s81:d592:l8>(gr18,592)
    0| 001D08 add      7FE77214   1     A         gr31=gr7,gr14
    0| 001D0C add      7D8BCA14   1     A         gr12=gr11,gr25
    0| 001D10 add      7D687A14   1     A         gr11=gr8,gr15
    0| 001D14 add      7FD1D214   1     A         gr30=gr17,gr26
    0| 001D18 add      7E89E214   1     A         gr20=gr9,gr28
    0| 001D1C add      7F90C214   1     A         gr28=gr16,gr24
    0| 001D20 add      7E66DA14   1     A         gr19=gr6,gr27
    0| 001D24 rldicl   7955F842   1     SRL8      gr21=gr10,1
  112| 001D28 ld       E86504F8   1     L8        gr3=<s52:d1272:l8>(gr5,1272)
  113| 001D2C ld       E8850560   1     L8        gr4=<s52:d1376:l8>(gr5,1376)
  114| 001D30 ld       E8A505C8   1     L8        gr5=<s52:d1480:l8>(gr5,1480)
  112| 001D34 ld       E8D200C8   1     L8        gr6=<s81:d200:l8>(gr18,200)
  113| 001D38 ld       E8F20198   1     L8        gr7=<s81:d408:l8>(gr18,408)
  114| 001D3C ld       E9120268   1     L8        gr8=<s81:d616:l8>(gr18,616)
    0| 001D40 bc       408101A0   1     BF        CL.117,cr0,0x2/gt,taken=20%(20,80)
    0| 001D44 ld       E9C10648   1     L8        gr14=#SPILL7(gr1,1608)
    0| 001D48 add      7FBDF214   1     A         gr29=gr29,gr30
    0| 001D4C add      7FD4E214   1     A         gr30=gr20,gr28
    0| 001D50 std      FBA10670   1     ST8       #SPILL12(gr1,1648)=gr29
    0| 001D54 std      FBC10678   1     ST8       #SPILL13(gr1,1656)=gr30
    0| 001D58 ld       EB810640   1     L8        gr28=#SPILL6(gr1,1600)
    0| 001D5C add      7FF6FA14   1     A         gr31=gr22,gr31
    0| 001D60 add      7D8C7214   1     A         gr12=gr12,gr14
    0| 001D64 std      FBE10658   1     ST8       #SPILL9(gr1,1624)=gr31
    0| 001D68 std      F9810660   1     ST8       #SPILL10(gr1,1632)=gr12
    0| 001D6C add      7D6BBA14   1     A         gr11=gr11,gr23
    0| 001D70 add      7E93E214   1     A         gr20=gr19,gr28
    0| 001D74 std      F9610668   1     ST8       #SPILL11(gr1,1640)=gr11
    0| 001D78 cmpdi    2CAA0000   1     C8        cr1=gr10,0
    0| 001D7C andi.    714A0001   1     RN4_R     gr10,cr0=gr10,0,0x1
    0| 001D80 cmpdi    2FB50000   1     C8        cr7=gr21,0
  109|                              CL.118:
  110| 001D84 addi     39400000   1     LI        gr10=0
    0| 001D88 bc       408500E8   1     BF        CL.119,cr1,0x2/gt,taken=20%(20,80)
    0| 001D8C or       7E93A378   1     LR        gr19=gr20
    0| 001D90 ld       EA410678   1     L8        gr18=#SPILL13(gr1,1656)
    0| 001D94 ld       EA210670   1     L8        gr17=#SPILL12(gr1,1648)
    0| 001D98 ld       EA010668   1     L8        gr16=#SPILL11(gr1,1640)
    0| 001D9C ld       E9E10660   1     L8        gr15=#SPILL10(gr1,1632)
    0| 001DA0 ld       E9C10658   1     L8        gr14=#SPILL9(gr1,1624)
  110|                              CL.120:
  112| 001DA4 or       7E6B9B78   1     LR        gr11=gr19
  114| 001DA8 or       7DEC7B78   1     LR        gr12=gr15
  113| 001DAC or       7E3F8B78   1     LR        gr31=gr17
  112| 001DB0 or       7E5E9378   1     LR        gr30=gr18
  114| 001DB4 or       7DDD7378   1     LR        gr29=gr14
  113| 001DB8 or       7E1C8378   1     LR        gr28=gr16
    0| 001DBC mtspr    7EA903A6   1     LCTR      ctr=gr21
    0| 001DC0 addi     394A0001   1     AI        gr10=gr10,1
    0| 001DC4 bc       41820020   1     BT        CL.898,cr0,0x4/eq,taken=50%(0,0)
  112| 001DC8 lfdux    7C0B1CEE   1     LFDU      fp0,gr11=w3da(gr11,gr3,0)
  113| 001DCC lfdux    7C3F24EE   1     LFDU      fp1,gr31=w3db(gr31,gr4,0)
  114| 001DD0 lfdux    7C4C2CEE   1     LFDU      fp2,gr12=w3dc(gr12,gr5,0)
  112| 001DD4 stfdux   7C1E35EE   1     STFDU     gr30,vp1i(gr30,gr6,0)=fp0
  113| 001DD8 stfdux   7C3C3DEE   1     STFDU     gr28,vp2i(gr28,gr7,0)=fp1
  114| 001DDC stfdux   7C5D45EE   1     STFDU     gr29,vp3i(gr29,gr8,0)=fp2
    0| 001DE0 bc       419E0070   1     BT        CL.809,cr7,0x4/eq,taken=20%(20,80)
    0|                              CL.898:
  112| 001DE4 lfdux    7C4B1CEE   1     LFDU      fp2,gr11=w3da(gr11,gr3,0)
  113| 001DE8 lfdux    7C1F24EE   1     LFDU      fp0,gr31=w3db(gr31,gr4,0)
  114| 001DEC lfdux    7C2C2CEE   1     LFDU      fp1,gr12=w3dc(gr12,gr5,0)
  112| 001DF0 lfdux    7C6B1CEE   1     LFDU      fp3,gr11=w3da(gr11,gr3,0)
  112| 001DF4 stfdux   7C5E35EE   1     STFDU     gr30,vp1i(gr30,gr6,0)=fp2
  113| 001DF8 lfdux    7C5F24EE   1     LFDU      fp2,gr31=w3db(gr31,gr4,0)
  114| 001DFC lfdux    7CAC2CEE   1     LFDU      fp5,gr12=w3dc(gr12,gr5,0)
  112| 001E00 stfdux   7C7E35EE   1     STFDU     gr30,vp1i(gr30,gr6,0)=fp3
    0| 001E04 bc       4240003C   1     BCF       ctr=CL.926,taken=0%(0,100)
    0| 001E08 ori      60210000   1     XNOP      
    0|                              CL.927:
  112| 001E0C lfdux    7C6B1CEE   1     LFDU      fp3,gr11=w3da(gr11,gr3,0)
  113| 001E10 stfdux   7C1C3DEE   1     STFDU     gr28,vp2i(gr28,gr7,0)=fp0
  114| 001E14 stfdux   7C3D45EE   1     STFDU     gr29,vp3i(gr29,gr8,0)=fp1
  113| 001E18 stfdux   7C5C3DEE   1     STFDU     gr28,vp2i(gr28,gr7,0)=fp2
  113| 001E1C lfdux    7C1F24EE   1     LFDU      fp0,gr31=w3db(gr31,gr4,0)
  112| 001E20 lfdux    7C8B1CEE   1     LFDU      fp4,gr11=w3da(gr11,gr3,0)
  114| 001E24 lfdux    7C2C2CEE   1     LFDU      fp1,gr12=w3dc(gr12,gr5,0)
  114| 001E28 stfdux   7CBD45EE   1     STFDU     gr29,vp3i(gr29,gr8,0)=fp5
  113| 001E2C lfdux    7C5F24EE   1     LFDU      fp2,gr31=w3db(gr31,gr4,0)
  112| 001E30 stfdux   7C7E35EE   1     STFDU     gr30,vp1i(gr30,gr6,0)=fp3
  112| 001E34 stfdux   7C9E35EE   1     STFDU     gr30,vp1i(gr30,gr6,0)=fp4
  114| 001E38 lfdux    7CAC2CEE   1     LFDU      fp5,gr12=w3dc(gr12,gr5,0)
    0| 001E3C bc       4200FFD0   1     BCT       ctr=CL.927,taken=100%(100,0)
    0|                              CL.926:
  113| 001E40 stfdux   7C1C3DEE   1     STFDU     gr28,vp2i(gr28,gr7,0)=fp0
  114| 001E44 stfdux   7C3D45EE   1     STFDU     gr29,vp3i(gr29,gr8,0)=fp1
  113| 001E48 stfdux   7C5C3DEE   1     STFDU     gr28,vp2i(gr28,gr7,0)=fp2
  114| 001E4C stfdux   7CBD45EE   1     STFDU     gr29,vp3i(gr29,gr8,0)=fp5
    0|                              CL.809:
  116| 001E50 cmpld    7F2A0040   1     CL8       cr6=gr10,gr0
    0| 001E54 add      7E73DA14   1     A         gr19=gr19,gr27
    0| 001E58 add      7E52C214   1     A         gr18=gr18,gr24
    0| 001E5C add      7E31D214   1     A         gr17=gr17,gr26
    0| 001E60 add      7E10BA14   1     A         gr16=gr16,gr23
    0| 001E64 add      7DEFCA14   1     A         gr15=gr15,gr25
    0| 001E68 add      7DCEB214   1     A         gr14=gr14,gr22
  116| 001E6C bc       4198FF38   1     BT        CL.120,cr6,0x8/llt,taken=80%(80,20)
  116|                              CL.119:
  117| 001E70 ld       E9410650   1     L8        gr10=#SPILL8(gr1,1616)
    0| 001E74 ld       E9610638   1     L8        gr11=#SPILL5(gr1,1592)
    0| 001E78 ld       E9810658   1     L8        gr12=#SPILL9(gr1,1624)
  117| 001E7C ld       EBE10618   1     L8        gr31=#SPILL1(gr1,1560)
    0| 001E80 ld       EBC10648   1     L8        gr30=#SPILL7(gr1,1608)
    0| 001E84 ld       EBA10660   1     L8        gr29=#SPILL10(gr1,1632)
    0| 001E88 ld       EB810630   1     L8        gr28=#SPILL4(gr1,1584)
    0| 001E8C ld       EA610668   1     L8        gr19=#SPILL11(gr1,1640)
    0| 001E90 ld       EA410620   1     L8        gr18=#SPILL2(gr1,1568)
    0| 001E94 ld       EA210670   1     L8        gr17=#SPILL12(gr1,1648)
    0| 001E98 ld       EA010628   1     L8        gr16=#SPILL3(gr1,1576)
    0| 001E9C ld       E9E10678   1     L8        gr15=#SPILL13(gr1,1656)
    0| 001EA0 ld       E9C10640   1     L8        gr14=#SPILL6(gr1,1600)
  117| 001EA4 addi     394A0001   1     AI        gr10=gr10,1
    0| 001EA8 add      7D8B6214   1     A         gr12=gr11,gr12
  117| 001EAC std      F9410650   1     ST8       #SPILL8(gr1,1616)=gr10
    0| 001EB0 std      F9810658   1     ST8       #SPILL9(gr1,1624)=gr12
  117| 001EB4 cmpld    7F2AF840   1     CL8       cr6=gr10,gr31
    0| 001EB8 add      7FBDF214   1     A         gr29=gr29,gr30
    0| 001EBC add      7E73E214   1     A         gr19=gr19,gr28
    0| 001EC0 std      FBA10660   1     ST8       #SPILL10(gr1,1632)=gr29
    0| 001EC4 std      FA610668   1     ST8       #SPILL11(gr1,1640)=gr19
    0| 001EC8 add      7E319214   1     A         gr17=gr17,gr18
    0| 001ECC add      7DEF8214   1     A         gr15=gr15,gr16
    0| 001ED0 std      FA210670   1     ST8       #SPILL12(gr1,1648)=gr17
    0| 001ED4 std      F9E10678   1     ST8       #SPILL13(gr1,1656)=gr15
    0| 001ED8 add      7E8EA214   1     A         gr20=gr14,gr20
  117| 001EDC bc       4198FEA8   1     BT        CL.118,cr6,0x8/llt,taken=80%(80,20)
  117|                              CL.117:
  122| 001EE0 ld       EBC20000   1     L8        gr30=.&&N&&mpipar(gr2,0)
  123| 001EE4 addi     3BE00003   1     LI        gr31=3
  121| 001EE8 addi     3BA00000   1     LI        gr29=0
  123| 001EEC stw      93E10090   1     ST4Z      T_5(gr1,144)=gr31
  123| 001EF0 stw      93E10094   1     ST4Z      T_6(gr1,148)=gr31
  123| 001EF4 stw      93A10098   1     ST4Z      T_7(gr1,152)=gr29
  121| 001EF8 stw      93BE0018   1     ST4Z      <s180:d24:l4>(gr30,24)=gr29
  122| 001EFC lwz      807E001C   1     L4Z       gr3=<s180:d28:l4>(gr30,28)
  123| 001F00 stw      93A1009C   1     ST4Z      T_8(gr1,156)=gr29
  123| 001F04 stw      93A100A0   1     ST4Z      T_9(gr1,160)=gr29
  123| 001F08 stw      93A100A4   1     ST4Z      T_10(gr1,164)=gr29
  123| 001F0C addi     390100A4   1     AI        gr8=gr1,164
  123| 001F10 addi     38E100A0   1     AI        gr7=gr1,160
  122| 001F14 addi     38030001   1     AI        gr0=gr3,1
  123| 001F18 addi     38C1009C   1     AI        gr6=gr1,156
  122| 001F1C stw      901E001C   1     ST4Z      <s180:d28:l4>(gr30,28)=gr0
  123| 001F20 addi     38A10098   1     AI        gr5=gr1,152
  123| 001F24 addi     38810094   1     AI        gr4=gr1,148
  123| 001F28 addi     38610090   1     AI        gr3=gr1,144
  123| 001F2C bl       48000001   1     CALL      bvalv1,7,T_5",gr3,T_6",gr4,T_7",gr5,T_8",gr6,T_9",gr7,T_10",gr8,vp1i",gr9,bvalv1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  123| 001F30 ori      60000000   1
  124| 001F34 ld       EB820000   1     L8        gr28=.&&N&vcvars(gr2,0)
  124| 001F38 stw      93E100A8   1     ST4Z      T_11(gr1,168)=gr31
  124| 001F3C stw      93E100AC   1     ST4Z      T_12(gr1,172)=gr31
  124| 001F40 stw      93A100B0   1     ST4Z      T_13(gr1,176)=gr29
  124| 001F44 stw      93A100B4   1     ST4Z      T_14(gr1,180)=gr29
  124| 001F48 stw      93A100B8   1     ST4Z      T_15(gr1,184)=gr29
  124| 001F4C stw      93A100BC   1     ST4Z      T_16(gr1,188)=gr29
  124| 001F50 ld       E93C0138   1     L8        gr9=<s81:d312:l8>(gr28,312)
  124| 001F54 addi     390100BC   1     AI        gr8=gr1,188
  124| 001F58 addi     38E100B8   1     AI        gr7=gr1,184
  124| 001F5C addi     38C100B4   1     AI        gr6=gr1,180
  124| 001F60 addi     38A100B0   1     AI        gr5=gr1,176
  124| 001F64 addi     388100AC   1     AI        gr4=gr1,172
  124| 001F68 addi     386100A8   1     AI        gr3=gr1,168
  124| 001F6C bl       48000001   1     CALL      bvalv2,7,T_11",gr3,T_12",gr4,T_13",gr5,T_14",gr6,T_15",gr7,T_16",gr8,vp2i",gr9,bvalv2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  124| 001F70 ori      60000000   1
  125| 001F74 stw      93E100C0   1     ST4Z      T_17(gr1,192)=gr31
  125| 001F78 stw      93E100C4   1     ST4Z      T_18(gr1,196)=gr31
  125| 001F7C stw      93A100C8   1     ST4Z      T_19(gr1,200)=gr29
  125| 001F80 stw      93A100CC   1     ST4Z      T_20(gr1,204)=gr29
  125| 001F84 stw      93A100D0   1     ST4Z      T_21(gr1,208)=gr29
  125| 001F88 stw      93A100D4   1     ST4Z      T_22(gr1,212)=gr29
  125| 001F8C ld       E93C0208   1     L8        gr9=<s81:d520:l8>(gr28,520)
  125| 001F90 addi     390100D4   1     AI        gr8=gr1,212
  125| 001F94 addi     38E100D0   1     AI        gr7=gr1,208
  125| 001F98 addi     38C100CC   1     AI        gr6=gr1,204
  125| 001F9C addi     38A100C8   1     AI        gr5=gr1,200
  125| 001FA0 addi     388100C4   1     AI        gr4=gr1,196
  125| 001FA4 addi     386100C0   1     AI        gr3=gr1,192
  125| 001FA8 bl       48000001   1     CALL      bvalv3,7,T_17",gr3,T_18",gr4,T_19",gr5,T_20",gr6,T_21",gr7,T_22",gr8,vp3i",gr9,bvalv3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  125| 001FAC ori      60000000   1
  126| 001FB0 lwz      801E0018   1     L4Z       gr0=<s180:d24:l4>(gr30,24)
  126| 001FB4 cmpdi    2C200000   1     C8        cr0=gr0,0
  126| 001FB8 bc       4182001C   1     BT        CL.68,cr0,0x4/eq,taken=60%(60,40)
  126| 001FBC ld       E8A20000   1     L8        gr5=.&&N&&mpiyes(gr2,0)
  126| 001FC0 addi     38DE0014   1     AI        gr6=gr30,20
  126| 001FC4 addi     387E0018   1     AI        gr3=gr30,24
  126| 001FC8 addi     38851770   1     AI        gr4=gr5,6000
  126| 001FCC bl       48000001   1     CALL      mpi_waitall,4,nreq",gr3,req[]",gr4,stat[]",gr5,ierr",gr6,mpi_waitall",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  126| 001FD0 ori      60000000   1
  126|                              CL.68:
  127| 001FD4 stw      93BE0018   1     ST4Z      <s180:d24:l4>(gr30,24)=gr29
  128| 001FD8 lwz      807E001C   1     L4Z       gr3=<s180:d28:l4>(gr30,28)
  129| 001FDC stw      93A100D8   1     ST4Z      T_23(gr1,216)=gr29
  129| 001FE0 stw      93A100DC   1     ST4Z      T_24(gr1,220)=gr29
  129| 001FE4 stw      93E100E0   1     ST4Z      T_25(gr1,224)=gr31
  129| 001FE8 stw      93E100E4   1     ST4Z      T_26(gr1,228)=gr31
  129| 001FEC stw      93A100E8   1     ST4Z      T_27(gr1,232)=gr29
  128| 001FF0 addi     38030001   1     AI        gr0=gr3,1
  129| 001FF4 stw      93A100EC   1     ST4Z      T_28(gr1,236)=gr29
  128| 001FF8 stw      901E001C   1     ST4Z      <s180:d28:l4>(gr30,28)=gr0
  129| 001FFC ld       E93C0068   1     L8        gr9=<s81:d104:l8>(gr28,104)
  129| 002000 addi     390100EC   1     AI        gr8=gr1,236
  129| 002004 addi     38E100E8   1     AI        gr7=gr1,232
  129| 002008 addi     38C100E4   1     AI        gr6=gr1,228
  129| 00200C addi     38A100E0   1     AI        gr5=gr1,224
  129| 002010 addi     388100DC   1     AI        gr4=gr1,220
  129| 002014 addi     386100D8   1     AI        gr3=gr1,216
  129| 002018 bl       48000001   1     CALL      bvalv1,7,T_23",gr3,T_24",gr4,T_25",gr5,T_26",gr6,T_27",gr7,T_28",gr8,vp1i",gr9,bvalv1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  129| 00201C ori      60000000   1
  130| 002020 stw      93A100F0   1     ST4Z      T_29(gr1,240)=gr29
  130| 002024 stw      93A100F4   1     ST4Z      T_30(gr1,244)=gr29
  130| 002028 stw      93E100F8   1     ST4Z      T_31(gr1,248)=gr31
  130| 00202C stw      93E100FC   1     ST4Z      T_32(gr1,252)=gr31
  130| 002030 stw      93A10100   1     ST4Z      T_33(gr1,256)=gr29
  130| 002034 stw      93A10104   1     ST4Z      T_34(gr1,260)=gr29
  130| 002038 ld       E93C0138   1     L8        gr9=<s81:d312:l8>(gr28,312)
  130| 00203C addi     39010104   1     AI        gr8=gr1,260
  130| 002040 addi     38E10100   1     AI        gr7=gr1,256
  130| 002044 addi     38C100FC   1     AI        gr6=gr1,252
  130| 002048 addi     38A100F8   1     AI        gr5=gr1,248
  130| 00204C addi     388100F4   1     AI        gr4=gr1,244
  130| 002050 addi     386100F0   1     AI        gr3=gr1,240
  130| 002054 bl       48000001   1     CALL      bvalv2,7,T_29",gr3,T_30",gr4,T_31",gr5,T_32",gr6,T_33",gr7,T_34",gr8,vp2i",gr9,bvalv2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  130| 002058 ori      60000000   1
  131| 00205C stw      93A10108   1     ST4Z      T_35(gr1,264)=gr29
  131| 002060 stw      93A1010C   1     ST4Z      T_36(gr1,268)=gr29
  131| 002064 stw      93E10110   1     ST4Z      T_37(gr1,272)=gr31
  131| 002068 stw      93E10114   1     ST4Z      T_38(gr1,276)=gr31
  131| 00206C stw      93A10118   1     ST4Z      T_39(gr1,280)=gr29
  131| 002070 stw      93A1011C   1     ST4Z      T_40(gr1,284)=gr29
  131| 002074 ld       E93C0208   1     L8        gr9=<s81:d520:l8>(gr28,520)
  131| 002078 addi     3901011C   1     AI        gr8=gr1,284
  131| 00207C addi     38E10118   1     AI        gr7=gr1,280
  131| 002080 addi     38C10114   1     AI        gr6=gr1,276
  131| 002084 addi     38A10110   1     AI        gr5=gr1,272
  131| 002088 addi     3881010C   1     AI        gr4=gr1,268
  131| 00208C addi     38610108   1     AI        gr3=gr1,264
  131| 002090 bl       48000001   1     CALL      bvalv3,7,T_35",gr3,T_36",gr4,T_37",gr5,T_38",gr6,T_39",gr7,T_40",gr8,vp3i",gr9,bvalv3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  131| 002094 ori      60000000   1
  132| 002098 lwz      801E0018   1     L4Z       gr0=<s180:d24:l4>(gr30,24)
  132| 00209C cmpdi    2C200000   1     C8        cr0=gr0,0
  132| 0020A0 bc       4182001C   1     BT        CL.69,cr0,0x4/eq,taken=60%(60,40)
  132| 0020A4 ld       E8A20000   1     L8        gr5=.&&N&&mpiyes(gr2,0)
  132| 0020A8 addi     38DE0014   1     AI        gr6=gr30,20
  132| 0020AC addi     387E0018   1     AI        gr3=gr30,24
  132| 0020B0 addi     38851770   1     AI        gr4=gr5,6000
  132| 0020B4 bl       48000001   1     CALL      mpi_waitall,4,nreq",gr3,req[]",gr4,stat[]",gr5,ierr",gr6,mpi_waitall",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  132| 0020B8 ori      60000000   1
  132|                              CL.69:
  133| 0020BC stw      93BE0018   1     ST4Z      <s180:d24:l4>(gr30,24)=gr29
  134| 0020C0 lwz      807E001C   1     L4Z       gr3=<s180:d28:l4>(gr30,28)
  135| 0020C4 stw      93A10120   1     ST4Z      T_41(gr1,288)=gr29
  135| 0020C8 stw      93A10124   1     ST4Z      T_42(gr1,292)=gr29
  135| 0020CC stw      93A10128   1     ST4Z      T_43(gr1,296)=gr29
  135| 0020D0 stw      93A1012C   1     ST4Z      T_44(gr1,300)=gr29
  135| 0020D4 stw      93E10130   1     ST4Z      T_45(gr1,304)=gr31
  134| 0020D8 addi     38030001   1     AI        gr0=gr3,1
  135| 0020DC stw      93E10134   1     ST4Z      T_46(gr1,308)=gr31
  134| 0020E0 stw      901E001C   1     ST4Z      <s180:d28:l4>(gr30,28)=gr0
  135| 0020E4 ld       E93C0068   1     L8        gr9=<s81:d104:l8>(gr28,104)
  135| 0020E8 addi     39010134   1     AI        gr8=gr1,308
  135| 0020EC addi     38E10130   1     AI        gr7=gr1,304
  135| 0020F0 addi     38C1012C   1     AI        gr6=gr1,300
  135| 0020F4 addi     38A10128   1     AI        gr5=gr1,296
  135| 0020F8 addi     38810124   1     AI        gr4=gr1,292
  135| 0020FC addi     38610120   1     AI        gr3=gr1,288
  135| 002100 bl       48000001   1     CALL      bvalv1,7,T_41",gr3,T_42",gr4,T_43",gr5,T_44",gr6,T_45",gr7,T_46",gr8,vp1i",gr9,bvalv1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  135| 002104 ori      60000000   1
  136| 002108 stw      93A10138   1     ST4Z      T_47(gr1,312)=gr29
  136| 00210C stw      93A1013C   1     ST4Z      T_48(gr1,316)=gr29
  136| 002110 stw      93A10140   1     ST4Z      T_49(gr1,320)=gr29
  136| 002114 stw      93A10144   1     ST4Z      T_50(gr1,324)=gr29
  136| 002118 stw      93E10148   1     ST4Z      T_51(gr1,328)=gr31
  136| 00211C stw      93E1014C   1     ST4Z      T_52(gr1,332)=gr31
  136| 002120 ld       E93C0138   1     L8        gr9=<s81:d312:l8>(gr28,312)
  136| 002124 addi     3901014C   1     AI        gr8=gr1,332
  136| 002128 addi     38E10148   1     AI        gr7=gr1,328
  136| 00212C addi     38C10144   1     AI        gr6=gr1,324
  136| 002130 addi     38A10140   1     AI        gr5=gr1,320
  136| 002134 addi     3881013C   1     AI        gr4=gr1,316
  136| 002138 addi     38610138   1     AI        gr3=gr1,312
  136| 00213C bl       48000001   1     CALL      bvalv2,7,T_47",gr3,T_48",gr4,T_49",gr5,T_50",gr6,T_51",gr7,T_52",gr8,vp2i",gr9,bvalv2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  136| 002140 ori      60000000   1
  137| 002144 stw      93A10150   1     ST4Z      T_53(gr1,336)=gr29
  137| 002148 stw      93A10154   1     ST4Z      T_54(gr1,340)=gr29
  137| 00214C stw      93A10158   1     ST4Z      T_55(gr1,344)=gr29
  137| 002150 stw      93A1015C   1     ST4Z      T_56(gr1,348)=gr29
  137| 002154 stw      93E10160   1     ST4Z      T_57(gr1,352)=gr31
  137| 002158 stw      93E10164   1     ST4Z      T_58(gr1,356)=gr31
  137| 00215C ld       E93C0208   1     L8        gr9=<s81:d520:l8>(gr28,520)
  137| 002160 addi     39010164   1     AI        gr8=gr1,356
  137| 002164 addi     38E10160   1     AI        gr7=gr1,352
  137| 002168 addi     38C1015C   1     AI        gr6=gr1,348
  137| 00216C addi     38A10158   1     AI        gr5=gr1,344
  137| 002170 addi     38810154   1     AI        gr4=gr1,340
  137| 002174 addi     38610150   1     AI        gr3=gr1,336
  137| 002178 bl       48000001   1     CALL      bvalv3,7,T_53",gr3,T_54",gr4,T_55",gr5,T_56",gr6,T_57",gr7,T_58",gr8,vp3i",gr9,bvalv3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  137| 00217C ori      60000000   1
  138| 002180 lwz      801E0018   1     L4Z       gr0=<s180:d24:l4>(gr30,24)
  138| 002184 cmpdi    2C200000   1     C8        cr0=gr0,0
  138| 002188 bc       40820AA4   1     BF        CL.1219,cr0,0x4/eq,taken=40%(40,60)
  138|                              CL.70:
  140| 00218C ld       E8620000   1     L8        gr3=.&&N&&param(gr2,0)
  140| 002190 lwa      E803000A   1     L4A       gr0=<s141:d8:l4>(gr3,8)
  140| 002194 cmpwi    2C000000   1     C4        cr0=gr0,0
  140| 002198 std      F8010618   1     ST8       #SPILL1(gr1,1560)=gr0
  140| 00219C bc       40810274   1     BF        CL.123,cr0,0x2/gt,taken=40%(40,60)
  143| 0021A0 ld       E8A20000   1     L8        gr5=.&&N&field(gr2,0)
  143| 0021A4 ld       EA020000   1     L8        gr16=.&&N&vcvars(gr2,0)
  144| 0021A8 ld       E8FC0138   1     L8        gr7=<s81:d312:l8>(gr28,312)
  145| 0021AC ld       E91C0208   1     L8        gr8=<s81:d520:l8>(gr28,520)
  144| 0021B0 ld       E95C0150   1     L8        gr10=<s81:d336:l8>(gr28,336)
  145| 0021B4 ld       E97C0220   1     L8        gr11=<s81:d544:l8>(gr28,544)
  144| 0021B8 ld       E9850208   1     L8        gr12=<s23:d520:l8>(gr5,520)
  145| 0021BC ld       EBE50270   1     L8        gr31=<s23:d624:l8>(gr5,624)
  144| 0021C0 ld       EBC50220   1     L8        gr30=<s23:d544:l8>(gr5,544)
  145| 0021C4 ld       EBA50288   1     L8        gr29=<s23:d648:l8>(gr5,648)
  143| 0021C8 ld       E88501A0   1     L8        gr4=<s23:d416:l8>(gr5,416)
  141| 0021CC lwa      E8030006   1     L4A       gr0=<s141:d4:l4>(gr3,4)
  143| 0021D0 ld       E8C501B8   1     L8        gr6=<s23:d440:l8>(gr5,440)
  144| 0021D4 ld       EA450238   1     L8        gr18=<s23:d568:l8>(gr5,568)
  145| 0021D8 ld       EA2502A0   1     L8        gr17=<s23:d672:l8>(gr5,672)
  144| 0021DC ld       E9D00168   1     L8        gr14=<s81:d360:l8>(gr16,360)
  145| 0021E0 ld       EA900238   1     L8        gr20=<s81:d568:l8>(gr16,568)
  143| 0021E4 ld       EADC0068   1     L8        gr22=<s81:d104:l8>(gr28,104)
  142| 0021E8 lwa      E9230002   1     L4A       gr9=<s141:d0:l4>(gr3,0)
  144| 0021EC std      FA410628   1     ST8       #SPILL3(gr1,1576)=gr18
  145| 0021F0 std      FA210630   1     ST8       #SPILL4(gr1,1584)=gr17
  144| 0021F4 std      F9C10640   1     ST8       #SPILL6(gr1,1600)=gr14
  144| 0021F8 ld       EB450250   1     L8        gr26=<s23:d592:l8>(gr5,592)
  145| 0021FC ld       EB2502B8   1     L8        gr25=<s23:d696:l8>(gr5,696)
  144| 002200 ld       EB100180   1     L8        gr24=<s81:d384:l8>(gr16,384)
  145| 002204 std      FA810648   1     ST8       #SPILL7(gr1,1608)=gr20
  143| 002208 ld       E87C0080   1     L8        gr3=<s81:d128:l8>(gr28,128)
  143| 00220C ld       EA6501D0   1     L8        gr19=<s23:d464:l8>(gr5,464)
  143| 002210 ld       EB8501E8   1     L8        gr28=<s23:d488:l8>(gr5,488)
  143| 002214 ld       E9F00098   1     L8        gr15=<s81:d152:l8>(gr16,152)
  143| 002218 ld       EB7000B0   1     L8        gr27=<s81:d176:l8>(gr16,176)
  145| 00221C ld       EAF00250   1     L8        gr23=<s81:d592:l8>(gr16,592)
    0| 002220 add      7FFFEA14   1     A         gr31=gr31,gr29
  143| 002224 std      FA610620   1     ST8       #SPILL2(gr1,1568)=gr19
    0| 002228 add      7D085A14   1     A         gr8=gr8,gr11
    0| 00222C add      7D6CF214   1     A         gr11=gr12,gr30
    0| 002230 add      7CE75214   1     A         gr7=gr7,gr10
  143| 002234 std      F9E10638   1     ST8       #SPILL5(gr1,1592)=gr15
    0| 002238 cmpwi    2C000000   1     C4        cr0=gr0,0
    0| 00223C add      7FF1FA14   1     A         gr31=gr17,gr31
    0| 002240 add      7D88A214   1     A         gr12=gr8,gr20
    0| 002244 add      7D6B9214   1     A         gr11=gr11,gr18
    0| 002248 add      7D477214   1     A         gr10=gr7,gr14
    0| 00224C add      7FC43214   1     A         gr30=gr4,gr6
  140| 002250 addi     38800000   1     LI        gr4=0
    0| 002254 add      7EB3E214   1     A         gr21=gr19,gr28
  140| 002258 std      F8810650   1     ST8       #SPILL8(gr1,1616)=gr4
    0| 00225C add      7E83B214   1     A         gr20=gr3,gr22
    0| 002260 add      7FAFDA14   1     A         gr29=gr15,gr27
    0| 002264 rldicl   7936F842   1     SRL8      gr22=gr9,1
  143| 002268 ld       E8650200   1     L8        gr3=<s23:d512:l8>(gr5,512)
  144| 00226C ld       E8850268   1     L8        gr4=<s23:d616:l8>(gr5,616)
  145| 002270 ld       E8A502D0   1     L8        gr5=<s23:d720:l8>(gr5,720)
  143| 002274 ld       E8D000C8   1     L8        gr6=<s81:d200:l8>(gr16,200)
  144| 002278 ld       E8F00198   1     L8        gr7=<s81:d408:l8>(gr16,408)
  145| 00227C ld       E9100268   1     L8        gr8=<s81:d616:l8>(gr16,616)
    0| 002280 bc       40810190   1     BF        CL.123,cr0,0x2/gt,taken=20%(20,80)
    0| 002284 add      7FF9FA14   1     A         gr31=gr25,gr31
    0| 002288 add      7D8CBA14   1     A         gr12=gr12,gr23
    0| 00228C std      FBE10658   1     ST8       #SPILL9(gr1,1624)=gr31
    0| 002290 std      F9810660   1     ST8       #SPILL10(gr1,1632)=gr12
    0| 002294 add      7D6BD214   1     A         gr11=gr11,gr26
    0| 002298 add      7D4AC214   1     A         gr10=gr10,gr24
    0| 00229C std      F9610668   1     ST8       #SPILL11(gr1,1640)=gr11
    0| 0022A0 std      F9410670   1     ST8       #SPILL12(gr1,1648)=gr10
    0| 0022A4 add      7EB5F214   1     A         gr21=gr21,gr30
    0| 0022A8 add      7E94EA14   1     A         gr20=gr20,gr29
    0| 0022AC cmpdi    2CA90000   1     C8        cr1=gr9,0
    0| 0022B0 andi.    71290001   1     RN4_R     gr9,cr0=gr9,0,0x1
    0| 0022B4 cmpdi    2FB60000   1     C8        cr7=gr22,0
    0| 0022B8 ori      60210000   1     XNOP      
    0| 0022BC ori      60210000   1     XNOP      
  140|                              CL.124:
  141| 0022C0 addi     39200000   1     LI        gr9=0
    0| 0022C4 bc       408500E4   1     BF        CL.125,cr1,0x2/gt,taken=20%(20,80)
    0| 0022C8 or       7E93A378   1     LR        gr19=gr20
    0| 0022CC or       7EB2AB78   1     LR        gr18=gr21
    0| 0022D0 ld       EA210670   1     L8        gr17=#SPILL12(gr1,1648)
    0| 0022D4 ld       EA010668   1     L8        gr16=#SPILL11(gr1,1640)
    0| 0022D8 ld       E9E10660   1     L8        gr15=#SPILL10(gr1,1632)
    0| 0022DC ld       E9C10658   1     L8        gr14=#SPILL9(gr1,1624)
  141|                              CL.126:
  143| 0022E0 or       7E6A9B78   1     LR        gr10=gr19
  145| 0022E4 or       7DEB7B78   1     LR        gr11=gr15
  144| 0022E8 or       7E2C8B78   1     LR        gr12=gr17
  143| 0022EC or       7E5F9378   1     LR        gr31=gr18
  145| 0022F0 or       7DDE7378   1     LR        gr30=gr14
  144| 0022F4 or       7E1D8378   1     LR        gr29=gr16
    0| 0022F8 mtspr    7EC903A6   1     LCTR      ctr=gr22
    0| 0022FC addi     39290001   1     AI        gr9=gr9,1
    0| 002300 bc       41820020   1     BT        CL.902,cr0,0x4/eq,taken=50%(0,0)
  143| 002304 lfdux    7C0A34EE   1     LFDU      fp0,gr10=vp1i(gr10,gr6,0)
  144| 002308 lfdux    7C2C3CEE   1     LFDU      fp1,gr12=vp2i(gr12,gr7,0)
  145| 00230C lfdux    7C4B44EE   1     LFDU      fp2,gr11=vp3i(gr11,gr8,0)
  143| 002310 stfdux   7C1F1DEE   1     STFDU     gr31,v1(gr31,gr3,0)=fp0
  144| 002314 stfdux   7C3D25EE   1     STFDU     gr29,v2(gr29,gr4,0)=fp1
  145| 002318 stfdux   7C5E2DEE   1     STFDU     gr30,v3(gr30,gr5,0)=fp2
    0| 00231C bc       419E006C   1     BT        CL.812,cr7,0x4/eq,taken=20%(20,80)
    0|                              CL.902:
  143| 002320 lfdux    7C4A34EE   1     LFDU      fp2,gr10=vp1i(gr10,gr6,0)
  144| 002324 lfdux    7C0C3CEE   1     LFDU      fp0,gr12=vp2i(gr12,gr7,0)
  145| 002328 lfdux    7C2B44EE   1     LFDU      fp1,gr11=vp3i(gr11,gr8,0)
  143| 00232C lfdux    7C6A34EE   1     LFDU      fp3,gr10=vp1i(gr10,gr6,0)
  143| 002330 stfdux   7C5F1DEE   1     STFDU     gr31,v1(gr31,gr3,0)=fp2
  144| 002334 lfdux    7C4C3CEE   1     LFDU      fp2,gr12=vp2i(gr12,gr7,0)
  145| 002338 lfdux    7CAB44EE   1     LFDU      fp5,gr11=vp3i(gr11,gr8,0)
  143| 00233C stfdux   7C7F1DEE   1     STFDU     gr31,v1(gr31,gr3,0)=fp3
    0| 002340 bc       42400038   1     BCF       ctr=CL.928,taken=0%(0,100)
    0|                              CL.929:
  143| 002344 lfdux    7C6A34EE   1     LFDU      fp3,gr10=vp1i(gr10,gr6,0)
  144| 002348 stfdux   7C1D25EE   1     STFDU     gr29,v2(gr29,gr4,0)=fp0
  145| 00234C stfdux   7C3E2DEE   1     STFDU     gr30,v3(gr30,gr5,0)=fp1
  144| 002350 stfdux   7C5D25EE   1     STFDU     gr29,v2(gr29,gr4,0)=fp2
  144| 002354 lfdux    7C0C3CEE   1     LFDU      fp0,gr12=vp2i(gr12,gr7,0)
  143| 002358 lfdux    7C8A34EE   1     LFDU      fp4,gr10=vp1i(gr10,gr6,0)
  145| 00235C lfdux    7C2B44EE   1     LFDU      fp1,gr11=vp3i(gr11,gr8,0)
  145| 002360 stfdux   7CBE2DEE   1     STFDU     gr30,v3(gr30,gr5,0)=fp5
  144| 002364 lfdux    7C4C3CEE   1     LFDU      fp2,gr12=vp2i(gr12,gr7,0)
  143| 002368 stfdux   7C7F1DEE   1     STFDU     gr31,v1(gr31,gr3,0)=fp3
  143| 00236C stfdux   7C9F1DEE   1     STFDU     gr31,v1(gr31,gr3,0)=fp4
  145| 002370 lfdux    7CAB44EE   1     LFDU      fp5,gr11=vp3i(gr11,gr8,0)
    0| 002374 bc       4200FFD0   1     BCT       ctr=CL.929,taken=100%(100,0)
    0|                              CL.928:
  144| 002378 stfdux   7C1D25EE   1     STFDU     gr29,v2(gr29,gr4,0)=fp0
  145| 00237C stfdux   7C3E2DEE   1     STFDU     gr30,v3(gr30,gr5,0)=fp1
  144| 002380 stfdux   7C5D25EE   1     STFDU     gr29,v2(gr29,gr4,0)=fp2
  145| 002384 stfdux   7CBE2DEE   1     STFDU     gr30,v3(gr30,gr5,0)=fp5
    0|                              CL.812:
  147| 002388 cmpld    7F290040   1     CL8       cr6=gr9,gr0
    0| 00238C add      7E73DA14   1     A         gr19=gr19,gr27
    0| 002390 add      7E52E214   1     A         gr18=gr18,gr28
    0| 002394 add      7E31C214   1     A         gr17=gr17,gr24
    0| 002398 add      7E10D214   1     A         gr16=gr16,gr26
    0| 00239C add      7DEFBA14   1     A         gr15=gr15,gr23
    0| 0023A0 add      7DCECA14   1     A         gr14=gr14,gr25
  147| 0023A4 bc       4198FF3C   1     BT        CL.126,cr6,0x8/llt,taken=80%(80,20)
  147|                              CL.125:
  148| 0023A8 ld       E9210650   1     L8        gr9=#SPILL8(gr1,1616)
    0| 0023AC ld       E9410630   1     L8        gr10=#SPILL4(gr1,1584)
    0| 0023B0 ld       E9610658   1     L8        gr11=#SPILL9(gr1,1624)
  148| 0023B4 ld       E9810618   1     L8        gr12=#SPILL1(gr1,1560)
    0| 0023B8 ld       EBE10648   1     L8        gr31=#SPILL7(gr1,1608)
    0| 0023BC ld       EBC10660   1     L8        gr30=#SPILL10(gr1,1632)
    0| 0023C0 ld       EBA10628   1     L8        gr29=#SPILL3(gr1,1576)
    0| 0023C4 ld       EA610668   1     L8        gr19=#SPILL11(gr1,1640)
    0| 0023C8 ld       EA410640   1     L8        gr18=#SPILL6(gr1,1600)
    0| 0023CC ld       EA210670   1     L8        gr17=#SPILL12(gr1,1648)
    0| 0023D0 ld       EA010620   1     L8        gr16=#SPILL2(gr1,1568)
    0| 0023D4 ld       E9E10638   1     L8        gr15=#SPILL5(gr1,1592)
  148| 0023D8 addi     39290001   1     AI        gr9=gr9,1
    0| 0023DC add      7D6A5A14   1     A         gr11=gr10,gr11
  148| 0023E0 std      F9210650   1     ST8       #SPILL8(gr1,1616)=gr9
    0| 0023E4 std      F9610658   1     ST8       #SPILL9(gr1,1624)=gr11
  148| 0023E8 cmpld    7F296040   1     CL8       cr6=gr9,gr12
    0| 0023EC add      7FDEFA14   1     A         gr30=gr30,gr31
    0| 0023F0 add      7E73EA14   1     A         gr19=gr19,gr29
    0| 0023F4 std      FBC10660   1     ST8       #SPILL10(gr1,1632)=gr30
    0| 0023F8 std      FA610668   1     ST8       #SPILL11(gr1,1640)=gr19
    0| 0023FC add      7E319214   1     A         gr17=gr17,gr18
    0| 002400 add      7EB0AA14   1     A         gr21=gr16,gr21
    0| 002404 std      FA210670   1     ST8       #SPILL12(gr1,1648)=gr17
    0| 002408 add      7E8FA214   1     A         gr20=gr15,gr20
  148| 00240C bc       4198FEB4   1     BT        CL.124,cr6,0x8/llt,taken=80%(80,20)
  148|                              CL.123:
  149| 002410 ld       E8620000   1     L8        gr3=.&&N&vcvars(gr2,0)
  149| 002414 lbz      8BE30072   1     L1Z       gr31=<s81:d114:l1>(gr3,114)
  149| 002418 rlwinm   57E0C9FF   1     SRL4_R    gr0,cr0=gr31,7
  149| 00241C rlwinm   57E00630   1     RN4       gr0=gr31,0,0x80
  149| 002420 bc       41820034   1     BT        CL.83,cr0,0x4/eq,taken=50%(0,0)
  149| 002424 rlwinm   57E306B4   1     RN4       gr3=gr31,0,0x20
  149| 002428 cmplwi   2A000000   1     CL4       cr4=gr0,0
  149| 00242C cmplwi   28830000   1     CL4       cr1=gr3,0
  149| 002430 cror     4C323382   1     CR_O      cr0=cr[41],0x2/gt,0x4/eq,0x4/eq,cr0
  149| 002434 bc       418107B4   1     BT        CL.1220,cr0,0x2/gt,taken=10%(10,90)
  149| 002438 ld       E8820000   1     L8        gr4=.&&N&vcvars(gr2,0)
  149| 00243C ld       E8640068   1     L8        gr3=<s81:d104:l8>(gr4,104)
  149| 002440 cmpdi    2C230000   1     C8        cr0=gr3,0
  149| 002444 bc       40820798   1     BF        CL.1221,cr0,0x4/eq,taken=40%(40,60)
  149|                              CL.86:
  149| 002448 ld       E8620000   1     L8        gr3=.&&N&vcvars(gr2,0)
  149| 00244C rlwinm   57E0073E   1     RN4       gr0=gr31,0,0xF
  149| 002450 stb      98030072   1     ST1Z      <s81:d114:l1>(gr3,114)=gr0
  149|                              CL.83:
  150| 002454 lbz      8BE3000A   1     L1Z       gr31=<s81:d10:l1>(gr3,10)
  150| 002458 rlwinm   57E0C9FF   1     SRL4_R    gr0,cr0=gr31,7
  150| 00245C rlwinm   57E00630   1     RN4       gr0=gr31,0,0x80
  150| 002460 bc       41820034   1     BT        CL.87,cr0,0x4/eq,taken=50%(0,0)
  150| 002464 rlwinm   57E306B4   1     RN4       gr3=gr31,0,0x20
  150| 002468 cmplwi   28800000   1     CL4       cr1=gr0,0
  150| 00246C cmplwi   2B030000   1     CL4       cr6=gr3,0
  150| 002470 cror     4C26D382   1     CR_O      cr0=cr[16],0x2/gt,0x4/eq,0x4/eq,cr0
  150| 002474 bc       41810724   1     BT        CL.1222,cr0,0x2/gt,taken=10%(10,90)
  150| 002478 ld       E8820000   1     L8        gr4=.&&N&vcvars(gr2,0)
  150| 00247C ld       E8640000   1     L8        gr3=<s81:d0:l8>(gr4,0)
  150| 002480 cmpdi    2C230000   1     C8        cr0=gr3,0
  150| 002484 bc       40820708   1     BF        CL.1223,cr0,0x4/eq,taken=40%(40,60)
  150|                              CL.90:
  150| 002488 ld       E8620000   1     L8        gr3=.&&N&vcvars(gr2,0)
  150| 00248C rlwinm   57E0073E   1     RN4       gr0=gr31,0,0xF
  150| 002490 stb      9803000A   1     ST1Z      <s81:d10:l1>(gr3,10)=gr0
  150|                              CL.87:
  151| 002494 lbz      8BE30142   1     L1Z       gr31=<s81:d322:l1>(gr3,322)
  151| 002498 rlwinm   57E0C9FF   1     SRL4_R    gr0,cr0=gr31,7
  151| 00249C rlwinm   57E00630   1     RN4       gr0=gr31,0,0x80
  151| 0024A0 bc       41820034   1     BT        CL.91,cr0,0x4/eq,taken=50%(0,0)
  151| 0024A4 rlwinm   57E306B4   1     RN4       gr3=gr31,0,0x20
  151| 0024A8 cmplwi   28800000   1     CL4       cr1=gr0,0
  151| 0024AC cmplwi   2B030000   1     CL4       cr6=gr3,0
  151| 0024B0 cror     4C26D382   1     CR_O      cr0=cr[16],0x2/gt,0x4/eq,0x4/eq,cr0
  151| 0024B4 bc       41810694   1     BT        CL.1224,cr0,0x2/gt,taken=10%(10,90)
  151| 0024B8 ld       E8820000   1     L8        gr4=.&&N&vcvars(gr2,0)
  151| 0024BC ld       E8640138   1     L8        gr3=<s81:d312:l8>(gr4,312)
  151| 0024C0 cmpdi    2C230000   1     C8        cr0=gr3,0
  151| 0024C4 bc       40820678   1     BF        CL.1225,cr0,0x4/eq,taken=40%(40,60)
  151|                              CL.94:
  151| 0024C8 ld       E8620000   1     L8        gr3=.&&N&vcvars(gr2,0)
  151| 0024CC rlwinm   57E0073E   1     RN4       gr0=gr31,0,0xF
  151| 0024D0 stb      98030142   1     ST1Z      <s81:d322:l1>(gr3,322)=gr0
  151|                              CL.91:
  152| 0024D4 lbz      8BE300DA   1     L1Z       gr31=<s81:d218:l1>(gr3,218)
  152| 0024D8 rlwinm   57E0C9FF   1     SRL4_R    gr0,cr0=gr31,7
  152| 0024DC rlwinm   57E00630   1     RN4       gr0=gr31,0,0x80
  152| 0024E0 bc       41820034   1     BT        CL.95,cr0,0x4/eq,taken=50%(0,0)
  152| 0024E4 rlwinm   57E306B4   1     RN4       gr3=gr31,0,0x20
  152| 0024E8 cmplwi   28800000   1     CL4       cr1=gr0,0
  152| 0024EC cmplwi   2B030000   1     CL4       cr6=gr3,0
  152| 0024F0 cror     4C26D382   1     CR_O      cr0=cr[16],0x2/gt,0x4/eq,0x4/eq,cr0
  152| 0024F4 bc       41810604   1     BT        CL.1226,cr0,0x2/gt,taken=10%(10,90)
  152| 0024F8 ld       E8820000   1     L8        gr4=.&&N&vcvars(gr2,0)
  152| 0024FC ld       E86400D0   1     L8        gr3=<s81:d208:l8>(gr4,208)
  152| 002500 cmpdi    2C230000   1     C8        cr0=gr3,0
  152| 002504 bc       408205E8   1     BF        CL.1227,cr0,0x4/eq,taken=40%(40,60)
  152|                              CL.98:
  152| 002508 ld       E8620000   1     L8        gr3=.&&N&vcvars(gr2,0)
  152| 00250C rlwinm   57E0073E   1     RN4       gr0=gr31,0,0xF
  152| 002510 stb      980300DA   1     ST1Z      <s81:d218:l1>(gr3,218)=gr0
  152|                              CL.95:
  153| 002514 lbz      8BE30212   1     L1Z       gr31=<s81:d530:l1>(gr3,530)
  153| 002518 rlwinm   57E0C9FF   1     SRL4_R    gr0,cr0=gr31,7
  153| 00251C rlwinm   57E00630   1     RN4       gr0=gr31,0,0x80
  153| 002520 bc       41820034   1     BT        CL.99,cr0,0x4/eq,taken=50%(0,0)
  153| 002524 rlwinm   57E306B4   1     RN4       gr3=gr31,0,0x20
  153| 002528 cmplwi   28800000   1     CL4       cr1=gr0,0
  153| 00252C cmplwi   2B030000   1     CL4       cr6=gr3,0
  153| 002530 cror     4C26D382   1     CR_O      cr0=cr[16],0x2/gt,0x4/eq,0x4/eq,cr0
  153| 002534 bc       41810574   1     BT        CL.1228,cr0,0x2/gt,taken=10%(10,90)
  153| 002538 ld       E8820000   1     L8        gr4=.&&N&vcvars(gr2,0)
  153| 00253C ld       E8640208   1     L8        gr3=<s81:d520:l8>(gr4,520)
  153| 002540 cmpdi    2C230000   1     C8        cr0=gr3,0
  153| 002544 bc       40820558   1     BF        CL.1229,cr0,0x4/eq,taken=40%(40,60)
  153|                              CL.102:
  153| 002548 ld       E8620000   1     L8        gr3=.&&N&vcvars(gr2,0)
  153| 00254C rlwinm   57E0073E   1     RN4       gr0=gr31,0,0xF
  153| 002550 stb      98030212   1     ST1Z      <s81:d530:l1>(gr3,530)=gr0
  153|                              CL.99:
  154| 002554 lbz      8BE301AA   1     L1Z       gr31=<s81:d426:l1>(gr3,426)
  154| 002558 rlwinm   57E0C9FF   1     SRL4_R    gr0,cr0=gr31,7
  154| 00255C rlwinm   57E00630   1     RN4       gr0=gr31,0,0x80
  154| 002560 bc       4182003C   1     BT        CL.103,cr0,0x4/eq,taken=40%(40,60)
  154| 002564 rlwinm   57E306B4   1     RN4       gr3=gr31,0,0x20
  154| 002568 cmplwi   28800000   1     CL4       cr1=gr0,0
  154| 00256C cmplwi   2B030000   1     CL4       cr6=gr3,0
  154| 002570 cror     4C26D382   1     CR_O      cr0=cr[16],0x2/gt,0x4/eq,0x4/eq,cr0
  154| 002574 bc       418104E4   1     BT        CL.1230,cr0,0x2/gt,taken=10%(10,90)
  154| 002578 ld       E8820000   1     L8        gr4=.&&N&vcvars(gr2,0)
  154| 00257C ld       E86401A0   1     L8        gr3=<s81:d416:l8>(gr4,416)
  154| 002580 cmpdi    2C230000   1     C8        cr0=gr3,0
  154| 002584 bc       4182000C   1     BT        CL.106,cr0,0x4/eq,taken=60%(60,40)
  154| 002588 bl       48000001   1     CALL      free,1,vp3r",gr3,free",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  154| 00258C ori      60000000   1
  154|                              CL.106:
  154| 002590 ld       E8620000   1     L8        gr3=.&&N&vcvars(gr2,0)
  154| 002594 rlwinm   57E0073E   1     RN4       gr0=gr31,0,0xF
  154| 002598 stb      980301AA   1     ST1Z      <s81:d426:l1>(gr3,426)=gr0
  154|                              CL.103:
  160| 00259C ld       EBA20000   1     L8        gr29=.&&N&&mpipar(gr2,0)
  161| 0025A0 ld       EBE20000   1     L8        gr31=.&&N&field(gr2,0)
  159| 0025A4 addi     3B800000   1     LI        gr28=0
  161| 0025A8 addi     3BC00003   1     LI        gr30=3
  161| 0025AC stw      93810170   1     ST4Z      T_61(gr1,368)=gr28
  161| 0025B0 stw      93C10168   1     ST4Z      T_59(gr1,360)=gr30
  159| 0025B4 stw      939D0018   1     ST4Z      <s180:d24:l4>(gr29,24)=gr28
  161| 0025B8 stw      93810174   1     ST4Z      T_62(gr1,372)=gr28
  160| 0025BC lwz      807D001C   1     L4Z       gr3=<s180:d28:l4>(gr29,28)
  161| 0025C0 stw      93C1016C   1     ST4Z      T_60(gr1,364)=gr30
  161| 0025C4 stw      93810178   1     ST4Z      T_63(gr1,376)=gr28
  161| 0025C8 stw      9381017C   1     ST4Z      T_64(gr1,380)=gr28
  161| 0025CC ld       E93F01A0   1     L8        gr9=<s23:d416:l8>(gr31,416)
  161| 0025D0 addi     3901017C   1     AI        gr8=gr1,380
  160| 0025D4 addi     38030001   1     AI        gr0=gr3,1
  161| 0025D8 addi     38E10178   1     AI        gr7=gr1,376
  160| 0025DC stw      901D001C   1     ST4Z      <s180:d28:l4>(gr29,28)=gr0
  161| 0025E0 addi     38C10174   1     AI        gr6=gr1,372
  161| 0025E4 addi     38A10170   1     AI        gr5=gr1,368
  161| 0025E8 addi     3881016C   1     AI        gr4=gr1,364
  161| 0025EC addi     38610168   1     AI        gr3=gr1,360
  161| 0025F0 bl       48000001   1     CALL      bvalv1,7,T_59",gr3,T_60",gr4,T_61",gr5,T_62",gr6,T_63",gr7,T_64",gr8,v1",gr9,bvalv1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  161| 0025F4 ori      60000000   1
  162| 0025F8 stw      93C10180   1     ST4Z      T_65(gr1,384)=gr30
  162| 0025FC stw      93C10184   1     ST4Z      T_66(gr1,388)=gr30
  162| 002600 stw      93810188   1     ST4Z      T_67(gr1,392)=gr28
  162| 002604 stw      9381018C   1     ST4Z      T_68(gr1,396)=gr28
  162| 002608 stw      93810190   1     ST4Z      T_69(gr1,400)=gr28
  162| 00260C stw      93810194   1     ST4Z      T_70(gr1,404)=gr28
  162| 002610 ld       E93F0208   1     L8        gr9=<s23:d520:l8>(gr31,520)
  162| 002614 addi     39010194   1     AI        gr8=gr1,404
  162| 002618 addi     38E10190   1     AI        gr7=gr1,400
  162| 00261C addi     38C1018C   1     AI        gr6=gr1,396
  162| 002620 addi     38A10188   1     AI        gr5=gr1,392
  162| 002624 addi     38810184   1     AI        gr4=gr1,388
  162| 002628 addi     38610180   1     AI        gr3=gr1,384
  162| 00262C bl       48000001   1     CALL      bvalv2,7,T_65",gr3,T_66",gr4,T_67",gr5,T_68",gr6,T_69",gr7,T_70",gr8,v2",gr9,bvalv2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  162| 002630 ori      60000000   1
  163| 002634 stw      93C10198   1     ST4Z      T_71(gr1,408)=gr30
  163| 002638 stw      93C1019C   1     ST4Z      T_72(gr1,412)=gr30
  163| 00263C stw      938101A0   1     ST4Z      T_73(gr1,416)=gr28
  163| 002640 stw      938101A4   1     ST4Z      T_74(gr1,420)=gr28
  163| 002644 stw      938101A8   1     ST4Z      T_75(gr1,424)=gr28
  163| 002648 stw      938101AC   1     ST4Z      T_76(gr1,428)=gr28
  163| 00264C ld       E93F0270   1     L8        gr9=<s23:d624:l8>(gr31,624)
  163| 002650 addi     390101AC   1     AI        gr8=gr1,428
  163| 002654 addi     38E101A8   1     AI        gr7=gr1,424
  163| 002658 addi     38C101A4   1     AI        gr6=gr1,420
  163| 00265C addi     38A101A0   1     AI        gr5=gr1,416
  163| 002660 addi     3881019C   1     AI        gr4=gr1,412
  163| 002664 addi     38610198   1     AI        gr3=gr1,408
  163| 002668 bl       48000001   1     CALL      bvalv3,7,T_71",gr3,T_72",gr4,T_73",gr5,T_74",gr6,T_75",gr7,T_76",gr8,v3",gr9,bvalv3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  163| 00266C ori      60000000   1
  164| 002670 lwz      801D0018   1     L4Z       gr0=<s180:d24:l4>(gr29,24)
  164| 002674 cmpdi    2C200000   1     C8        cr0=gr0,0
  164| 002678 bc       4182001C   1     BT        CL.107,cr0,0x4/eq,taken=60%(60,40)
  164| 00267C ld       E8A20000   1     L8        gr5=.&&N&&mpiyes(gr2,0)
  164| 002680 addi     38DD0014   1     AI        gr6=gr29,20
  164| 002684 addi     387D0018   1     AI        gr3=gr29,24
  164| 002688 addi     38851770   1     AI        gr4=gr5,6000
  164| 00268C bl       48000001   1     CALL      mpi_waitall,4,nreq",gr3,req[]",gr4,stat[]",gr5,ierr",gr6,mpi_waitall",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  164| 002690 ori      60000000   1
  164|                              CL.107:
  165| 002694 stw      939D0018   1     ST4Z      <s180:d24:l4>(gr29,24)=gr28
  166| 002698 lwz      807D001C   1     L4Z       gr3=<s180:d28:l4>(gr29,28)
  167| 00269C stw      938101B0   1     ST4Z      T_77(gr1,432)=gr28
  167| 0026A0 stw      938101B4   1     ST4Z      T_78(gr1,436)=gr28
  167| 0026A4 stw      93C101B8   1     ST4Z      T_79(gr1,440)=gr30
  167| 0026A8 stw      93C101BC   1     ST4Z      T_80(gr1,444)=gr30
  167| 0026AC stw      938101C0   1     ST4Z      T_81(gr1,448)=gr28
  166| 0026B0 addi     38030001   1     AI        gr0=gr3,1
  167| 0026B4 stw      938101C4   1     ST4Z      T_82(gr1,452)=gr28
  166| 0026B8 stw      901D001C   1     ST4Z      <s180:d28:l4>(gr29,28)=gr0
  167| 0026BC ld       E93F01A0   1     L8        gr9=<s23:d416:l8>(gr31,416)
  167| 0026C0 addi     390101C4   1     AI        gr8=gr1,452
  167| 0026C4 addi     38E101C0   1     AI        gr7=gr1,448
  167| 0026C8 addi     38C101BC   1     AI        gr6=gr1,444
  167| 0026CC addi     38A101B8   1     AI        gr5=gr1,440
  167| 0026D0 addi     388101B4   1     AI        gr4=gr1,436
  167| 0026D4 addi     386101B0   1     AI        gr3=gr1,432
  167| 0026D8 bl       48000001   1     CALL      bvalv1,7,T_77",gr3,T_78",gr4,T_79",gr5,T_80",gr6,T_81",gr7,T_82",gr8,v1",gr9,bvalv1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  167| 0026DC ori      60000000   1
  168| 0026E0 stw      938101C8   1     ST4Z      T_83(gr1,456)=gr28
  168| 0026E4 stw      938101CC   1     ST4Z      T_84(gr1,460)=gr28
  168| 0026E8 stw      93C101D0   1     ST4Z      T_85(gr1,464)=gr30
  168| 0026EC stw      93C101D4   1     ST4Z      T_86(gr1,468)=gr30
  168| 0026F0 stw      938101D8   1     ST4Z      T_87(gr1,472)=gr28
  168| 0026F4 stw      938101DC   1     ST4Z      T_88(gr1,476)=gr28
  168| 0026F8 ld       E93F0208   1     L8        gr9=<s23:d520:l8>(gr31,520)
  168| 0026FC addi     390101DC   1     AI        gr8=gr1,476
  168| 002700 addi     38E101D8   1     AI        gr7=gr1,472
  168| 002704 addi     38C101D4   1     AI        gr6=gr1,468
  168| 002708 addi     38A101D0   1     AI        gr5=gr1,464
  168| 00270C addi     388101CC   1     AI        gr4=gr1,460
  168| 002710 addi     386101C8   1     AI        gr3=gr1,456
  168| 002714 bl       48000001   1     CALL      bvalv2,7,T_83",gr3,T_84",gr4,T_85",gr5,T_86",gr6,T_87",gr7,T_88",gr8,v2",gr9,bvalv2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  168| 002718 ori      60000000   1
  169| 00271C stw      938101E0   1     ST4Z      T_89(gr1,480)=gr28
  169| 002720 stw      938101E4   1     ST4Z      T_90(gr1,484)=gr28
  169| 002724 stw      93C101E8   1     ST4Z      T_91(gr1,488)=gr30
  169| 002728 stw      93C101EC   1     ST4Z      T_92(gr1,492)=gr30
  169| 00272C stw      938101F0   1     ST4Z      T_93(gr1,496)=gr28
  169| 002730 stw      938101F4   1     ST4Z      T_94(gr1,500)=gr28
  169| 002734 ld       E93F0270   1     L8        gr9=<s23:d624:l8>(gr31,624)
  169| 002738 addi     390101F4   1     AI        gr8=gr1,500
  169| 00273C addi     38E101F0   1     AI        gr7=gr1,496
  169| 002740 addi     38C101EC   1     AI        gr6=gr1,492
  169| 002744 addi     38A101E8   1     AI        gr5=gr1,488
  169| 002748 addi     388101E4   1     AI        gr4=gr1,484
  169| 00274C addi     386101E0   1     AI        gr3=gr1,480
  169| 002750 bl       48000001   1     CALL      bvalv3,7,T_89",gr3,T_90",gr4,T_91",gr5,T_92",gr6,T_93",gr7,T_94",gr8,v3",gr9,bvalv3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  169| 002754 ori      60000000   1
  170| 002758 lwz      801D0018   1     L4Z       gr0=<s180:d24:l4>(gr29,24)
  170| 00275C cmpdi    2C200000   1     C8        cr0=gr0,0
  170| 002760 bc       4182001C   1     BT        CL.108,cr0,0x4/eq,taken=60%(60,40)
  170| 002764 ld       E8A20000   1     L8        gr5=.&&N&&mpiyes(gr2,0)
  170| 002768 addi     38DD0014   1     AI        gr6=gr29,20
  170| 00276C addi     387D0018   1     AI        gr3=gr29,24
  170| 002770 addi     38851770   1     AI        gr4=gr5,6000
  170| 002774 bl       48000001   1     CALL      mpi_waitall,4,nreq",gr3,req[]",gr4,stat[]",gr5,ierr",gr6,mpi_waitall",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  170| 002778 ori      60000000   1
  170|                              CL.108:
  171| 00277C stw      939D0018   1     ST4Z      <s180:d24:l4>(gr29,24)=gr28
  172| 002780 lwz      807D001C   1     L4Z       gr3=<s180:d28:l4>(gr29,28)
  173| 002784 stw      938101F8   1     ST4Z      T_95(gr1,504)=gr28
  173| 002788 stw      938101FC   1     ST4Z      T_96(gr1,508)=gr28
  173| 00278C stw      93810200   1     ST4Z      T_97(gr1,512)=gr28
  173| 002790 stw      93810204   1     ST4Z      T_98(gr1,516)=gr28
  173| 002794 stw      93C10208   1     ST4Z      T_99(gr1,520)=gr30
  172| 002798 addi     38030001   1     AI        gr0=gr3,1
  173| 00279C stw      93C1020C   1     ST4Z      T_100(gr1,524)=gr30
  172| 0027A0 stw      901D001C   1     ST4Z      <s180:d28:l4>(gr29,28)=gr0
  173| 0027A4 ld       E93F01A0   1     L8        gr9=<s23:d416:l8>(gr31,416)
  173| 0027A8 addi     3901020C   1     AI        gr8=gr1,524
  173| 0027AC addi     38E10208   1     AI        gr7=gr1,520
  173| 0027B0 addi     38C10204   1     AI        gr6=gr1,516
  173| 0027B4 addi     38A10200   1     AI        gr5=gr1,512
  173| 0027B8 addi     388101FC   1     AI        gr4=gr1,508
  173| 0027BC addi     386101F8   1     AI        gr3=gr1,504
  173| 0027C0 bl       48000001   1     CALL      bvalv1,7,T_95",gr3,T_96",gr4,T_97",gr5,T_98",gr6,T_99",gr7,T_100",gr8,v1",gr9,bvalv1",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  173| 0027C4 ori      60000000   1
  174| 0027C8 stw      93810210   1     ST4Z      T_101(gr1,528)=gr28
  174| 0027CC stw      93810214   1     ST4Z      T_102(gr1,532)=gr28
  174| 0027D0 stw      93810218   1     ST4Z      T_103(gr1,536)=gr28
  174| 0027D4 stw      9381021C   1     ST4Z      T_104(gr1,540)=gr28
  174| 0027D8 stw      93C10220   1     ST4Z      T_105(gr1,544)=gr30
  174| 0027DC stw      93C10224   1     ST4Z      T_106(gr1,548)=gr30
  174| 0027E0 ld       E93F0208   1     L8        gr9=<s23:d520:l8>(gr31,520)
  174| 0027E4 addi     39010224   1     AI        gr8=gr1,548
  174| 0027E8 addi     38E10220   1     AI        gr7=gr1,544
  174| 0027EC addi     38C1021C   1     AI        gr6=gr1,540
  174| 0027F0 addi     38A10218   1     AI        gr5=gr1,536
  174| 0027F4 addi     38810214   1     AI        gr4=gr1,532
  174| 0027F8 addi     38610210   1     AI        gr3=gr1,528
  174| 0027FC bl       48000001   1     CALL      bvalv2,7,T_101",gr3,T_102",gr4,T_103",gr5,T_104",gr6,T_105",gr7,T_106",gr8,v2",gr9,bvalv2",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  174| 002800 ori      60000000   1
  175| 002804 stw      93810228   1     ST4Z      T_107(gr1,552)=gr28
  175| 002808 stw      9381022C   1     ST4Z      T_108(gr1,556)=gr28
  175| 00280C stw      93810230   1     ST4Z      T_109(gr1,560)=gr28
  175| 002810 stw      93810234   1     ST4Z      T_110(gr1,564)=gr28
  175| 002814 stw      93C10238   1     ST4Z      T_111(gr1,568)=gr30
  175| 002818 stw      93C1023C   1     ST4Z      T_112(gr1,572)=gr30
  175| 00281C ld       E93F0270   1     L8        gr9=<s23:d624:l8>(gr31,624)
  175| 002820 addi     3901023C   1     AI        gr8=gr1,572
  175| 002824 addi     38E10238   1     AI        gr7=gr1,568
  175| 002828 addi     38C10234   1     AI        gr6=gr1,564
  175| 00282C addi     38A10230   1     AI        gr5=gr1,560
  175| 002830 addi     3881022C   1     AI        gr4=gr1,556
  175| 002834 addi     38610228   1     AI        gr3=gr1,552
  175| 002838 bl       48000001   1     CALL      bvalv3,7,T_107",gr3,T_108",gr4,T_109",gr5,T_110",gr6,T_111",gr7,T_112",gr8,v3",gr9,bvalv3",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  175| 00283C ori      60000000   1
  176| 002840 lwz      801D0018   1     L4Z       gr0=<s180:d24:l4>(gr29,24)
  176| 002844 cmpdi    2C200000   1     C8        cr0=gr0,0
  176| 002848 bc       4182001C   1     BT        CL.109,cr0,0x4/eq,taken=60%(60,40)
  176| 00284C ld       E8A20000   1     L8        gr5=.&&N&&mpiyes(gr2,0)
  176| 002850 addi     38DD0014   1     AI        gr6=gr29,20
  176| 002854 addi     387D0018   1     AI        gr3=gr29,24
  176| 002858 addi     38851770   1     AI        gr4=gr5,6000
  176| 00285C bl       48000001   1     CALL      mpi_waitall,4,nreq",gr3,req[]",gr4,stat[]",gr5,ierr",gr6,mpi_waitall",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  176| 002860 ori      60000000   1
  176|                              CL.109:
  180| 002864 ld       E8610610   1     L8        gr3=#SPILL0(gr1,1552)
  180| 002868 bl       48000001   1     CALL      normvel,1,vrms,gr3,normvel",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  180| 00286C ori      60000000   1
  183| 002870 lwz      801D0008   1     L4Z       gr0=<s180:d8:l4>(gr29,8)
  183| 002874 cmpdi    2C200000   1     C8        cr0=gr0,0
  183| 002878 bc       41820068   1     BT        CL.1235,cr0,0x4/eq,taken=40%(40,60)
  190|                              CL.188:
  190| 00287C ld       E8010850   1     L8        gr0=#stack(gr1,2128)
  190| 002880 lwa      E981084A   1     L4A       gr12=#stack(gr1,2120)
  190| 002884 addi     38210840   1     AI        gr1=gr1,2112
  190| 002888 ld       E9C1FF70   1     L8        gr14=#stack(gr1,-144)
  190| 00288C ld       E9E1FF78   1     L8        gr15=#stack(gr1,-136)
  190| 002890 mtspr    7C0803A6   1     LLR       lr=gr0
  190| 002894 mtcrf    7D820120   1     MTCRF     cr2=gr12
  190| 002898 mtcrf    7D808120   1     MTCRF     cr4=gr12
  190| 00289C ld       EA01FF80   1     L8        gr16=#stack(gr1,-128)
  190| 0028A0 ld       EA21FF88   1     L8        gr17=#stack(gr1,-120)
  190| 0028A4 ld       EA41FF90   1     L8        gr18=#stack(gr1,-112)
  190| 0028A8 ld       EA61FF98   1     L8        gr19=#stack(gr1,-104)
  190| 0028AC ld       EA81FFA0   1     L8        gr20=#stack(gr1,-96)
  190| 0028B0 ld       EAA1FFA8   1     L8        gr21=#stack(gr1,-88)
  190| 0028B4 ld       EAC1FFB0   1     L8        gr22=#stack(gr1,-80)
  190| 0028B8 ld       EAE1FFB8   1     L8        gr23=#stack(gr1,-72)
  190| 0028BC ld       EB01FFC0   1     L8        gr24=#stack(gr1,-64)
  190| 0028C0 ld       EB21FFC8   1     L8        gr25=#stack(gr1,-56)
  190| 0028C4 ld       EB41FFD0   1     L8        gr26=#stack(gr1,-48)
  190| 0028C8 ld       EB61FFD8   1     L8        gr27=#stack(gr1,-40)
  190| 0028CC ld       EB81FFE0   1     L8        gr28=#stack(gr1,-32)
  190| 0028D0 ld       EBA1FFE8   1     L8        gr29=#stack(gr1,-24)
  190| 0028D4 ld       EBC1FFF0   1     L8        gr30=#stack(gr1,-16)
  190| 0028D8 ld       EBE1FFF8   1     L8        gr31=#stack(gr1,-8)
  190| 0028DC bclr     4E800020   1     BA        lr
    0|                              CL.1235:
  184| 0028E0 ld       EBE20000   1     L8        gr31=.$STATIC(gr2,0)
  184| 0028E4 ori      639E8000   1     OIL       gr30=gr28,0x8000
  184| 0028E8 addi     38600006   1     LI        gr3=6
  184| 0028EC addi     38800101   1     LI        gr4=257
  184| 0028F0 or       7FC6F378   1     LR        gr6=gr30
  184| 0028F4 addi     38E00000   1     LI        gr7=0
  184| 0028F8 addi     38BF0100   1     AI        gr5=gr31,256
  184| 0028FC addi     39000000   1     LI        gr8=0
  184| 002900 addi     39200000   1     LI        gr9=0
  184| 002904 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#21",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  184| 002908 ori      60000000   1
  184| 00290C ld       EB820000   1     L8        gr28=.+CONSTANT_AREA(gr2,0)
  184| 002910 or       7C7D1B78   1     LR        gr29=gr3
  184| 002914 addi     38A0002C   1     LI        gr5=44
  184| 002918 addi     38C00001   1     LI        gr6=1
  184| 00291C addi     389C000C   1     AI        gr4=gr28,12
  184| 002920 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  184| 002924 ori      60000000   1
  184| 002928 or       7FA3EB78   1     LR        gr3=gr29
  184| 00292C bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  184| 002930 ori      60000000   1
  185| 002934 addi     38BF0140   1     AI        gr5=gr31,320
  185| 002938 addi     38600006   1     LI        gr3=6
  185| 00293C addi     38800101   1     LI        gr4=257
  185| 002940 or       7FC6F378   1     LR        gr6=gr30
  185| 002944 addi     38E00000   1     LI        gr7=0
  185| 002948 addi     39000000   1     LI        gr8=0
  185| 00294C addi     39200000   1     LI        gr9=0
  185| 002950 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#23",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  185| 002954 ori      60000000   1
  185| 002958 or       7C7D1B78   1     LR        gr29=gr3
  185| 00295C addi     389C0094   1     AI        gr4=gr28,148
  185| 002960 addi     38A00027   1     LI        gr5=39
  185| 002964 addi     38C00001   1     LI        gr6=1
  185| 002968 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  185| 00296C ori      60000000   1
  185| 002970 or       7FA3EB78   1     LR        gr3=gr29
  185| 002974 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  185| 002978 ori      60000000   1
  186| 00297C addi     38BF0180   1     AI        gr5=gr31,384
  186| 002980 or       7FC6F378   1     LR        gr6=gr30
  186| 002984 addi     38600006   1     LI        gr3=6
  186| 002988 addi     38800101   1     LI        gr4=257
  186| 00298C addi     38E00000   1     LI        gr7=0
  186| 002990 addi     39000000   1     LI        gr8=0
  186| 002994 addi     39200000   1     LI        gr9=0
  186| 002998 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#25",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  186| 00299C ori      60000000   1
  186| 0029A0 or       7C7D1B78   1     LR        gr29=gr3
  186| 0029A4 addi     389C00BC   1     AI        gr4=gr28,188
  186| 0029A8 addi     38A00028   1     LI        gr5=40
  186| 0029AC addi     38C00001   1     LI        gr6=1
  186| 0029B0 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  186| 0029B4 ori      60000000   1
  186| 0029B8 or       7FA3EB78   1     LR        gr3=gr29
  186| 0029BC bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  186| 0029C0 ori      60000000   1
  187| 0029C4 addi     38BF01C0   1     AI        gr5=gr31,448
  187| 0029C8 or       7FC6F378   1     LR        gr6=gr30
  187| 0029CC addi     38600006   1     LI        gr3=6
  187| 0029D0 addi     38800101   1     LI        gr4=257
  187| 0029D4 addi     38E00000   1     LI        gr7=0
  187| 0029D8 addi     39000000   1     LI        gr8=0
  187| 0029DC addi     39200000   1     LI        gr9=0
  187| 0029E0 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#27",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  187| 0029E4 ori      60000000   1
  187| 0029E8 or       7C7D1B78   1     LR        gr29=gr3
  187| 0029EC addi     389C00E4   1     AI        gr4=gr28,228
  187| 0029F0 addi     38A00025   1     LI        gr5=37
  187| 0029F4 addi     38C00001   1     LI        gr6=1
  187| 0029F8 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  187| 0029FC ori      60000000   1
  187| 002A00 or       7FA3EB78   1     LR        gr3=gr29
  187| 002A04 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  187| 002A08 ori      60000000   1
  188| 002A0C addi     38BF0200   1     AI        gr5=gr31,512
  188| 002A10 or       7FC6F378   1     LR        gr6=gr30
  188| 002A14 addi     38600006   1     LI        gr3=6
  188| 002A18 addi     38800101   1     LI        gr4=257
  188| 002A1C addi     38E00000   1     LI        gr7=0
  188| 002A20 addi     39000000   1     LI        gr8=0
  188| 002A24 addi     39200000   1     LI        gr9=0
  188| 002A28 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#29",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,@PALI_SHADOW_CONST.rns0.,gr9,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  188| 002A2C ori      60000000   1
  188| 002A30 addi     389C000C   1     AI        gr4=gr28,12
  188| 002A34 or       7C7F1B78   1     LR        gr31=gr3
  188| 002A38 addi     38A0002C   1     LI        gr5=44
  188| 002A3C addi     38C00001   1     LI        gr6=1
  188| 002A40 bl       48000001   1     CALL      _xlfWriteLDChar,4,gr3-gr6,_xlfWriteLDChar",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  188| 002A44 ori      60000000   1
  188| 002A48 or       7FE3FB78   1     LR        gr3=gr31
  188| 002A4C bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  188| 002A50 ori      60000000   1
    0| 002A54 b        4BFFFE28   1     B         CL.188,-1
    0|                              CL.1230:
  154| 002A58 ld       E8020000   1     L8        gr0=.+CONSTANT_AREA(gr2,0)
  154| 002A5C addi     3BE00000   1     LI        gr31=0
  154| 002A60 addi     3860000A   1     LI        gr3=10
  154| 002A64 std      FBE10070   1     ST8       #MX_TEMP1(gr1,112)=gr31
  154| 002A68 addi     39210300   1     AI        gr9=gr1,768
  154| 002A6C std      F8610308   1     ST8       <a1:d776:l8>(gr1,776)=gr3
  154| 002A70 addi     38600000   1     LI        gr3=0
  154| 002A74 addi     38800003   1     LI        gr4=3
  154| 002A78 std      F8010300   1     ST8       <a1:d768:l8>(gr1,768)=gr0
  154| 002A7C addi     38A0006D   1     LI        gr5=109
  154| 002A80 addi     38C00000   1     LI        gr6=0
  154| 002A84 addi     38E00000   1     LI        gr7=0
  154| 002A88 addi     39000000   1     LI        gr8=0
  154| 002A8C addi     3940009A   1     LI        gr10=154
  154| 002A90 bl       48000001   1     CALL      _xlfErrorExitWithLoc,9,gr3-gr6,ShadowTemp_1.rns2.,gr7,ShadowTemp_1.rns2.,gr8,filename_6,gr9,gr10,ShadowTemp_1.rns2.,_xlfErrorExitWithLoc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  154| 002A94 ori      60000000   1
  154| 002A98 tw       7C8E7008   1     TRAP      9
    0|                              CL.1229:
  153| 002A9C bl       48000001   1     CALL      free,1,vp3i",gr3,free",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  153| 002AA0 ori      60000000   1
    0| 002AA4 b        4BFFFAA4   1     B         CL.102,-1
    0|                              CL.1228:
  153| 002AA8 ld       E8020000   1     L8        gr0=.+CONSTANT_AREA(gr2,0)
  153| 002AAC addi     3BE00000   1     LI        gr31=0
  153| 002AB0 addi     3860000A   1     LI        gr3=10
  153| 002AB4 std      FBE10070   1     ST8       #MX_TEMP1(gr1,112)=gr31
  153| 002AB8 addi     392102E0   1     AI        gr9=gr1,736
  153| 002ABC std      F86102E8   1     ST8       <a1:d744:l8>(gr1,744)=gr3
  153| 002AC0 addi     38600000   1     LI        gr3=0
  153| 002AC4 addi     38800003   1     LI        gr4=3
  153| 002AC8 std      F80102E0   1     ST8       <a1:d736:l8>(gr1,736)=gr0
  153| 002ACC addi     38A0006D   1     LI        gr5=109
  153| 002AD0 addi     38C00000   1     LI        gr6=0
  153| 002AD4 addi     38E00000   1     LI        gr7=0
  153| 002AD8 addi     39000000   1     LI        gr8=0
  153| 002ADC addi     39400099   1     LI        gr10=153
  153| 002AE0 bl       48000001   1     CALL      _xlfErrorExitWithLoc,9,gr3-gr6,ShadowTemp_1.rns2.,gr7,ShadowTemp_1.rns2.,gr8,filename_5,gr9,gr10,ShadowTemp_1.rns2.,_xlfErrorExitWithLoc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  153| 002AE4 ori      60000000   1
  153| 002AE8 tw       7C8E7008   1     TRAP      9
    0|                              CL.1227:
  152| 002AEC bl       48000001   1     CALL      free,1,vp2r",gr3,free",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  152| 002AF0 ori      60000000   1
    0| 002AF4 b        4BFFFA14   1     B         CL.98,-1
    0|                              CL.1226:
  152| 002AF8 ld       E8020000   1     L8        gr0=.+CONSTANT_AREA(gr2,0)
  152| 002AFC addi     3BE00000   1     LI        gr31=0
  152| 002B00 addi     3860000A   1     LI        gr3=10
  152| 002B04 std      FBE10070   1     ST8       #MX_TEMP1(gr1,112)=gr31
  152| 002B08 addi     392102C0   1     AI        gr9=gr1,704
  152| 002B0C std      F86102C8   1     ST8       <a1:d712:l8>(gr1,712)=gr3
  152| 002B10 addi     38600000   1     LI        gr3=0
  152| 002B14 addi     38800003   1     LI        gr4=3
  152| 002B18 std      F80102C0   1     ST8       <a1:d704:l8>(gr1,704)=gr0
  152| 002B1C addi     38A0006D   1     LI        gr5=109
  152| 002B20 addi     38C00000   1     LI        gr6=0
  152| 002B24 addi     38E00000   1     LI        gr7=0
  152| 002B28 addi     39000000   1     LI        gr8=0
  152| 002B2C addi     39400098   1     LI        gr10=152
  152| 002B30 bl       48000001   1     CALL      _xlfErrorExitWithLoc,9,gr3-gr6,ShadowTemp_1.rns2.,gr7,ShadowTemp_1.rns2.,gr8,filename_4,gr9,gr10,ShadowTemp_1.rns2.,_xlfErrorExitWithLoc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  152| 002B34 ori      60000000   1
  152| 002B38 tw       7C8E7008   1     TRAP      9
    0|                              CL.1225:
  151| 002B3C bl       48000001   1     CALL      free,1,vp2i",gr3,free",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  151| 002B40 ori      60000000   1
    0| 002B44 b        4BFFF984   1     B         CL.94,-1
    0|                              CL.1224:
  151| 002B48 ld       E8020000   1     L8        gr0=.+CONSTANT_AREA(gr2,0)
  151| 002B4C addi     3BE00000   1     LI        gr31=0
  151| 002B50 addi     3860000A   1     LI        gr3=10
  151| 002B54 std      FBE10070   1     ST8       #MX_TEMP1(gr1,112)=gr31
  151| 002B58 addi     392102A0   1     AI        gr9=gr1,672
  151| 002B5C std      F86102A8   1     ST8       <a1:d680:l8>(gr1,680)=gr3
  151| 002B60 addi     38600000   1     LI        gr3=0
  151| 002B64 addi     38800003   1     LI        gr4=3
  151| 002B68 std      F80102A0   1     ST8       <a1:d672:l8>(gr1,672)=gr0
  151| 002B6C addi     38A0006D   1     LI        gr5=109
  151| 002B70 addi     38C00000   1     LI        gr6=0
  151| 002B74 addi     38E00000   1     LI        gr7=0
  151| 002B78 addi     39000000   1     LI        gr8=0
  151| 002B7C addi     39400097   1     LI        gr10=151
  151| 002B80 bl       48000001   1     CALL      _xlfErrorExitWithLoc,9,gr3-gr6,ShadowTemp_1.rns2.,gr7,ShadowTemp_1.rns2.,gr8,filename_3,gr9,gr10,ShadowTemp_1.rns2.,_xlfErrorExitWithLoc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  151| 002B84 ori      60000000   1
  151| 002B88 tw       7C8E7008   1     TRAP      9
    0|                              CL.1223:
  150| 002B8C bl       48000001   1     CALL      free,1,vp1r",gr3,free",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  150| 002B90 ori      60000000   1
    0| 002B94 b        4BFFF8F4   1     B         CL.90,-1
    0|                              CL.1222:
  150| 002B98 ld       E8020000   1     L8        gr0=.+CONSTANT_AREA(gr2,0)
  150| 002B9C addi     3BE00000   1     LI        gr31=0
  150| 002BA0 addi     3860000A   1     LI        gr3=10
  150| 002BA4 std      FBE10070   1     ST8       #MX_TEMP1(gr1,112)=gr31
  150| 002BA8 addi     39210280   1     AI        gr9=gr1,640
  150| 002BAC std      F8610288   1     ST8       <a1:d648:l8>(gr1,648)=gr3
  150| 002BB0 addi     38600000   1     LI        gr3=0
  150| 002BB4 addi     38800003   1     LI        gr4=3
  150| 002BB8 std      F8010280   1     ST8       <a1:d640:l8>(gr1,640)=gr0
  150| 002BBC addi     38A0006D   1     LI        gr5=109
  150| 002BC0 addi     38C00000   1     LI        gr6=0
  150| 002BC4 addi     38E00000   1     LI        gr7=0
  150| 002BC8 addi     39000000   1     LI        gr8=0
  150| 002BCC addi     39400096   1     LI        gr10=150
  150| 002BD0 bl       48000001   1     CALL      _xlfErrorExitWithLoc,9,gr3-gr6,ShadowTemp_1.rns2.,gr7,ShadowTemp_1.rns2.,gr8,filename_2,gr9,gr10,ShadowTemp_1.rns2.,_xlfErrorExitWithLoc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  150| 002BD4 ori      60000000   1
  150| 002BD8 tw       7C8E7008   1     TRAP      9
    0|                              CL.1221:
  149| 002BDC bl       48000001   1     CALL      free,1,vp1i",gr3,free",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  149| 002BE0 ori      60000000   1
    0| 002BE4 b        4BFFF864   1     B         CL.86,-1
    0|                              CL.1220:
  149| 002BE8 ld       E8020000   1     L8        gr0=.+CONSTANT_AREA(gr2,0)
  149| 002BEC addi     3BE00000   1     LI        gr31=0
  149| 002BF0 addi     3860000A   1     LI        gr3=10
  149| 002BF4 std      FBE10070   1     ST8       #MX_TEMP1(gr1,112)=gr31
  149| 002BF8 addi     39210260   1     AI        gr9=gr1,608
  149| 002BFC std      F8610268   1     ST8       <a1:d616:l8>(gr1,616)=gr3
  149| 002C00 addi     38600000   1     LI        gr3=0
  149| 002C04 addi     38800003   1     LI        gr4=3
  149| 002C08 std      F8010260   1     ST8       <a1:d608:l8>(gr1,608)=gr0
  149| 002C0C addi     38A0006D   1     LI        gr5=109
  149| 002C10 addi     38C00000   1     LI        gr6=0
  149| 002C14 addi     38E00000   1     LI        gr7=0
  149| 002C18 addi     39000000   1     LI        gr8=0
  149| 002C1C addi     39400095   1     LI        gr10=149
  149| 002C20 bl       48000001   1     CALL      _xlfErrorExitWithLoc,9,gr3-gr6,ShadowTemp_1.rns2.,gr7,ShadowTemp_1.rns2.,gr8,filename_1,gr9,gr10,ShadowTemp_1.rns2.,_xlfErrorExitWithLoc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  149| 002C24 ori      60000000   1
  149| 002C28 tw       7C8E7008   1     TRAP      9
    0|                              CL.1219:
  138| 002C2C ld       E8A20000   1     L8        gr5=.&&N&&mpiyes(gr2,0)
  138| 002C30 addi     38DE0014   1     AI        gr6=gr30,20
  138| 002C34 addi     387E0018   1     AI        gr3=gr30,24
  138| 002C38 addi     38851770   1     AI        gr4=gr5,6000
  138| 002C3C bl       48000001   1     CALL      mpi_waitall,4,nreq",gr3,req[]",gr4,stat[]",gr5,ierr",gr6,mpi_waitall",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
  138| 002C40 ori      60000000   1
    0| 002C44 b        4BFFF548   1     B         CL.70,-1
   90|                              CL.521:
    0| 002C48 ld       E8010798   1     L8        gr0=#SPILL49(gr1,1944)
    0| 002C4C mtspr    7C0903A6   1     LCTR      ctr=gr0
   90|                              CL.410:
   84| 002C50 addi     38630001   1     AI        gr3=gr3,1
   84| 002C54 cmpd     7C230000   1     C8        cr0=gr3,gr0
   84| 002C58 bc       4100FFF8   1     BCTT      ctr=CL.410,cr0,0x1/lt,taken=80%(80,20)
    0| 002C5C b        4BFFEC88   1     B         CL.159,-1
   90|                              CL.506:
    0| 002C60 ld       E8010798   1     L8        gr0=#SPILL49(gr1,1944)
    0| 002C64 mtspr    7C0903A6   1     LCTR      ctr=gr0
   90|                              CL.455:
   84| 002C68 addi     38630001   1     AI        gr3=gr3,1
   84| 002C6C cmpd     7C230000   1     C8        cr0=gr3,gr0
   84| 002C70 bc       4100FFF8   1     BCTT      ctr=CL.455,cr0,0x1/lt,taken=80%(80,20)
    0| 002C74 b        4BFFE404   1     B         CL.171,-1
   90|                              CL.496:
    0| 002C78 mtspr    7F4903A6   1     LCTR      ctr=gr26
    0| 002C7C or       7F40D378   1     LR        gr0=gr26
   90|                              CL.485:
   84| 002C80 addi     38630001   1     AI        gr3=gr3,1
   84| 002C84 cmpd     7C230000   1     C8        cr0=gr3,gr0
   84| 002C88 bc       4100FFF8   1     BCTT      ctr=CL.485,cr0,0x1/lt,taken=80%(80,20)
    0| 002C8C b        4BFFDE88   1     B         CL.187,-1
   64|                              CL.33:
   64| 002C90 addi     38800020   1     LI        gr4=32
   64| 002C94 bl       48000001   1     CALL      gr3=__xlf_malloc,2,gr3,gr4,vp3i",__xlf_malloc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   64| 002C98 ori      60000000   1
   64| 002C9C ld       E9820000   1     L8        gr12=.&&N&vcvars(gr2,0)
   64| 002CA0 cmpdi    2C230000   1     C8        cr0=gr3,0
   64| 002CA4 std      F86C0208   1     ST8       <s81:d520:l8>(gr12,520)=gr3
   64| 002CA8 bc       4182DAA8   1     BT        CL.216,cr0,0x4/eq,taken=50%(0,0)
   64| 002CAC addi     380000F0   1     LI        gr0=240
   64| 002CB0 stb      980C0212   1     ST1Z      <s81:d530:l1>(gr12,530)=gr0
    0| 002CB4 b        4BFFDB10   1     B         CL.32,-1
   63|                              CL.27:
   63| 002CB8 addi     38800020   1     LI        gr4=32
   63| 002CBC bl       48000001   1     CALL      gr3=__xlf_malloc,2,gr3,gr4,vp3r",__xlf_malloc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   63| 002CC0 ori      60000000   1
   63| 002CC4 ld       E9820000   1     L8        gr12=.&&N&vcvars(gr2,0)
   63| 002CC8 cmpdi    2C230000   1     C8        cr0=gr3,0
   63| 002CCC std      F86C01A0   1     ST8       <s81:d416:l8>(gr12,416)=gr3
   63| 002CD0 bc       4182D954   1     BT        CL.217,cr0,0x4/eq,taken=50%(0,0)
   63| 002CD4 addi     380000F0   1     LI        gr0=240
   63| 002CD8 stb      980C01AA   1     ST1Z      <s81:d426:l1>(gr12,426)=gr0
    0| 002CDC b        4BFFD9BC   1     B         CL.26,-1
   62|                              CL.21:
   62| 002CE0 addi     38800020   1     LI        gr4=32
   62| 002CE4 bl       48000001   1     CALL      gr3=__xlf_malloc,2,gr3,gr4,vp2i",__xlf_malloc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   62| 002CE8 ori      60000000   1
   62| 002CEC ld       E9820000   1     L8        gr12=.&&N&vcvars(gr2,0)
   62| 002CF0 cmpdi    2C230000   1     C8        cr0=gr3,0
   62| 002CF4 std      F86C0138   1     ST8       <s81:d312:l8>(gr12,312)=gr3
   62| 002CF8 bc       4182D804   1     BT        CL.218,cr0,0x4/eq,taken=50%(0,0)
   62| 002CFC addi     380000F0   1     LI        gr0=240
   62| 002D00 stb      980C0142   1     ST1Z      <s81:d322:l1>(gr12,322)=gr0
    0| 002D04 b        4BFFD86C   1     B         CL.20,-1
   61|                              CL.15:
   61| 002D08 addi     38800020   1     LI        gr4=32
   61| 002D0C bl       48000001   1     CALL      gr3=__xlf_malloc,2,gr3,gr4,vp2r",__xlf_malloc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   61| 002D10 ori      60000000   1
   61| 002D14 ld       E9820000   1     L8        gr12=.&&N&vcvars(gr2,0)
   61| 002D18 cmpdi    2C230000   1     C8        cr0=gr3,0
   61| 002D1C std      F86C00D0   1     ST8       <s81:d208:l8>(gr12,208)=gr3
   61| 002D20 bc       4182D6B4   1     BT        CL.219,cr0,0x4/eq,taken=50%(0,0)
   61| 002D24 addi     380000F0   1     LI        gr0=240
   61| 002D28 stb      980C00DA   1     ST1Z      <s81:d218:l1>(gr12,218)=gr0
    0| 002D2C b        4BFFD71C   1     B         CL.14,-1
   60|                              CL.9:
   60| 002D30 addi     38800020   1     LI        gr4=32
   60| 002D34 bl       48000001   1     CALL      gr3=__xlf_malloc,2,gr3,gr4,vp1i",__xlf_malloc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   60| 002D38 ori      60000000   1
   60| 002D3C ld       E9820000   1     L8        gr12=.&&N&vcvars(gr2,0)
   60| 002D40 cmpdi    2C230000   1     C8        cr0=gr3,0
   60| 002D44 std      F86C0068   1     ST8       <s81:d104:l8>(gr12,104)=gr3
   60| 002D48 bc       4182D564   1     BT        CL.220,cr0,0x4/eq,taken=50%(0,0)
   60| 002D4C addi     380000F0   1     LI        gr0=240
   60| 002D50 stb      980C0072   1     ST1Z      <s81:d114:l1>(gr12,114)=gr0
    0| 002D54 b        4BFFD5CC   1     B         CL.8,-1
   59|                              CL.3:
   59| 002D58 addi     38800020   1     LI        gr4=32
   59| 002D5C bl       48000001   1     CALL      gr3=__xlf_malloc,2,gr3,gr4,vp1r",__xlf_malloc",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   59| 002D60 ori      60000000   1
   59| 002D64 ld       E8820000   1     L8        gr4=.&&N&vcvars(gr2,0)
   59| 002D68 cmpdi    2C230000   1     C8        cr0=gr3,0
   59| 002D6C std      F8640000   1     ST8       <s81:d0:l8>(gr4,0)=gr3
   59| 002D70 bc       4182D404   1     BT        CL.221,cr0,0x4/eq,taken=50%(0,0)
   59| 002D74 addi     380000F0   1     LI        gr0=240
   59| 002D78 stb      9804000A   1     ST1Z      <s81:d10:l1>(gr4,10)=gr0
    0| 002D7C b        4BFFD474   1     B         CL.2,-1
     |               Tag Table
     | 002D80        00000000 00012203 80120000 00002D80
     |               Instruction count         2912
     |               Straight-line exec time   2971
     |               Constant Area
     | 000000        67656E76 656C2E66 39304942 47454E56 454C2020 20202020
     | 000018        20202020 20202020 2020203A 202D2D2D 2D2D2D2D 2D2D2D2D
     | 000030        2D2D2D2D 2D2D2D20 47454E56 454C2020 20202020 20202020
     | 000048        20202020 2020203A 20737461 72742067 656E6572 61746520
     | 000060        6F662020 47454E56 454C2020 20202020 20202020 20202020
     | 000078        2020203A 2076656C 6F636974 79206669 656C6420 20202020
     | 000090        3F000000 47454E56 454C2020 20202020 20202020 20202020
     | 0000A8        2020203A 2067656E 65726174 696F6E20 6F662049 47454E56
     | 0000C0        454C2020 20202020 20202020 20202020 2020203A 2076656C
     | 0000D8        6F636974 79206669 656C6420 47454E56 454C2020 20202020
     | 0000F0        20202020 20202020 2020203A 2066696E 69736865 64202121
     | 000108        20

 
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    genvel.f90                  07/08/15   15:48:54
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
 
    Source records read.......................................     190
1501-510  Compilation successful for file genvel.f90.
1501-543  Object file created.
