IBM XL Fortran for Blue Gene, V14.1 (5799-AH1) Version 14.01.0000.0012 --- mhdshktube.f90 07/08/15 15:48:49
 
>>>>> OPTIONS SECTION <<<<<
***   Options In Effect   ***
  
         ==  On / Off Options  ==
         CR              NODIRECTSTORAG  ESCAPE          I4
         INLGLUE         NOLIBESSL       NOLIBPOSIX      OBJECT
         SWAPOMP         THREADED        UNWIND          ZEROSIZE
  
         ==  Options Of Integer Type ==
         ALIAS_SIZE(65536)     MAXMEM(-1)            OPTIMIZE(3)
         SPILLSIZE(512)        STACKTEMP(0)
  
         ==  Options of Integer and Character Type ==
         CACHE(LEVEL(1),TYPE(I),ASSOC(4),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(I),ASSOC(16),COST(80),LINE(128))
         CACHE(LEVEL(1),TYPE(D),ASSOC(8),COST(6),LINE(64),SIZE(16))
         CACHE(LEVEL(2),TYPE(D),ASSOC(16),COST(80),LINE(128))
         INLINE(NOAUTO,LEVEL(5))
         HOT(FASTMATH,LEVEL(0))
         SIMD(AUTO)
  
         ==  Options Of Character Type  ==
         64()                  ALIAS(STD,NOINTPTR)   ALIGN(BINDC(LINUXPPC),STRUCT(NATURAL))
         ARCH(QP)              AUTODBL(NONE)         DESCRIPTOR(V1)
         DIRECTIVE(IBM*,IBMT)  ENUM()                FLAG(I,I)
         FLOAT(MAF,FOLD,RSQRT,FLTINT)
         FREE(F90)             GNU_VERSION(DOT_TRIPLE)
         HALT(S)               IEEE(NEAR)            INTSIZE(4)
         LIST()                LANGLVL(EXTENDED)     REALSIZE(4)
         REPORT(HOTLIST)       STRICT(NONE,NOPRECISION,NOEXCEPTIONS,NOIEEEFP,NONANS,NOINFINITIES,NOSUBNORMALS,NOZEROSIGNS,NOOPERATIONPRECISION,ORDER,NOLIBRARY,NOCONSTRUCTCOPY,NOVECTORPRECISION)
         TUNE(QP)              UNROLL(AUTO)          XFLAG()
         XLF2003(NOPOLYMORPHIC,NOBOZLITARGS,NOSIGNDZEROINTR,NOSTOPEXCEPT,NOVOLATILE,NOAUTOREALLOC,OLDNANINF)
         XLF2008(NOCHECKPRESENCE)
         XLF77(LEADZERO,BLANKPAD)
         XLF90(SIGNEDZERO,AUTODEALLOC)
  
>>>>> SOURCE SECTION <<<<<
** mhdshktube   === End of Compilation 1 ===
 
>>>>> LOOP TRANSFORMATION SECTION <<<<<

1586-534 (I) Loop (loop index 1) at mhdshktube.f90 <line 100> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 2) at mhdshktube.f90 <line 101> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns3.[1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns2.[2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns1.[1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns2.[1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns3.[2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns1.[2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-536 (I) Loop (loop index 3) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at mhdshktube.f90 <line 105> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at mhdshktube.f90 <line 104> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at mhdshktube.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at mhdshktube.f90 <line 104> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*(1ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at mhdshktube.f90 <line 105> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 3) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 3) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 3) at mhdshktube.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 3) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*(2ll + ($$CIV6 * 2ll + (long long) kn % 2ll)) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
1586-534 (I) Loop (loop index 4) at mhdshktube.f90 <line 110> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 5) at mhdshktube.f90 <line 111> was not SIMD vectorized because the loop is not the innermost loop.
1586-538 (I) Loop (loop index 6) at mhdshktube.f90 <line 112> was not SIMD vectorized because it contains unsupported loop structure.
1586-552 (I) Loop (loop index 6) at mhdshktube.f90 <line 112> was not SIMD vectorized because it contains control flow.
1586-534 (I) Loop (loop index 10) at mhdshktube.f90 <line 100> was not SIMD vectorized because the loop is not the innermost loop.
1586-534 (I) Loop (loop index 11) at mhdshktube.f90 <line 101> was not SIMD vectorized because the loop is not the innermost loop.
1586-540 (I) Loop (loop index 12) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v3%addr  + d-v3%rvo))->v3[].rns3.[$$CIV2 + 1ll][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v1%addr  + d-v1%rvo))->v1[].rns1.[$$CIV2 + 1ll][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-540 (I) Loop (loop index 12) at mhdshktube.f90 <line 102> was not SIMD vectorized because it contains memory references ((double *)((char *)d-v2%addr  + d-v2%rvo))->v2[].rns2.[$$CIV2 + 1ll][$$CIV1 + 1ll][$$CIV0 + 1ll] =  0.0000000000000000E+000; with non-vectorizable strides.
1586-536 (I) Loop (loop index 12) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains memory references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at mhdshktube.f90 <line 105> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at mhdshktube.f90 <line 105> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v3%addr  + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 12) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains memory references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at mhdshktube.f90 <line 103> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at mhdshktube.f90 <line 103> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v1%addr  + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
1586-536 (I) Loop (loop index 12) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable alignment.
1586-540 (I) Loop (loop index 12) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains memory references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with non-vectorizable strides.
1586-554 (I) Loop (loop index 12) at mhdshktube.f90 <line 104> was not SIMD vectorized because the floating point operation is not vectorizable under -qstrict.
1586-556 (I) Loop (loop index 12) at mhdshktube.f90 <line 104> was not SIMD vectorized because it contains non-stride-one store references ((char *)d-v2%addr  + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
1586-543 (I) <SIMD info> Total number of the innermost loops considered <"3">. Total number of the innermost loops SIMD vectorized <"0">.


    15|         SUBROUTINE mhdshktube ()
    44|           x10 =  4.0000000000000000E+002
    45|           x20 =  5.0000000000000000E-001
    46|           x30 =  5.0000000000000000E-001
    47|           d0 =  1.0000000000000000E+000
    48|           p0 =  1.0000000000000000E+000
    49|           b1_0 =  7.5000000000000000E-001
    50|           b2_0 =  1.0000000000000000E+000
    51|           b3_0 =  0.0000000000000000E+000
    52|           b1_1 =  7.5000000000000000E-001
    53|           b2_1 = -1.0000000000000000E+000
    54|           b3_1 =  0.0000000000000000E+000
    55|           d1 =  1.2500000000000000E-001
    56|           p1 =  1.0000000000000000E-001
    58|           IF ((myid == 0)) THEN
    15|             |pgen%nlitems%type.off32 = 4
                    |pgen%nlitems%kind.off40 = 
                    |pgen%nlitems%size.off48 = 
                    |pgen%nlitems%name_addr.off56 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 4
                    |pgen%nlitems%name_len.off64 = 3
                    |pgen%nlitems%item_addr.off72 = loc(x10)
                    |pgen%nlitems%type.off80 = 4
                    |pgen%nlitems%kind.off88 = 
                    |pgen%nlitems%size.off96 = 
                    |pgen%nlitems%name_addr.off104 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 8
                    |pgen%nlitems%name_len.off112 = 3
                    |pgen%nlitems%item_addr.off120 = loc(x20)
                    |pgen%nlitems%type.off128 = 4
                    |pgen%nlitems%kind.off136 = 
                    |pgen%nlitems%size.off144 = 
                    |pgen%nlitems%name_addr.off152 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 12
                    |pgen%nlitems%name_len.off160 = 2
                    |pgen%nlitems%item_addr.off168 = loc(p0)
                    |pgen%nlitems%type.off176 = 4
                    |pgen%nlitems%kind.off184 = 
                    |pgen%nlitems%size.off192 = 
                    |pgen%nlitems%name_addr.off200 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 14
                    |pgen%nlitems%name_len.off208 = 2
                    |pgen%nlitems%item_addr.off216 = loc(d0)
                    |pgen%nlitems%type.off224 = 4
                    |pgen%nlitems%kind.off232 = 
                    |pgen%nlitems%size.off240 = 
                    |pgen%nlitems%name_addr.off248 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 16
                    |pgen%nlitems%name_len.off256 = 2
                    |pgen%nlitems%item_addr.off264 = loc(p1)
                    |pgen%nlitems%type.off272 = 4
                    |pgen%nlitems%kind.off280 = 
                    |pgen%nlitems%size.off288 = 
                    |pgen%nlitems%name_addr.off296 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 18
                    |pgen%nlitems%name_len.off304 = 2
                    |pgen%nlitems%item_addr.off312 = loc(d1)
                    |pgen%nlitems%type.off320 = 0
                    |pgen%nlitems%kind.off328 = 
                    |pgen%nlitems%size.off336 = 
                    |pgen%nlitems%name_addr.off344 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 20
                    |pgen%nlitems%name_len.off352 = 7
                    |pgen%nlitems%item_addr.off360 = loc(idirect)
                    |pgen%nlitems%type.off368 = 4
                    |pgen%nlitems%kind.off376 = 
                    |pgen%nlitems%size.off384 = 
                    |pgen%nlitems%name_addr.off392 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 28
                    |pgen%nlitems%name_len.off400 = 3
                    |pgen%nlitems%item_addr.off408 = loc(x30)
                    |pgen%nlitems%type.off416 = 4
                    |pgen%nlitems%kind.off424 = 
                    |pgen%nlitems%size.off432 = 
                    |pgen%nlitems%name_addr.off440 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 32
                    |pgen%nlitems%name_len.off448 = 4
                    |pgen%nlitems%item_addr.off456 = loc(b1_0)
                    |pgen%nlitems%type.off464 = 4
                    |pgen%nlitems%kind.off472 = 
                    |pgen%nlitems%size.off480 = 
                    |pgen%nlitems%name_addr.off488 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 36
                    |pgen%nlitems%name_len.off496 = 4
                    |pgen%nlitems%item_addr.off504 = loc(b2_0)
                    |pgen%nlitems%type.off512 = 4
                    |pgen%nlitems%kind.off520 = 
                    |pgen%nlitems%size.off528 = 
                    |pgen%nlitems%name_addr.off536 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 40
                    |pgen%nlitems%name_len.off544 = 4
                    |pgen%nlitems%item_addr.off552 = loc(b1_1)
                    |pgen%nlitems%type.off560 = 4
                    |pgen%nlitems%kind.off568 = 
                    |pgen%nlitems%size.off576 = 
                    |pgen%nlitems%name_addr.off584 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 44
                    |pgen%nlitems%name_len.off592 = 4
                    |pgen%nlitems%item_addr.off600 = loc(b2_1)
                    |pgen%nlitems%type.off608 = 4
                    |pgen%nlitems%kind.off616 = 
                    |pgen%nlitems%size.off624 = 
                    |pgen%nlitems%name_addr.off632 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 48
                    |pgen%nlitems%name_len.off640 = 4
                    |pgen%nlitems%item_addr.off648 = loc(b3_0)
                    |pgen%version = 129
                    |pgen%name_addr = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90"
                    |pgen%name_len = 4
                    |pgen%num_of_items = 14
                    |pgen%nlitems%type.off656 = 4
                    |pgen%nlitems%kind.off664 = 
                    |pgen%nlitems%size.off672 = 
                    |pgen%nlitems%name_addr.off680 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 52
                    |pgen%nlitems%name_len.off688 = 4
                    |pgen%nlitems%item_addr.off696 = loc(b3_1)
    59|             |pgen%name_flags = 0
                    #2 = _xlfBeginIO(1,2,#1,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#2))
    60|             |pgen%name_flags = 0
                    #4 = _xlfBeginIO(2,258,#3,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#4))
    61|             buf_in[].off1744 = x10
    62|             buf_in[].off1752 = x20
    63|             buf_in[].off1760 = d0
    64|             buf_in[].off1768 = p0
    65|             buf_in[].off1776 = d1
    66|             buf_in[].off1784 = p1
    67|             buf_in[].off1792 = b1_0
    68|             buf_in[].off1800 = b1_1
    69|             buf_in[].off1808 = b2_0
    70|             buf_in[].off1816 = b2_1
    71|             buf_in[].off1824 = b3_0
    72|             buf_in[].off1832 = b3_1
    73|             ibuf_in[].off144 = idirect
    74|           ENDIF
    75|           T_2 = 12
                  T_3 = 1275070495
                  T_4 = 0
                  CALL mpi_bcast(buf_in,T_2,T_3,T_4,comm3d,ierr)
    77|           T_5 = 1
                  T_6 = 1275069467
                  T_7 = 0
                  CALL mpi_bcast(ibuf_in,T_5,T_6,T_7,comm3d,ierr)
    79|           IF ((myid <> 0)) THEN
    80|             x10 = buf_in[].off1744
    81|             x20 = buf_in[].off1752
    82|             d0 = buf_in[].off1760
    83|             p0 = buf_in[].off1768
    84|             d1 = buf_in[].off1776
    85|             p1 = buf_in[].off1784
    86|             b1_0 = buf_in[].off1792
    87|             b1_1 = buf_in[].off1800
    88|             b2_0 = buf_in[].off1808
    89|             b2_1 = buf_in[].off1816
    90|             b3_0 = buf_in[].off1824
    91|             b3_1 = buf_in[].off1832
    92|             idirect = ibuf_in[].off144
    93|           ENDIF
    97|           e0 = p0 / gamm1
    98|           e1 = p1 / gamm1
   100|           IF ((MOD(int(kn), 2) > 0  .AND.  int(kn) > 0)) THEN
                    $$CIV2 = 0
       Id=10        DO $$CIV2 = $$CIV2, MOD(int(kn), int(2))-1
   101|               IF ((int(jn) > 0)) THEN
                        $$CIV1 = 0
       Id=11            DO $$CIV1 = $$CIV1, int(int(jn))-1
   102|                   IF ((int(in) > 0)) THEN
                            $$CIV0 = 0
       Id=12                DO $$CIV0 = $$CIV0, int(int(in))-1
   103|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
   104|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
   105|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
   106|                     ENDDO
                          ENDIF
   107|                 ENDDO
                      ENDIF
   108|             ENDDO
                  ENDIF
   100|           IF ((int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 2))) THEN
                    $$CIV6 = int(0)
       Id=1         DO $$CIV6 = $$CIV6, int((((int(kn) - MOD(int(kn), 2)) - 1)&
                &        / 2 + 1))-1
   101|               IF ((int(jn) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int(int(jn))-1
   102|                   IF ((int(in) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int(int(in))-1
   103|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   104|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   105|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   103|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   104|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   105|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   106|                     ENDDO
                          ENDIF
   107|                 ENDDO
                      ENDIF
   108|             ENDDO
                  ENDIF
   110|           IF ((int(kn) > 0)) THEN
                    $$CIV5 = 0
       Id=4         DO $$CIV5 = $$CIV5, int(int(kn))-1
   111|               IF ((int(jn) > 0)) THEN
                        $$CIV4 = 0
       Id=5             DO $$CIV4 = $$CIV4, int(int(jn))-1
   112|                   IF ((int(in) > 0)) THEN
                            $$CIV3 = 0
       Id=6                 DO $$CIV3 = $$CIV3, int(int(in))-1
   113|                       IF (.NOT.(idirect == 1)) GOTO lab_18
   114|                       IF (.NOT.(d-x1a%addr%x1a($$CIV3 + 1) <= x10)) &
                &               GOTO lab_19
   115|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e0
   116|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d0
   117|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_0
   118|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_0
   119|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_0
   120|                       GOTO lab_20
                              lab_19
   121|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e1
   122|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d1
   123|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_1
   124|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_1
   125|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_1
   126|                       lab_20
   127|                       lab_18
   128|                       IF (.NOT.(idirect == 2)) GOTO lab_21
   129|                       IF (.NOT.(d-x2a%addr%x2a($$CIV4 + 1) <= x20)) &
                &               GOTO lab_22
   130|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e0
   131|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d0
   132|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_0
   133|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_0
   134|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_0
   135|                       GOTO lab_23
                              lab_22
   136|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e1
   137|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d1
   138|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_1
   139|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_1
   140|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_1
   141|                       lab_23
   142|                       lab_21
   143|                       IF (.NOT.(idirect == 3)) GOTO lab_24
   144|                       IF (.NOT.(d-x3a%addr%x3a($$CIV5 + 1) <= x30)) &
                &               GOTO lab_25
   145|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e0
   146|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d0
   147|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_0
   148|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_0
   149|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_0
   150|                       GOTO lab_26
                              lab_25
   151|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e1
   152|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d1
   153|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_1
   154|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_1
   155|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_1
   156|                       lab_26
   157|                       lab_24
   158|                     ENDDO
                          ENDIF
   159|                 ENDDO
                      ENDIF
   160|             ENDDO
                  ENDIF
   163|           RETURN
                END SUBROUTINE mhdshktube


Source        Source        Loop Id       Action / Information                                      
File          Line                                                                                  
----------    ----------    ----------    ----------------------------------------------------------
         0           100            10    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           101            11    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*($$CIV2 + 1ll) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v1%addr  
                                          + d-v1%rvo + (d-v1%bounds%mult[].off464)*($$CIV2 + 
                                          1ll) + (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*($$CIV2 + 1ll) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           104                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v2%addr  
                                          + d-v2%rvo + (d-v2%bounds%mult[].off568)*($$CIV2 + 
                                          1ll) + (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
         0           105                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           105                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*($$CIV2 + 1ll) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           105                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           105                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v3%addr  
                                          + d-v3%rvo + (d-v3%bounds%mult[].off672)*($$CIV2 + 
                                          1ll) + (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
         0           100             1    Outer loop has been unrolled 2 time(s).
         0           100             1    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           101             2    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(1ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(1ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v1%addr  
                                          + d-v1%rvo + (d-v1%bounds%mult[].off464)*(1ll + 
                                          ($$CIV6 * 2ll + (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(1ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(1ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           104                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v2%addr  
                                          + d-v2%rvo + (d-v2%bounds%mult[].off568)*(1ll + 
                                          ($$CIV6 * 2ll + (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
         0           105                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(1ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           105                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(1ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           105                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           105                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v3%addr  
                                          + d-v3%rvo + (d-v3%bounds%mult[].off672)*(1ll + 
                                          ($$CIV6 * 2ll + (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(2ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v1%addr  + d-v1%rvo + 
                                          (d-v1%bounds%mult[].off464)*(2ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           103                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           103                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v1%addr  
                                          + d-v1%rvo + (d-v1%bounds%mult[].off464)*(2ll + 
                                          ($$CIV6 * 2ll + (long long) kn % 2ll)) + 
                                          (d-v1%bounds%mult[].off488)*($$CIV1 + 1ll) + 
                                          (d-v1%bounds%mult[].off512)*($$CIV0 + 1ll)).
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(2ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v2%addr  + d-v2%rvo + 
                                          (d-v2%bounds%mult[].off568)*(2ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           104                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           104                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v2%addr  
                                          + d-v2%rvo + (d-v2%bounds%mult[].off568)*(2ll + 
                                          ($$CIV6 * 2ll + (long long) kn % 2ll)) + 
                                          (d-v2%bounds%mult[].off592)*($$CIV1 + 1ll) + 
                                          (d-v2%bounds%mult[].off616)*($$CIV0 + 1ll)).
         0           105                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(2ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll))  with 
                                          non-vectorizable alignment.
         0           105                  Loop was not SIMD vectorized because it contains 
                                          memory references ((char *)d-v3%addr  + d-v3%rvo + 
                                          (d-v3%bounds%mult[].off672)*(2ll + ($$CIV6 * 2ll + 
                                          (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)) with  
                                          non-vectorizable strides.
         0           105                  Loop was not SIMD vectorized because the floating 
                                          point operation is not  vectorizable under -qstrict.
         0           105                  Loop was not SIMD vectorized because it contains 
                                          non-stride-one store  references ((char *)d-v3%addr  
                                          + d-v3%rvo + (d-v3%bounds%mult[].off672)*(2ll + 
                                          ($$CIV6 * 2ll + (long long) kn % 2ll)) + 
                                          (d-v3%bounds%mult[].off696)*($$CIV1 + 1ll) + 
                                          (d-v3%bounds%mult[].off720)*($$CIV0 + 1ll)).
         0           110             4    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           111             5    Loop was not SIMD vectorized because the loop is not 
                                          the innermost loop.
         0           112             6    Loop was not SIMD vectorized because it contains 
                                          unsupported loop structure.
         0           112             6    Loop was not SIMD vectorized because it contains 
                                          control flow.


    15|         SUBROUTINE mhdshktube ()
    44|           x10 =  4.0000000000000000E+002
    45|           x20 =  5.0000000000000000E-001
    46|           x30 =  5.0000000000000000E-001
    47|           d0 =  1.0000000000000000E+000
    48|           p0 =  1.0000000000000000E+000
    49|           b1_0 =  7.5000000000000000E-001
    50|           b2_0 =  1.0000000000000000E+000
    51|           b3_0 =  0.0000000000000000E+000
    52|           b1_1 =  7.5000000000000000E-001
    53|           b2_1 = -1.0000000000000000E+000
    54|           b3_1 =  0.0000000000000000E+000
    55|           d1 =  1.2500000000000000E-001
    56|           p1 =  1.0000000000000000E-001
    58|           IF ((myid == 0)) THEN
    15|             |pgen%nlitems%type.off32 = 4
                    |pgen%nlitems%kind.off40 = 
                    |pgen%nlitems%size.off48 = 
                    |pgen%nlitems%name_addr.off56 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 4
                    |pgen%nlitems%name_len.off64 = 3
                    |pgen%nlitems%item_addr.off72 = loc(x10)
                    |pgen%nlitems%type.off80 = 4
                    |pgen%nlitems%kind.off88 = 
                    |pgen%nlitems%size.off96 = 
                    |pgen%nlitems%name_addr.off104 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 8
                    |pgen%nlitems%name_len.off112 = 3
                    |pgen%nlitems%item_addr.off120 = loc(x20)
                    |pgen%nlitems%type.off128 = 4
                    |pgen%nlitems%kind.off136 = 
                    |pgen%nlitems%size.off144 = 
                    |pgen%nlitems%name_addr.off152 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 12
                    |pgen%nlitems%name_len.off160 = 2
                    |pgen%nlitems%item_addr.off168 = loc(p0)
                    |pgen%nlitems%type.off176 = 4
                    |pgen%nlitems%kind.off184 = 
                    |pgen%nlitems%size.off192 = 
                    |pgen%nlitems%name_addr.off200 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 14
                    |pgen%nlitems%name_len.off208 = 2
                    |pgen%nlitems%item_addr.off216 = loc(d0)
                    |pgen%nlitems%type.off224 = 4
                    |pgen%nlitems%kind.off232 = 
                    |pgen%nlitems%size.off240 = 
                    |pgen%nlitems%name_addr.off248 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 16
                    |pgen%nlitems%name_len.off256 = 2
                    |pgen%nlitems%item_addr.off264 = loc(p1)
                    |pgen%nlitems%type.off272 = 4
                    |pgen%nlitems%kind.off280 = 
                    |pgen%nlitems%size.off288 = 
                    |pgen%nlitems%name_addr.off296 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 18
                    |pgen%nlitems%name_len.off304 = 2
                    |pgen%nlitems%item_addr.off312 = loc(d1)
                    |pgen%nlitems%type.off320 = 0
                    |pgen%nlitems%kind.off328 = 
                    |pgen%nlitems%size.off336 = 
                    |pgen%nlitems%name_addr.off344 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 20
                    |pgen%nlitems%name_len.off352 = 7
                    |pgen%nlitems%item_addr.off360 = loc(idirect)
                    |pgen%nlitems%type.off368 = 4
                    |pgen%nlitems%kind.off376 = 
                    |pgen%nlitems%size.off384 = 
                    |pgen%nlitems%name_addr.off392 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 28
                    |pgen%nlitems%name_len.off400 = 3
                    |pgen%nlitems%item_addr.off408 = loc(x30)
                    |pgen%nlitems%type.off416 = 4
                    |pgen%nlitems%kind.off424 = 
                    |pgen%nlitems%size.off432 = 
                    |pgen%nlitems%name_addr.off440 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 32
                    |pgen%nlitems%name_len.off448 = 4
                    |pgen%nlitems%item_addr.off456 = loc(b1_0)
                    |pgen%nlitems%type.off464 = 4
                    |pgen%nlitems%kind.off472 = 
                    |pgen%nlitems%size.off480 = 
                    |pgen%nlitems%name_addr.off488 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 36
                    |pgen%nlitems%name_len.off496 = 4
                    |pgen%nlitems%item_addr.off504 = loc(b2_0)
                    |pgen%nlitems%type.off512 = 4
                    |pgen%nlitems%kind.off520 = 
                    |pgen%nlitems%size.off528 = 
                    |pgen%nlitems%name_addr.off536 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 40
                    |pgen%nlitems%name_len.off544 = 4
                    |pgen%nlitems%item_addr.off552 = loc(b1_1)
                    |pgen%nlitems%type.off560 = 4
                    |pgen%nlitems%kind.off568 = 
                    |pgen%nlitems%size.off576 = 
                    |pgen%nlitems%name_addr.off584 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 44
                    |pgen%nlitems%name_len.off592 = 4
                    |pgen%nlitems%item_addr.off600 = loc(b2_1)
                    |pgen%nlitems%type.off608 = 4
                    |pgen%nlitems%kind.off616 = 
                    |pgen%nlitems%size.off624 = 
                    |pgen%nlitems%name_addr.off632 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 48
                    |pgen%nlitems%name_len.off640 = 4
                    |pgen%nlitems%item_addr.off648 = loc(b3_0)
                    |pgen%version = 129
                    |pgen%name_addr = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90"
                    |pgen%name_len = 4
                    |pgen%num_of_items = 14
                    |pgen%nlitems%type.off656 = 4
                    |pgen%nlitems%kind.off664 = 
                    |pgen%nlitems%size.off672 = 
                    |pgen%nlitems%name_addr.off680 = &
                &     "pgenx10Ix20Ip0d0p1d1idirectIx30Ib1_0b2_0b1_1b2_1b3_0b3_1mh&
                &     dshktube.f90" + 52
                    |pgen%nlitems%name_len.off688 = 4
                    |pgen%nlitems%item_addr.off696 = loc(b3_1)
    59|             |pgen%name_flags = 0
                    #2 = _xlfBeginIO(1,2,#1,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#2))
    60|             |pgen%name_flags = 0
                    #4 = _xlfBeginIO(2,258,#3,32768,NULL,0,|pgen)
                    _xlfEndIO(%VAL(#4))
    61|             buf_in[].off1744 = x10
    62|             buf_in[].off1752 = x20
    63|             buf_in[].off1760 = d0
    64|             buf_in[].off1768 = p0
    65|             buf_in[].off1776 = d1
    66|             buf_in[].off1784 = p1
    67|             buf_in[].off1792 = b1_0
    68|             buf_in[].off1800 = b1_1
    69|             buf_in[].off1808 = b2_0
    70|             buf_in[].off1816 = b2_1
    71|             buf_in[].off1824 = b3_0
    72|             buf_in[].off1832 = b3_1
    73|             ibuf_in[].off144 = idirect
    74|           ENDIF
    75|           T_2 = 12
                  T_3 = 1275070495
                  T_4 = 0
                  CALL mpi_bcast(buf_in,T_2,T_3,T_4,comm3d,ierr)
    77|           T_5 = 1
                  T_6 = 1275069467
                  T_7 = 0
                  CALL mpi_bcast(ibuf_in,T_5,T_6,T_7,comm3d,ierr)
    79|           IF ((myid <> 0)) THEN
    80|             x10 = buf_in[].off1744
    81|             x20 = buf_in[].off1752
    82|             d0 = buf_in[].off1760
    83|             p0 = buf_in[].off1768
    84|             d1 = buf_in[].off1776
    85|             p1 = buf_in[].off1784
    86|             b1_0 = buf_in[].off1792
    87|             b1_1 = buf_in[].off1800
    88|             b2_0 = buf_in[].off1808
    89|             b2_1 = buf_in[].off1816
    90|             b3_0 = buf_in[].off1824
    91|             b3_1 = buf_in[].off1832
    92|             idirect = ibuf_in[].off144
    93|           ENDIF
    97|           e0 = p0 / gamm1
    98|           e1 = p1 / gamm1
   100|           IF ((MOD(int(kn), 2) > 0  .AND.  int(kn) > 0)) THEN
                    $$CIV2 = 0
       Id=10        DO $$CIV2 = $$CIV2, MOD(int(kn), int(2))-1
   101|               IF ((int(jn) > 0)) THEN
                        $$CIV1 = 0
       Id=11            DO $$CIV1 = $$CIV1, int(int(jn))-1
   102|                   IF ((int(in) > 0)) THEN
                            $$CIV0 = 0
       Id=12                DO $$CIV0 = $$CIV0, int(int(in))-1
   103|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
   104|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
   105|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,$$CIV2 + 1) =  &
                &               0.0000000000000000E+000
   106|                     ENDDO
                          ENDIF
   107|                 ENDDO
                      ENDIF
   108|             ENDDO
                  ENDIF
   100|           IF ((int(kn) > 0  .AND.  int(kn) > MOD(int(kn), 2))) THEN
                    $$CIV6 = int(0)
       Id=1         DO $$CIV6 = $$CIV6, int((((int(kn) - MOD(int(kn), 2)) - 1)&
                &        / 2 + 1))-1
   101|               IF ((int(jn) > 0)) THEN
                        $$CIV1 = 0
       Id=2             DO $$CIV1 = $$CIV1, int(int(jn))-1
   102|                   IF ((int(in) > 0)) THEN
                            $$CIV0 = 0
       Id=3                 DO $$CIV0 = $$CIV0, int(int(in))-1
   103|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   104|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   105|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,1 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   103|                       d-v1%addr%v1($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   104|                       d-v2%addr%v2($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   105|                       d-v3%addr%v3($$CIV0 + 1,$$CIV1 + 1,2 + ($$CIV6 * &
                &               2 + MOD(int(kn), 2))) =  0.0000000000000000E+000
   106|                     ENDDO
                          ENDIF
   107|                 ENDDO
                      ENDIF
   108|             ENDDO
                  ENDIF
   110|           IF ((int(kn) > 0)) THEN
                    $$CIV5 = 0
       Id=4         DO $$CIV5 = $$CIV5, int(int(kn))-1
   111|               IF ((int(jn) > 0)) THEN
                        $$CIV4 = 0
       Id=5             DO $$CIV4 = $$CIV4, int(int(jn))-1
   112|                   IF ((int(in) > 0)) THEN
                            $$CIV3 = 0
       Id=6                 DO $$CIV3 = $$CIV3, int(int(in))-1
   113|                       IF (.NOT.(idirect == 1)) GOTO lab_18
   114|                       IF (.NOT.(d-x1a%addr%x1a($$CIV3 + 1) <= x10)) &
                &               GOTO lab_19
   115|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e0
   116|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d0
   117|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_0
   118|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_0
   119|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_0
   120|                       GOTO lab_20
                              lab_19
   121|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e1
   122|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d1
   123|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_1
   124|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_1
   125|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_1
   126|                       lab_20
   127|                       lab_18
   128|                       IF (.NOT.(idirect == 2)) GOTO lab_21
   129|                       IF (.NOT.(d-x2a%addr%x2a($$CIV4 + 1) <= x20)) &
                &               GOTO lab_22
   130|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e0
   131|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d0
   132|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_0
   133|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_0
   134|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_0
   135|                       GOTO lab_23
                              lab_22
   136|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e1
   137|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d1
   138|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_1
   139|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_1
   140|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_1
   141|                       lab_23
   142|                       lab_21
   143|                       IF (.NOT.(idirect == 3)) GOTO lab_24
   144|                       IF (.NOT.(d-x3a%addr%x3a($$CIV5 + 1) <= x30)) &
                &               GOTO lab_25
   145|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e0
   146|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d0
   147|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_0
   148|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_0
   149|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_0
   150|                       GOTO lab_26
                              lab_25
   151|                       d-e%addr%e($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = e1
   152|                       d-d%addr%d($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = d1
   153|                       d-b1%addr%b1($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b1_1
   154|                       d-b2%addr%b2($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b2_1
   155|                       d-b3%addr%b3($$CIV3 + 1,$$CIV4 + 1,$$CIV5 + 1) = &
                &               b3_1
   156|                       lab_26
   157|                       lab_24
   158|                     ENDDO
                          ENDIF
   159|                 ENDDO
                      ENDIF
   160|             ENDDO
                  ENDIF
   163|           RETURN
                END SUBROUTINE mhdshktube

 
 
>>>>> OBJECT SECTION <<<<<
 GPR's set/used:   ssus ssss ssss s-ss  ssss ssss ssss ssss
 FPR's set/used:   ssss ssss ssss ss--  --ss ssss ssss ssss
 CCR's set/used:   sss- ssss
     | 000000                           PDEF     mhdshktube
   15|                                  PROC      
    0| 000000 stfd     DBE1FFF8   1     STFL      #stack(gr1,-8)=fp31
    0| 000004 stfd     DBC1FFF0   1     STFL      #stack(gr1,-16)=fp30
    0| 000008 stfd     DBA1FFE8   1     STFL      #stack(gr1,-24)=fp29
    0| 00000C stfd     DB81FFE0   1     STFL      #stack(gr1,-32)=fp28
    0| 000010 stfd     DB61FFD8   1     STFL      #stack(gr1,-40)=fp27
    0| 000014 stfd     DB41FFD0   1     STFL      #stack(gr1,-48)=fp26
    0| 000018 stfd     DB21FFC8   1     STFL      #stack(gr1,-56)=fp25
    0| 00001C stfd     DB01FFC0   1     STFL      #stack(gr1,-64)=fp24
    0| 000020 stfd     DAE1FFB8   1     STFL      #stack(gr1,-72)=fp23
    0| 000024 stfd     DAC1FFB0   1     STFL      #stack(gr1,-80)=fp22
    0| 000028 stfd     DAA1FFA8   1     STFL      #stack(gr1,-88)=fp21
    0| 00002C stfd     DA81FFA0   1     STFL      #stack(gr1,-96)=fp20
    0| 000030 stfd     DA61FF98   1     STFL      #stack(gr1,-104)=fp19
    0| 000034 stfd     DA41FF90   1     STFL      #stack(gr1,-112)=fp18
    0| 000038 std      FBE1FF88   1     ST8       #stack(gr1,-120)=gr31
    0| 00003C std      FBC1FF80   1     ST8       #stack(gr1,-128)=gr30
    0| 000040 std      FBA1FF78   1     ST8       #stack(gr1,-136)=gr29
    0| 000044 std      FB81FF70   1     ST8       #stack(gr1,-144)=gr28
    0| 000048 std      FB61FF68   1     ST8       #stack(gr1,-152)=gr27
    0| 00004C std      FB41FF60   1     ST8       #stack(gr1,-160)=gr26
    0| 000050 std      FB21FF58   1     ST8       #stack(gr1,-168)=gr25
    0| 000054 std      FB01FF50   1     ST8       #stack(gr1,-176)=gr24
    0| 000058 std      FAE1FF48   1     ST8       #stack(gr1,-184)=gr23
    0| 00005C std      FAC1FF40   1     ST8       #stack(gr1,-192)=gr22
    0| 000060 std      FAA1FF38   1     ST8       #stack(gr1,-200)=gr21
    0| 000064 std      FA81FF30   1     ST8       #stack(gr1,-208)=gr20
    0| 000068 std      FA61FF28   1     ST8       #stack(gr1,-216)=gr19
    0| 00006C std      FA41FF20   1     ST8       #stack(gr1,-224)=gr18
    0| 000070 std      FA21FF18   1     ST8       #stack(gr1,-232)=gr17
    0| 000074 std      FA01FF10   1     ST8       #stack(gr1,-240)=gr16
    0| 000078 std      F9E1FF08   1     ST8       #stack(gr1,-248)=gr15
    0| 00007C std      F9C1FF00   1     ST8       #stack(gr1,-256)=gr14
    0| 000080 mfspr    7C0802A6   1     LFLR      gr0=lr
    0| 000084 mfcr     7D800026   1     LFCR      gr12=cr[24],2
    0| 000088 stw      91810008   1     ST4A      #stack(gr1,8)=gr12
    0| 00008C std      F8010010   1     ST8       #stack(gr1,16)=gr0
    0| 000090 stdu     F821FA21   1     ST8U      gr1,#stack(gr1,-1504)=gr1
   58| 000094 ld       EBE20000   1     L8        gr31=.&&N&&mpipar(gr2,0)
   44| 000098 ld       E8620000   1     L8        gr3=.+CONSTANT_AREA(gr2,0)
   44| 00009C addi     38C04079   1     LI        gr6=16505
   45| 0000A0 addi     38E001FF   1     LI        gr7=511
   53| 0000A4 addi     38800BFF   1     LI        gr4=3071
   47| 0000A8 addi     390003FF   1     LI        gr8=1023
   58| 0000AC lwz      801F0004   1     L4Z       gr0=<s134:d4:l4>(gr31,4)
   56| 0000B0 lfd      CBE30078   1     LFL       fp31=+CONSTANT_AREA(gr3,120)
   49| 0000B4 lfs      C3C30064   1     LFS       fp30=+CONSTANT_AREA(gr3,100)
   47| 0000B8 lfs      C3430060   1     LFS       fp26=+CONSTANT_AREA(gr3,96)
   51| 0000BC lfs      C2C30068   1     LFS       fp22=+CONSTANT_AREA(gr3,104)
   49| 0000C0 addi     392007FD   1     LI        gr9=2045
   55| 0000C4 addi     38A000FF   1     LI        gr5=255
   44| 0000C8 rldicr   78C683C6   1     SLL8      gr6=gr6,48
   45| 0000CC rldicr   78E7AA86   1     SLL8      gr7=gr7,53
   52| 0000D0 fmr      FFA0F090   1     LRFL      fp29=fp30
   44| 0000D4 std      F8C100A0   1     ST8       x10(gr1,160)=gr6
   47| 0000D8 fmr      FF20D090   1     LRFL      fp25=fp26
   45| 0000DC std      F8E100A8   1     ST8       x20(gr1,168)=gr7
   48| 0000E0 fmr      FF00D090   1     LRFL      fp24=fp26
   46| 0000E4 std      F8E100B0   1     ST8       x30(gr1,176)=gr7
   50| 0000E8 fmr      FEE0D090   1     LRFL      fp23=fp26
   56| 0000EC stfd     DBE10100   1     STFL      p1(gr1,256)=fp31
   51| 0000F0 fmr      FEA0B090   1     LRFL      fp21=fp22
   53| 0000F4 rldicr   7884A2C6   1     SLL8      gr4=gr4,52
   54| 0000F8 fmr      FE60B090   1     LRFL      fp19=fp22
   53| 0000FC std      F88100E8   1     ST8       b2_1(gr1,232)=gr4
   47| 000100 rldicr   7906A2C6   1     SLL8      gr6=gr8,52
   49| 000104 rldicr   79279B06   1     SLL8      gr7=gr9,51
   47| 000108 std      F8C100B8   1     ST8       d0(gr1,184)=gr6
   48| 00010C std      F8C100C0   1     ST8       p0(gr1,192)=gr6
   49| 000110 std      F8E100C8   1     ST8       b1_0(gr1,200)=gr7
   50| 000114 std      F8C100D0   1     ST8       b2_0(gr1,208)=gr6
   52| 000118 std      F8E100E0   1     ST8       b1_1(gr1,224)=gr7
   51| 00011C addi     3BC00000   1     LI        gr30=0
   55| 000120 rldicr   78A4B246   1     SLL8      gr4=gr5,54
   51| 000124 std      FBC100D8   1     ST8       b3_0(gr1,216)=gr30
   54| 000128 std      FBC100F0   1     ST8       b3_1(gr1,240)=gr30
   55| 00012C std      F88100F8   1     ST8       d1(gr1,248)=gr4
   58| 000130 cmpdi    2C200000   1     C8        cr0=gr0,0
   44| 000134 lfs      C3830058   1     LFS       fp28=+CONSTANT_AREA(gr3,88)
   45| 000138 lfs      C363005C   1     LFS       fp27=+CONSTANT_AREA(gr3,92)
   53| 00013C lfs      C283006C   1     LFS       fp20=+CONSTANT_AREA(gr3,108)
   55| 000140 lfs      C2430070   1     LFS       fp18=+CONSTANT_AREA(gr3,112)
   58| 000144 bc       408202C4   1     BF        CL.1,cr0,0x4/eq,taken=60%(60,40)
    0| 000148 std      FBC10260   1     ST8       <a1:d608:l8>(gr1,608)=gr30
    0| 00014C addi     38C30014   1     AI        gr6=gr3,20
    0| 000150 addi     38E30018   1     AI        gr7=gr3,24
    0| 000154 std      F8C10158   1     ST8       <a1:d344:l8>(gr1,344)=gr6
    0| 000158 std      F8E10188   1     ST8       <a1:d392:l8>(gr1,392)=gr7
    0| 00015C addi     38C100A0   1     AI        gr6=gr1,160
    0| 000160 addi     38E3001C   1     AI        gr7=gr3,28
    0| 000164 std      F8C10168   1     ST8       <a1:d360:l8>(gr1,360)=gr6
    0| 000168 std      F8E101B8   1     ST8       <a1:d440:l8>(gr1,440)=gr7
    0| 00016C addi     38C100A8   1     AI        gr6=gr1,168
    0| 000170 addi     38E00002   1     LI        gr7=2
    0| 000174 std      F8C10198   1     ST8       <a1:d408:l8>(gr1,408)=gr6
    0| 000178 std      F8E101C0   1     ST8       <a1:d448:l8>(gr1,448)=gr7
    0| 00017C std      F8E101F0   1     ST8       <a1:d496:l8>(gr1,496)=gr7
    0| 000180 std      F8E10220   1     ST8       <a1:d544:l8>(gr1,544)=gr7
    0| 000184 std      F8E10250   1     ST8       <a1:d592:l8>(gr1,592)=gr7
    0| 000188 addi     38C100C0   1     AI        gr6=gr1,192
    0| 00018C addi     38E100B8   1     AI        gr7=gr1,184
    0| 000190 std      F8C101C8   1     ST8       <a1:d456:l8>(gr1,456)=gr6
    0| 000194 std      F8E101F8   1     ST8       <a1:d504:l8>(gr1,504)=gr7
    0| 000198 addi     38C100F8   1     AI        gr6=gr1,248
    0| 00019C addi     38000004   1     LI        gr0=4
    0| 0001A0 std      F8C10258   1     ST8       <a1:d600:l8>(gr1,600)=gr6
    0| 0001A4 std      F8010140   1     ST8       <a1:d320:l8>(gr1,320)=gr0
    0| 0001A8 std      F8010170   1     ST8       <a1:d368:l8>(gr1,368)=gr0
    0| 0001AC std      F80101A0   1     ST8       <a1:d416:l8>(gr1,416)=gr0
    0| 0001B0 std      F80101D0   1     ST8       <a1:d464:l8>(gr1,464)=gr0
    0| 0001B4 std      F8010200   1     ST8       <a1:d512:l8>(gr1,512)=gr0
    0| 0001B8 std      F8010230   1     ST8       <a1:d560:l8>(gr1,560)=gr0
    0| 0001BC std      F8010268   1     ST8       <a1:d616:l8>(gr1,616)=gr0
    0| 0001C0 std      F8010270   1     ST8       <a1:d624:l8>(gr1,624)=gr0
    0| 0001C4 addi     38C3001E   1     AI        gr6=gr3,30
    0| 0001C8 addi     38800008   1     LI        gr4=8
    0| 0001CC std      F8C101E8   1     ST8       <a1:d488:l8>(gr1,488)=gr6
    0| 0001D0 std      F8810148   1     ST8       <a1:d328:l8>(gr1,328)=gr4
    0| 0001D4 std      F8810150   1     ST8       <a1:d336:l8>(gr1,336)=gr4
    0| 0001D8 std      F8810178   1     ST8       <a1:d376:l8>(gr1,376)=gr4
    0| 0001DC std      F8810180   1     ST8       <a1:d384:l8>(gr1,384)=gr4
    0| 0001E0 std      F88101A8   1     ST8       <a1:d424:l8>(gr1,424)=gr4
    0| 0001E4 std      F88101B0   1     ST8       <a1:d432:l8>(gr1,432)=gr4
    0| 0001E8 std      F88101D8   1     ST8       <a1:d472:l8>(gr1,472)=gr4
    0| 0001EC std      F88101E0   1     ST8       <a1:d480:l8>(gr1,480)=gr4
    0| 0001F0 std      F8810208   1     ST8       <a1:d520:l8>(gr1,520)=gr4
    0| 0001F4 std      F8810210   1     ST8       <a1:d528:l8>(gr1,528)=gr4
    0| 0001F8 std      F8810238   1     ST8       <a1:d568:l8>(gr1,568)=gr4
    0| 0001FC addi     38A00003   1     LI        gr5=3
    0| 000200 std      F8810240   1     ST8       <a1:d576:l8>(gr1,576)=gr4
    0| 000204 addi     39030020   1     AI        gr8=gr3,32
    0| 000208 std      F8A10160   1     ST8       <a1:d352:l8>(gr1,352)=gr5
    0| 00020C std      F9010218   1     ST8       <a1:d536:l8>(gr1,536)=gr8
    0| 000210 addi     38C10100   1     AI        gr6=gr1,256
    0| 000214 addi     38E30022   1     AI        gr7=gr3,34
    0| 000218 std      F8A10190   1     ST8       <a1:d400:l8>(gr1,400)=gr5
    0| 00021C std      F8C10228   1     ST8       <a1:d552:l8>(gr1,552)=gr6
    0| 000220 std      F8E10248   1     ST8       <a1:d584:l8>(gr1,584)=gr7
    0| 000224 addi     38C30024   1     AI        gr6=gr3,36
    0| 000228 std      F8A102B0   1     ST8       <a1:d688:l8>(gr1,688)=gr5
    0| 00022C std      F8010310   1     ST8       <a1:d784:l8>(gr1,784)=gr0
    0| 000230 std      F8010320   1     ST8       <a1:d800:l8>(gr1,800)=gr0
    0| 000234 std      F8810328   1     ST8       <a1:d808:l8>(gr1,808)=gr4
    0| 000238 std      F8810330   1     ST8       <a1:d816:l8>(gr1,816)=gr4
    0| 00023C std      F8010340   1     ST8       <a1:d832:l8>(gr1,832)=gr0
    0| 000240 std      F8010350   1     ST8       <a1:d848:l8>(gr1,848)=gr0
    0| 000244 std      F8810358   1     ST8       <a1:d856:l8>(gr1,856)=gr4
    0| 000248 std      F8810360   1     ST8       <a1:d864:l8>(gr1,864)=gr4
    0| 00024C std      F8010370   1     ST8       <a1:d880:l8>(gr1,880)=gr0
    0| 000250 addi     3B6100E8   1     AI        gr27=gr1,232
    0| 000254 std      F8C10278   1     ST8       <a1:d632:l8>(gr1,632)=gr6
    0| 000258 std      F8010380   1     ST8       <a1:d896:l8>(gr1,896)=gr0
    0| 00025C std      F8810388   1     ST8       <a1:d904:l8>(gr1,904)=gr4
    0| 000260 addi     38A100F0   1     AI        gr5=gr1,240
    0| 000264 std      F8810390   1     ST8       <a1:d912:l8>(gr1,912)=gr4
    0| 000268 addi     39400007   1     LI        gr10=7
    0| 00026C std      F8A103D8   1     ST8       <a1:d984:l8>(gr1,984)=gr5
   59| 000270 ld       EB820000   1     L8        gr28=.$STATIC(gr2,0)
    0| 000274 std      F9410280   1     ST8       <a1:d640:l8>(gr1,640)=gr10
    0| 000278 addi     38A30044   1     AI        gr5=gr3,68
    0| 00027C std      FB610378   1     ST8       <a1:d888:l8>(gr1,888)=gr27
    0| 000280 addi     39610080   1     AI        gr11=gr1,128
    0| 000284 addi     39830040   1     AI        gr12=gr3,64
    0| 000288 std      F80103A0   1     ST8       <a1:d928:l8>(gr1,928)=gr0
    0| 00028C std      F9810398   1     ST8       <a1:d920:l8>(gr1,920)=gr12
    0| 000290 addi     38E0000E   1     LI        gr7=14
    0| 000294 addi     39430010   1     AI        gr10=gr3,16
    0| 000298 std      F9610288   1     ST8       <a1:d648:l8>(gr1,648)=gr11
    0| 00029C std      F9410128   1     ST8       <a1:d296:l8>(gr1,296)=gr10
    0| 0002A0 addi     390100D8   1     AI        gr8=gr1,216
    0| 0002A4 addi     39200081   1     LI        gr9=129
    0| 0002A8 std      F8A103C8   1     ST8       <a1:d968:l8>(gr1,968)=gr5
    0| 0002AC std      F8E10138   1     ST8       <a1:d312:l8>(gr1,312)=gr7
    0| 0002B0 addi     38A3002C   1     AI        gr5=gr3,44
    0| 0002B4 std      F90103A8   1     ST8       <a1:d936:l8>(gr1,936)=gr8
    0| 0002B8 addi     38C100B0   1     AI        gr6=gr1,176
    0| 0002BC stw      91210120   1     ST4Z      <a1:d288:l4>(gr1,288)=gr9
    0| 0002C0 addi     38E30030   1     AI        gr7=gr3,48
    0| 0002C4 std      F8A102A8   1     ST8       <a1:d680:l8>(gr1,680)=gr5
    0| 0002C8 addi     390100C8   1     AI        gr8=gr1,200
    0| 0002CC std      F8C102B8   1     ST8       <a1:d696:l8>(gr1,696)=gr6
    0| 0002D0 addi     39230034   1     AI        gr9=gr3,52
    0| 0002D4 std      F8E102D8   1     ST8       <a1:d728:l8>(gr1,728)=gr7
    0| 0002D8 addi     394100D0   1     AI        gr10=gr1,208
    0| 0002DC std      F90102E8   1     ST8       <a1:d744:l8>(gr1,744)=gr8
    0| 0002E0 addi     39630038   1     AI        gr11=gr3,56
    0| 0002E4 std      F9210308   1     ST8       <a1:d776:l8>(gr1,776)=gr9
    0| 0002E8 addi     398100E0   1     AI        gr12=gr1,224
    0| 0002EC std      F9410318   1     ST8       <a1:d792:l8>(gr1,792)=gr10
    0| 0002F0 addi     3863003C   1     AI        gr3=gr3,60
    0| 0002F4 std      F8010290   1     ST8       <a1:d656:l8>(gr1,656)=gr0
    0| 0002F8 std      F8810298   1     ST8       <a1:d664:l8>(gr1,664)=gr4
   59| 0002FC ori      63DD8000   1     OIL       gr29=gr30,0x8000
    0| 000300 std      F88102A0   1     ST8       <a1:d672:l8>(gr1,672)=gr4
    0| 000304 std      F80102C0   1     ST8       <a1:d704:l8>(gr1,704)=gr0
    0| 000308 std      F88102C8   1     ST8       <a1:d712:l8>(gr1,712)=gr4
    0| 00030C std      F88102D0   1     ST8       <a1:d720:l8>(gr1,720)=gr4
    0| 000310 std      F80102E0   1     ST8       <a1:d736:l8>(gr1,736)=gr0
    0| 000314 std      F80102F0   1     ST8       <a1:d752:l8>(gr1,752)=gr0
    0| 000318 std      F88102F8   1     ST8       <a1:d760:l8>(gr1,760)=gr4
    0| 00031C std      F8810300   1     ST8       <a1:d768:l8>(gr1,768)=gr4
   59| 000320 stw      93C10124   1     ST4Z      <a1:d292:l4>(gr1,292)=gr30
    0| 000324 std      F80103D0   1     ST8       <a1:d976:l8>(gr1,976)=gr0
    0| 000328 std      F80103B0   1     ST8       <a1:d944:l8>(gr1,944)=gr0
    0| 00032C std      F88103B8   1     ST8       <a1:d952:l8>(gr1,952)=gr4
    0| 000330 std      F88103C0   1     ST8       <a1:d960:l8>(gr1,960)=gr4
    0| 000334 std      F8010130   1     ST8       <a1:d304:l8>(gr1,304)=gr0
    0| 000338 std      F9610338   1     ST8       <a1:d824:l8>(gr1,824)=gr11
    0| 00033C std      F9810348   1     ST8       <a1:d840:l8>(gr1,840)=gr12
    0| 000340 std      F8610368   1     ST8       <a1:d872:l8>(gr1,872)=gr3
   59| 000344 addi     38600001   1     LI        gr3=1
   59| 000348 addi     38800002   1     LI        gr4=2
   59| 00034C or       7F85E378   1     LR        gr5=gr28
   59| 000350 or       7FA6EB78   1     LR        gr6=gr29
   59| 000354 addi     38E00000   1     LI        gr7=0
   59| 000358 addi     39000000   1     LI        gr8=0
   59| 00035C addi     39210120   1     AI        gr9=gr1,288
   59| 000360 bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#1",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,|pgen,gr9,#def_xlfBeginIO11",_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   59| 000364 ori      60000000   1
   59| 000368 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   59| 00036C ori      60000000   1
   60| 000370 addi     38BC0040   1     AI        gr5=gr28,64
   60| 000374 addi     38600002   1     LI        gr3=2
   60| 000378 addi     38800102   1     LI        gr4=258
   60| 00037C or       7FA6EB78   1     LR        gr6=gr29
   60| 000380 addi     38E00000   1     LI        gr7=0
   60| 000384 addi     39000000   1     LI        gr8=0
   60| 000388 addi     39210120   1     AI        gr9=gr1,288
   60| 00038C bl       48000001   1     CALL      gr3=_xlfBeginIO,7,gr3,gr4,#3",gr5,gr6,@PALI_SHADOW_CONST.rns0.,gr7,gr8,|pgen,gr9,#use_xlfBeginIO21,_xlfBeginIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   60| 000390 ori      60000000   1
   60| 000394 bl       48000001   1     CALL      gr3=_xlfEndIO,1,gr3,_xlfEndIO",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr4"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   60| 000398 ori      60000000   1
   61| 00039C lfd      CB8100A0   1     LFL       fp28=x10(gr1,160)
   62| 0003A0 lfd      CB6100A8   1     LFL       fp27=x20(gr1,168)
   63| 0003A4 lfd      CB2100B8   1     LFL       fp25=d0(gr1,184)
   64| 0003A8 lfd      CB0100C0   1     LFL       fp24=p0(gr1,192)
   65| 0003AC lfd      CA4100F8   1     LFL       fp18=d1(gr1,248)
   66| 0003B0 lfd      CBE10100   1     LFL       fp31=p1(gr1,256)
   61| 0003B4 stfd     DB9F06D0   1     STFL      <s134:d1744:l8>(gr31,1744)=fp28
   62| 0003B8 stfd     DB7F06D8   1     STFL      <s134:d1752:l8>(gr31,1752)=fp27
   63| 0003BC stfd     DB3F06E0   1     STFL      <s134:d1760:l8>(gr31,1760)=fp25
   64| 0003C0 stfd     DB1F06E8   1     STFL      <s134:d1768:l8>(gr31,1768)=fp24
   65| 0003C4 stfd     DA5F06F0   1     STFL      <s134:d1776:l8>(gr31,1776)=fp18
   66| 0003C8 stfd     DBFF06F8   1     STFL      <s134:d1784:l8>(gr31,1784)=fp31
   67| 0003CC lfd      CBC100C8   1     LFL       fp30=b1_0(gr1,200)
   68| 0003D0 lfd      CBA100E0   1     LFL       fp29=b1_1(gr1,224)
   69| 0003D4 lfd      CAE100D0   1     LFL       fp23=b2_0(gr1,208)
   70| 0003D8 lfd      CA8100E8   1     LFL       fp20=b2_1(gr1,232)
   71| 0003DC lfd      CAA100D8   1     LFL       fp21=b3_0(gr1,216)
   72| 0003E0 lfd      CA6100F0   1     LFL       fp19=b3_1(gr1,240)
   73| 0003E4 lwa      EB410082   1     L4A       gr26=idirect(gr1,128)
   67| 0003E8 stfd     DBDF0700   1     STFL      <s134:d1792:l8>(gr31,1792)=fp30
   68| 0003EC stfd     DBBF0708   1     STFL      <s134:d1800:l8>(gr31,1800)=fp29
   69| 0003F0 stfd     DAFF0710   1     STFL      <s134:d1808:l8>(gr31,1808)=fp23
   70| 0003F4 stfd     DA9F0718   1     STFL      <s134:d1816:l8>(gr31,1816)=fp20
   73| 0003F8 std      FB410458   1     ST8       #SPILL0(gr1,1112)=gr26
   71| 0003FC stfd     DABF0720   1     STFL      <s134:d1824:l8>(gr31,1824)=fp21
   72| 000400 stfd     DA7F0728   1     STFL      <s134:d1832:l8>(gr31,1832)=fp19
   73| 000404 stw      935F0090   1     ST4Z      <s134:d144:l4>(gr31,144)=gr26
   74|                              CL.1:
   75| 000408 addis    3FA04C00   1     LIU       gr29=19456
   75| 00040C addi     3800000C   1     LI        gr0=12
   75| 000410 addi     387D081F   1     AI        gr3=gr29,2079
   75| 000414 stw      93C1008C   1     ST4Z      T_4(gr1,140)=gr30
   75| 000418 stw      90610088   1     ST4Z      T_3(gr1,136)=gr3
   75| 00041C addi     387F06D0   1     AI        gr3=gr31,1744
   75| 000420 stw      90010084   1     ST4Z      T_2(gr1,132)=gr0
   75| 000424 addi     38C1008C   1     AI        gr6=gr1,140
   75| 000428 addi     38A10088   1     AI        gr5=gr1,136
   75| 00042C addi     38810084   1     AI        gr4=gr1,132
   75| 000430 addi     38FF0020   1     AI        gr7=gr31,32
   75| 000434 addi     391F0014   1     AI        gr8=gr31,20
   75| 000438 bl       48000001   1     CALL      mpi_bcast,6,buf_in[]",gr3,T_2",gr4,T_3",gr5,T_4",gr6,comm3d",gr7,ierr",gr8,#ProcAlias",mpi_bcast",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   75| 00043C ori      60000000   1
   77| 000440 addi     38000001   1     LI        gr0=1
   77| 000444 addi     387D041B   1     AI        gr3=gr29,1051
   77| 000448 stw      90010090   1     ST4Z      T_5(gr1,144)=gr0
   77| 00044C stw      90610094   1     ST4Z      T_6(gr1,148)=gr3
   77| 000450 stw      93C10098   1     ST4Z      T_7(gr1,152)=gr30
   77| 000454 addi     38C10098   1     AI        gr6=gr1,152
   77| 000458 addi     38A10094   1     AI        gr5=gr1,148
   77| 00045C addi     38810090   1     AI        gr4=gr1,144
   77| 000460 addi     387F0090   1     AI        gr3=gr31,144
   77| 000464 addi     38FF0020   1     AI        gr7=gr31,32
   77| 000468 addi     391F0014   1     AI        gr8=gr31,20
   77| 00046C bl       48000001   1     CALL      mpi_bcast,6,ibuf_in[]",gr3,T_5",gr4,T_6",gr5,T_7",gr6,comm3d",gr7,ierr",gr8,#ProcAlias",mpi_bcast",fcr",#MX_TEMP1",gr1,cr[01567]",gr0",gr3"-gr12",fp0"-fp13",mq",lr",xer",fsr",ca",ctr"
   77| 000470 ori      60000000   1
   79| 000474 lwz      801F0004   1     L4Z       gr0=<s134:d4:l4>(gr31,4)
   79| 000478 cmpdi    2C200000   1     C8        cr0=gr0,0
   79| 00047C bc       4182003C   1     BT        CL.2,cr0,0x4/eq,taken=50%(0,0)
   92| 000480 lwa      E81F0092   1     L4A       gr0=<s134:d144:l4>(gr31,144)
   80| 000484 lfd      CB9F06D0   1     LFL       fp28=<s134:d1744:l8>(gr31,1744)
   81| 000488 lfd      CB7F06D8   1     LFL       fp27=<s134:d1752:l8>(gr31,1752)
   82| 00048C lfd      CB3F06E0   1     LFL       fp25=<s134:d1760:l8>(gr31,1760)
   83| 000490 lfd      CB1F06E8   1     LFL       fp24=<s134:d1768:l8>(gr31,1768)
   84| 000494 lfd      CA5F06F0   1     LFL       fp18=<s134:d1776:l8>(gr31,1776)
   85| 000498 lfd      CBFF06F8   1     LFL       fp31=<s134:d1784:l8>(gr31,1784)
   86| 00049C lfd      CBDF0700   1     LFL       fp30=<s134:d1792:l8>(gr31,1792)
   92| 0004A0 std      F8010458   1     ST8       #SPILL0(gr1,1112)=gr0
   87| 0004A4 lfd      CBBF0708   1     LFL       fp29=<s134:d1800:l8>(gr31,1800)
   88| 0004A8 lfd      CAFF0710   1     LFL       fp23=<s134:d1808:l8>(gr31,1808)
   89| 0004AC lfd      CA9F0718   1     LFL       fp20=<s134:d1816:l8>(gr31,1816)
   90| 0004B0 lfd      CABF0720   1     LFL       fp21=<s134:d1824:l8>(gr31,1824)
   91| 0004B4 lfd      CA7F0728   1     LFL       fp19=<s134:d1832:l8>(gr31,1832)
   93|                              CL.2:
   97| 0004B8 ld       E8620000   1     L8        gr3=.&&N&&root(gr2,0)
  100| 0004BC ld       E8A20000   1     L8        gr5=.&&N&&param(gr2,0)
   97| 0004C0 lfd      C84300E8   1     LFL       fp2=<s161:d232:l8>(gr3,232)
  100| 0004C4 lwa      E8C5000A   1     L4A       gr6=<s166:d8:l4>(gr5,8)
   97| 0004C8 qvfre    10001030   1     QVFRE     fp0=fp2
  100| 0004CC sradi    7CC00E74   1     SRA8CA    gr0,ca=gr6,1
  100| 0004D0 cmpwi    2F060000   1     C4        cr6=gr6,0
  100| 0004D4 addze    7C000194   1     ADDE      gr0,ca=gr0,0,ca
  100| 0004D8 std      F8C10460   1     ST8       #SPILL1(gr1,1120)=gr6
  100| 0004DC rldicr   78030FA4   1     SLL8      gr3=gr0,1
   97| 0004E0 fmsub    FC22D038   1     FMS       fp1=fp26,fp2,fp0,fcr
  100| 0004E4 subf     7C833051   1     S_R       gr4,cr0=gr6,gr3
  100| 0004E8 crand    4C390A02   1     CR_N      cr0=cr[60],0x2/gt,0x2/gt,0x2/gt,cr0
   97| 0004EC fnmsub   FC00007C   1     FNMS      fp0=fp0,fp0,fp1,fcr
   97| 0004F0 fmsub    FC22D038   2     FMS       fp1=fp26,fp2,fp0,fcr
   97| 0004F4 fnmsub   FC00007C   2     FNMS      fp0=fp0,fp0,fp1,fcr
   97| 0004F8 fmul     FC380032   2     MFL       fp1=fp24,fp0,fcr
   98| 0004FC fmul     FC7F0032   2     MFL       fp3=fp31,fp0,fcr
   97| 000500 fmsub    FC82C078   2     FMS       fp4=fp24,fp2,fp1,fcr
   98| 000504 fmsub    FC42F8F8   2     FMS       fp2=fp31,fp2,fp3,fcr
   97| 000508 fnmsub   FC20093C   2     FNMS      fp1=fp1,fp0,fp4,fcr
   98| 00050C fnmsub   FC0018BC   2     FNMS      fp0=fp3,fp0,fp2,fcr
  100| 000510 bc       408100EC   1     BF        CL.71,cr0,0x2/gt,taken=50%(0,0)
  103| 000514 ld       E9020000   1     L8        gr8=.&&N&field(gr2,0)
  101| 000518 lwa      E8050006   1     L4A       gr0=<s166:d4:l4>(gr5,4)
  102| 00051C lwa      EBE50002   1     L4A       gr31=<s166:d0:l4>(gr5,0)
  100| 000520 addi     38A00000   1     LI        gr5=0
  103| 000524 ld       E92801A0   1     L8        gr9=<s32:d416:l8>(gr8,416)
  104| 000528 ld       E9480208   1     L8        gr10=<s32:d520:l8>(gr8,520)
  105| 00052C ld       E9680270   1     L8        gr11=<s32:d624:l8>(gr8,624)
  103| 000530 ld       E98801B8   1     L8        gr12=<s32:d440:l8>(gr8,440)
  104| 000534 ld       EB080220   1     L8        gr24=<s32:d544:l8>(gr8,544)
  105| 000538 ld       EB280288   1     L8        gr25=<s32:d648:l8>(gr8,648)
  103| 00053C ld       EBC801E8   1     L8        gr30=<s32:d488:l8>(gr8,488)
  104| 000540 ld       EBA80250   1     L8        gr29=<s32:d592:l8>(gr8,592)
  105| 000544 ld       EB8802B8   1     L8        gr28=<s32:d696:l8>(gr8,696)
    0| 000548 cmpwi    2C800000   1     C4        cr1=gr0,0
  103| 00054C ld       EB6801D0   1     L8        gr27=<s32:d464:l8>(gr8,464)
  104| 000550 ld       EB480238   1     L8        gr26=<s32:d568:l8>(gr8,568)
  105| 000554 ld       EA6802A0   1     L8        gr19=<s32:d672:l8>(gr8,672)
  103| 000558 ld       E8C80200   1     L8        gr6=<s32:d512:l8>(gr8,512)
  104| 00055C ld       E8E80268   1     L8        gr7=<s32:d616:l8>(gr8,616)
  105| 000560 ld       E90802D0   1     L8        gr8=<s32:d720:l8>(gr8,720)
    0| 000564 bc       40850880   1     BF        CL.173,cr1,0x2/gt,taken=40%(40,60)
    0| 000568 add      7D6BCA14   1     A         gr11=gr11,gr25
    0| 00056C add      7D4AC214   1     A         gr10=gr10,gr24
    0| 000570 add      7D296214   1     A         gr9=gr9,gr12
    0| 000574 add      7D6BE214   1     A         gr11=gr11,gr28
    0| 000578 add      7D4AEA14   1     A         gr10=gr10,gr29
    0| 00057C add      7D29F214   1     A         gr9=gr9,gr30
    0| 000580 add      7F2B9A14   1     A         gr25=gr11,gr19
    0| 000584 add      7F0AD214   1     A         gr24=gr10,gr26
    0| 000588 add      7EE9DA14   1     A         gr23=gr9,gr27
    0| 00058C cmpdi    2C3F0000   1     C8        cr0=gr31,0
  100|                              CL.66:
  101| 000590 addi     39200000   1     LI        gr9=0
    0| 000594 bc       40810050   1     BF        CL.70,cr0,0x2/gt,taken=50%(0,0)
    0| 000598 or       7EF6BB78   1     LR        gr22=gr23
    0| 00059C or       7F15C378   1     LR        gr21=gr24
    0| 0005A0 or       7F34CB78   1     LR        gr20=gr25
  101|                              CL.67:
    0| 0005A4 addi     39290001   1     AI        gr9=gr9,1
  105| 0005A8 or       7E8AA378   1     LR        gr10=gr20
  104| 0005AC or       7EABAB78   1     LR        gr11=gr21
  103| 0005B0 or       7ECCB378   1     LR        gr12=gr22
    0| 0005B4 mtspr    7FE903A6   1     LCTR      ctr=gr31
    0| 0005B8 ori      60210000   1     XNOP      
    0| 0005BC ori      60210000   1     XNOP      
    0|                              CL.269:
  103| 0005C0 stfdux   7ECC35EE   1     STFDU     gr12,v1(gr12,gr6,0)=fp22
  104| 0005C4 stfdux   7ECB3DEE   1     STFDU     gr11,v2(gr11,gr7,0)=fp22
  105| 0005C8 stfdux   7ECA45EE   1     STFDU     gr10,v3(gr10,gr8,0)=fp22
    0| 0005CC bc       4200FFF4   1     BCT       ctr=CL.269,taken=100%(100,0)
  107| 0005D0 cmpld    7CA90040   1     CL8       cr1=gr9,gr0
    0| 0005D4 add      7ED6F214   1     A         gr22=gr22,gr30
    0| 0005D8 add      7EB5EA14   1     A         gr21=gr21,gr29
    0| 0005DC add      7E94E214   1     A         gr20=gr20,gr28
  107| 0005E0 bc       4184FFC4   1     BT        CL.67,cr1,0x8/llt,taken=80%(80,20)
  107|                              CL.70:
  108| 0005E4 addi     38A50001   1     AI        gr5=gr5,1
    0| 0005E8 add      7EF7DA14   1     A         gr23=gr23,gr27
  108| 0005EC cmpd     7CA42800   1     C8        cr1=gr4,gr5
    0| 0005F0 add      7F18D214   1     A         gr24=gr24,gr26
    0| 0005F4 add      7F33CA14   1     A         gr25=gr19,gr25
  108| 0005F8 bc       4185FF98   1     BT        CL.66,cr1,0x2/gt,taken=80%(80,20)
  108|                              CL.71:
  100| 0005FC ld       E8010460   1     L8        gr0=#SPILL1(gr1,1120)
  100| 000600 cmpd     7CA02000   1     C8        cr1=gr0,gr4
  100| 000604 crand    4C392A02   1     CR_N      cr0=cr[61],0x2/gt,0x2/gt,0x2/gt,cr0
  100| 000608 bc       40810188   1     BF        CL.36,cr0,0x2/gt,taken=50%(0,0)
  103| 00060C ld       E8C20000   1     L8        gr6=.&&N&field(gr2,0)
  101| 000610 ld       EAE20000   1     L8        gr23=.&&N&&param(gr2,0)
  108| 000614 addi     3863FFFF   1     AI        gr3=gr3,-1
  108| 000618 sradi    7C670E74   1     SRA8CA    gr7,ca=gr3,1
  100| 00061C addi     38600000   1     LI        gr3=0
  103| 000620 ld       E8A601D0   1     L8        gr5=<s32:d464:l8>(gr6,464)
  104| 000624 ld       E9260238   1     L8        gr9=<s32:d568:l8>(gr6,568)
  105| 000628 ld       E98602A0   1     L8        gr12=<s32:d672:l8>(gr6,672)
  103| 00062C ld       EB4601A0   1     L8        gr26=<s32:d416:l8>(gr6,416)
  104| 000630 ld       E9660208   1     L8        gr11=<s32:d520:l8>(gr6,520)
  105| 000634 ld       E9060270   1     L8        gr8=<s32:d624:l8>(gr6,624)
  103| 000638 ld       EB2601B8   1     L8        gr25=<s32:d440:l8>(gr6,440)
  104| 00063C ld       EBE60220   1     L8        gr31=<s32:d544:l8>(gr6,544)
  105| 000640 ld       E9460288   1     L8        gr10=<s32:d648:l8>(gr6,648)
  103| 000644 ld       EBA601E8   1     L8        gr29=<s32:d488:l8>(gr6,488)
  104| 000648 ld       EB860250   1     L8        gr28=<s32:d592:l8>(gr6,592)
  105| 00064C ld       EB6602B8   1     L8        gr27=<s32:d696:l8>(gr6,696)
  101| 000650 lwa      E8170006   1     L4A       gr0=<s166:d4:l4>(gr23,4)
    0| 000654 add      7F39D214   1     A         gr25=gr25,gr26
    0| 000658 add      7D6BFA14   1     A         gr11=gr11,gr31
    0| 00065C add      7F485214   1     A         gr26=gr8,gr10
    0| 000660 mulld    7D0429D2   1     M         gr8=gr4,gr5
    0| 000664 mulld    7FE461D2   1     M         gr31=gr4,gr12
    0| 000668 mulld    7D4449D2   1     M         gr10=gr4,gr9
    0| 00066C rldicr   79960FA4   1     SLL8      gr22=gr12,1
    0| 000670 add      7F1ADA14   1     A         gr24=gr26,gr27
    0| 000674 std      FAC10468   1     ST8       #SPILL2(gr1,1128)=gr22
    0| 000678 rldicr   79350FA4   1     SLL8      gr21=gr9,1
    0| 00067C add      7D6BE214   1     A         gr11=gr11,gr28
    0| 000680 rldicr   78BA0FA4   1     SLL8      gr26=gr5,1
    0| 000684 add      7C99EA14   1     A         gr4=gr25,gr29
  108| 000688 addze    7CE70194   1     ADDE      gr7,ca=gr7,0,ca
    0| 00068C cmpwi    2C000000   1     C4        cr0=gr0,0
    0| 000690 add      7F36C214   1     A         gr25=gr22,gr24
    0| 000694 std      FAA10470   1     ST8       #SPILL3(gr1,1136)=gr21
  102| 000698 lwa      EBD70002   1     L4A       gr30=<s166:d0:l4>(gr23,0)
    0| 00069C add      7F0CC214   1     A         gr24=gr12,gr24
    0| 0006A0 add      7EEBAA14   1     A         gr23=gr11,gr21
    0| 0006A4 add      7D895A14   1     A         gr12=gr9,gr11
    0| 0006A8 add      7D64D214   1     A         gr11=gr4,gr26
    0| 0006AC add      7D242A14   1     A         gr9=gr4,gr5
  103| 0006B0 ld       E8860200   1     L8        gr4=<s32:d512:l8>(gr6,512)
  104| 0006B4 ld       E8A60268   1     L8        gr5=<s32:d616:l8>(gr6,616)
  105| 0006B8 ld       E8C602D0   1     L8        gr6=<s32:d720:l8>(gr6,720)
    0| 0006BC bc       408100D4   1     BF        CL.36,cr0,0x2/gt,taken=20%(20,80)
    0| 0006C0 add      7EA85A14   1     A         gr21=gr8,gr11
    0| 0006C4 add      7E884A14   1     A         gr20=gr8,gr9
    0| 0006C8 addi     39070001   1     AI        gr8=gr7,1
    0| 0006CC add      7F39FA14   1     A         gr25=gr25,gr31
    0| 0006D0 std      F9010478   1     ST8       #SPILL4(gr1,1144)=gr8
    0| 0006D4 add      7F18FA14   1     A         gr24=gr24,gr31
    0| 0006D8 add      7EEABA14   1     A         gr23=gr10,gr23
    0| 0006DC add      7ECA6214   1     A         gr22=gr10,gr12
    0| 0006E0 cmpdi    2C3E0000   1     C8        cr0=gr30,0
  100|                              CL.37:
  101| 0006E4 addi     38E00000   1     LI        gr7=0
    0| 0006E8 bc       40810078   1     BF        CL.38,cr0,0x2/gt,taken=20%(20,80)
    0| 0006EC or       7E93A378   1     LR        gr19=gr20
    0| 0006F0 or       7EB2AB78   1     LR        gr18=gr21
    0| 0006F4 or       7ED1B378   1     LR        gr17=gr22
    0| 0006F8 or       7EF0BB78   1     LR        gr16=gr23
    0| 0006FC or       7F0FC378   1     LR        gr15=gr24
    0| 000700 or       7F2ECB78   1     LR        gr14=gr25
  101|                              CL.39:
    0| 000704 addi     38E70001   1     AI        gr7=gr7,1
  105| 000708 or       7DC87378   1     LR        gr8=gr14
  105| 00070C or       7DE97B78   1     LR        gr9=gr15
  104| 000710 or       7E0A8378   1     LR        gr10=gr16
  104| 000714 or       7E2B8B78   1     LR        gr11=gr17
  103| 000718 or       7E4C9378   1     LR        gr12=gr18
  103| 00071C or       7E7F9B78   1     LR        gr31=gr19
    0| 000720 mtspr    7FC903A6   1     LCTR      ctr=gr30
    0|                              CL.270:
  103| 000724 stfdux   7EDF25EE   1     STFDU     gr31,v1(gr31,gr4,0)=fp22
  103| 000728 stfdux   7ECC25EE   1     STFDU     gr12,v1(gr12,gr4,0)=fp22
  104| 00072C stfdux   7ECB2DEE   1     STFDU     gr11,v2(gr11,gr5,0)=fp22
  104| 000730 stfdux   7ECA2DEE   1     STFDU     gr10,v2(gr10,gr5,0)=fp22
  105| 000734 stfdux   7EC935EE   1     STFDU     gr9,v3(gr9,gr6,0)=fp22
  105| 000738 stfdux   7EC835EE   1     STFDU     gr8,v3(gr8,gr6,0)=fp22
    0| 00073C bc       4200FFE8   1     BCT       ctr=CL.270,taken=100%(100,0)
  107| 000740 cmpld    7CA70040   1     CL8       cr1=gr7,gr0
    0| 000744 add      7E73EA14   1     A         gr19=gr19,gr29
    0| 000748 add      7E52EA14   1     A         gr18=gr18,gr29
    0| 00074C add      7E31E214   1     A         gr17=gr17,gr28
    0| 000750 add      7E10E214   1     A         gr16=gr16,gr28
    0| 000754 add      7DEFDA14   1     A         gr15=gr15,gr27
    0| 000758 add      7DCEDA14   1     A         gr14=gr14,gr27
  107| 00075C bc       4184FFA8   1     BT        CL.39,cr1,0x8/llt,taken=80%(80,20)
  107|                              CL.38:
  108| 000760 ld       E9010478   1     L8        gr8=#SPILL4(gr1,1144)
    0| 000764 ld       E8E10468   1     L8        gr7=#SPILL2(gr1,1128)
    0| 000768 ld       E9210470   1     L8        gr9=#SPILL3(gr1,1136)
  108| 00076C addi     38630001   1     AI        gr3=gr3,1
    0| 000770 add      7EB5D214   1     A         gr21=gr21,gr26
    0| 000774 add      7E94D214   1     A         gr20=gr20,gr26
  108| 000778 cmpld    7CA34040   1     CL8       cr1=gr3,gr8
    0| 00077C add      7F27CA14   1     A         gr25=gr7,gr25
    0| 000780 add      7F07C214   1     A         gr24=gr7,gr24
    0| 000784 add      7EE9BA14   1     A         gr23=gr9,gr23
    0| 000788 add      7EC9B214   1     A         gr22=gr9,gr22
  108| 00078C bc       4184FF58   1     BT        CL.37,cr1,0x8/llt,taken=80%(80,20)
  108|                              CL.36:
  110| 000790 bc       409905C4   1     BF        CL.379,cr6,0x2/gt,taken=20%(20,80)
  116| 000794 ld       E8620000   1     L8        gr3=.&&N&field(gr2,0)
  114| 000798 ld       E8820000   1     L8        gr4=.&&N&grid(gr2,0)
  110| 00079C addi     3A600000   1     LI        gr19=0
  111| 0007A0 ld       EA820000   1     L8        gr20=.&&N&&param(gr2,0)
  110| 0007A4 std      FA610480   1     ST8       #SPILL5(gr1,1152)=gr19
  144| 0007A8 lfd      C84100B0   1     LFL       fp2=x30(gr1,176)
  118| 0007AC ld       EA430370   1     L8        gr18=<s32:d880:l8>(gr3,880)
  117| 0007B0 ld       EB230308   1     L8        gr25=<s32:d776:l8>(gr3,776)
  116| 0007B4 ld       E9830000   1     L8        gr12=<s32:d0:l8>(gr3,0)
  116| 0007B8 ld       EBE30018   1     L8        gr31=<s32:d24:l8>(gr3,24)
  118| 0007BC ld       E8C30340   1     L8        gr6=<s32:d832:l8>(gr3,832)
  118| 0007C0 ld       EAC30358   1     L8        gr22=<s32:d856:l8>(gr3,856)
  118| 0007C4 std      FA4104A0   1     ST8       #SPILL9(gr1,1184)=gr18
  117| 0007C8 std      FB210498   1     ST8       #SPILL8(gr1,1176)=gr25
  116| 0007CC ld       EB830030   1     L8        gr28=<s32:d48:l8>(gr3,48)
  144| 0007D0 ld       E9240070   1     L8        gr9=<s106:d112:l8>(gr4,112)
    0| 0007D4 add      7E2CFA14   1     A         gr17=gr12,gr31
  119| 0007D8 ld       E96303A8   1     L8        gr11=<s32:d936:l8>(gr3,936)
  119| 0007DC ld       EAE303C0   1     L8        gr23=<s32:d960:l8>(gr3,960)
  117| 0007E0 ld       E8A302D8   1     L8        gr5=<s32:d728:l8>(gr3,728)
  116| 0007E4 std      FB810490   1     ST8       #SPILL7(gr1,1168)=gr28
    0| 0007E8 ld       E98104A0   1     L8        gr12=#SPILL9(gr1,1184)
  117| 0007EC ld       EAA302F0   1     L8        gr21=<s32:d752:l8>(gr3,752)
    0| 0007F0 add      7CC6B214   1     A         gr6=gr6,gr22
  119| 0007F4 ld       EA0303D8   1     L8        gr16=<s32:d984:l8>(gr3,984)
  115| 0007F8 ld       E9E30098   1     L8        gr15=<s32:d152:l8>(gr3,152)
  115| 0007FC ld       EBA300B0   1     L8        gr29=<s32:d176:l8>(gr3,176)
  115| 000800 ld       E8E30068   1     L8        gr7=<s32:d104:l8>(gr3,104)
  115| 000804 ld       E9430080   1     L8        gr10=<s32:d128:l8>(gr3,128)
  144| 000808 addi     3A690008   1     AI        gr19=gr9,8
    0| 00080C add      7D266214   1     A         gr9=gr6,gr12
    0| 000810 ld       E9810498   1     L8        gr12=#SPILL8(gr1,1176)
  119| 000814 std      FA0104A8   1     ST8       #SPILL10(gr1,1192)=gr16
  115| 000818 ld       EB4300C8   1     L8        gr26=<s32:d200:l8>(gr3,200)
    0| 00081C add      7D6BBA14   1     A         gr11=gr11,gr23
    0| 000820 add      7CA5AA14   1     A         gr5=gr5,gr21
  129| 000824 ld       E9040038   1     L8        gr8=<s106:d56:l8>(gr4,56)
  116| 000828 ld       EB830048   1     L8        gr28=<s32:d72:l8>(gr3,72)
  116| 00082C ld       EB630060   1     L8        gr27=<s32:d96:l8>(gr3,96)
  117| 000830 ld       EB230320   1     L8        gr25=<s32:d800:l8>(gr3,800)
  117| 000834 ld       EB030338   1     L8        gr24=<s32:d824:l8>(gr3,824)
  118| 000838 ld       EAE30388   1     L8        gr23=<s32:d904:l8>(gr3,904)
  118| 00083C ld       EAC303A0   1     L8        gr22=<s32:d928:l8>(gr3,928)
  115| 000840 std      F9E10488   1     ST8       #SPILL6(gr1,1160)=gr15
  111| 000844 lwa      E8140006   1     L4A       gr0=<s166:d4:l4>(gr20,4)
  112| 000848 lwa      EBD40002   1     L4A       gr30=<s166:d0:l4>(gr20,0)
  119| 00084C ld       EAA303F0   1     L8        gr21=<s32:d1008:l8>(gr3,1008)
  119| 000850 ld       EA830408   1     L8        gr20=<s32:d1032:l8>(gr3,1032)
  114| 000854 ld       E9C40000   1     L8        gr14=<s106:d0:l8>(gr4,0)
    0| 000858 add      7E105A14   1     A         gr16=gr16,gr11
  114| 00085C ld       E9640018   1     L8        gr11=<s106:d24:l8>(gr4,24)
  129| 000860 ld       E8640050   1     L8        gr3=<s106:d80:l8>(gr4,80)
  144| 000864 ld       E8840088   1     L8        gr4=<s106:d136:l8>(gr4,136)
    0| 000868 add      7FEFEA14   1     A         gr31=gr15,gr29
    0| 00086C add      7DE75214   1     A         gr15=gr7,gr10
    0| 000870 add      7CE56214   1     A         gr7=gr5,gr12
    0| 000874 ld       E8A10490   1     L8        gr5=#SPILL7(gr1,1168)
    0| 000878 add      7FFAFA14   1     A         gr31=gr26,gr31
  144| 00087C add      7C849A14   1     A         gr4=gr4,gr19
  114| 000880 add      7E6B7214   1     A         gr19=gr11,gr14
    0| 000884 add      7D6FFA14   1     A         gr11=gr15,gr31
    0| 000888 ld       E9E10458   1     L8        gr15=#SPILL0(gr1,1112)
    0| 00088C std      F96104D0   1     ST8       #SPILL15(gr1,1232)=gr11
  129| 000890 addi     3A480008   1     AI        gr18=gr8,8
    0| 000894 add      7D54AA14   1     A         gr10=gr20,gr21
    0| 000898 add      7D16BA14   1     A         gr8=gr22,gr23
    0| 00089C add      7CD8CA14   1     A         gr6=gr24,gr25
    0| 0008A0 add      7D9BE214   1     A         gr12=gr27,gr28
    0| 0008A4 add      7CA58A14   1     A         gr5=gr5,gr17
  129| 0008A8 add      7C639214   1     A         gr3=gr3,gr18
    0| 0008AC add      7E2A8214   1     A         gr17=gr10,gr16
    0| 0008B0 add      7DC84A14   1     A         gr14=gr8,gr9
    0| 0008B4 std      FA2104B0   1     ST8       #SPILL11(gr1,1200)=gr17
    0| 0008B8 std      F9C104B8   1     ST8       #SPILL12(gr1,1208)=gr14
    0| 0008BC add      7E463A14   1     A         gr18=gr6,gr7
    0| 0008C0 add      7E056214   1     A         gr16=gr5,gr12
    0| 0008C4 std      FA4104C0   1     ST8       #SPILL13(gr1,1216)=gr18
    0| 0008C8 std      FA0104C8   1     ST8       #SPILL14(gr1,1224)=gr16
    0| 0008CC cmpwi    2C000000   1     C4        cr0=gr0,0
    0| 0008D0 cmpdi    2CBE0000   1     C8        cr1=gr30,0
    0| 0008D4 cmpwi    2F0F0001   1     C4        cr6=gr15,1
    0| 0008D8 cmpwi    2F8F0002   1     C4        cr7=gr15,2
    0| 0008DC cmpwi    2E8F0003   1     C4        cr5=gr15,3
  110|                              CL.43:
  111| 0008E0 bc       408102A0   1     BF        CL.44,cr0,0x2/gt,taken=20%(20,80)
    0| 0008E4 ld       E8E10480   1     L8        gr7=#SPILL5(gr1,1152)
  111| 0008E8 addi     38A00000   1     LI        gr5=0
    0| 0008EC ld       EA4104D0   1     L8        gr18=#SPILL15(gr1,1232)
    0| 0008F0 ld       EA2104C8   1     L8        gr17=#SPILL14(gr1,1224)
    0| 0008F4 ld       EA0104C0   1     L8        gr16=#SPILL13(gr1,1216)
    0| 0008F8 ld       E9E104B8   1     L8        gr15=#SPILL12(gr1,1208)
    0| 0008FC ld       E9C104B0   1     L8        gr14=#SPILL11(gr1,1200)
    0| 000900 rldicr   78E61F24   1     SLL8      gr6=gr7,3
  111|                              CL.45:
  112| 000904 bc       4085025C   1     BF        CL.46,cr1,0x2/gt,taken=50%(0,0)
    0| 000908 bc       409A0394   1     BF        CL.180,cr6,0x4/eq,taken=50%(0,0)
  114| 00090C or       7E679B78   1     LR        gr7=gr19
    0| 000910 mtspr    7FC903A6   1     LCTR      ctr=gr30
  114| 000914 lfdu     CC670008   1     LFDU      fp3,gr7=x1a(gr7,8)
    0| 000918 rldicr   78A81F24   1     SLL8      gr8=gr5,3
    0| 00091C or       7DC97378   1     LR        gr9=gr14
    0| 000920 or       7DEA7B78   1     LR        gr10=gr15
    0| 000924 or       7E0B8378   1     LR        gr11=gr16
    0| 000928 or       7E2C8B78   1     LR        gr12=gr17
    0| 00092C or       7E5F9378   1     LR        gr31=gr18
  114| 000930 fcmpu    FD03E000   1     CFL       cr2=fp3,fp28
    0| 000934 bc       4240019C   1     BCF       ctr=CL.318,taken=0%(0,100)
  114| 000938 lfdu     CC870008   1     LFDU      fp4,gr7=x1a(gr7,8)
    0| 00093C bc       424000D4   1     BCF       ctr=CL.311,taken=0%(0,100)
    0| 000940 ori      60210000   1     XNOP      
    0| 000944 ori      60210000   1     XNOP      
  112|                              CL.47:
  114| 000948 bc       4189001C   1     BT        CL.19,cr2,0x40/fgt,taken=50%(0,0)
  115| 00094C stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  116| 000950 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  117| 000954 stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  118| 000958 stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  119| 00095C stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
    0| 000960 b        48000018   1     B         CL.18,-1
  120|                              CL.19:
  121| 000964 stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  122| 000968 stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  123| 00096C stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  124| 000970 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  125| 000974 stfd     DA690000   1     STFL      b3(gr9,0)=fp19
  127|                              CL.18:
  114| 000978 fcmpu    FD04E000   1     CFL       cr2=fp4,fp28
  114| 00097C lfdu     CC870008   1     LFDU      fp4,gr7=x1a(gr7,8)
  128| 000980 bc       409E003C   1     BF        CL.21,cr7,0x4/eq,taken=50%(0,0)
  129| 000984 lfdx     7C6344AE   1     LFL       fp3=x2a(gr3,gr8,0)
  129| 000988 fcmpu    FE03D800   1     CFL       cr4=fp3,fp27
  129| 00098C bc       4191001C   1     BT        CL.22,cr4,0x40/fgt,taken=50%(0,0)
  130| 000990 stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  131| 000994 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  132| 000998 stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  133| 00099C stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  134| 0009A0 stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
    0| 0009A4 b        48000018   1     B         CL.21,-1
  135|                              CL.22:
  136| 0009A8 stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  137| 0009AC stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  138| 0009B0 stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  139| 0009B4 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  140| 0009B8 stfd     DA690000   1     STFL      b3(gr9,0)=fp19
  142|                              CL.21:
  143| 0009BC bc       4096003C   1     BF        CL.24,cr5,0x4/eq,taken=50%(0,0)
  144| 0009C0 lfdx     7C6434AE   1     LFL       fp3=x3a(gr4,gr6,0)
  144| 0009C4 fcmpu    FE031000   1     CFL       cr4=fp3,fp2
  144| 0009C8 bc       4191001C   1     BT        CL.25,cr4,0x40/fgt,taken=50%(0,0)
  145| 0009CC stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  146| 0009D0 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  147| 0009D4 stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  148| 0009D8 stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  149| 0009DC stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
    0| 0009E0 b        48000018   1     B         CL.24,-1
  150|                              CL.25:
  151| 0009E4 stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  152| 0009E8 stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  153| 0009EC stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  154| 0009F0 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  155| 0009F4 stfd     DA690000   1     STFL      b3(gr9,0)=fp19
  157|                              CL.24:
    0| 0009F8 add      7D29A214   1     A         gr9=gr9,gr20
    0| 0009FC add      7D4AB214   1     A         gr10=gr10,gr22
    0| 000A00 add      7D6BC214   1     A         gr11=gr11,gr24
    0| 000A04 add      7D8CDA14   1     A         gr12=gr12,gr27
    0| 000A08 add      7FFAFA14   1     A         gr31=gr26,gr31
    0| 000A0C bc       4200FF3C   1     BCT       ctr=CL.47,taken=100%(100,0)
    0|                              CL.311:
  114| 000A10 bc       4189001C   1     BT        CL.305,cr2,0x40/fgt,taken=50%(0,0)
  115| 000A14 stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  116| 000A18 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  117| 000A1C stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  118| 000A20 stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  119| 000A24 stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
    0| 000A28 b        48000018   1     B         CL.306,-1
  120|                              CL.305:
  121| 000A2C stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  122| 000A30 stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  123| 000A34 stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  124| 000A38 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  125| 000A3C stfd     DA690000   1     STFL      b3(gr9,0)=fp19
  127|                              CL.306:
  114| 000A40 fcmpu    FD04E000   1     CFL       cr2=fp4,fp28
  128| 000A44 bc       409E003C   1     BF        CL.308,cr7,0x4/eq,taken=50%(0,0)
  129| 000A48 lfdx     7C6344AE   1     LFL       fp3=x2a(gr3,gr8,0)
  129| 000A4C fcmpu    FE03D800   1     CFL       cr4=fp3,fp27
  129| 000A50 bc       4191001C   1     BT        CL.307,cr4,0x40/fgt,taken=50%(0,0)
  130| 000A54 stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  131| 000A58 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  132| 000A5C stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  133| 000A60 stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  134| 000A64 stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
    0| 000A68 b        48000018   1     B         CL.308,-1
  135|                              CL.307:
  136| 000A6C stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  137| 000A70 stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  138| 000A74 stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  139| 000A78 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  140| 000A7C stfd     DA690000   1     STFL      b3(gr9,0)=fp19
  142|                              CL.308:
  143| 000A80 bc       4096003C   1     BF        CL.310,cr5,0x4/eq,taken=50%(0,0)
  144| 000A84 lfdx     7C6434AE   1     LFL       fp3=x3a(gr4,gr6,0)
  144| 000A88 fcmpu    FE031000   1     CFL       cr4=fp3,fp2
  144| 000A8C bc       4191001C   1     BT        CL.309,cr4,0x40/fgt,taken=50%(0,0)
  145| 000A90 stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  146| 000A94 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  147| 000A98 stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  148| 000A9C stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  149| 000AA0 stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
    0| 000AA4 b        48000018   1     B         CL.310,-1
  150|                              CL.309:
  151| 000AA8 stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  152| 000AAC stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  153| 000AB0 stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  154| 000AB4 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  155| 000AB8 stfd     DA690000   1     STFL      b3(gr9,0)=fp19
  157|                              CL.310:
    0| 000ABC add      7D29A214   1     A         gr9=gr9,gr20
    0| 000AC0 add      7D4AB214   1     A         gr10=gr10,gr22
    0| 000AC4 add      7D6BC214   1     A         gr11=gr11,gr24
    0| 000AC8 add      7D8CDA14   1     A         gr12=gr12,gr27
    0| 000ACC add      7FFAFA14   1     A         gr31=gr26,gr31
    0|                              CL.318:
  114| 000AD0 bc       4189001C   1     BT        CL.312,cr2,0x40/fgt,taken=50%(0,0)
  116| 000AD4 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  115| 000AD8 stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  117| 000ADC stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  118| 000AE0 stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  119| 000AE4 stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
    0| 000AE8 b        48000018   1     B         CL.313,-1
  120|                              CL.312:
  121| 000AEC stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  122| 000AF0 stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  123| 000AF4 stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  124| 000AF8 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  125| 000AFC stfd     DA690000   1     STFL      b3(gr9,0)=fp19
  127|                              CL.313:
  128| 000B00 bc       409E003C   1     BF        CL.315,cr7,0x4/eq,taken=50%(0,0)
  129| 000B04 lfdx     7C6344AE   1     LFL       fp3=x2a(gr3,gr8,0)
  129| 000B08 fcmpu    FE03D800   1     CFL       cr4=fp3,fp27
  129| 000B0C bc       4191001C   1     BT        CL.314,cr4,0x40/fgt,taken=50%(0,0)
  130| 000B10 stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  131| 000B14 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  132| 000B18 stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  133| 000B1C stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  134| 000B20 stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
    0| 000B24 b        48000018   1     B         CL.315,-1
  135|                              CL.314:
  136| 000B28 stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  137| 000B2C stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  138| 000B30 stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  139| 000B34 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  140| 000B38 stfd     DA690000   1     STFL      b3(gr9,0)=fp19
  142|                              CL.315:
  143| 000B3C bc       40960024   1     BF        CL.46,cr5,0x4/eq,taken=50%(0,0)
  144| 000B40 lfdx     7C6434AE   1     LFL       fp3=x3a(gr4,gr6,0)
  144| 000B44 fcmpu    FE031000   1     CFL       cr4=fp3,fp2
  144| 000B48 bc       4191013C   1     BT        CL.316,cr4,0x40/fgt,taken=50%(0,0)
  145| 000B4C stfd     D83F0000   1     STFL      e(gr31,0)=fp1
  146| 000B50 stfd     DB2C0000   1     STFL      d(gr12,0)=fp25
  147| 000B54 stfd     DBCB0000   1     STFL      b1(gr11,0)=fp30
  148| 000B58 stfd     DAEA0000   1     STFL      b2(gr10,0)=fp23
  149| 000B5C stfd     DAA90000   1     STFL      b3(gr9,0)=fp21
  158|                              CL.46:
  159| 000B60 addi     38A50001   1     AI        gr5=gr5,1
    0| 000B64 add      7E52EA14   1     A         gr18=gr18,gr29
  159| 000B68 cmpld    7E250040   1     CL8       cr4=gr5,gr0
    0| 000B6C add      7E31E214   1     A         gr17=gr17,gr28
    0| 000B70 add      7E10CA14   1     A         gr16=gr16,gr25
    0| 000B74 add      7DEFBA14   1     A         gr15=gr15,gr23
    0| 000B78 add      7DCEAA14   1     A         gr14=gr14,gr21
  159| 000B7C bc       4190FD88   1     BT        CL.45,cr4,0x8/llt,taken=80%(80,20)
  159|                              CL.44:
  160| 000B80 ld       E8A10480   1     L8        gr5=#SPILL5(gr1,1152)
    0| 000B84 ld       E8C104A8   1     L8        gr6=#SPILL10(gr1,1192)
    0| 000B88 ld       E8E104B0   1     L8        gr7=#SPILL11(gr1,1200)
  160| 000B8C ld       E9010460   1     L8        gr8=#SPILL1(gr1,1120)
    0| 000B90 ld       E92104A0   1     L8        gr9=#SPILL9(gr1,1184)
    0| 000B94 ld       E94104B8   1     L8        gr10=#SPILL12(gr1,1208)
    0| 000B98 ld       E9610498   1     L8        gr11=#SPILL8(gr1,1176)
    0| 000B9C ld       E98104C0   1     L8        gr12=#SPILL13(gr1,1216)
    0| 000BA0 ld       EBE10490   1     L8        gr31=#SPILL7(gr1,1168)
    0| 000BA4 ld       EA4104C8   1     L8        gr18=#SPILL14(gr1,1224)
    0| 000BA8 ld       EA210488   1     L8        gr17=#SPILL6(gr1,1160)
    0| 000BAC ld       EA0104D0   1     L8        gr16=#SPILL15(gr1,1232)
  160| 000BB0 addi     38A50001   1     AI        gr5=gr5,1
    0| 000BB4 add      7CE63A14   1     A         gr7=gr6,gr7
  160| 000BB8 std      F8A10480   1     ST8       #SPILL5(gr1,1152)=gr5
    0| 000BBC std      F8E104B0   1     ST8       #SPILL11(gr1,1200)=gr7
  160| 000BC0 cmpld    7E254040   1     CL8       cr4=gr5,gr8
    0| 000BC4 add      7D495214   1     A         gr10=gr9,gr10
    0| 000BC8 add      7D8B6214   1     A         gr12=gr11,gr12
    0| 000BCC std      F94104B8   1     ST8       #SPILL12(gr1,1208)=gr10
    0| 000BD0 std      F98104C0   1     ST8       #SPILL13(gr1,1216)=gr12
    0| 000BD4 add      7E52FA14   1     A         gr18=gr18,gr31
    0| 000BD8 add      7E108A14   1     A         gr16=gr16,gr17
    0| 000BDC std      FA4104C8   1     ST8       #SPILL14(gr1,1224)=gr18
    0| 000BE0 std      FA0104D0   1     ST8       #SPILL15(gr1,1232)=gr16
  160| 000BE4 bc       4190FCFC   1     BT        CL.43,cr4,0x8/llt,taken=80%(80,20)
  163|                              CL.84:
  163| 000BE8 ld       E80105F0   1     L8        gr0=#stack(gr1,1520)
  163| 000BEC lwa      E98105EA   1     L4A       gr12=#stack(gr1,1512)
  163| 000BF0 lfd      CBE105D8   1     LFL       fp31=#stack(gr1,1496)
  163| 000BF4 lfd      CBC105D0   1     LFL       fp30=#stack(gr1,1488)
  163| 000BF8 lfd      CBA105C8   1     LFL       fp29=#stack(gr1,1480)
  163| 000BFC lfd      CB8105C0   1     LFL       fp28=#stack(gr1,1472)
  163| 000C00 lfd      CB6105B8   1     LFL       fp27=#stack(gr1,1464)
  163| 000C04 lfd      CB4105B0   1     LFL       fp26=#stack(gr1,1456)
  163| 000C08 lfd      CB2105A8   1     LFL       fp25=#stack(gr1,1448)
  163| 000C0C lfd      CB0105A0   1     LFL       fp24=#stack(gr1,1440)
  163| 000C10 lfd      CAE10598   1     LFL       fp23=#stack(gr1,1432)
  163| 000C14 lfd      CAC10590   1     LFL       fp22=#stack(gr1,1424)
  163| 000C18 lfd      CAA10588   1     LFL       fp21=#stack(gr1,1416)
  163| 000C1C lfd      CA810580   1     LFL       fp20=#stack(gr1,1408)
  163| 000C20 lfd      CA610578   1     LFL       fp19=#stack(gr1,1400)
  163| 000C24 lfd      CA410570   1     LFL       fp18=#stack(gr1,1392)
  163| 000C28 addi     382105E0   1     AI        gr1=gr1,1504
  163| 000C2C mtspr    7C0803A6   1     LLR       lr=gr0
  163| 000C30 mtcrf    7D820120   1     MTCRF     cr2=gr12
  163| 000C34 mtcrf    7D808120   1     MTCRF     cr4=gr12
  163| 000C38 ld       E9C1FF00   1     L8        gr14=#stack(gr1,-256)
  163| 000C3C ld       E9E1FF08   1     L8        gr15=#stack(gr1,-248)
  163| 000C40 ld       EA01FF10   1     L8        gr16=#stack(gr1,-240)
  163| 000C44 ld       EA21FF18   1     L8        gr17=#stack(gr1,-232)
  163| 000C48 ld       EA41FF20   1     L8        gr18=#stack(gr1,-224)
  163| 000C4C ld       EA61FF28   1     L8        gr19=#stack(gr1,-216)
  163| 000C50 ld       EA81FF30   1     L8        gr20=#stack(gr1,-208)
  163| 000C54 ld       EAA1FF38   1     L8        gr21=#stack(gr1,-200)
  163| 000C58 ld       EAC1FF40   1     L8        gr22=#stack(gr1,-192)
  163| 000C5C ld       EAE1FF48   1     L8        gr23=#stack(gr1,-184)
  163| 000C60 ld       EB01FF50   1     L8        gr24=#stack(gr1,-176)
  163| 000C64 ld       EB21FF58   1     L8        gr25=#stack(gr1,-168)
  163| 000C68 ld       EB41FF60   1     L8        gr26=#stack(gr1,-160)
  163| 000C6C ld       EB61FF68   1     L8        gr27=#stack(gr1,-152)
  163| 000C70 ld       EB81FF70   1     L8        gr28=#stack(gr1,-144)
  163| 000C74 ld       EBA1FF78   1     L8        gr29=#stack(gr1,-136)
  163| 000C78 ld       EBC1FF80   1     L8        gr30=#stack(gr1,-128)
  163| 000C7C ld       EBE1FF88   1     L8        gr31=#stack(gr1,-120)
  163| 000C80 bclr     4E800020   1     BA        lr
  150|                              CL.316:
  151| 000C84 stfd     D81F0000   1     STFL      e(gr31,0)=fp0
  152| 000C88 stfd     DA4C0000   1     STFL      d(gr12,0)=fp18
  153| 000C8C stfd     DBAB0000   1     STFL      b1(gr11,0)=fp29
  154| 000C90 stfd     DA8A0000   1     STFL      b2(gr10,0)=fp20
  155| 000C94 stfd     DA690000   1     STFL      b3(gr9,0)=fp19
    0| 000C98 b        4BFFFEC8   1     B         CL.46,-1
    0|                              CL.180:
    0| 000C9C rldicr   78A71F24   1     SLL8      gr7=gr5,3
    0| 000CA0 or       7DC87378   1     LR        gr8=gr14
    0| 000CA4 or       7DE97B78   1     LR        gr9=gr15
    0| 000CA8 or       7E0A8378   1     LR        gr10=gr16
    0| 000CAC or       7E2B8B78   1     LR        gr11=gr17
    0| 000CB0 or       7E4C9378   1     LR        gr12=gr18
    0| 000CB4 mtspr    7FC903A6   1     LCTR      ctr=gr30
    0| 000CB8 ori      60210000   1     XNOP      
    0| 000CBC ori      60210000   1     XNOP      
  112|                              CL.132:
  128| 000CC0 bc       409E003C   1     BF        CL.136,cr7,0x4/eq,taken=50%(0,0)
  129| 000CC4 lfdx     7C633CAE   1     LFL       fp3=x2a(gr3,gr7,0)
  129| 000CC8 fcmpu    FE03D800   1     CFL       cr4=fp3,fp27
  129| 000CCC bc       4191001C   1     BT        CL.135,cr4,0x40/fgt,taken=50%(0,0)
  130| 000CD0 stfd     D82C0000   1     STFL      e(gr12,0)=fp1
  131| 000CD4 stfd     DB2B0000   1     STFL      d(gr11,0)=fp25
  132| 000CD8 stfd     DBCA0000   1     STFL      b1(gr10,0)=fp30
  133| 000CDC stfd     DAE90000   1     STFL      b2(gr9,0)=fp23
  134| 000CE0 stfd     DAA80000   1     STFL      b3(gr8,0)=fp21
    0| 000CE4 b        48000018   1     B         CL.136,-1
  135|                              CL.135:
  136| 000CE8 stfd     D80C0000   1     STFL      e(gr12,0)=fp0
  137| 000CEC stfd     DA4B0000   1     STFL      d(gr11,0)=fp18
  138| 000CF0 stfd     DBAA0000   1     STFL      b1(gr10,0)=fp29
  139| 000CF4 stfd     DA890000   1     STFL      b2(gr9,0)=fp20
  140| 000CF8 stfd     DA680000   1     STFL      b3(gr8,0)=fp19
  142|                              CL.136:
  143| 000CFC bc       4096003C   1     BF        CL.138,cr5,0x4/eq,taken=50%(0,0)
  144| 000D00 lfdx     7C6434AE   1     LFL       fp3=x3a(gr4,gr6,0)
  144| 000D04 fcmpu    FE031000   1     CFL       cr4=fp3,fp2
  144| 000D08 bc       4191001C   1     BT        CL.137,cr4,0x40/fgt,taken=50%(0,0)
  145| 000D0C stfd     D82C0000   1     STFL      e(gr12,0)=fp1
  146| 000D10 stfd     DB2B0000   1     STFL      d(gr11,0)=fp25
  147| 000D14 stfd     DBCA0000   1     STFL      b1(gr10,0)=fp30
  148| 000D18 stfd     DAE90000   1     STFL      b2(gr9,0)=fp23
  149| 000D1C stfd     DAA80000   1     STFL      b3(gr8,0)=fp21
    0| 000D20 b        48000018   1     B         CL.138,-1
  150|                              CL.137:
  151| 000D24 stfd     D80C0000   1     STFL      e(gr12,0)=fp0
  152| 000D28 stfd     DA4B0000   1     STFL      d(gr11,0)=fp18
  153| 000D2C stfd     DBAA0000   1     STFL      b1(gr10,0)=fp29
  154| 000D30 stfd     DA890000   1     STFL      b2(gr9,0)=fp20
  155| 000D34 stfd     DA680000   1     STFL      b3(gr8,0)=fp19
  157|                              CL.138:
    0| 000D38 add      7D08A214   1     A         gr8=gr8,gr20
    0| 000D3C add      7D29B214   1     A         gr9=gr9,gr22
    0| 000D40 add      7D4AC214   1     A         gr10=gr10,gr24
    0| 000D44 add      7D6BDA14   1     A         gr11=gr11,gr27
    0| 000D48 add      7D8CD214   1     A         gr12=gr12,gr26
    0| 000D4C bc       4200FF74   1     BCT       ctr=CL.132,taken=100%(100,0)
    0| 000D50 b        4BFFFE10   1     B         CL.46,-1
  110|                              CL.379:
  163| 000D54 ld       E98105F0   1     L8        gr12=#stack(gr1,1520)
  163| 000D58 lfd      CBE105D8   1     LFL       fp31=#stack(gr1,1496)
  163| 000D5C lfd      CBC105D0   1     LFL       fp30=#stack(gr1,1488)
  163| 000D60 lfd      CBA105C8   1     LFL       fp29=#stack(gr1,1480)
  163| 000D64 lfd      CB8105C0   1     LFL       fp28=#stack(gr1,1472)
  163| 000D68 lfd      CB6105B8   1     LFL       fp27=#stack(gr1,1464)
  163| 000D6C lfd      CB4105B0   1     LFL       fp26=#stack(gr1,1456)
  163| 000D70 lfd      CB2105A8   1     LFL       fp25=#stack(gr1,1448)
  163| 000D74 lfd      CB0105A0   1     LFL       fp24=#stack(gr1,1440)
  163| 000D78 lfd      CAE10598   1     LFL       fp23=#stack(gr1,1432)
  163| 000D7C lfd      CAC10590   1     LFL       fp22=#stack(gr1,1424)
  163| 000D80 lfd      CAA10588   1     LFL       fp21=#stack(gr1,1416)
  163| 000D84 lfd      CA810580   1     LFL       fp20=#stack(gr1,1408)
  163| 000D88 lfd      CA610578   1     LFL       fp19=#stack(gr1,1400)
  163| 000D8C lfd      CA410570   1     LFL       fp18=#stack(gr1,1392)
  163| 000D90 addi     382105E0   1     AI        gr1=gr1,1504
  163| 000D94 mtspr    7D8803A6   1     LLR       lr=gr12
  163| 000D98 ld       E9C1FF00   1     L8        gr14=#stack(gr1,-256)
  163| 000D9C ld       E9E1FF08   1     L8        gr15=#stack(gr1,-248)
  163| 000DA0 ld       EA01FF10   1     L8        gr16=#stack(gr1,-240)
  163| 000DA4 ld       EA21FF18   1     L8        gr17=#stack(gr1,-232)
  163| 000DA8 ld       EA41FF20   1     L8        gr18=#stack(gr1,-224)
  163| 000DAC ld       EA61FF28   1     L8        gr19=#stack(gr1,-216)
  163| 000DB0 ld       EA81FF30   1     L8        gr20=#stack(gr1,-208)
  163| 000DB4 ld       EAA1FF38   1     L8        gr21=#stack(gr1,-200)
  163| 000DB8 ld       EAC1FF40   1     L8        gr22=#stack(gr1,-192)
  163| 000DBC ld       EAE1FF48   1     L8        gr23=#stack(gr1,-184)
  163| 000DC0 ld       EB01FF50   1     L8        gr24=#stack(gr1,-176)
  163| 000DC4 ld       EB21FF58   1     L8        gr25=#stack(gr1,-168)
  163| 000DC8 ld       EB41FF60   1     L8        gr26=#stack(gr1,-160)
  163| 000DCC ld       EB61FF68   1     L8        gr27=#stack(gr1,-152)
  163| 000DD0 ld       EB81FF70   1     L8        gr28=#stack(gr1,-144)
  163| 000DD4 ld       EBA1FF78   1     L8        gr29=#stack(gr1,-136)
  163| 000DD8 ld       EBC1FF80   1     L8        gr30=#stack(gr1,-128)
  163| 000DDC ld       EBE1FF88   1     L8        gr31=#stack(gr1,-120)
  163| 000DE0 bclr     4E800020   1     BA        lr
  107|                              CL.173:
    0| 000DE4 mtspr    7C8903A6   1     LCTR      ctr=gr4
  107|                              CL.162:
  108| 000DE8 addi     38A50001   1     AI        gr5=gr5,1
  108| 000DEC cmpd     7CA52000   1     C8        cr1=gr5,gr4
  108| 000DF0 bc       4104FFF8   1     BCTT      ctr=CL.162,cr1,0x1/lt,taken=80%(80,20)
    0| 000DF4 b        4BFFF808   1     B         CL.71,-1
     |               Tag Table
     | 000DF8        00000000 00012203 8E120000 00000DF8
     |               Instruction count          894
     |               Straight-line exec time    902
     |               Constant Area
     | 000000        6D686473 686B7475 62652E66 39300000 7067656E 78313049
     | 000018        78323049 70306430 70316431 69646972 65637449 78333049
     | 000030        62315F30 62325F30 62315F31 62325F31 62335F30 62335F31
     | 000048        6D686473 686B7475 62652E66 39304942 43C80000 3F000000
     | 000060        3F800000 3F400000 00000000 BF800000 3E000000 49424D20
     | 000078        3FB99999 9999999A

 
 
>>>>> FILE TABLE SECTION <<<<<
 
 
                                       FILE CREATION        FROM
FILE NO   FILENAME                    DATE       TIME       FILE    LINE
     0    mhdshktube.f90              07/08/15   15:48:49
 
 
>>>>> COMPILATION EPILOGUE SECTION <<<<<
 
 
FORTRAN Summary of Diagnosed Conditions
 
TOTAL   UNRECOVERABLE  SEVERE       ERROR     WARNING    INFORMATIONAL
               (U)       (S)         (E)        (W)          (I)
    0           0         0           0          0            0
 
 
    Source records read.......................................     163
1501-510  Compilation successful for file mhdshktube.f90.
1501-543  Object file created.
